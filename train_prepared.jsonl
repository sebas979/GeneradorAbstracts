{"prompt":"Análisis de algoritmos criptográficos clásicos vs algoritmos cuánticos. ->","completion":" En este trabajo de investigación se realizó una comparación de los algoritmos criptográficos cuánticos vs clásicos con respecto a la seguridad en la obtención de la clave, en base a una revisión sistemática de donde se definió parámetros medibles de comparación, entre estos algoritmos como: la unidad estructural de la información, base de su seguridad, origen de la clave, tamaño de la clave, si el atacante copia la información, detección de intrusos y tecnología aplicada en el mercado, es de importancia conocer el algoritmo criptográfico más fuerte para la seguridad de la información debido a que la tecnología va en incremento y al mismo tiempo la información se convierte en un activo de gran valor a proteger ya que los hackers al interceptar información pueden realizar denegación de servicios, falta de integridad en datos, daños físicos a estructuras, robos millonarios de dólares e información. También se desarrolló el estudio técnico-económico para la de implementar un sistema cuántico en una infraestructura gubernamental del Consejo Nacional Electoral (CNE). Del estudio se determinó que los algoritmos criptográficos cuánticos son más apropiados para este propósito, esto se demostró con el método estadístico CHI cuadrado, para la comprobación de hipótesis. Se concluye que es técnicamente factible la propuesta de implementar criptografía cuántica con el algoritmo BB84 en la estructura nacional gubernamental CNE, con una inversión aproximada al 0.022% del gasto público de 2017. Se recomienda implementar la propuesta técnica económica planteada en la presente investigación para en la infraestructura de CNE en función de garantizar la seguridad de la información.In this research work, a comparison of quantum vs classical cryptographic algorithms was made with regard to the security in obtaining the key, it was based on a systematic review where measurable parameters of comparison were defined, among these algorithms as: the structural unit of information, base of its security, key origin, key size, if the attacker copies the information, intrusion detection and technology applied in the market, it is important to know the strongest cryptographic algorithm for the security of the information because the technology is increasing and at the same time the information becomes a valuable asset to protect since the hackers when intercepting information can perform denial of services, lack of data integrity, physical damage to structures, thefts of millions of dollars and information. Also the technical-economic study was developed to implement a quantum system in a governmental infrastructure of the National Electoral Council (NEC). From the study, it was determined that the quantum cryptographic algorithms are more appropriate for this purpose; this was demonstrated with the CHI square statistical method, for the verification of the hypothesis. It is concluded that the proposal to implement quantum cryptography with the BB84 algorithm in the national government structure NEC is technically feasible, with an approximate investment of 0.022% of public expenditure in 2017. It is recommended to implement the economic technical proposal raised in this research for the infrastructure of NEC in order to guarantee the security of the information.\n"}
{"prompt":"Modelo poblacional con algoritmos genéticos ->","completion":" Para el desarrollo de este trabajo, “MODELO POBLACIONAL CON ALGORITMOS GENÉTICOS”, he investigado la rama de la inteligencia artificial, como son los algoritmos genéticos. Primero presento en forma general los aspectos que envuelven los algoritmos genéticos, parto de la necesidad de optimizar, así como su historia y posibles aplicaciones y luego he cubierto detalladamente todo lo que pude investigar sobre la teoría de los algoritmos genéticos, sus fundamentos matemáticos, tipos de algoritmos genéticos, representación del mismo, partes y operadores más importantes de los algoritmos genéticos. Además se presenta una pequeñísima comparación con otros métodos de programación evolutiva, tales como los algoritmos genéticos paralelos, también llamados algoritmos meméticos, las redes neuronales, y los autómatas celulares. Además hago un estudio de los principales modelos de crecimiento poblacional, aplicados tanto a humanos como a animales y luego propongo un modelo basado en el paradigma de los algoritmos genéticos llevando a cabo una simulación poblacional utilizando una aplicación que he desarrollado completamente en el lenguaje de cuarta generación, Visual C++ 6.0. Finalmente, comparo entre mi modelo de crecimiento poblacional y los modelos convencionales, basándome en un subconjunto de datos de los que son generados por mi modelo, y realizar una predicción de los restantes.\n"}
{"prompt":"Algoritmos de minería de datos ->","completion":" El constante avance tecnológico ha permitido en todas las organizaciones recolectar y almacenar todo tipo de información, volúmenes crecientes de información quedan almacenadas, las cuales pueden brindar conocimiento.The ever advancing technology has allowed in all organizations collect and store all kinds of information, increasing volumes of information are stored, wich can provide knowledge.\n"}
{"prompt":"Algoritmos de búsqueda de patrones de texto ->","completion":" The purpose of this study was to determine the efficiency of the algorithms for searching text patterns: Brute Force, Boyer-Moore-Horspool, Knuth-Morris-Pratt and MapReduce, in order to establish which one or which showed the best behavior. To comply with its development it was necessary to use the methods: bibliographic, analytical and experimental design with analysis of variance with several factors. Through the bibliographic method it was possible to define algorithms to search for text patterns. Afterwards, the analysis of the algorithms was performed with the analytical method, where the following indicators were used: number of hits, resources to store and process (RAM) and the response time, then the algorithms were compiled on six different computers with the IDE (Integrated Development Environment): C-Free, Dev-C ++ and CodeBlocks. Finally, the efficiency and effectiveness of the algorithms were established through experimental design with analysis of variance with several factors. The procedure described above allowed us to establish that in the indicators: on number of hits and response time the Brute Force algorithm is more efficient, while IDE CodeBlocks presented better behavior with respect to the algorithms.El presente trabajo de titulación tuvo como propósito determinar la eficiencia de los algoritmos de búsqueda de patrones de textos: Fuerza Bruta, Boyer-Moore-Horspool, Knuth- Morris-Pratt y MapReduce, para establecer cuál o cuáles presentaban un mejor comportamiento. Para cumplir con el desarrollo del mismo fue necesario emplear los métodos: bibliográfico, analítico y diseño experimental con análisis de varianza con varios factores. A través del método bibliográfico se pudo definir los algoritmos de búsqueda de patrones de texto, posteriormente se realizó el análisis de los algoritmos con el método analítico donde se emplearon los siguientes indicadores: cantidad de aciertos, recursos para almacenar y procesar (memoria RAM) y tiempo de respuesta, luego se compilaron los algoritmos en seis computadoras diferentes con las IDE (Integrated Development Environment, por sus siglas en inglés): C-Free, Dev-C++ y CodeBlocks. Finalmente, se estableció la eficiencia y eficacia de los algoritmos por medio de diseño experimental con análisis de varianza con varios factores. El procedimiento antes descrito permitió establecer que en los indicadores: cantidad de aciertos y tiempo de respuesta el algoritmo Fuerza Bruta es más eficiente y eficaz, mientras que la IDE CodeBlocks presentó mejor comportamiento con respecto a los algoritmos.\n"}
{"prompt":"Algoritmo de Clustering dinámico para trayectoria GPS. ->","completion":" PDFHoy en d´ıa existen varios dispositivos tecnologicos en lo cual permiten extraer datos de ´ trayectorias GPS como son los Smartphone, GPS y sensores etc. Gracias a esta herramienta se puede almacenar en las bases de datos grandes volumenes de datos del recorrido vehicular ´ de taxis de diferentes pa´ıses como son: China, Ecuador y Brasil. Estos datos recolectados se podran evaluar y analizar los agrupamientos de clustering mediante el algoritmo din ´ amico ´ basado en densidad. Para analizar los datos GPS de las bases de datos se realizo modificaciones ´ al archivo csv para que el algoritmo dinamico pueda procesar los datos de las trayectorias GPS ´ y entender los agrupamientos de clustering que se forman dinamicamente. El algoritmo de ´ clustering dinamico basado en densidad trabajan con dos etapas que son: la etapa de distancia ´ y la etapa de densidad. En la etapa de distancia se usa la norma L1 o Manhattan que permite ver la distancia mas cercana de los clustering para agrupar los datos, en cambio en la etapa de ´ densidad se obtiene un resultado final donde se muestra los clustering. Entonces el algoritmo de clustering dinamico basado en densidad muestra los resultados finales del agrupamiento de ´ trayectorias GPS de manera satisfactoria.Nowadays there are several technological devices in which they allow to extract data from GPS trajectories such as Smartphone, GPS and sensors etc. Thanks to this tool, large volumes of data on the vehicular route of taxis from different countries such as: China, Ecuador and Brazil can be stored in the databases. These collected data can be evaluated and analyzed in the clustering groupings using the dynamic density-based algorithm. To analyze the GPS data from the databases, modifications were made to the csv file so that the dynamic algorithm can process the data of the GPS trajectories and understand the clustering groups that are dynamically formed. The density-based dynamic clustering algorithm works with two stages which are: the distance stage and the density stage. In the distance stage, the L1 or Manhattan norm is used, which allows to see the closest distance of the clusters to group the data, while in the density stage, a final result is obtained where the clusters are shown. Then the density-based dynamic clustering algorithm displays the final results of the GPS track clustering in a satisfactory way.\n"}
{"prompt":"Inteligencia Artificial, algoritmos y libertad de expresión ->","completion":" La Inteligencia Artificial puede presentarse como un aliado al momento de moderar contenidos violentos o de noticias aparentes, pero su utilizaciónsin intervención humana que contextualice y traduzca adecuadamente la expresión deja abierto el riesgo de que se genere censura previa En la actualidad esto se encuentra en debate dentro del ámbito internacional dado que, al carecer la Inteligencia Artificial de la capacidad para contextualizar lo que modera, se ésta presentando más como una herramienta de censura previa indiscriminada, que como una moderación en busca de proteger la libertad de expresión. Por ello luego de analizar la legislación internacional, informes de organismos internacionales y los términos y condiciones de Twitter y Facebook, sugerimos cinco propuesta tendientes a mejorar la moderación algorítmica de contenidos. En primer término proponemos que los Estados compatibilicen sus legislaciones internas respetando los estándares internacionales de libertad de expresión. También instamos a que desarrollenpolíticas públicas consistentes en implementar legislaciones protectoras de las condiciones laborales de supervisores humanos sobre las decisiones automatizadas de remoción de contenido. Por su parte, entendemos que las redes sociales deben presentar términos y condiciones claros y consistentes, adoptar políticas internas de transparencia y rendición de cuentas acerca de cómo opera la IA en la difusión y remoción de contenido en línea y, finalmente, deben realizar evaluaciones previas de impacto de su IA a los derechos humanos.\/\/ Artificial Intelligence can be presented as an ally when moderating violent content or apparent news, but its use without human intervention that contextualizes and adequately translates the expression leaves open the risk of prior censorship. At present this is under debate within the international arena given that, since Artificial Intelligence lacks the ability to contextualize what it moderates, it is presented more as a tool for indiscriminate prior censorship, than as a moderation in order to protect the freedom of expression. Therefore, after analyzing international legislation, reports from international organizations and the terms and conditions of Twitter and Facebook, we suggest five proposals aimed at improving algorithmic content moderation. In the first place, we propose that the States reconcile their internal laws while respecting international standards of freedom of expression. We also urge that they develop public policies consistent with implementing legislation that protects the working conditions of human supervisors on automated content removal decisions. For its part, we understand that social networks must present clear and consistent terms and conditions, adopt internal policies of transparency and accountability about how AI operates in the dissemination and removal of online content and, finally, they must carry out prior evaluations impact of your AI on human rights.\n"}
{"prompt":"Control PID digital algoritmo, diseño e implementación ->","completion":" Este artículo ofrece una guía procedimental de diseño e implementación de un controlador PID digital, dirigido a estudiantes que estén o hayan cursado las asignaturas Teoría de Control y Microprocesadores. Se plantea una metodología general, de tal manera que, pueda ser implementado en cualquier sistema microprocesado y lenguaje de programación, dando la libertad al alumno de mejorarlo y ejecutarlo de acuerdo a sus conveniencias técnicas y económicas. En la parte final se presenta una alternativa de implementación mediante la utilización de un computador personal y un microcontrolador.Cuencanúmero 23\n"}
{"prompt":"Algoritmo de asignación de canales para redes de comunicación inalámbricas con acceso oportunista basado en algoritmos genéticos ->","completion":" La creciente demanda de conectividad inalámbrica (e.g. estándar IEEE802.11) en zonas densamente pobladas, conlleva a una gran cantidad de dispositivos de acceso inalámbrico operando sin coordinación sobre un mismo espacio geográfico, lo que podría llevar a altos niveles de interferencia entre los dispositivos, ya que operan en bandas de uso compartido (i.e. ISM). Fruto de esto se podrían generar problemas de funcionamiento tales como la atenuación del nivel de señal de transmisión y consecuentemente un bajo rendimiento de la red. Una posible solución a estos problemas podría ser el uso oportunista de canales de bandas licenciadas que tienen algún tipo de disponibilidad temporal o espacial. En este contexto se propone un sistema que disminuya la congestión del espectro en la banda ISM, mediante el desarrollo de un mecanismo de asignación de canales con acceso oportunista al espectro subutilizado, empleando conocidas técnicas heurísticas para la asignación de recursos.GuayaquilIngeniero en Electrónica y Telecomunicaciones\n"}
{"prompt":"Algoritmo de Asignación de Canales para Redes de Comunicación Inalámbricas con Acceso Oportunista basado en Algoritmos Genéticos ->","completion":" La creciente demanda de conectividad inalámbrica (e.g. estándar IEEE802.11) en zonas densamente pobladas, conlleva a una gran cantidad de dispositivos de acceso inalámbrico operando sin coordinación sobre un mismo espacio geográfico, lo que podría llevar a altos niveles de interferencia entre los dispositivos, ya que operan en bandas de uso compartido (e.g.ISM). Fruto de esto se podrían generar problemas de funcionamiento tales como la atenuación del nivel de señal de transmisión y consecuentemente un bajo rendimiento de la red. Una posible solución a estos problemas podría ser el uso oportunista de canales de bandas licenciadas que tienen algún tipo de disponibilidad temporal o espacial. En este contexto se propone un sistema que disminuya la congestión del espectro en la banda ISM, mediante el desarrollo de un mecanismo de asignación de canales con acceso oportunista al espectro subutilizado, empleando conocidas técnicas heurísticas para la asignación de recursos como son los algoritmos genéticos, comúnmente utilizados en problemas de optimización complejos. Para esto será considerada la heterogeneidad del espectro y la priorización del uso de la banda ISM, con la finalidad de disminuir interferencias entre WLANs en un escenario urbano con diferentes densidades de dispositivos.The growing demand for wireless connectivity (e.g.IEEE802.11 standard) in densely populated, leading to have a large number of wireless devices operating without coordination on the same geographic space, which could lead to high levels of interference between devices, already operating in bands shared (e.g.ISM). The result of this operation could lead to problems such as attenuation of the transmitted signal level and consequently low network performance. One possible solution to these problems could be the opportunistic use of channels licensed bands that have some sort of temporal or spatial availability. In this context, a system to decrease congestion spectrum in the ISM band, by developing a mechanism for allocating channels with opportunistic access to underutilized spectrum, using techniques known heuristics for the allocation of resources such as genetic algorithms is proposed, commonly used in complex optimization problems. To this will be considered the heterogeneity of the spectrum and prioritizing the use of ISM band, in order to reduce interference between WLANs in an urban setting with different densities of devices.\n"}
{"prompt":"Procesamiento de datos de espectrometría de masas: Algoritmos y metodologías ->","completion":" RESUMENEl cáncer es una enfermedad asintomática en una etapa temprana y muy difícil de diagnosticar. En muchos de los casos no es percibida hasta que ya alcanza la metástasis. Es la segunda causa de muerte en el Ecuador a pesar de que los avances conseguidos en los últimos tiempos han sido revolucionarios, existen casos en donde el cáncer es detectado en su etapa terminal y aún no se ha encontrado ninguna metodología científica ni empírica que indique la presencia de esta patología. Las metodologías tradicionales de diagnóstico en cualquiera de sus tipos aciertan a un número relativamente bajo de casos en sus etapas tempranas, usando métodos invasivos con el riesgo de ser falsos positivos o falsos negativos. Centros de investigación y universidades han juntado esfuerzos para buscar alternativas de diagnóstico y tratamiento del cáncer usando métodos que permitan mejorar la eficacia del diagnóstico. En este trabajo se aborda un análisis de las diferentes etapas implicadas en el procesamiento de datos de muestras de tejidos cancerosos y saludables usando espectrometría de masas, usando plataformas computacionales, aplicados al mejoramiento de la calidad de las mediciones para posteriores aplicaciones de definición de biomarcadores.Palabras clave: Procesamiento de datos, espectrometría de masas, biomarcadores, plataformas computacionales, procesamiento digital de señales.ABSTRACTCancer is an asymptomatic disease at an early stage and very difficult to diagnose in many cases it is not perceived until it has already reached the stage of metastasis, spreading in other organs of the body. It is the second cause of death in Ecuador despite progress made in recent years have been revolutionary, there are cases where the cancer is detected in its terminal stage and still has not found any scientific or empirical methodology to indicate the presence of this pathology. Traditional methods of diagnosing cancer in any of its types are relatively ineffective in early stages, using invasive methods and at risk of being detected as false positive or false negative. Research centers and universities have joined forces to seek alternative diagnosis and treatment of cancer using methods to improve the efficiency of diagnosis and detection of cancer in its early stages. This paper discusses a group of algorithms and methodologies for processing data sets of mass spectrometry measurements of cancer and normal analyzed samples using computing platforms aimed at improving the quality of measurements for biomarkers definition applications.Keywords: Data processing, mass spectrometry, biomarkers, computing platforms, digital signal processing.\n"}
{"prompt":"Sistema de recomendación de contenidos audiovisuales: Algoritmo de inferencia semántica ->","completion":" RESUMENEste artículo presenta el análisis de un Algoritmo de Inferencia Semántica utilizado en un Sistema de Recomendación de Contenidos Audiovisuales en el contexto de la Televisión Digital. Los resultados obtenidos muestran que la inclusión de diferentes propiedades semánticas y sus combinaciones, influye directamente en la reducción del error absoluto promedio obtenido en la predicción de la calificación otorgada por un usuario a un ítem determinado. Además se ha determinado que la propiedad Actor tiene un impacto mayor con respecto a otras propiedades analizadas.Palabras clave: Televisión digital, sistemas de recomendación semánticos, Web semántica, propiedades semánticas, ontologías.ABSTRACTThis article presents the analysis of a Semantic Inference Algorithm used in an Audiovisual Content Recommender System in the domain of Digital Television. The obtained results show that the inclusion of distinct semantic properties and their combinations lead to a considerable reduction of the Mean Absolute Error (MAE) obtained for user rating prediction computation and that the semantic property Actor has the major influence over recommendation estimation.Keywords: Digital television, semantic recommender systems, Web semantic, semantic properties, ontologies.\n"}
{"prompt":"Filtrado de SPAM en SMS mediante algoritmos de aprendizaje automático ->","completion":" One of the most common forms of communication using mobile phones is through SMS, or short message service. Financial institutions, television companies and the telephone operators are examples of companies that takes advantage of this type of communication; however, this technology is not exempt from unwanted messages or SPAM. This article describes both the application of automatic learning algorithms for SPAM's filter and an experimenting with a data set of 5,574 SMS to evaluate the performance of models using techniques such as Logistic Regression, Super Vector Machine, KNN, Random Forest and AdaBoost to filter and predict unwanted messages.Una de las más comunes formas de comunicación a través de teléfonos móviles sigue siendo mediante SMS o servicio de mensajes cortos, por sus siglas en inglés. Las entidades financieras, televisoras y las propias operadoras de telefonía son ejemplos de compañías que aprovechan al máximo este tipo de comunicación, pero esta tecnología no está exenta de los molestosos mensajes no deseados o SPAM. El presente artículo describe la aplicación de algoritmos de aprendizaje automático como medio para la detección de SMS no deseados, y mediante la experimentación con un conjunto de datos de 5,574 mensajes de texto o SMS evalúa el rendimiento de modelos que utilizan técnicas como Regresión Logística, Super Vector Machine, KNN, RandomForest y AdaBoost para clasificar y predecir mensajes no deseados.\n"}
{"prompt":"Algoritmo de detección de bordes en imágenes con NIOS II ->","completion":" El proyecto consiste en la implementación de un algoritmo de procesamiento de imágenes utilizando la tarjeta de desarrollo DE2 ALTERA, basada en un dispositivo ALTERA CYCLONE II FPGA junto con memorias embebidas y un PROCESADOR NIOS II INTEGRADO, que ayudará en el objetivo, el cual es detectar el borde de una imagen. Para la realización del proyecto se aplican tres etapas. La primera etapa está basada en el almacenamiento de la imagen en la memoria SDRAM, la siguiente etapa se basa principalmente en leer los datos almacenados en la SDRAM y procesarlos correctamente para poder obtener su matriz, la cual contiene la información de la imagen, y una última etapa donde por medio de algoritmos implementados en código c, se procede a obtener la imagen resultante, la misma que mostrara solamente los bordes de la imagen originalmente almacenada.GuayaquilIngeniero en Electrónica y Telecomunicaciones\n"}
{"prompt":"Máquina calculadora basada en el algoritmo cordic con NIOS II ->","completion":" El presente documento contiene toda la información sobre el desarrollo e implementación de una máquina calculadora basada en el algoritmo cordic con NIOS II. La parte más importante en el desarrollo de esta máquina calculadora se centra en la aplicación de un IP core que permite el cálculo de las funciones seno y coseno de un valor de ángulo que es ingresado por el usuario. El IP core usa el algoritmo cordic para el cálculo de dichas funciones y por medio de la implementación de un bus avalon se interconecta a un procesador NIOS II integrado y a otros bloques embebidos en un dispositivos altera Cyclone II FPGA.GuayaquilIngeniero en Telemática\n"}
{"prompt":"Optimización de una cartera de inversiones utilizando algoritmos genéticos ->","completion":" El presente trabajo muestra la aplicación de la novedosa técnica de los algoritmos genéticos en la solución de un problema de optimización de una cartera de acciones. Aunque este problema ha sido comúnmente resuelto haciendo uso de los métodos tradicionales, bajo el enfoque de esta tesina se resuelve este problema explicando cada uno de los elementos que componen los algoritmos genéticos. El capítulo 1 muestra la naturaleza del problema con ejemplos concretos. El capítulo 2 presenta el modelo matemático del problema, en este capítulo se mencionan los conocidos términos de riesgo y rendimiento, los cuales son claves a la hora de entender y resolver este problema.GuayaquilIngenierìa en Estadística Informática\n"}
{"prompt":"Nuevas Tecnologías de computación ->","completion":" Todo nuestro desarrollo en comunicación se ha realizado sin intervención o apoyo gubernamental y, aún sin la asistencia de la UNESCO. Disponer de personal debidamente preparado a cargo del sistema para que la información sea creada, difundida y coordinada en forma efectiva dentro de cada institución. Sin esta coordinción, las computadoras y la comunicación interactiva se convierten en un juguete y un lujo del individuo que tuvo la osadía suficiente como para introducir tales elementos en la institución, pero pasan ser simplemente una pérdida en finanzas y creatividad de aquellos que no comparten ni participan en el uso de su pleno potencial.\n"}
{"prompt":"Mecánica de la computación ->","completion":" Licenciada en Ciencias de la Educación, Mención Informática\n"}
{"prompt":"Introducción a la computación cuántica ->","completion":" Las computadoras actuales están llegando al límite de la miniaturización y la frecuencia de pulsaciones de los relojes de cuarzo, pronto no podrán ser más rápidos. La computación cuántica es una gran promesa que podría permitirnos seguir construyendo computadoras más veloces........\n"}
{"prompt":"Inventarios de equipos de computación ->","completion":" InventarioEl presente informe trata la implementación de un sistema de inventario de equipos tecnológicos para la carrera informática de la Facultad de Filosofía, Letras y Ciencias de la educación de la Universidad de Guayaquil. Para recoger la información se procedió a aplicar las encuestas para investigar la influencia de las TIC´s en la carrera de informática. Los directivos y personal administrativo estuvieron muy de acuerdo en que la ventaja del uso de un inventario de equipos tecnológicos facilitaría la realización de trabajos laboriosos en un mínimo de tiempo. Las TIC´s son medios necesarios en la educación hoy día para transmitir valiosos conocimientos. Es por ello que esta investigación se da a conocer la aplicación de las tecnologías de la información a través un novedoso sistema de inventario, un medio para que el usuario a través de la tecnología pueda obtener información exacta y rápida de los bienes tecnológicos a su disposición, informados a través de la gran red, proporcionando mayor claridad a la hora de tomar decisiones, reduciendo la distancia geográfica y el tiempo. Cabe destacar que el impulso de implementar este medio de información a través de internet, le permitirá a la institución lograr un nivel organizacional óptimo, acorde a los grandes centros universitarios hoy en día a nivel nacionalThis report deals with the implementation of an inventory system of technological equipment for computer career at the Faculty of Philosophy, Letters and Science Education at the University of Guayaquil. To collect the information necessary to implement surveys to investigate the influence of TIC`s in the race computer. Managers and staff strongly agreed that the advantage of using an inventory of technical equipment would facilitate the realization of laborious work in minimal time. TIC`s are means in education today to transmit valuable knowledge. That is why this research discloses the application of information technology through a new inventory system, a means for the user through technology to get accurate and rapid information technology assets available, informed through the large network, providing greater clarity when making decisions, reducing the geographical distance and time. Note that the impulse to implement this means of information via the internet, will allow the institution optimal organizational level, according to the large university centers today nationwide.\n"}
{"prompt":"Web Site de aprendizaje interactivo de computación ->","completion":" En el capítulo primero de la primera parte hemos aclarado conceptos que se utilizan en los sistemas de comunicación aplicados a la educación, así como las formas de transmitir, guardar y entregar la información. Así pues abordamos tópicos como el libro, la impresión digital, discos compactos, texto e hipertexto, a medida que la tecnología ha ido avanzando analizamos también enciclopedias electrónicas y bases de conocimiento. Se presenta también un cuadro comparativo entre ventajas y desventajas entre las diferentes formas de presentar la información basado en criterios como: la actualidad en la información, disponibilidad, costo de adquisición, costo de mantenimiento, rapidez de acceso a la información, confiabilidad y facilidades que ayudan a la comprensión; llegando a la conclusión de que cada usuario, dependiendo de sus necesidades y recursos determinará la mejor opción de adquirir y suministrar conocimientos. La presentación de la información en páginas web o en el internet tiene muchas más ventajas.\n"}
{"prompt":"Web Site de aprendizaje interactivo de computación ->","completion":" Con los avances en la tecnología y facilidad para decifrar los mensajes en tinta invisible, se han inventado tintas que reaccionan con diferentes químicos. De esta manera hoy en día se revelan los mensajes ocultos cual si se revelaran películas de camára fotográfica en un laboratorio. En la actualidad el software esteganográfico es muy eficiente, puede esconder información en sonidos e imágenes.....\n"}
{"prompt":"Estudio químico, computacional y farmacológico de ibuprofeno ->","completion":" En esta investigación, se presenta un estudio teórico y experimental de la reacción de síntesis del ibuprofeno. El objetivo de esta disertación fue aplicar los conceptos espectroscópicos y termodinámicos dentro del marco de la Teoría del Funcional de la Densidad y compararlos con los datos experimentales. La investigación consta de tres etapas. La primera abarca el trabajo de laboratorio, el cual, incluye la síntesis experimental, la extracción del principio activo del producto comercial, y el análisis por espectroscopia de infrarrojos y ultravioleta\/visible de los productos obtenidos. En la segunda, se utilizó el programa de modelamiento electrónico estructural GAUSSIAN 03, donde se obtuvo una optimización molecular de todas las estructuras que intervienen en la reacción, las energías y las propiedades espectroscópicas (espectro IR, espectro UV\/VIS y espectro RMN). La tercera comprende una modelación de la interacción de la molécula de ibuprofeno con las enzimas Ciclooxigenasa 1, Ciclooxigenasa 2 y Citocromo P450 2C9 por medio de métodos de dinámica molecular. Para esto, se utilizó el programa Autodock 4 y Autodock VINA. En la síntesis experimental se obtuvo un rendimiento de la reacción de 1,37%. Se aislaron todos los productos intermedios y se obtuvieron los espectros que fueron comparados con los espectros computacionales. El producto final tuvo una correlación del 92% en comparación al estándar, lo que demuestra que se trata de ibuprofeno impuro. La extracción de muestras comerciales fue un éxito obteniéndose una correlación de espectros mayor al 98%, lo que indica que el principio activo es efectivamente ibuprofeno. En el estudio termodinámico se obtuvieron entalpías estándar de reacción negativas para cada paso de la reacción de síntesis, lo que demuestra que la síntesis de ibuprofeno es un proceso exotérmico. Los espectros computacionales fueron comparados con los obtenidos experimentalmente y los de la literatura, obteniéndose una excelente correlación. En el modelamiento molecular, los mejores resultados se lograron con Autodock VINA, por lo que éstos fueron comparados con resultados experimentales obtenidos mediante cristalografía de rayos X. Los métodos computacionales, tanto el acoplamiento molecular como el modelamiento electrónico estructural, son totalmente comparables con resultados obtenidos experimentalmente demostrando ser bastante exactos. Esto comprueba la aplicabilidad de estos métodos en el proceso de síntesis y diseño de nuevos fármacos.\n"}
{"prompt":"Computación en la Nube (Cloud Computing) ->","completion":" El trabajo que se presenta a continuación tiene como tema generador: Computación en la Nube, aplicado a micro, pequeñas o medianas empresas, mediante un plan de negocios administrado por AIM soluciones S.A., cuya constitución permitirá ofrecer servicios intangibles para infraestructura tecnológica , ni para desarrollo de software por parte de los usuarios; puesto que, la disponibilidad de los recursos será su responsabilidad, gestionada con los respectivos proveedores, necesitando el usuario únicamente acceso a internet.GuayaquilMagíster Ejecutiva en Administración de Empresas\n"}
{"prompt":"Diseño de un paquete grafico computacional ->","completion":" TRATA SOBRE LA PROGRAMACION COMO UNA SALIDA A LA BUSQUEDA DE SOLUCIONES DE PROBLEMAS, CON LA UNICA FINALIDAD DE PRESTAR UNA AYUDA INMEDIATA A USUARIOS QUE NECESITAN DE RAPIDOS RESULTADOS. UNA DE LAS NECESIDADES QUE SE LES PRESENTAN A TODO USUARIO EN SU INTERACCION CON LA MAQUINA ES EL DE CONTAR CON UN SISTEMA QUE BRINDE LAS CARACTERISTICAS DE UNA DISCIPLINA GRAFICA, Y ESTA ES PRECISAMENTE LA FINALIDAD DEL PROYECTO A REALIZAR CONSTITUIDO POR EL DISEÑO DE UN PAQUETE GRAFICO COMPUTACIONAL QUE A PESAR DE LA EXISTENCIA DE OTROS PAQUETES SE CARACTERIZARA POR EL USO DE FUNDAMENTOS EMPLEADOS EN LA PROGRAMACION DE GRAFICOS Y LA INTERVENCION DE HERRAMIENTAS MATEMATICAS\n"}
{"prompt":"Técnicas de diseño vial para aplicación computacional ->","completion":" Este es un trabajo de investigaciOn que nos permite dibujar en AutoCad el trazado Horizontal de una carretera, desarrollando el Proyecto Vertical de la misma poniendo en uso los parámetros de diseño dictadas P01 el MOP, asi como el calculo del movimiento de tierras que se va a ocasionar una vez que se haga efectivo en el terreno este estud 10.This is a research work that allows us to draw in AutoCad the Horizontal layout of a highway, developing the Vertical Project of the same putting in use the design parameters dictated P01 the MOP, as well as the calculation of the movement of lands that is going to Cause once this field is made effective on the ground 10.\n"}
{"prompt":"Tecnologías de computación y Tercer mundo ->","completion":" Nuestro mundo ha sido modificado por un chip, un elemento diminuto de apenas cinco milímetros cuadrados con circuitos de conmutación altamente integrados y que ya para 1985 ponía a disposición del microprocesador más de un millón de unidades lógicas dentro de fracciones de segundo, haciendo posibles nuevos sistemas de comunicación.\n"}
{"prompt":"Estrategias didácticas en el aprendizaje de computación ->","completion":" \"El tema surge por la necesidad que se observó en la Unidad Educativa Básica Mons. Juan Wiesneth donde nos dimos cuenta por medio de una encuesta que el problema más significativo de la institución es la falta de equipos de computación suficiente para el aprendizaje de los estudiantes por lo cual los estudiantes no tienen un conocimientos idóneo sobre la materia, por esta razón es necesario la utilización de material didáctico para mejorar las clases y hacerlas más entretenidas. El material didáctico es el soporte que nos garantiza que el estudiante pueda captar el tema que se está tratando en clase y permite que se llegue a él con más facilidad, y así desarrollen sus actitudes y destrezas y a su vez lograr que sus conocimientos se fortalezcan de una manera sencilla y dinámica. En los docentes las estrategias didácticas son de gran ayuda para desarrollar una buena clase porque no es suficiente planificar sino además utilizar estrategias que puedan llegar al estudiante para que de esa forma cambie la enseñanza tradicional que era; llegar, explicar el tema y no permitir que el estudiante participe y de su propio criterio sobre el tema y así pueda desarrollar sus conocimientos pues que el docente ya no es transmisor del conocimiento si no facilitador del aprendizaje. El crecimiento acelerado de los avances tecnológicos ha traído consigo el planteamiento de exigencias por la sociedad actual, por esta razón debemos formar estudiantes de calidad que puedan desarrollarse de forma práctica en su vida profesional, lo que implica la necesidad de un cambio en la educación. Para la utilización de las estrategias didácticas no existe una norma establecida, esta dependerá del entorno en el cual se desarrolle la clase y el tema que se va a tratar, el docente debe seleccionar el material adecuado con el que se va a trabajar, este debe de ser novedoso interesante y creativo ya que la correcta utilización de estos materiales ayudara a que el estudiante aprenda de una manera correcta.\"\n"}
{"prompt":"Software educativo en el aprendizaje de Computación ->","completion":" El uso de las herramientas didácticas en la enseñanza aprendizaje de computación, permite a los alumnos desarrollar capacidades intelectuales. El maestro debe poseer una amplia gama de herramientas didácticas para la estructuración de su clase además manejar diferentes estrategias para que de esta manera los estudiantes desarrollen sus conocimientos y les permitan hacerlas más sencillas sin olvidar las diferentes técnicas que le faciliten crear un ambiente apropiado para la enseñanza. El aprendizaje de esta herramienta va a permitir ampliar el conocimiento a los estudiantes, puesto le va a facilitar su aprendizaje mediante la interacción de ambos durante su desarrollo. Enseñar es un acto comunicativo, en el cual el docente pone de manifiesto sus conocimientos, en gran parte los conocimientos adquiridos por los estudiantes depende de la práctica que se tengan, el éxito va a ser acorde a la continuidad que tengan desarrollando sus actividades escolares. La aplicación de herramientas tecnológicas es un incentivo didáctico muy importante para los estudiantes, ya que existen muchos los factores que imposibilitan a los alumnos aprender computación en la actualidad. Si los alumnos se divierten en el computador les ayudará a aprender disfrutando, los que hará que se incrementen el desarrollo de sus capacidades, además permite que los acontecimientos que el docente enseña se aprendan placenteramente. Por lo tanto los estudiantes ameritan una relación educativa integral donde intervengan todos los factores internos y externos relacionados en el desarrollo con el aprendizaje. Son los maestros quienes deben emplear nuevas estrategias metodológicas para mejorar el sistema de estudio, utilizando herramientas didácticas, teniendo en cuenta el valor didáctico que deben tener. El impacto social de las tecnologías de la información está tocando mucho las escuelas, propiciando modificaciones en las formas tradicionales de enseñar y aprender, despertando el interés y el gusto por el r aprendizaje de la asignatura.\n"}
{"prompt":"Tecnologías de computación y Tercer Mundo ->","completion":" Este número aborda la comunicación desde las tres interpretaciones más importantes: la tradicionalista, la militar y mercantilista y el arte popular tan inestable, cuestionado y cambiante. Canclini cuestiona la compartamentalización de cultura: popular y de medios y esboza los problemas que plantea la tradicional miopía de no reconocer la universalización : ¿Re-intelección de los medios? apuntes sobre un libro de los Mattelart, ¿\"Ética\"\" o \"\"Deontología\"\" de la comunicación social?, El lenguaje del vestido y de la fiesta,Talleres de cultura Popular en Santiago de Chile, El dilema del arte popular en Bolivia,¿Sobrevivirán las artesanías aborígenes argentinas?, Los tejedores de El Tintorero, Tecnologías de computación y Tercer Mundo, La cobertura del terremoto en México, La comunicación como quehacer y como problema, la comunicación planificada sirve al desarrollo\"\n"}
{"prompt":"?Existe esperanza para el modelaje computacional del dolor? ->","completion":" El conocimiento insuficiente que se tiene en relaci?n a los mecanismos involucrados en la experiencia del dolor, especialmente si la misma se manifiesta como una patolog?a, demanda un abordaje interdisciplinario que incluye el uso de modelos matem?tico- computacionales. Algunas ventajas de este tipo de aproximaciones radican en su car?cter no invasivo y en su capacidad para permitir, tanto la demostraci?n de hip?tesis y teor?as, como la formulaci?n de otras nuevas. No obstante, la utilizaci?n de modelos computacionales para el estudio del dolor (MCED) parece ser muy limitada en comparaci?n con la que se le ha dado a aproximaciones m?s tradicionales, lo que no se corresponde con el enfoque hol?stico que se requiere para abordar la naturaleza multidimensional del dolor. En el presente art?culo, se revisan y discuten las diferentes estrategias que se han empleado en la construcci?n de MCED, con el fin de identificar algunas de las tendencias que, posiblemente, no han permitido un mayor uso de los mismos en la pr?ctica cl?nica y proponer, eventualmente, una serie de recomendaciones que podr?an resultar de utilidad para contrarrestar tales tendencias.http:\/\/erevistas.saber.ula.ve\/index.php\/actabioclinica\/article\/view\/7386\n"}
{"prompt":"Guía para evaluar el desempeño de redes de computación ->","completion":" Guía para evaluar el desempeño de redes de computación, consta de cuatro capítulos en los que se indican de manera detallada El primer capítulo contiene información general acerca de redes de computación, evaluación del desempeño, tipos de servidores y se realiza un análisis de varias herramientas disponibles para la evaluación en las plataformas Windows y Unix. Esto nos sirve como preámbulo para entender de mejor manera los componentes que intervienen durante toda la evaluación En el segundo capítulo se realiza un análisis profundo del medio en el que se va a realizar la evaluación, se define el universo de compañías dedicadas a la gestión de TI y de éstas se toma una muestra estadística. En las compañías de la muestra se realiza una encuesta dirigida al encargado del departamento de TI con el fin de obtener datos referenciales en cuanto a las estructuras de la redes y verificar la viabilidad del proyecto. Con este análisis se pueda corroborar que todas las empresas encuetadas tenían la necesidad de una guía para realizar una evaluación precisa del desempeño de su red En el tercer capítulo se desarrolla la guía como tal, se indica detalladamente todos y cada uno de los pasos y requerimientos que el evaluador debe tomar en cuenta para realizar la evaluación Se definen los productos de la evaluación que serán entregados a la administración de la empresa como son la Carta Final, el Informe Técnico y el Informe Ejecutivo. Una Carta de Respuesta por parte de la administración de la empresa y de los encargados del área de TI es necesaria para una retroalimentación por parte de los evaluadores\n"}
{"prompt":"Control de Inventario en la Corporación Tecnológica Computacional ->","completion":" Since ancient times the ancestors kept large quantities of food for times of drought is where the inventory arises, these ensured the subsistence in times of scarcity with the storage of goods and food calling this the existence of inventory. Therefore, today the control in the companies in the purchases and sales of the goods or services they provide is where the importance of proper handling of their inventories comes from, where the company will maintain an adequate accounting control and thus At the end of each period obtain a reliable status of the economic situation of the company. The inventory is part of the current asset that is ready for sale, that is, all the merchandise that the company owns and that is in stock valued at the cost of acquisition, for sale or productive activities.Desde tiempos de la antigüedad los antepasados guardaban grandes cantidades de alimentos para tiempos de sequía es donde surge el inventario, estos aseguraban la subsistencia en épocas de escasez con el almacenamiento de bienes y alimentos llamando a esto la existencia de inventario. Por lo cual hoy en la actualidad el control en las empresas en las compras y ventas de los bienes o servicios que brinden es de donde proviene la importancia de llevar un manejo adecuado de sus inventarios, en donde la empresa mantendrá un control contable oportuno y así al final de cada periodo obtener un estado confiable de la situación económica de la empresa. El inventario forma parte del activo corriente que está dispuesto para la venta, es decir, toda la mercadería que posee la empresa y que está en almacén valorada al costo de adquisición, para la venta o actividades productivas.\n"}
{"prompt":"Programación de los medios ->","completion":" El 75 por ciento de la programación latinoamericana va dirigida hacia el entretenimiento. Los programas educativo-culturales apenas llegan al 5 por ciento. Pero están las telenovelas.\n"}
{"prompt":"Programación de los medios ->","completion":" El 75 por ciento de la programación latinoamericana va dirigida hacia el entretenimiento y tiene procedencia en 54 por ciento del extranjero solo el 20 por ciento es producción nacional. Los programas educativo-culturales apenas llegan al 5 por ciento. Lo que más se produce y difunde son las telenovelas.\n"}
{"prompt":"Programación en la nube como alternativa a la programación de aplicaciones web tradicionales ->","completion":" Este documento analiza cómo es posible la implementación de una nueva infraestructura de desarrollo web, la programación en la nube, mediante el desarrollo de un caso de estudio, el cual se encuentra optimizado para funcionar tanto en un entorno de servidor como en un entorno de desarrollo en la nube, para responder a una posible alternativa de desarrollo más económica a la tradicional. Para responder el tiempo de respuesta de ambos entornos de desarrollo se propone la metodología desarrollada por Papadopolous, optimizada para poder encapsular el entorno de pruebas y comparar el rendimiento en ambas tecnologías. En el capítulo 1 se describe la problemática a resolver durante el presente trabajo, así como bases teóricas que sustentan una posible solución, misma que se resume como objetivo principal del documento. En el capítulo 2 se sienta las bases teóricas que describen el contexto actual sobre el desarrollo web, así como la metodología a utilizar para proponer una solución al problema. En el capítulo 3 se aplica la metodología descrita en capitulo previo, dentro del cual se realiza el desarrollo de la aplicación. Luego, en el capítulo 4 y con toda la metodología aplicada, se analiza los resultados obtenidos durante la experimentación realizada en el capítulo 3. Finalmente, en el capítulo 5 se desglosan tanto las conclusiones como recomendaciones relacionadas al documento y el resultado obtenido..Trabajo de investigación.\n"}
{"prompt":"Programación extrema: alcances y aplicación ->","completion":" Programación Extrema o XP (por sus siglas en inglés) es una metodología de desarrollo de Software basada en valores y prácticas orientadas a aumentar la productividad de los equipos desarrolladores con énfasis a la adaptabilidad a los cambios de requerimientos de clientes y usuarios finales antes que a la previsibilidad, aduciendo que es imposible prever todo antes de empezar a codificar. Básicamente, la idea de XP consiste en trabajar estrechamente junto al cliente, desarrollando pequeñas unidades funcionales en ciclos cortos de desarrollo llamados iteraciones, realizando los diseños y la planificación sobre la marcha sin invertir gran cantidad de tiempo en este aspecto y poniendo más interés en desarrollar código óptimo y sencillo, probado continuamente a través de pruebas unitarias y funcionales continuas. La metodología consiste de un conjunto de valores, principios y prácticas que sirven de directrices para guiar a los equipos de desarrollo a un ambiente agradable y eficiente al momento de trabajar con programación extrema.\n"}
{"prompt":"Ejercicios de Programación en JAVA ->","completion":" EJERCICIOS DE PROGRAMACIÓN EN JAVA, CON TEMAS COMO ORIENTACIÓN A OBJETOS, HERENCIA, POLIMORFISMO, LISTAS, CLASES FINALES\n"}
{"prompt":"Programación de Arrays En C++ ->","completion":" En el presente artículo se presenta una breve base teórica de la programación empleando el lenguaje C++, enfocándose en el desarrollo del tema de arrays y sus métodos de ordenación. Añadiendo temas necesarios referentes a la programación con el lenguaje C++, ya que estos temas van a ser necesarios para poder dar solución al problema planteado, de dicho problema se explicará el análisis, fragmentos del cogido empleado para brindar una solución al ejercicio. Una vez terminado el ejercicio se ha de comenzar con el análisis de los IDES´S que se emplearan para el desarrollo del programa, añadiendo un análisis sobre los métodos más utilizados en el ordenamiento de datos de un arrays, tomando en cuenta investigaciones posteriores se le determinara una ponderación a cada método para lograr validar cuál de ellos es el más empleado, todo esto se realizar a través de unas tablas porcentuales de la cual se tomaran los datos obtenidos y se determinara las conclusiones sobre estos parámetros a analizar.\n"}
{"prompt":"Fundamentos de programación para ciencias e ingeniería ->","completion":" El desarrollo de los dispositivos computacionales con un alto rendimiento en términos de memoria, capacidad de almacenamiento y velocidad de procesamiento de la información, ha desafiado inminentemente a los desarrolladores de software. La actual generación de programadores se ve en la necesidad de implementar aplicaciones que sean capaces de responder a los requerimientos del usuario, aprovechando los recursos tecnológicos disponibles. La actual demanda de programas pretende satisfacer un sin número de campos profesionales como los negocios, la educación, el sector social, entre otros. Particularmente, dedicaremos nuestra atención a los programas que tienen principales aplicaciones en Ciencias e Ingeniería. Este tipo de programas han emergido como una poderosa herramienta en la investigación y desarrollo de nueva tecnología. Permiten la evaluación de fórmulas complejas con una alta precisión. Además, estos programas interactúan con un conjunto de datos provenientes de sensores, y que son procesados a velocidades significativas. Este libro propone revisar los fundamentos necesarios para la elaboración de programas en una plataforma de programación conocida como MATLAB. Este entorno de programación ofrece la posibilidad de introducir al estudiante en el desarrollo de programación secuencial, programación estructurada y programación modular.\n"}
{"prompt":"Ejercicios de Programación en Consola de C# ->","completion":" Ambato (Pontificia Univertidad Católica del Ecuador) - (Universidad Técnica )Pontificia Univertidad Católica del Ecuador\n"}
{"prompt":"Programacion de obras del Sistema Sur ->","completion":" El estudio de esta tesis comprende la proyección de la demanda de energía y potencia eléctrica para el período comprendido entre los años 1973-1990 y, la programación de las obras necesarias que se deberán desarrollar para alimentar el área abarcada por el Sistema Eléctrico Sur.GuayaquilIngeniero Eléctrico\n"}
{"prompt":"Técnicas de programación en ambientes clientes-servidor ->","completion":" Trata sobre un esquema de trabajo de comunicación (cliente-servidor) ya que las que las redes de computadoras ofrecen ha evolucionado lentamente comparado con la demanda de los servicios esperados. Requiere mecanismos de transporte de requerimientos\/respuestas como lo son los siguientes: Netbios Sockets de TCP\/IP named-pipes y RPC. Con los 3 primeros mecanismos mencionados se necesita conocer con que estacion a conectarse en cambio con el último que es RPC se elimina esta limitación accesando a un servicio de directorio.GuayaquilIngeniero en Computación\n"}
{"prompt":"Breve introducción a la programación estructurada ->","completion":" El gran desarrollo tecnológico de los últimos años ha hecho posible la fabricación de computadoras y, en general, de equipos electrónicos sofisticados de gran capacidad de acción y de costos cada vez menores. En el campo de la computación digital, es un hecho cierto que con los nuevos adelantos tecnológicos se están produciendo equipos con capacidad de procesamiento notable, mayor velocidad, poco peso y volumen y costos que disminuyen dramáticamente.\n"}
{"prompt":"Tecnicas de programación en ambientes clientes-servidor ->","completion":" Trata sobre un esquema de trabajo de comunicacion (cliente-servidor) ya que las que las redes de computadoras ofrecen ha evolucionado lentamente comparado con la demanda de los servicios esperados. Requiere mecanismos de transporte de requerimientos\/respuestas como lo son los siguientes: NETBIOS SOCKETS DE TCP\/IP NAMED-PIPES Y RPC. Con los 03 primeros mecanismos mencionados se necesita conocer con que estacion a conectarse en cambio con el ultimo que es RPC se elimina esta limitacion accesando a un servicio de directorio\n"}
{"prompt":"Tutor de multimedia de programación estructurada I ->","completion":" AprendizajeEl presente Proyecto Educativo Titulado: “Tutor Multimedia de Programación Estructurada I”, propuesta: “elaboración de un cd puesto en línea (Aula Virtual) cual forma un medio de aprendizaje educativo multimedia diseñado como material de apoyo para los alumnos de esta asignatura. Construido en formato flash, el mismo pretende acercar a los estudiantes el contenido de esta disciplina, que ha demostrado conllevar cierta dificultad. Por este motivo, el programa estructura el contenido empleando una serie de recursos didácticos característicos de los materiales multimedia como son el uso de hipertexto, la interactividad, una interfaz amigable y sencilla y la integración de los temas con materiales de apoyo en distintos formatos (texto, gráficas, videos, etc.). En este artículo se realiza una descripción de los diferentes contenidos del CD para explicando y analizando sus posibilidades de uso, tomando como referencia los conceptos clave sobre las potencialidades didácticas de los materiales multimedia, cuya introducción ha superado en gran medida las expectativas más optimistas de facilidad del aprendizaje que hace unos años atrás. Es por ello el presente proyecto forma una herramienta de consolidación de los conocimientos previos adquiridos de fundamentos de programación por el estudiante e inclusive fundamentan los nuevos conocimientos a partir del uso del lenguaje de C++, por lo consiguiente esta representa una guía de fortalecimiento de la educación profesional ya que representa una alternativa audiovisual que se toma como sinónimo de fuente de información, investigación y recurso didáctico o herramienta de enseñanza-aprendizaje de la materia. Con lo que se puede llegar a la conclusión que este trabajo es una opción valiosa de aprendizaje, gracias a la investigación realizada y con la ayuda de aportaciones personales, sirvió como información de apoyo y motivación para la enseñanza - aprendizaje de los estudiantes ya que después de esto entendieron la importancia de adquirir y conservar buenas bases que le ayudarán a tener permanentemente el uso del lenguaje de programación\n"}
{"prompt":"PROGRAMACION DE SOFTWARE DE ACCESO BIOMETRICO ->","completion":" AdobeLa aplicación BioSystem fue desarrollada para tener un control de la asistencia de los empleados en una empresa, esta aplicación fue diseñada usando una arquitectura cliente servidor a través de un servidor de base de datos postgreSQL, un servidor de aplicación Web como el Apache, mediante el uso de Java como lenguaje de programación y de un gestor de reportes como el JasperReports. Para acceder a la información es necesario ingresar el código del empleado con su respectiva clave, a través de un Web Browser Gracias a la asignación de perfiles a los usuarios se puede controlar el tipo de accesibilidad a las secciones de la aplicación, dándole así control sobre el trato y procesamiento de la información. Posibilitando la capacidad de enviar reportes en formato PDF o mediante un documento Excel, les damos disponibilidad de la información de los empleados a las personas que requieran de tal. El propósito principal de esta aplicación es el de proporcionar a las empresas la posibilidad de administrar las eventualidades producidas en la asistencias de sus empleados, así como el control en el acceso a las áreas autorizadas a estos, y poder tomar correctivos de ser necesario para solucionar estas situaciones.The BioSystem application was developed to have a control attendance of employees in a company, this application was designed using a client server architecture through a database server postgreSQL data, Web application server such as Apache, by the use of Java as a programming language and a transmission reports as JasperReports. To access the information you need to enter the code employee with their respective key, through a Web Browser Thanks to the assignment of profiles users can control the type accessibility to the sections of the application, giving you control over the treatment and processing of information. Enabling the ability to send reports in PDF format or by Excel document, give them availability of information employed persons requiring such. The main purpose of this application is to provide businesses the ability to manage eventualities produced in assists of its employees, as well as control access to areas authorized to these, and to take corrective measures if necessary to address these situations.\n"}
{"prompt":"Técnicas programación neurolingüísticas en el aprendizaje colaborativo. ->","completion":" El presente trabajo de investigación nace de la importancia de fomentar, el aprendizaje colaborativo en los estudiantes de Primer año de bachillerato de la Unidad Educativa “Francisco Huerta Rendón”, con la aplicación de las Técnicas programación neurolingüísticas, ya que es considerada como una herramienta útil para el desarrollo académico del educando. Para ello, fue necesario aplicar una encuesta a los docentes con el fin de obtener una información mucho más relevante en cuanto a la problemática identificada, sus posibles causantes como también la solución que se le podría generar. Así mismo, se aplicó una entrevista al rector de la institución con el mismo objetivo. Con ello, se llegó a la conclusión del beneficio que podría causar la aplicación de las técnicas de programación neurolingüística para el mejoramiento del aprendizaje colaborativo en los estudiantes, donde se pretende diseñar talleres educativos dirigido a los docentes con la finalidad de acabar con la problemática que se encuentra afectando el proceso de aprendizaje de los estudiantes.\n"}
{"prompt":"Programación neurolingüística (PNL), neuromarketing y placebo ->","completion":" Es imposible desconocer el impacto del consumo de bienes y servicios en la sociedad contemporánea. En Ecuador, el Índice de Confianza del Consumidor (ICC), que mide el grado de optimismo que los consumidores sienten sobre el estado general de la economía y sobre su situación financiera personal, para el mes de septiembre de 2014 se encuentra en 45,2 puntos (Banco Central del Ecuador, 2014). Del reporte se aprecia que la confianza del hogar es inferior a medida que la edad del jefe del hogar aumenta. Es decir, el ICC para los hoga- res cuyos jefes son menores a 30 años fue de 48,1 puntos, mientras que para aquellos hogares cuyo jefe tiene más de 65 años fue de 43,8 (Banco Central del Ecuador, 2014). ¿La gran pregunta es en qué se basa el cere- bro para tomar una decisión sobre un consumo? El neuromarketing es un campo emergente que representa un puente entre el estudio del comportamiento del consumidor y las neurociencias cognitivas. El neuromarketing emplea métodos de vanguardia desarrollados por la neurociencia para explorar la mente sin que se requiera una participación consciente por parte del sujeto investigado (Lee, Broderick, y Chamberlain, 2007).\n"}
{"prompt":"Enriquecimiento semántico de guías de programación electrónica ->","completion":" Los grandes avances en el ámbito tecnológico y especialmente en el campo de la Televisión Digital han generado nuevas líneas de investigación, y esta tesis es un ejemplo de ello. Este trabajo presenta una forma de ayudar a los usuarios de televisión digital a obtener información de forma rápida sobre la programación que observan y es de su interés. Sin embargo, el problema actual se debe a que los difusores de televisión digital no siempre aportan la información suficiente de la programación a sus usuarios, lo que ocasiona que los usuarios recurran a otras fuentes de información perdiendo tiempo valioso. Este trabajo describe una solución a este problema al integrar la televisión y la gran cantidad de información disponible en internet mediante el uso de tecnologías semánticas con el fin de que los televidentes obtengan información completa de los programas que ellos desean conocer. Específicamente esta tesis busca enriquecer o suministrar información adicional a los programas transmitidos por los diferentes canales de televisión utilizando métodos y técnicas del campo de la web semántica con el objetivo de recopilar información útil desde repositorios ontológicos y no ontológicos. El resultado final será una base de conocimiento que contenga información detallada de la programación que emite un canal de televisión digital.The great developments in the technological area and especially in the area of the Digital Television have generated new researching lines, and this thesis is an example of that. This work presents a helping tool for Digital Television users providing the fastest way to get information about the programs they observe and which they like. However, the actual problem occurs since the Digital Television broadcasters not always give enough information to users about the programs, which is a problem because they use other information sources wasting worthy time. A solution to that problem is developed in this work, since the television and the huge and available information in the internet are integrated by using semantic technologies in order to let users get a complete information about the programs they want to know. Especially this thesis looks for enriching extra information about the programs transmitted by the different television channels by using the semantic web methods and techniques to get helpful information from ontological and no ontological repositories. The final result will be an ontological data base containing detailed program information.Ingeniero de SistemasCuenca\n"}
{"prompt":"Los métodos de programación en ingeniería vial ->","completion":" Definimos un programa, como el resultado de un estudio previo a la realización de una obra y que nos ofrece una anticipación de lo que realmente va a suceder al efectivisarla. Estos programas para cumplir las condiciones necesarias de presión deben tener en cuenta todos los factores que influirán en el trabajo, por ejemplo: Factores físicos, económicos, técnicos, etc. el plan de esta obra empieza con un estudio de los principales métodos de programación en lo referente a duraciones, analizando sus ventajas y desventajas de forma que haya una base para poder seleccionar el método más conveniente para realizar un determinado trabajo. A continuación se realizará un estudio del método Pert costos, método que sirve para relacionar tiempo y costo, a base de esto seleccionar el programa óptimo a utilizarse. Al final se incluye un apéndice con los elementales conocimientos sobre estadística matemáticas, indispensables para realizar una programaciónIngeniero CivilCuenca\n"}
{"prompt":"La programación aplicada a la construcción ->","completion":" Actualmente una edificación se realiza de una manera no organizada por lo que se presentan problemas económicos y en la continuidad del proceso constructivo, para lo cual esta tesis pretende que estos problemas sean resueltos con anterioridad mediante la programación, para ello se escogió el método CPM lo que implica determinar el análisis de los precios unitarios, luego el cálculo volumétrico y con los precios unitarios obtenidos determinar el presupuesto de la obra. Para demostrar la validez de la programación, se construyó la obra con un control de la misma y estableció cuadros comparativos de rendimiento, de costos unitarios, de costos jornales y de presupuesto entre lo programado y lo obtenido en realidadArquitectoCuenca\n"}
{"prompt":"Simulación de los Procesos Psicrométricos ->","completion":" Los procesos físicos de evaporación y de condensación del agua y viceversa establecen mecanismos de adición y eliminación de humedad, provocando cambios en los diferentes sistemas ecológicos, habitacionales e industriales. Múltiples procesos de acondicionamiento de aire son necesarios en la industria. Estos procesos han sido modelados matemáticamente como operaciones unitarias de humidificación, deshumidificación y secado, los mismos que están en función de varios parámetros psicrométricos como temperatura, humedad relativa, humedad absoluta, presión, y otros. Su cálculo por ecuaciones resulta más o menos complejo, las soluciones gráficas son más prácticas, pero menos precisas, software y simuladores en psicrometría son escasos. Este estudio desarrolla la creación de un modelo computarizado, creado en función de un algoritmo que puede disminuir la complejidad, acelerar la secuencia de operaciones y mejorar la precisión de los cálculos, útil tanto en la industria como en la docencia. El software es basado en el lenguaje Java® para simular casos y métodos de cálculo de procesos de humidificación, deshumidificación, secado y mezclas de aire basado en las ecuaciones básicas de la psicrometría, para un amplio rango de temperaturas y a diferentes alturas sobre el nivel del mar. El modelo ha sido validado para las condiciones Ecuador, mostrando buena correlación entre los resultados calculados manualmente frente a los obtenidos por la simulación.The physical processes of water evaporation and condensation and the corresponding reverse processes, establish mechanisms of addition and\/or removal of moisture, causing changes in different ecological, housing and industrial systems. Multiple air conditioning processes are needed in the industry, these have been modeled mathematically as unit operations of humidification, dehumidification and drying, in turn, they depend on several psychrometric parameters such as temperature, relative humidity, absolute humidity, pressure, etc. Its calculation by equations is more or less complex; graphic solutions are more convenient, but less precise; software and simulation packages in psychrometry are scarce. This paper develops the creation of a computerized model based on an algorithmic tool that can reduce complexity and improve the accuracy of these calculations, useful both for industrial and teaching applications. This software is based on the ®Java language to simulate cases and calculation methods of humidification, dehumidification, drying and mixtures of air based on psychrometric equations. The software can be used for a wide range of temperatures and at different altitudes above sea level. The validation of the model has been performed in Ecuador´s environmental conditions. Results showed good correlation between the results obtained via manual computation and those obtained using the model.\n"}
{"prompt":"Simulación digital de generadores sincrónicos ->","completion":" Se efectua un estudio del generador síncrono, con el cual será posible desarrollar un modelo matemático que simule el comportamiento de la máquina en cualquier estado de operación. En base de ésto se realiza la simulación digital del generador síncrono que esquemáticamente puede ser resumido de la siguiente manera: se realiza un estudio general de las máquinas sincrónicas, analizando el comportamiento del generador en estado estable. Se describen los diversos modelos que pueden ser usados para la simulación de las máquinas sincrónicas, siendo el modelo matemático implementado aquel que toma como variables de estado a los enlaces de flujo, así también se analizan aspectos adicionales a ser considerados en la simulación, tales como la saturación del entrehierro de la máquina.GuayaquilIngeniero en Electricidad Especialización Potencia\n"}
{"prompt":"Simulación de protocolos de comunicaciones ->","completion":" To share data across the network requires an advance notice, and this communication is governed by certain protocols, under compliance, they allow communication. This premise led to the idea of the project \"Simulation of Communication Protocols\" that with simulation equipments allow to analyze and understand how a package or plot travels through a network to provide voice services, data and telephony using a protocol analyzer equipment Radcom RC-100WL. They will treated with different types of tools for analyzing and monitoring networks, as well as analyzers and \/ or simulators, revise a software used to analyze and simulate networks with different protocols LAN and WAN. An analysis of the structure of the frames or packets of the protocols in use today as MAC, IP LAN and HDLC, Frame Relay and ATM WAN network will be done.\n"}
{"prompt":"Simulación del servicio del Trolebus ->","completion":" Introducción. Marco teórico. Desarrollo del sistema. Implementación y pruebas. Evaluación. Conclusiones y recomendaciones.\n"}
{"prompt":"La simulación de los contratos ->","completion":" Doctor en Jurisprudencia y Abogado de los Tribunales de Justicia de la RepúblicaCuenca\n"}
{"prompt":"Simulación de los procesos psicrométricos ->","completion":" Los procesos físicos de evaporación y de condensación del agua y viceversa establecen mecanismos de adición y eliminación de humedad, provocando cambios en los diferentes sistemas ecológicos, habitacionales e industriales. Múltiples procesos de acondicionamiento de aire son necesarios en la industria. Estos procesos han sido modelados matemáticamente como operaciones unitarias de humidificación, deshumidificación y secado, los mismos que están en función de varios parámetros psicrométricos como temperatura, humedad relativa, humedad absoluta, presión, y otros. Su cálculo por ecuaciones resulta más o menos complejo, las soluciones gráficas son más prácticas, pero menos precisas, software y simuladores en psicrometría son escasos. Este estudio desarrolla la creación de un modelo computarizado, creado en función de un algoritmo que puede disminuir la complejidad, acelerar la secuencia de operaciones y mejorar la precisión de los cálculos, útil tanto en la industria como en la docencia. El software es basado en el lenguaje Java® para simular casos y métodos de cálculo de procesos de humidificación, deshumidificación, secado y mezclas de aire basado en las ecuaciones básicas de la psicrometría, para un amplio rango de temperaturas y a diferentes alturas sobre el nivel del mar. El modelo ha sido validado para las condiciones Ecuador, mostrando buena correlación entre los resultados calculados manualmente frente a los obtenidos por la simulación.The physical processes of water evaporation and condensation and the corresponding reverse processes, establish mechanisms of addition and\/or removal of moisture, causing changes in different ecological, housing and industrial systems. Multiple air conditioning processes are needed in the industry, these have been modeled mathematically as unit operations of humidification, dehumidification and drying, in turn, they depend on several psychrometric parameters such as temperature, relative humidity, absolute humidity, pressure, etc. Its calculation by equations is more or less complex; graphic solutions are more convenient, but less precise; software and simulation packages in psychrometry are scarce. This paper develops the creation of a computerized model based on an algorithmic tool that can reduce complexity and improve the accuracy of these calculations, useful both for industrial and teaching applications. This software is based on the ®Java language to simulate cases and calculation methods of humidification, dehumidification, drying and mixtures of air based on psychrometric equations. The software can be used for a wide range of temperatures and at different altitudes above sea level. The validation of the model has been performed in Ecuador´s environmental conditions. Results showed good correlation between the results obtained via manual computation and those obtained using the model.Cuencanúmero 15\n"}
{"prompt":"Simulación de transformadores de corriente. ->","completion":" In this work is shown the results of the modelation in MATLAB\/Simulink of generic Current Transformer, which could be configured by the user. It develops an ideal models, a model that take in account the saturation curve of the CT from the real experiment. Other model that take in account the hysteresis and the three phase TC model were done. With the virtual CTs were made several simulation and were verified the results comparing with the results obtained in the reference. Were simulated big magnitude current that are considered like short circuit and their influence in the saturation and their dependence with the load connected to them was studied. Were made experiments with real CTs and were verified that the mathematic models (virtual) made in MATLAB are similar to the real ones. The same secondary current wave form are obtained with the simulation and with real experiments. These models could be used in the Electric Protection teaching process due to that is easier to study the behavior of the virtual CT for several conditions than to try to made the same experiment with real instruments and CTs.En este trabajo se mostrarán los resultados de la modelación en MATLAB\/Simulink de un transformador de corriente genérico, el cual puede ser configurado por el usuario. Se desarrolló un modelo ideal, un modelo que toma en cuenta la curva de saturación de un TC a partir de los datos obtenidos en ensayos de laboratorios; así como también un modelo que tomó en cuenta lazos de histéresis y un modelo de TC trifásico. Se realizan diversas simulaciones de los modelos creados y se comprobaron los resultados a partir de los resultados obtenidos de las revisiones bibliográficas. Se simularon grandes corrientes que representan cortocircuitos y su influencia en la saturación y la dependencia con la carga conectada al mismo. Se realizaron ensayos a TCs reales y se verificaron que los modelos matemáticos modelados en MATLAB representan a los TCs reales. Ondas de corrientes secundarias similares a las obtenidas en los experimentos reales se obtuvieron en la simulación. Los modelos pueden ser utilizados en la enseñanza de las protecciones dado que resulta muy fácil estudiar el comportamiento de un TC para distintas condiciones que hacerlo desde el punto de vista de experimentos reales.\n"}
{"prompt":"Simulación causal de Inexistencia o Nulidad ->","completion":" La simulación contractual es aquella divergencia entre lo querido y lo declarado, divergencia concertada por los agentes contratantes con fines de engaño, no necesariamente ilícitos. Puede estar presente en cualquier tipo de negocio jurídico, pues lo particulares en uso de la autonomía de la voluntad están facultados para acordar lo que mejor satisfaga sus intereses teniendo siempre como referente la ley, la moral y el orden público. La simulación puesta al descubierto está sujeta a la sanción de nulidad. La sanción puede ser absoluta para casos de simulación absoluta donde solo se dio vida a la apariencia de un negocio, o de nulidad absoluta e incluso relativa en casos de simulación relativa donde existen dos contratos: uno con voluntad aparente y otro real. El tema de la inexistencia tratado ampliamente por la doctrina en nuestra legislación solo constituye un referente, pues circunstancias que podrían ser objeto de declaratoria de inexistencia son sancionados con nulidad absoluta, ya que esta figura jurídica al no estar consagrada en un capítulo específico dentro del Código Civil se subsumen dentro de la nulidad.Dra. Lorena Naranjo Godoy\n"}
{"prompt":"Simulación de secuencia de minado “Proyecto Najayo” ->","completion":" El objetivo de este proyecto de graduación es generar la simulación de secuencia de minado del Proyecto “Najayo”, una mina de caliza; para esto fue indispensable la capacitación en el manejo de programas informáticos especializados en minería como son Surpac® y Minesched®, los cuales fueron aplicados en el desarrollo de la secuencia minera. La empresa Soluciones en Geología y Minería S.A.S., fue la encargada de realizar la planificación de esta mina; por lo tanto los resultados de este trabajo serán contrastados y comparados o aquellos obtenidos por esta empresa.Ingeniero de Minas\n"}
{"prompt":"Modelamiento y simulación de un sistema electroneumático ->","completion":" El presente trabajo tiene como objetivo modelar y simular un sistema electro-neumático evaluando el desempeño de los programas de simulación a utilizar. Los tres programas en donde se implementó el modelo son Matlab\/Simulink, Scilab\/Xcos y Openmodelica. Como primer paso seleccionamos la válvula reguladora de presión como el sistema electro-neumático a modelar.GuayaquilIngeniero en Electricidad Especialización Electrónica y Automatización Industrial\n"}
{"prompt":"Modelamiento, optimización y simulación de ecualizacion ->","completion":" RESUMEN El presente trabajo hace una breve explicación de lo que implica el sistema de transmisión OFDM y cómo funciona mediante el aprovechamiento del espectro radioeléctrico de una manera más optima, para luego centrarse en el objetivo principal que es explicar la ecualización por tonos, la cual busca mejorar el rendimiento en un sistema multiportadora OFDM. Se enuncia y se explica la matemática del cálculo de los índices requeridos, y a continuación se hará una explicación gráfica a través de simulación de cómo es el proceso y el efecto de los filtros que se aplican en cada portadora. Para terminar una simulación que nos muestra los niveles de ruido después del ecualizador para un tono determinado, relacionándolo con la necesidad de mayor capacidad computacional a través del efecto producido por un mayor o menor filtrado.\n"}
{"prompt":"Estudio, modelamiento y simulación de sistemas mimo ->","completion":" El presente trabajo se enfoca en el desarrollo de dos soluciones que permitan resolver las interferencias co-canales presentes en los sistemas MIMO (Multiple Input Multiple Output), mediante el uso de ecualizadores. Como se observara en las siguientes secciones, la solución planteada es el Beamforming, el cual consta de dos tipos de ecualizadores para poder hallar la matriz de pesos, la cual será analizada más adelante y veremos cuál de los dos tipos de ecualizadores cumple con el objetivo de eliminar eficazmente las interferencias co-canales. Las dos soluciones analizadas serán aplicadas en el método Beamforming en un sistema Wireless, en el cual se consideró el efecto del ruido blanco aditivo gausiano y el canal a utilizar es el flat fading Rayleigh.\n"}
{"prompt":"Simulación digital-analógica del motor de inducción ->","completion":" Se analiza el comportamiento de un motor de inducción en sus periodos transientes, ya sean éstos durante su arranque, o producidos por diferentes perturbaciones mientras está trabajando en estado estable. Para analizar estos problemas se hace un estudio general del motor de inducción, para poder desarrollar un modelo matemático que pueda ser facilmente simulado, a fin de estudiar su estado dinamico. Para cumplir la finalidad de este estudio, se desarrolla a la máquina en un sistema de ecuaciones diferenciales, para luego simularla con las características de un motor de inducción típico, analizando su comportamiento en el dominio del tiempo.GuayaquilIngeniero en Electricidad Especialización Potencia\n"}
{"prompt":"Modelamiento y simulación de una caldera ->","completion":" El objetivo de este trabajo es modelar y simular un generador de vapor o caldera avaluando el desempeño de cada uno de los programas seleccionados para implementar el modelo matemático son Matlab\/Simulink y Scilab\/Xcos. se seleccionará un generador de vapor específico y luego se describirán los análisis realizados para obtener la descripción matemática del mismo.GuayaquilIngeniera en Electricidad Especialización Electrónica y Automatización Industrial\n"}
{"prompt":"Modelamiento y simulación de sistemas mimo ->","completion":" Systems multiple input multiple output (MIMO) take advantage of multipath propagation to reduce the error rate and increase the transmission rate. The IEEE 802.11n standard this kind of technology used for data rates up to 600Mbps and is already proven that 4G cellular technology can achieve transfer rates up to 100Mbps at a distance of 200m. MIMO has three major categories among them are: Beamforming, Spatial Multiplexing and Diversity Code. In this project we will discuss Beamforming technology, which allows a maximum radiation of the desired signal to the user and in the direction of users interfering signal is reduced. This technique uses two types of EQ to find the matrix of weights between these includes: Zero Forcing and Minimum Mean Square Error.\n"}
{"prompt":"La simulación laboral en el sector público. ->","completion":" El tema planteado sobre la simulación laboral en el sector público, ha sido desarrollado mediante un proceso sistemático, partiendo de los antecedentes en donde se determina que la simulación en esencia constituye toda forma de encubrimiento de una relación jurídico laboral, situación que se da con conocimiento de causa, tanto en el sector público como en el privado, para reemplazarla con otra relación ya sea de carácter administrativo, civil, mercantil u otra índole, no obstante prohibición expresa contemplada en el artículo 327 de la Constitución de la República. La metodología que se utilizó en este trabajo fue con un enfoque paradigmático crítico- propositivo, para que no quede solamente en la recolección de datos, sino que utilizaron las herramientas propias de una investigación cualitativa, que permitió interpretar los resultados del análisis de este fenómeno dentro de la realidad ecuatoriana; con la investigación descriptiva, se caracterizaron los elementos que intervienen en la relación laboral, para llegar a la conclusión de que, se están utilizando mecanismos para generar fraude laboral, con formas de contratación ajenas al ámbito laboral, cuando el contratado es efectivamente un trabajador. En virtud de los resultados obtenidos en los análisis de casos específicos, en los cuales se establece que existen claramente configurados los elementos de una relación típicamente laboral, pues se configura la existencia de una prestación de servicios lícitos y personales, bajo la dependencia administrativa y económica del empleador, con una remuneración, que bajo cualquier denominación perciben los servidores regularmente, con lo cual se afecta un bien jurídico protegido, surge la necesidad de proponer un proyecto de Ley Reformatoria al Código del Trabajo y al Código Integral Penal (COIP), para el establecimiento de sanciones a los representantes legales de las instituciones públicas, que incurran deliberadamente en la utilización de figuras contractuales y otros mecanismo y artificios legales, para aparentar una relación de naturaleza distinta a la laboral, de esta manera se dará la tutela efectiva a los ciudadanos, generando confianza y seguridad jurídica.The issue raised about labor simulation in the public sector has been developed through a systematic process, based on the background where it is determined that simulation in essence constitutes all forms of cover-up of a labor legal relationship, a situation that occurs with knowledge of cause, both in the public and private sectors, to replace it with another relationship, whether administrative, civil, commercial or other, notwithstanding the express prohibition contemplated in article 327 of the Constitution of the Republic. The methodology used in this work was with a critical-propositional paradigmatic approach, so that it not only remained in data collection, but they used the tools of a qualitative investigation, which allowed us to interpret the results of the analysis of this phenomenon within of the Ecuadorian reality; With the descriptive research, the elements that intervene in the employment relationship were characterized, to reach the conclusion that mechanisms are being used to generate labor fraud, with forms of contracting outside the workplace, when the hired is actually a worker. By virtue of the results obtained in the analyzes of specific cases, in which it is established that the elements of a typically labor relationship exist clearly configured, since the existence of a legal and personal provision of services is configured, under the administrative and economic dependence of the employer, with a remuneration, that under any denomination the servants receive regularly, with which a protected legal asset is affected, the need arises to propose a draft Reform Law to the Labor Code and the Comprehensive Criminal Code (COIP), to the establishment of sanctions to the legal representatives of public institutions, who deliberately incur in the use of contractual figures and other legal mechanisms and devices, to appear as a relationship of a different nature to the labor, in this way effective guardianship will be given to citizens, generating trust and legal security\n"}
{"prompt":"Conceptualización del movimiento rectilíneo utilizando simulaciones interactivas. ->","completion":" El objetivo principal de este proyecto es determinar la incidencia del uso de los simuladores interactivos para la conceptualización del movimiento rectilíneo uniforme. Esta investigación se realizó en la Unidad Educativa Dante Alighieri en segundo de bachillerato, mediante un método de análisis-síntesis y cuasi-experimental aplicando una modalidad cuali cuantitativa, bibliográfica y de campo, se aplicó talleres didácticos mediante el fundamento de la teoría de los campos conceptuales de Vergnaud y las fases de aprendizaje según Kolb, haciendo uso de las simulaciones interactivas del proyecto PhET, para justificar este trabajo se efectuó, test, prueba de hipótesis y la aplicación de datos estadísticos, por lo que por medio de la prueba Q de Cochran se concluye de tal manera que los estudiantes alcanzaron un nivel significativo de conceptualización, aplicando la propuesta de este trabajo.The main objective of this project is to determine the incidence of the use of interactive simulators for the conceptualization of uniform rectilinear movement. This research was carried out in the Dante Alighieri Educational Unit in the second year of high school, using a method of analysis-synthesis and quasi-experimental applying a qualitative-quantitative, bibliographic and field modality, didactic workshops were applied through the foundation of the theory of the conceptual fields of Vergnaud and the learning phases according to Kolb, making use of the interactive simulations of the PhET project, to justify this work was carried out, test, hypothesis test and application of statistical data, so by means of the Cochran Q test is concluded in such a way that students reached a significant level of conceptualization, applying the proposal of this work.\n"}
{"prompt":"Simulaciones interactivas en el aprendizaje significativo. ->","completion":" Esta investigación trata del aprendizaje significativo en estudiantes del Primer Año de Bachillerato en la Unidad Educativa Juan Bautista Aguirre, es necesario aplicar innovaciones en beneficio de la comunidad educativa. El objetivo es analizar la Simulaciones interactivas en el aprendizaje significativo. Propuesta: Implementación de simulaciones interactivas de conservación de la energía mecánica péndulo simple, la cual hará participar activamente a los estudiantes. Los datos recopilados mediante la investigación descriptiva aplica la encuesta para realizar la entrevista a la comunidad educativa, se considera que los estudiantes que cursan el primer año de bachillerato desconocen la existencia de los software libres que se puede aplicar en el área de física, lo que ha despertado la curiosidad y desean conocer más acerca de las simulaciones interactivas y el buen uso de las herramientas tecnológica que existente en la web sin costo para colaborar en el mejoramiento del proceso educativo.\n"}
{"prompt":"Análisis y simulación aerodinámica de una esfera ->","completion":" En el trabajo se desarrolla una investigación detallada sobre la teoría de flujo potencial. La superficie ha analizar es una esfera; la cuál es de las más utilizadas e interesantes en el aspecto aerodinámico; ya que con frecuencia, el lector se habrá dado cuenta de las formas redondeadas que se utilizan frecuentemente en las aplicaciones que se aprecia en la vida cotidiana. Para ello, se diseña y construye un modelo de maqueta para la esfera, en este caso se utiliza la impresión 3D. Los resultados son obtenidos en el túnel de viento de la Universidad. Con ellos, se aplica la teoría de flujo potencial para comprobar los resultados con la literatura, y finalmente validarlos en un software computacional.\n"}
{"prompt":"LA RESPONSABILIDAD EXTRACONTRACTUAL Y LA INTELIGENCIA ARTIFICIAL ->","completion":" Al igual que muchas innovaciones a lo largo de la historia, la Inteligencia Artificial está creciendo de forma exponencial, apareciendo cada día en la mayoría de los ámbitos cotidianos, dotando a sistemas y aparatos con la misma. Por consiguiente, el uso de la Inteligencia Artificial generará un volumen de problemas en el ámbito del Derecho, al no existir una normativa nacional e internacional que regule en su totalidad esta nueva tecnología transformadora. El presente trabajo indagará la responsabilidad civil extracontractual, perpetrando un análisis sobre los factores técnicos que provocan dichos problemas jurídicos. Se enfocará en el marco jurídico y fundamentos doctrinales de la responsabilidad extracontractual y se presentarán razones por los cuales se observa la falta de seguridad jurídica de la regulación existente. Lo cual, se ejemplificará mediante ejemplos determinados de posibles daños causados por sistemas dotados de Inteligencia Artificial. Finalmente, se buscará dar soluciones a estos problemas jurídicos, brindando directrices del deber ser de la nueva regulación en materia de daños ocasionados por sistemas dotados de Inteligencia Artificial.Like many innovations throughout history, Artificial Intelligence is growing exponentially, it has appeared among the most commonly things used in daily life, providing most systems, machines, and devices with it. Therefore, the use of Artificial Intelligence will generate a number of problems that the actual national and international legislations around the world does not entirely regulate. Hence this paper will investigate non - contractual civil liability, perpetuating an analysis of the technical factors that cause these legal problems. It will focus on the legal framework and doctrinal institutions of non - contractual liability and will exhibit reasons why the actual legislation does not certainty. This will be exemplified by specific examples of possible damages caused by systems equipped with Artificial Intelligence. Finally, it will seek to provide solutions to these legal problems, providing guidelines on the must be for the new legislations on damages caused by systems equipped with Artificial Intelligence.\n"}
{"prompt":"Creación de un demo de un videojuego con inteligencia artificial ->","completion":" The following paper was born from the search of artificial intelligence used in the video games from programmers and developers, both international and Ecuadorian. In thus, this type of technology has been investigated in this research and, based on an analysis, the results of this investigation can be found below. It proceeds with a historical summary on how the themes of video games and artificial intelligence were born, how they are seen, how they were developed and how they have evolved and innovated over time. The research has been carried out within a world and national perspective. Finally, the main goal with this work is to provide better tools, since it contains an extensive step by step explanation of how to create a video game with artificial intelligence. This document will serve students, programmers and developers as a guide for the creation of their own projects.El presente trabajo es una investigación que nace a partir de la búsqueda de la cantidad de Inteligencia artificial utilizada en los videojuegos de programadores y desarrolladores, tanto ecuatorianos como internacionales. En general, se ha investigado sobre este tipo de tecnologías y a partir de un análisis, a continuación, se podrá encontrar los resultados de dicha investigación. Se procede con un resumen histórico sobre como las temáticas de los videojuegos y la inteligencia artificial nacieron, como son vistos, como se desarrollan y como han ido evolucionando e innovando a lo largo del tiempo. La investigación se ha realizado dentro de una perspectiva de nivel mundial y nacional. Por último, lo que se desea lograr con este trabajo es proporcionar mejores herramientas, ya que el mismo, contiene una extensa explicación paso a paso, de cómo crear un videojuego con Inteligencia artificial. Este documento servirá a estudiantes, programadores y desarrolladores como guía para la creación de sus propios proyectos.\n"}
{"prompt":"Inteligencia Artificial en el campo de las Finanzas ->","completion":" La inteligencia artificial (IA) surge en la d?cada de los 40; el trabajo reconocido de Turing (1950) tuvo gran relevancia y fue considerado padre de la IA, este art?culo titulado ?Computing Machinery and Intelligence? presenta la probabilidad de que una maquina pueda imitar el pensamiento de una persona, adem?s, da a conocer un test que prueba la capacidad de una m?quina comparada con el pensamiento humano.\n"}
{"prompt":"Automatización de pruebas psicológicas proyectivas, utilizando técnicas de inteligencia artificial ->","completion":" 1. Los tests 2. Tests psicológicos proyectivos objeto de automatización 3. La selección del personal 4. La inteligencia artificial 5. Estudio de las herramientas de desarrollo 6. Análisis, diseño e implementación 7. Conclusiones y recomendacionesLas técnicas de selección del personal son fundamentales, hoy más que nunca, para el crecimiento de una empresa cualquiera sea su magnitud. La selección del candidato indicado puede ayudar a crecer a una empresa, por el contrario seleccionar a quien no se debe puede ser costoso, hablando en términos de tiempo y dinero. La función del psicólogo o del entrevistador, es sumamente delicada debido a su complejidad, ya que con frecuencia se dan casos en que por juicios subjetivos de la persona encargada de la selección, se píerden buenos candidatos o por estos mismos perjuicios se hace una mala selecciónDisertación(Ingeniería en sistemas)Ingeniería en sistemas\n"}
{"prompt":"Inteligencia artificial como sujetos de derecho u objeto de derecho. ->","completion":" El tema a investigar es una cuestión muy novedosa en la actualidad, pero no descabellada, la inteligencia artificial como lo vemos ahora, ya es una realidad ¿pero serán consideradas en un futuro como sujetos de derecho u objeto de derecho? Si bien es cierto, la tecnología es objeto de derecho, pero la ciencia ha ido evolucionando a tal nivel de crear inteligencia artificial que supera actividades del mismo ser humano, incluso llegando a relacionarse y comunicarse con la humanidad, logrando así una cuasi independencia, porque aún tienen limitaciones dichas inteligencias artificiales. Si la sociedad sigue en ese rumbo, la inteligencia artificial podría llegar al punto de poder representarse a sí mismo, contraer responsabilidades y obligaciones, tal y como tienen los sujetos de derecho. Tal vez puede darse el caso como los animales y la naturaleza, que son consideradas sujetos de derecho, pero sus acciones legales son accionadas por nosotros mismos, así también se crean leyes para la protección de estos sujetos de derecho.The topic to be investigated is a very new question at present, but not far-fetched, artificial intelligence as we see it now, is already a reality, but will they be considered in the future as subjects of law or object of law? While it is true, technology are objects of law, but science has evolved to such a level of creating artificial intelligence that they exceed activities of the same human being, even coming to relate and communicate with humanity, thus reaching a quasi-independence, because it still has limitations such artificial intelligences. If society continues in this direction, artificial intelligence could reach the point of being able to represent itself, to contract responsibilities and obligations, just as the subjects of law have. Perhaps it may be the case as animals and nature, which are considered subjects of law, but their legal actions are triggered by ourselves, so also laws are created for the protection of these subjects of law.\n"}
{"prompt":"COVID-19: Respuestas desde la ingeniería y la inteligencia artificial ->","completion":" ¿Cómo actúa nuestro cuerpo para defenderse? ¿Cómo funcionan las vacunas? ¿Cómo se diagnostica la enfermedad? ¿Puede la ingeniería y la inteligencia artificial dar una respuesta al diagnóstico? Estas preguntas sirvieron de base para el desarrollo de una investigación que permitió evaluar la respuesta de la inteligencia artificial frente a la pandemia. En estas páginas se describen conceptos fundamentales que se utilizaron para reconocer patrones relacionados con la tos COVID y de las capacidades reales de los sistemas inteligentes para detectarla. Esta obra tiene un enfoque de difusión científica, con un lenguaje cercano y amigable para los lectores y contribuye a los avances logrados alrededor del mundo.\n"}
{"prompt":"Análisis de información médica con técnicas de inteligencia artificial ->","completion":" Resumen: Este trabajo tiene como objetivo analizar y explorar información médica de pacientes diabéticos, con el fin de identificar grupos de pacientes que presenten síntomas similares mediante técnicas de inteligencia artificial. En el se realizaron experimentos basados en la metodología CRISP-DM, empleando técnicas de clusterización y el algoritmo DBSCAN además del método semántico análisis de la semántica latente (LSA). Una vez identificados los grupos se identificó aquellos síntomas comunes y propios de la diabetes. Se realizó un análisis con los datos obtenidos de la experimentación y para finalizar se evaluó y validó la información alcanzada con ayuda del coeficiente Silhouette y con un grupo de expertos.\n"}
{"prompt":"Prototipo de robot manipulador con visión artificial ->","completion":" Introducción. Marco teórico. Metodología y materiales. Diseño del robot manipulador con visión artificial. Conclusiones y recomendaciones\n"}
{"prompt":"Creación de Códigos y Contra Códigos para la Activación de Programas, Utilizando Elementos de Inteligencia Artificial ->","completion":" En la actualidad, el desarrollo de software ha crecido notablemente, hasta el punto de que en todas las organizaciones se trabaja al menos con un programa y al hablar de programas, hablamos de información, la cual es muy vital para el desenvolvimiento de cualquier negocio, por lo que a su vez, la piratería está en constante aumento y sucede a nivel mundial, generando grandes pérdidas para toda organización que se dedica al desarrollo de software. Como medio para tratar de impedir estos plagios, se utiliza la Seguridad Informática, que no es más que la protección de Información y de Sistemas de Información, ya sea para evitar su acceso, uso, divulgación, interrupción o destrucción. En el presente proyecto, como Solución, se aplicarán métodos de encriptación, usando Redes Neuronales Artificiales con el método de aprendizaje Hopfield, para proteger de mejor manera el acceso no deseado a programas que se activan por medio de un código o serial, tomado de los periféricos de un computador.\n"}
{"prompt":"Caracterización y modelación de la red de comercialización de combustible automotriz utilizando técnicas de inteligencia artificial ->","completion":" En este trabajo se propone una metodología dirigida al descubrimiento del conocimiento oculto en información que aparentemente no aporta valor; el objetivo es determinar en la red de comercialización de combustible automotriz consumos anómalos que puedan derivar en posibles delitos hidrocarburíferos. La metodología incluye la utilización de técnicas de inteligencia artificial. La técnica seleccionada es la de minería de datos porque a través de esta se puede encontrar correlaciones útiles para algún proceso, esto permite que una persona con poca experiencia adquiera la comprensión sobre un tema específico de manera fácil y rápida. El presente documento contiene los siguientes capítulos: En el capítulo I se describen los fundamentos teóricos sobre los cuales se basa la investigación. En el capítulo II se detalla las técnicas de investigación aplicadas para el cumplimiento de los objetivos. En el capítulo III se especifica la metodología propuesta para categorizar y modelar la red de comercialización de combustible automotriz utilizando técnicas de inteligencia artificial.\n"}
{"prompt":"Desarrollo de un videojuego de acción utilizando técnicas y algoritmos de inteligencia artificial ->","completion":" This project refers to the design, development and implementation of the video game \"Neon Days\" an action third person shooter, which through research and use of a methodology, software development techniques were applied in order to make an action multi-platform video game that is implemented with artificial intelligence techniques and algorithms. The design of the game's environment includes the main view, activities that the player can do, actual environment and the enemies the player will encounter, within the game's mechanics and the core gameplay. Additionally, a graphic user interface was designed, so the player can be aware of it's surrounding and state of the main character. Through a game development framework all of the above was implemented, besides, it was also implemented an adaptive difficulty which was achieved with artificial intelligence techniques and algorithms that were applied to enemies. As a final result this project delivers a fully functional and designed system which has a high human-machine interaction, meaning, an action video game with adaptive difficultyEl presente proyecto trata del diseño, desarrollo e implementación del videojuego de acción en tercera persona \"Neon Days\", que por medio de la investigación y aplicación de una metodología, se aplicaron técnicas de desarrollo de software con el fin de crear un videojuego de acción multiplataforma que utiliza técnicas y algoritmos de inteligencia artificial. Se diseñó el ambiente del mismo, estableciendo cual será la vista principal, las actividades que realizara el jugador, el lugar en donde se encuentra y los enemigos a los que debe enfrentar, así como las mecánicas del juego y la jugabilidad del mismo; en conjunto se diseñó una interfaz gráfica que permite al jugador comprender su entorno y el estado en el que se encuentra el personaje. Por medio de un framework de desarrollo de videojuegos se implementó lo antes mencionado y, adicionalmente, una dificultad adaptable que se logró a través de técnicas y algoritmos de inteligencia artificial aplicada a los enemigos. Este proyecto entrega como resultado final un sistema diseñado y funcional con una alta interacción humano computador, es decir, un videojuego de acción con dificultad adaptable.\n"}
{"prompt":"Aplicación de la inteligencia artificial en el proceso de dosificación y envasado de líquidos. ->","completion":" Los procesos de dosificación y envasado de líquidos se ejecutan de forma manual en la mayoría de las entidades que se dedican a esta labor y el resultado no suele ser el estimado, puesto que en ambos procesos se deja esta función al operario basando su resultado en la apreciación de la vista humana de cada usuario. Se plantea como solución a esta necesidad la implantación de un sistema de control on\/off y una aplicación de visión artificial por ordenador, la propuesta consta de dos procesos; el primero trata sobre la mezcla de colores controlada y monitorizada por un sistema SCADA capaz de obtener nueve tonalidades de colores basados en el modelo de color RGB, comenzando con la descarga de los tres colores primarios (rojo, verde y azul) y en paralelo verificando su caudal antes de llegar al tanque dosificador que homogeniza la mezcla, el segundo proceso empieza con el llenado y finaliza con la detección del nivel del llenado a través del reconocimiento de patrones previamente definidos vía cámara USB en base a los protocolos de un sistema de inspección por visión artificial. Se cuenta con un microcontrolador ATmega2560 que es el encargado de comunicar vía USB el sistema de control con los elementos de entrada (interruptores, pulsadores y sensores) y en conjunto a una etapa de potencia permite el control desde el sistema de los dispositivos de salida (actuadores), la programación se basa en la lógica de máquinas de estados finitos mediante el lenguaje G de NI LabVIEW, con la finalidad de obtener la industrialización de los dos procesos. Los métodos de investigación empleados en esta propuesta son los siguientes; observación, consulta bibliográfica, consulta a expertos y experimentación. Con base a los resultados de las pruebas realizadas se concluye que el sistema cuenta con una eficiencia del 90%.\n"}
{"prompt":"Inteligencia artificial aplicada a robot asistencial para la interacción con niños en edad temprana. ->","completion":" El presente Trabajo de Titulación consiste en la aplicación de la Inteligencia Artificial a un robot asistencial para la interacción con niños en edad temprana en la Escuela Superior Politécnica de Chimborazo, Facultad de Informática y Electrónica, Ingeniería Electrónica en Control y Redes Industriales. Con esta investigación el usuario dispondrá de un robot en forma de pingüino que interactúa con el niño en el típico juego de buscar y patear la pelota. Se utilizó el método Inductivo para obtener ideas generales en la programación a partir de premisas particulares y el método Experimental para el desarrollo de pruebas y corrección de errores en el funcionamiento del robot. El prototipo consta de un minicomputador Raspberry Pi sobre el cual se realizó la programación mediante el uso de bibliotecas del software Open Source que controlan: el tracking de la pelota a través de la cámara OMNI-VISION, los motores reductores que permiten el desplazamiento del robot, los dispositivos sensoriales que detectan la presencia del niño y de obstáculos, los altavoces que emiten mensajes pregrabados aleatoriamente. Se implementó el Algoritmo de Umbralización, mediante el cual el robot busca y sigue la pelota en el transcurso del juego. El robot interactuó con diez niños de 1 a 5 años de edad, el 80% de ellos mostraron mayor interés en el juego durante 25 minutos, incentivando así su desarrollo intelectual y psicomotriz; mientras que 20% de ellos se mostraron tímidos en la interacción con el robot con un tiempo de juego de 5 minutos. El prototipo en forma de pingüino incorpora los elementos básicos de un Sistema de Visión Artificial, logrando así un robot de aspecto amigable con los niños. Se recomienda a los estudiantes de la Escuela de Ingeniería Electrónica, tomar los resultados de esta investigación para profundizar los conocimientos en el amplio campo de la Inteligencia Artificial.This work involves the application Degree of Artificial Intelligence to a medical robot for interacting with children at an early age at the Polytechnic School of Chimborazo, Faculty of Informatics and Electronics, Electronics Engineering in Control and Industrial Networking. Through research, the user will have a penguin shaped robot that interacts with the child in the typical game of seek and kick the ball. The inductive method was used to obtain general ideas in programming from particular premises and the experimental method to test development and correction of errors in the operation of the robot. The prototype consists of a minicomputer Raspberry Pi on which programming is performed by using libraries of Open Source software that control: tracking the ball through the OMNI-VISION camera gear motors that allow the movement of the robot, sensory devices that detect the presence of the child and obstacles, the speakers that emit randomly prerecorded messages. Thresholding Algorithm, by which the robot seeks out and follows the ball during the game was implemented. The robot interacted with ten children 1 to 5 years old, 80% of them showed more interest in the game for 25 minutes, thus encouraging their intellectual and psychomotor development; while 20% of them were shy in the interaction with the robot with a playing time of 5 minutes. The penguin shaped prototype incorporates the basic elements of a machine vision system, thus achieving a friendly looking robot with children. It is recommended to students of the School of Electronic Engineering to take the results of this research to deepen knowledge in the broad field of Artificial Intelligence.\n"}
{"prompt":"Estudio de las Técnicas de Inteligencia Artificial Mediante el Apoyo de un Software Educativo ->","completion":" El presente trabajo es un software educativo para el estudio de la materia de Inteligencia artificial, fue desarrollado con la finalidad de conocer más a fondo las principales técnicas, conceptos y aplicaciones que servirán para el aprendizaje de estos temas a los estudiantes de Informática de la Escuela Superior Politécnica de Chimborazo. En los recursos utilizados pudimos contar con tecnología para la Web utilizando el entorno de programación PHP, MySQL, Apache. Para el diseño utilizamos la herramienta Dreamweaver como editor de páginas Web. Utilizamos técnicas pedagógicas pues es un sistema de aprendizaje. Mediante este Sistema se accede a la información de Inteligencia Artificial y apoyo a los estudiantes a comprender estos temas para aprender, evaluarse y además mediante un análisis de los resultados se evidenció que un 80% se mejora el aprendizaje de las técnicas y conceptos de Inteligencia Artificial. Brinda una interfaz amigable de navegación, la cual tuvo una gran aceptación y fue comprobada su utilidad mediante la prueba de implementación y puesta en marcha en la Red durante 15 días, al cual accedieron 50 usuarios quienes mediante la aplicación de entrevistas y encuestas permitieron conocer la satisfacción del 90% de la labor desarrollada. Se concluye que este software educativo de Inteligencia Artificial desarrollado puede ser utilizado para el aprendizaje de esta materia. Recomendamos utilizar este software en el curriculum de la facultad para el desarrollo de la Inteligencia Artificial en la Escuela de Informática.\n"}
{"prompt":"Aplicación de la inteligencia artificial al control de los motores de inducción ->","completion":" Se enmarca en los esfuerzos que realiza la comunidad científica internacional en el control de sistemas de grandes prestaciones con motores de inducción. Se investigó el desempeño de los controladores neurales empleando la lógica difusa y el filtro de kalman como observador de la velocidad en un esquema de control directo del par y del flujo del estator. El soporte programático para la solución delas estrategias de control que brinda el programa profesional matlab y su herramienta de simulación simulink.GuayaquilMagister en Automatización y Control Industrial\n"}
{"prompt":"Mantenimiento predictivo para la supervisión de motores eléctricos aplicando técnicas de inteligencia artificial. ->","completion":" En el presente trabajo de titulación se realizó el estudio de un sistema de mantenimiento predictivo con el uso de técnicas de inteligencia artificial aplicadas a un motor eléctrico. El sistema se basa en el análisis de variables provenientes de un variador de velocidad y diferentes tipos de sensores para poder presentar los resultados al usuario por medio de un sistema SCADA. La investigación tuvo un enfoque cuantitativo ya que se realizó un análisis de gran cantidad de datos para llegar al resultado. El objetivo del trabajo se orienta en estimar el estado del motor a través de sus variables, a fin de determinar el momento opimo para realizar un mantenimiento: El análisis de los datos se lo realizo mediante una de las técnicas de inteligencia artificial denominado redes neuronales. Como resultado del presente trabajo, se logró integrar todos los equipos del sistema propuesto y así poder realizar el análisis que permitiría estimar un momento apropiado para un mantenimiento. Con el fin de comprobar su funcionamiento, se realizaron diferentes pruebas que se basaron en comprobar si la adquisición, almacenamiento y análisis de los datos obtenidos. Dichas pruebas permitieron determinar que el sistema cumplía con el objetivo principal, brindando información fiable para finalmente presentarla a través de un sistema SCADA.In the present degree work, it was developed the study of a system of predictive maintenance with the use of artificial intelligence techniques, applied to an electric motor, the system is based on the analysis of variables coming from a drive and different types of sensors to present the results to the user through a SCADA system. The research had a quantitative approach because a large amount of data was analyzed in order to achieve the result. The objective of the work is to be able to estimate the state of the motor by the analysis of its data and to be able to estimate the optimal moment to carry out a maintenance. The analysis of the data is carried out by an artificial intelligence method called neural networks. As a result of the present work, it was possible to integrate all the equipment of the proposed system and be able to perform the analysis that would allow estimating an appropriate moment for a maintenance. In order to check its operation, different tests were carried out that were based on checking the acquisition, storage and analysis of the data obtained. These tests allowed to determine that the system complied with the main objective, providing reliable information to finally present it through a SCADA system.\n"}
{"prompt":"Desarrollo de un sistema SCADA para la supervisión de un proceso industrial utilizando inteligencia artificial. ->","completion":" En el presente trabajo de titulación se ha realizado el diseño de un sistema SCADA para la supervisión de un proceso industrial aplicando inteligencia artificial a través de algoritmos de lógica difusa, para ello se debe diseñar y simular el entorno industrial a través del programa CODESYS, el cual permite programar dicho proceso, y a la vez utilizando el programa de I.A. para realizar la supervisión inteligente de la simulac ión. El estudio realizado es de tipo correlacional, lo cual implica la relación entre las variables de posicionamiento en un proceso de ensamblaje vehicular. Este tipo de procesos necesitan manejar estrictos estándares de montaje para poder cumplir con las expectativas de la actual industria automovilística, la cual requiere de una amplia capacidad de procesamiento para realizar la administración y toma de decisiones con respecto a esta clase de aplicaciones. Los resultados de las pruebas de simulación arrojaron los siguientes resultados: Las mediciones de la posición de las piezas a trasladar se realizaron correctamente, la supervisión y control inteligente de los elementos del proceso, cintas transportadoras, brazos robóticos, piezas, etc. El algoritmo basado en lógica difusa, para la supervisión de la simulación del proceso industrial de tipo línea de ensamblaje vehicular, logró optimizar el control, la supervisión y adquisición de datos del proceso analizado.In the present degree work, the design of a SCADA system for the supervision of an industrial process has been carried out applying artificial intelligence through algorithms of fuzzy logic, for this the industrial environment must be designed and simulated through the CODESYS program, the which allows to program this process, and at the same time using the AI program to perform intelligent simula t ion monitoring. The study carried out is of a correlational type, which implies the relationship between the positioning variables in a vehicular assembly process. These types of processes need to handle strict assembly standards in order to meet the expectations of the current automobile industry, which requires ample processing capacity to perform the administration and decision making regarding this kind of applications. The results of the simulation tests yielded the following results: The measurements of the position of the pieces to be transferred were carried out correctly, the intelligent supervision and control of the process elements, conveyor belts, robotic arms, parts, etc. The algorithm based on fuzzy logic, for the supervision of the simulation of the industrial process of the vehicle assembly line type, managed to optimize the control, supervision and data acquisition of the analyzed process.\n"}
{"prompt":"Reclutadores: entre la agilidad de la inteligencia artificial y la emotividad de la interacción humana ->","completion":" Se puede llegar a un punto en el que se podría complementar lo cuantitativo y cualitativo, es decir la IA con la interpretación humana para obtener muy buenos resultados en el proceso de adquisición de talento, eso sí, cuidando uno de los mayores riesgos: el ético\n"}
{"prompt":"Complejidad formal en ladrillo ->","completion":" El presente estudio muestra una recopilaci?n de las diferentes estrategias empleadas para el dise?o y construcci?n de formas complejas que emplean el ladrillo como material principal. Adem?s de esta categorizaci?n tambi?n se analizan las posibles causas que conllevan a la decisi?n de modificar el aparejo de ladrillo com?n.\n"}
{"prompt":"Complejidad, epistemología y multirreferencialidad ->","completion":" Pensamos seriamente en las dificultades para muchos estudiantes de educación de poder explicar y aplicar la epistemología, ya sea porque no la saben, porque poco la conocen o porque quién sabe si podrán creer en sus bondades científicas. A menudo los cursos de epistemología se vuelven densos y teóricos, de difícil entendimiento y en consecuencia los estudiantes poco saben usar sus conceptos y fundamentos. Puede suceder lo que menciona M. Quintana (1983, en Bartomeu, Juárez, Juárez, y Santiago, 1992: 234), que “los epistemólogos no conocen la pedagogía y los pedagogos no saben epistemología”. Nos preguntamos si un estudiante de maestría en prácticas educativas, desarrollo docente, investigación educativa, etc., puede emplear nociones y conceptos de la epistemología con sus alumnos en su tarea docente; es decir, cómo es posible llevar los aprendizajes de la epistemología adquiridos en el aula o de las lecturas de investigación, de las asesorías de tesis, etc., de parte de los estudiantes a un campo de la realidad práctica de su trabajo docente. Deseamos analizar algunos elementos de la “cima” del conocimiento de la epistemología y poderlos llevar al “valle” de la realidad donde se desarrolla la vida académica, sin caer en una falsa epistemología o en una equivocada pedagogía.\n"}
{"prompt":"Globalización y nueva complejidad social ->","completion":" El mundo está atravesando una transición de una sociedad industrial, que giraba en torno del trabajo como fuerza y valor, hacia una sociedad del conocimiento, cuyo núcleo es la información y la capacidad para manejarla y producirla. Esta transformación, que tiende a darse a escala global, ha sido impulsada fundamentalmente por los cambios producidos en el plano de la tecno-economía, cuyos actores primordiales son las transnacionales y los científicos y profesionales de la información. En el plano de la política, que no alcanza a dar respuesta a estos cambios, han cumplido un rol importante los nuevos movimientos sociales, que desplazaron la centralidad de los partidos políticos y de los movimientos sociales clásicos, como los sindicatos.\n"}
{"prompt":"COMPLEJIDAD EN LA MORFOGÉNESIS ARQUITECTÓNICA; ->","completion":" En el presente trabajo se discute sobre la situación de la educación en Universidades de Arquitectura, problemas de la estructura analista para el alumnado y un vértice de cómo dialogar, interpretar y proponer conceptos de otras disciplinas para justificar y generar una propuesta de proyecto arquitectónico como herramienta de diseño.  La propuesta planteada no intenta generar una analogía como inspiración al proceso proyectual sino evidenciar la manera en que el alumno puede valerse de conceptos, teorías o modelos de otras disciplinas para generar un discurso arquitectónico que defienda un proceso de diseño; así también se genera un punto de vista donde el proceso proyectual debe estar vinculado a enseñar al alumno a pensar, diseñar y proyectar como síntesis sustentado en la interdisciplinariedad y ciencias de la complejidad como un enfoque de diálogo entre saberes que permiten la generación de un discurso en el desarrollo proyectual de arquitectura y que debe evidenciarse en la concepción morfológica del proyecto. Palabras claveProceso proyectual, síntesis, complejidad, morfogénesis, diálogo interdisciplinar. AbstractIn the present work, the educational situation in Architecture Universities is discussed, as well as problems in the analyst structure for the student body and a vertex in how to discuss, interpret and propose concepts of other disciplines in order to justify and generate a proposal of the architectural project as a design tool. This proposal does not attempt to generate an analogy as inspiration to the design process, but to gain evidence as an effort to show how concepts, theories and models from other subjects can encourage students to create an architectural discourse that stands for a design process. This also develops a different point of view where the design process must be linked to teach the student how to think, design and project as a synthesis based on the interdisciplinary and complexity sciences as an approach to the dialogues of knowledge. This allows the generation of a discourse in the design development of architecture, which will evidence the morphological conception of the project.KeywordsProject process, synthesis, complexity, morphogenesis, interdisciplinary dialogue.\n"}
{"prompt":"Lo disciplinar de la complejidad ->","completion":" El 01 de octubre de 2021, se cumplió sesenta y dos (62) años de vida institucional, como Facultad de Arquitectura y Urbanismo, y setenta y cinco (75) años como Escuela de Arquitectura, comenzó a funcionar en el año de 1946, anexa a la Facultad de Ciencias Físicas y Matemáticas.\n"}
{"prompt":"La democracia enfrentada a la complejidad ->","completion":" La creciente complejidad social y económica pone nuevos retos a la capacidad de organización política de las sociedades, complejidad respecto de la cual los ordenamientos democráticos no estarían preparados. Al no lograr enfrentar estas nuevas condiciones de complejidad, la democracia termina por generar obstáculos o problemas a las propias lógicas económicas, sociales y productivas, deteniendo su capacidad de innovación.\n"}
{"prompt":"Internación domiciliaria para pacientes crónicos de alta complejidad ->","completion":" Servicios de Salud BAC is an Enterprise focused in chronic patients that require mechanical ventilation for life support. The main goal is to develop a business plan of an enterprise that guarantees quality medical services for chronic patients health care in their homes with their family as their principal care taker. This service is achieved with the contingent of specialists who are going along with the patient and the family optimizing in this way the capacity installed in the intensive cares area of public health institutions reducing costs of attention for this group of patients. Focusing on chronic patients group of different pathologies, the highest percentage of diseases that require of mechanical ventilation are neuromuscular diseases with a 43% of registered cases. These analyzed groups represent 1,399 of Pichinchas patients expenses in 2011, with an average of 116 patients in a month that leave from the Health Institutions with this pathology. These statistics are confirmed by the census accomplished to critical patients that have been checked in ICU of the Social Security Hospital and Private Health Care Hospitals where 58% of patients have the indicated pathology. The data variation is because of the inadequate distribution of outcomes of Health Care Institution. The quantity of beds in the Intensive cares area is less than the quantity required by the Public Health Ministry, which generate a deficit of 18% on the needed infrastructure. Chronic Patients are part of the 43% of ICU beds. Public Health Insurance Companies as IESS, ISSPOL and ISSFA are the only ones that offer unlimited coverage to their beneficiaries. Now a days IESS has coverage of 51% of the Ecuadorian population as beneficiaries of a Health System. This percentage is going to increase with the Universal Insurance project which is in discussion. This business model is feasible for its execution, with an invest of 100,000.00 USD and an indebtedness of 169,687.00. The net utility would be 12% on the first year with an increase of 17% on the second year. On the third year there is a decrease on the utility on a 12%, this is because of the competitors incomes that is going to reduce the price in a 15%. On the fifth year there is an estimate increase of a 14%. The project TIR would be 43.08% with a 10.08% of discount rate and 4,760,172 of VAN.La empresa de Servicios de Salud BAC es una empresa enfocada a la atención de pacientes crónicos de alta complejidad que requieren ventilación mecánica como soporte de vida. El objetivo principal es desarrollar un plan de negocios de una empresa que garantice la calidad de servicio médico para el cuidado de salud de los pacientes crónicos de alta complejidad en sus domicilios con la familia como cuidador primario. Este servicio se logra con el contingente de especialistas que acompañarán al paciente y a la familia en sus hogares optimizando de esta manera la capacidad instalada de las áreas de cuidados intensivos de las instituciones de salud pública y la reducción de costos de atención al grupo de pacientes crónicos. De acuerdo a la agrupación realizada por tipo de patología el mayor porcentaje de las enfermedades, que derivan en una condición que requieren ventilación mecánica como soporte de vida, son las Patologías Neuromusculares con el 43 % de los casos registrados. Este grupo analizado corresponde a 1,399 egresos de pacientes en el año 2011 en la provincia de Pichincha, con un promedio de 116 pacientes mensuales que egresaron de las Instituciones de Salud con esta patología. Esta tendencia se confirma con el censo realizado a los pacientes críticos que están siendo atendidos en las Unidades de Cuidados Intensivos (UCI) del Hospital del Seguro Social y de los Hospitales Privados de Salud, en donde el 58 % tiene la patología indicada. Los datos varían por la falta de distribución inadecuada de los egresos en las Instituciones de Salud. Las camas en las Unidades de Cuidados Intensivos son menores a las requeridas por el Ministerio de Salud Pública (MSP), lo que genera un déficit del 18% en la infraestructura requerida. Los pacientes crónicos ocupan actualmente el 43% de ocupación de las camas de UCI. Las Aseguradoras Públicas, IESS, ISSPOL e ISSFA son las únicas que brindan cobertura ilimitada a sus beneficiarios. El IESS actualmente tiene cubierto al 51% de la población en el Ecuador como beneficiarios del Sistema de Salud, este porcentaje va a aumentar con el proyecto de Aseguramiento Universal que está en discusión. Este modelo de negocio es viable para su ejecución, con una inversión de 100,000.00 USD y un endeudamiento de 169,687.00 se obtiene una Utilidad Neta del 12% en el primer año y con incremento al 17% para en el segundo año, en el tercer año existe una baja en la Utilidad Neta al 12% ya que se prevé el ingreso de competidores lo cual hará que el precio de venta baje en un 15%. En el quinto año se proyecta un crecimiento al 14%. El TIR del proyecto es del 43.08% con una tasa de descuento de 10.08% y un VAN de 4, 760,172 USD.\n"}
{"prompt":"El documental en la era de la complejidad ->","completion":" Del 14 al 16 de mayo de 2013, la Universidad Andina Simón Bolívar, en coordinación con la Corporación Cinememoria, llevó a cabo el Coloquio Internacional de Cine Documental. El evento, realizado en el contexto de la décima segunda edición del Festival Encuentros del Otro Cine (EDOC), tuvo como finalidad establecer un espacio de discusión académica sobre el cine documental que acompañe a los procesos de expansión de la producción y consumo que este género ha tenido en la última década en el país. El evento buscó dar a conocer los debates teóricos contemporáneos sobre el cine documental, así como también estimular la investigación y producción teórica sobre el documental ecuatoriano. Este libro constituye una memoria de los debates planteados en el Coloquio; recoge las conferencias y ponencias, excepto algunas que no pudieron ser presentadas por razones de fuerza mayor, excluye la actividad de los talleres que por la naturaleza de su formato no calzaban adecuadamente dentro del esquema de esta publicación. La publicación de estos materiales, debidamente evaluados, revisados y editados, constituye una forma de continuar el debate y el diálogo.\n"}
{"prompt":"Metodologías participativas con enfoque integrador desde la complejidad ->","completion":" El artículo presenta una revisión literaria científica de propuestas que han surgido ante el predominio epistemológico del positivismo y de una visión reduccionista y mecanicista del mundo. Estas alternativas son: La teoría de la complejidad que supera el pensamiento reduccionista, mecanicista y dicotómico; ya que permite analizar la realidad desde diversas perspectivas, enfoques y saberes, y al mismo tiempo cataliza la transformación y el cambio de situaciones. La teoría de sistemas en la que se propone que el cambio de la realidad viene desde los sistemas emergentes o auto organizados. Las Metodologías participativas que plantean diversas técnicas que promueven el diálogo entre el saber académico y el saber social (popular). Enfoques integradores y descolonizadores del pensamiento que trascienden y desbordan el positivismo como modos de producción de conocimiento basados en relaciones sujeto–sujeto, más que en sujeto-objeto.The article presents a scientific literature review of proposals that have emerged with the epistemological dominance of positivism, reductionist and mechanistic worldview.These alternatives are: The complexity theory that exceeds the reductionist, mechanistic and dichotomous thinking, and allows to analyze the reality from different perspectives, approaches and knowledge, and catalyzes the transformation and changing situations. The systems theory , which proposed that the change actually comes from the selforganizing and emergent systems. The Participatory Methodologies raising various techniques that promote dialogue between academic knowledge and social knowledge (popular). Integrative approaches and decolonization thoughts that transcend and go beyond positivism as modes of knowledge production based on subject-subject relations, rather than subject-object relations.\n"}
{"prompt":"Barrio Nigeria: calidad de vida, buen vivir y complejidad ->","completion":" Este texto recoge un análisis de la calidad de vida, buen vivir y complejidad de los hermanos afroecuatorianos del barrio Nigeria, ubicado en la ciudad de Guayaquil. Además, muestra el progreso que estas personas han logrado mediante el trabajo y sacrificio en búsqueda de la construcción de su propio buen vivir. El estudio detalla aquellos rasgos complejos que constituyen al hermano afroecuatoriano migrante que dejó su provincia natal (Esmeraldas), en búsqueda de mejores días, sobre todo, por alcanzar el llamado crecimiento propuesto desde una visión occidentalizada. Se plantea un análisis de los diversos subsistemas (educación, salud, cultura, representación política, etc.) que conforman este sistema social llamado barrio Nigeria. También recoge la riqueza cultural del pueblo afro, la lucha que mantiene por su preservación, la identidad que se enfrenta al paradigma de la occidentalización. Por otro lado, como dos caras de una misma moneda, se reflejan los peligros que existen en una sociedad donde la pobreza y miseria traen como consecuencia la violencia y consumo de drogas. Por último, en la narrativa del texto, se evidencia la intervención realizada desde diferentes instituciones y personas que han contribuido al desarrollo de esta ciudad.\n"}
{"prompt":"La educación bajo el signo de la complejidad ->","completion":" La complejidad involucra la adopción de una nueva visión del mundo, de uno mismo y de las relaciones entre varios niveles implicados. El problema básico es que existe una desarticulación entre un discurso que declara la complejidad como constructo esencial y una práctica esquemática y reduccionista que genera un contexto incoherente para el aprendizaje. Se trata de introducir una comprensión holística que pretende responder a los nuevos desafíos que la vida y el ecosistema plantean en el momento actual. El objetivo es considerar algunas reflexiones acerca de la complejidad para luego, plantear la educación desde esta visión usando una metodología descriptiva y analítica, desde una postura reflexiva, en diálogo entre diversas posturas y con aportes de varios autores para tratar de volver simple algo que es complejo en sí mismo. Para realizar el recorrido, se plantean algunas ideas introductorias sobre el tema; luego se define la complejidad desde su origen semántico para caracterizarla en sus elementos más determinantes. Posteriormente, se pasa a describir sus principios: dialógico, de recursividad organizacional y hologramático. En un siguiente momento, se plantea la educación y los elementos que debe considerar para volverse compleja y terminar con el planteamiento de algunos desafíos que enfrentan las personas si desean proponer o aún más, desarrollar una Educación bajo el Signo de la Complejidad.\/\/Complexity involves the adoption of a new vision of the world, of oneself and of the relationships between various levels involved. The basic problem is that there is a disarticulation between a discourse that declares complexity as an essential construct and a schematic and reductionist practice that generates an incoherent context for learning. It is about introducing a holistic understanding that aims to respond to the new challenges that life and the ecosystem pose at the present time. The objective is to consider some reflections on complexity and then approach education from this perspective using a descriptive and analytical methodology, from a reflective position, in dialogue between different positions and with contributions from various authors to try to make something that is simple complex in itself. To carry out the tour, some introductory ideas are raised on the subject; then complexity is defined from its semantic origin to characterize it in its most determining elements. Later, it goes on to describe its principles: dialogic, organizational recursion and hologram. In a next moment, education is presented and the elements that must be considered to become complex to end with the exposition of some challenges that people face if they want to propose and even more, develop an Education under the Sign of Complexity.\n"}
{"prompt":"El movimiento estudiantil secundario en Chile abordado desde la complejidad ->","completion":" Este artículo tiene por objetivo analizar el movimiento estudiantil secundario de Chile desde un abordaje transdisciplinar, como fenómeno complejo insuficientemente investigado y reflexionado por parte de las ciencias sociales y las humanidades. El problema general en el que se inscribe este objetivo es el de la crisis de las instituciones de la democracia liberal, y más específicamente, el de las relaciones entre los conceptos de ciudadanía y complejidad, para la interpretación del movimiento estudiantil secundario. Partiendo de la distinción entre aquella participación ciudadana que se concreta bajo formas institucionalizadas de delegación del poder en una elite política; y una ciudadanía participativa, crítica y transformadora, que promueve y se realiza en formas de asociación y organización política igualitarias, en el ejercicio de una soberanía como praxis comprometida con la construcción de lo público y del bien común. La información ha sido analizada recurriendo a métodos hermenéutico-comprensivos propios de las ciencias sociales y las humanidades, cuyos fundamentos dialogan con la tradición del pensamiento complejo, convergiendo en la crítica al reduccionismo positivista del conocimiento. Se concluye estableciendo la existencia de una tendencia o transición al interior del movimiento estudiantil secundario, que va desde formas de asociatividad y organizaciones propias del modelo liberal, que delega la soberanía de la ciudadanía en representantes electos o electas, hacia la preeminencia de otra corriente, de carácter contra hegemónico: un modelo democrático de participación directa e igualitaria en el autogobierno comunitario.\/\/This article aims to analyze the secondary student movement in Chile from a transdisciplinary approach, as a complex phenomenon insufficiently investigated and reflected on by the social sciences and humanities. The general problem in which this objective is inscribed is that of the crisis in the institutions of liberal democracy, and more specifically, that of the relations between the concepts of citizenship and complexity, for the interpretation of the secondary student movement. Starting from the distinction between that citizen participation that takes shape under institutionalized forms of delegation of power in a political elite; and a participative, critical and transforming citizenship, which promotes and is carried out in forms of egalitarian association and political organization, in the exercise of sovereignty as praxis committed to the construction of the public and the common good. The information has been analyzed using hermeneutic-comprehensive methods typical of the social sciences and humanities, the foundations of which dialogue with the tradition of complex thought, converging in the critique of positivist reductionism of knowledge. It concludes by establishing the existence of a trend or transition within the secondary student movement, which goes from forms of association and organization typical of the liberal model, which delegates the sovereignty of citizenship to elected representatives, towards the preeminence of another current, Counter-hegemonic in character: a democratic model of direct and equal participation in community self-government.\n"}
{"prompt":"Epistemología de la evaluación educativa desde la teoría de complejidad ->","completion":" This research: “Epistemology of the educational evaluation from the theory of Complexity”, highlights the deep relationship between the epistemologic field, the contribution of the theory of Complexity, and the influence of the Positive Sciences in the account of the evaluation of the teaching-learning process; stating a process of analysis regarding to the reductions in which the educational evaluation lays. Therefore, I highlight the importance of establishing epistemological considerations about the structure of the sciences, starting from an historical analysis of the scientific method that highlights Galilee’s and Aristotle’s models to visualize how the positive sciences in modernity emerge and they have become absolute methodically under mathematical and quantitative strict conditions as a result of a type of instrumental rationality.El presente trabajo investigativo: “Epistemología de la evaluación educativa desde la teoría de la complejidad”, resalta la íntima relación entre el campo epistemológico, los aportes de la teoría de la complejidad y la influencia de las ciencias positivas en la evaluación de los procesos de enseñanza – aprendizaje, planteando un proceso de análisis en torno a los reduccionismos en los que ha incurrido la práctica de la evaluación educativa. En este sentido, resaltamos la importancia de establecer consideraciones epistemológicas sobre la estructura de las ciencias, partiendo de un breve análisis histórico del método científico que resalta los modelos de Aristóteles y Galileo, hasta poder visualizar cómo surgen las ciencias positivas en la modernidad y se absolutizan metódicamente bajo condiciones estrictamente matemáticas y cuantitativas fruto de un tipo de racionalidad instrumental.\n"}
{"prompt":"Metodologías participativas con enfoque integrador desde la complejidad ->","completion":" El artículo presenta una revisión literaria científica de propuestas que han surgido ante el predominio epistemológico del positivismo y de una visión reduccionista y mecanicista del mundo. Estas alternativas son: La teoría de la complejidad que supera el pensamiento reduccionista, mecanicista y dicotómico; ya que permite analizar la realidad desde diversas perspectivas, enfoques y saberes, y al mismo tiempo cataliza la transformación y el cambio de situaciones. La teoría de sistemas en la que se propone que el cambio de la realidad viene desde los sistemas emergentes o auto organizados. Las Metodologías participativas que plantean diversas técnicas que promueven el diálogo entre el saber académico y el saber social (popular). Enfoques integradores y descolonizadores del pensamiento que trascienden y desbordan el positivismo como modos de producción de conocimiento basados en relaciones sujeto–sujeto, más que en sujeto-objeto.The article presents a scientific literature review of proposals that have emerged with the epistemological dominance of positivism, reductionist and mechanistic worldview. These alternatives are: The complexity theory that exceeds the reductionist, mechanistic and dichotomous thinking, and allows to analyze the reality from different perspectives, approaches and knowledge, and catalyzes the transformation and changing situations. The systems theory , which proposed that the change actually comes from the selforganizing and emergent systems. The Participatory Methodologies raising various techniques that promote dialogue between academic knowledge and social knowledge (popular). Integrative approaches and decolonization thoughts that transcend and go beyond positivism as modes of knowledge production based on subject-subject relations, rather than subject object relations.Cuencanúmero 20\n"}
{"prompt":"La complejidad de la violencia en el aula ->","completion":" Hay tanta desconfianza con la teoría que no es extraño escuchar frases como: ¿Para qué explicar o analizar la violencia? Es como si las explicaciones no tuvieran ninguna importancia, dándole énfasis a la interpretación Marxista de la tesis de Feuerbach: “Busquemos las soluciones al problema en lugar de interpretaciones”.\n"}
{"prompt":"¿Cómo gobernar la complejidad urbana? Mesa Plenaria Gobernabilidad ->","completion":" En el auditorio de la Universidad del Azuay, el día jueves 5 de octubre en la mañana, se llevó a cabo la cuarta mesa temática del Congreso de Estudios de la Ciudad, en la cual se abordó el tema ¿Cómo gobernar la complejidad urbana? La presentación estuvo a cargo de Jaime Erazo, quien resaltó la importancia de la gobernanza en el desarrollo político y espacial de las ciudades; recalcó, además, que está ligada a las diversas formas de gestión, el bienestar de la ciudadanía y los procesos que hacen posible la toma de decisiones para garantizar la accesibilidad a los servicios.\n"}
{"prompt":"Elaboración de protocolos de remisión en emergencias obstétricas desde niveles de baja complejidad ->","completion":" PDFLa mortalidad materna evitable se incrementa por el abordaje inadecuado de las pacientes, desacierto en diagnósticos, tratamientos no adecuados y retardo en las remisiones. Por lo anterior, es necesario dotar a los profesionales de la salud que atienden las EO en niveles de baja complejidad de protocolos de atención médica prácticos y de fácil adherencia, que los guie en el diagnóstico, tratamiento inicial y remisión a los hospitales de referencia, en condiciones adecuadas para continuar con el tratamiento médico o quirúrgico indicado. Se revisaron las historias clínicas de las muertes maternas ocurridas en el Hospital Gineco-Obstétrico Enrique C Sotomayor en el año 2015. Se aplicó una entrevista no estructurada a médicos del servicio de admisiones y urgencias del citado hospital, la cual indagó sobre sus conceptos sobre las remisiones recibidas y el uso de los protocolos en los niveles de atención de baja complejidad. Se realizó una revisión sistemática con las palabras clave, mortalidad materna, emergencia obstétrica y protocolos de atención, con el fin de obtener consenso sobre diagnóstico y tratamiento inicial de las EO. Por último se realizó búsqueda manual en las GPC de Ecuador, Colombia y México también en busca de consenso para la aplicación de intervencionesPreventable maternal mortality is increased by the inadequate approach of patients, mistake in diagnosis, inadequate treatment and delayed referrals. Therefore, it is necessary to provide health professionals serving the EO in levels of low complexity of protocols of practical medical care and easy to grip, to lead them in the diagnosis, initial treatment and referral to referral hospitals, under conditions suitable to continue the medical or surgical treatment indicated. The medical records of maternal deaths in the Obstetric-Gynecologic Hospital Enrique C. Sotomayor in 2015. It reviewed an unstructured interview medical service admissions and emergency department of that hospital, which asked about his views on the was applied referrals received and the use of protocols in the levels of care of low complexity. a systematic review with keywords, maternal mortality, emergency obstetric care protocols, in order to obtain consensus on diagnosis and initial treatment of EO was performed. Finally manual search was conducted in the CPG Ecuador, Colombia and Mexico also looking for consensus for the implementation of interventions..Universidad de Guayaquil. Facultad de Ciencias Médicas. Escuela de Graduados\n"}
{"prompt":"Jugar para \"aprender (por fin) a vivir\", o la complejidad del juego como estrategia pedagógica ->","completion":" El diálogo con las experiencias que se describen en este artículo busca resaltar el valor pedagógico del juego como acción ritual y cuya finalidad es vivir la libertad. Sin embargo, esta condición liberadora no siempre se presenta cuando el juego se usa como estrategia pedagógica, porque al ser parte de la planeación educativa, el juego debe cumplir un objetivo, que como tal lo alejaría de su condición liberadora.\n"}
{"prompt":"LA COMPLEJIDAD EN LAS ESTRUCTURAS DE LA VIOLENCIA: UNA MIRADA DESDE EL PROCESO EDUCATIVO ->","completion":" es el inicio de un camino de investigación1. No se trata de un ensayo con resultados y conclusiones, sino del recuento de una hipótesis, una cartografía de lo que queremos investigar. El tema de estudio es ‘la violencia’ y su interés es hacer las conexiones de ésta con la educación vivida en los sectores campesinos, periféricos de las urbes e indígenas de nuestro país. La motivación para realizar este documento surge de una larga trayectoria de trabajo con docentes y futuros docentes de los sectores nombrados, con quienes hemos debatido el tema de la violencia y, generalmente, terminamos referidos a nosotros mismos, a nuestros pasados, a nuestras experiencias educativas.\n"}
{"prompt":"Lógica clásica y lógica difusa: Facetas que las caracterizan ->","completion":" El análisis de información bibliográfica, como proceso metodológico para este artículo, condujo a la elaboración de matrices correspondientes a cada una de las facetas: lógica, relacional, epistémica y de conjuntos, de las lógicas clásica y difusa. La interrelación y análisis de las diferentes premisas constantes en estas matrices permitió la diversificación en la concepción de cada una de ellas, considerando a la lógica clásica como ciencia de los principios formales y normativos del razonamiento, que centra su atención en la forma lógica de adoptar los pensamientos para la construcción de lenguajes formales con claridad y precisión, y a la lógica difusa como ciencia de los principios formales del razonamiento aproximado, flexible y tolerante con la imprecisión, capaz de modelar problemas no lineales.Además, se manifiestan sucintamente aplicaciones de la lógica difusa, entre otras: los sistemas de control y redes neuronales.Palabras clave: Lógica, sistemas de control, redes neuronales.Analysis of bibliographic information, such as methodological process for this article, led to the elaboration of matrices corresponding to each of the facets: logical, relational, epistemic and sets, from classic and diffuse logics. The interrelationship and analysis of different premises constants in these arrays allowed the diversification in the conception of each of them, whereas the classical logic as a science of the formal and regulatory principles of reasoning, which focuses on the logical form of adopting the thoughts to the construction of formal languages with clarity and precision, and diffuse logic as the science of the formal principles of approximate reasoning, flexible and tolerant of imprecision, capable of modeling non-linear problems. In addition, applications of diffuse logic are briefly manifested, among others: control systems and neural networks.Keywords: Logic, control systems, neural networks.\n"}
{"prompt":"Lógica clásica y lógica difusa: Facetas que las caracterizan ->","completion":" El análisis de información bibliográfica, como proceso metodológico para este artículo, condujo a la elaboración de matrices correspondientes a cada una de las facetas: lógica, relacional, epistémica y de conjuntos, de las lógicas clásica y difusa. La interrelación y análisis de las diferentes premisas constantes en estas matrices permitió la diversificación en la concepción de cada una de ellas, considerando a la lógica clásica como ciencia de los principios formales y normativos del razonamiento, que centra su atención en la forma lógica de adoptar los pensamientos para la construcción de lenguajes formales con claridad y precisión, y a la lógica difusa como ciencia de los principios formales del razonamiento aproximado, flexible y tolerante con la imprecisión, capaz de modelar problemas no lineales. Además, se manifiestan sucintamente aplicaciones de la lógica difusa, entre otras: los sistemas de control y redes neuronales.Analysis of bibliographic information, such as methodological process for this article, led to the elaboration of matrices corresponding to each of the facets: logical, relational, epistemic and sets, from classic and diffuse logics. The interrelationship and analysis of different premises constants in these arrays allowed the diversification in the conception of each of them, whereas the classical logic as a science of the formal and regulatory principles of reasoning, which focuses on the logical form of adopting the thoughts to the construction of formal languages with clarity and precision, and diffuse logic as the science of the formal principles of approximate reasoning, flexible and tolerant of imprecision, capable of modeling non-linear problems. In addition, applications of diffuse logic are briefly manifested, among others: control systems and neural networks.Cuencanúmero 2\n"}
{"prompt":"Lógica clásica y lógica difusa, facetas que la caracteriza ->","completion":" En el presente artículo se consideran algunos aspectos que caracterizan la lógica clásica y la lógica difusa. Caracterizaciones que diversifican la concepción de cada una de ellas, considerando a la lógica clásica como ciencia de los principios formales y normativos del razonamiento, que centra su atención en la forma lógica de adoptar los pensamientos para la construcción de lenguajes formales con claridad y precisión, y a la lógica difusa, como ciencia de los principios formales del razonamiento aproximado, flexible y tolerante con la imprecisión, capaz de modelar problemas no lineales. Se exterioriza además, lo pertinente a las aplicaciones de la lógica difusa, entre otras: sistemas de control y redes neuronales.Diplomado Superior en Docencia UniversitariaCuenca\n"}
{"prompt":"La memoria lógica ->","completion":" Antes de ceñirnos al desarrollo cíe* nuestro tema, nos parece prudente detenernos por algunos momentos en una breve descripción de lo que se entiende por memoria en general.La memoria no es la unidad qye fácilmente creemos comprender todos; es un complejo de naturaleza elevada, razón por la cual no es tarea demasiado fácil el encontrar una definición que abarque todo y sólo el definido.\n"}
{"prompt":"Psicoanálisis : de la lógica del bienestar a la lógica del malestar en Freud (una aproximación epistemológica) ->","completion":" En el territorio de la teoría psicoanalítica de Freud es imprescindible hacer una introducción a los cuestionamientos por una epistemología, a la que el Psicoanálisis tendrá que situarse de frente, dando por tanto como resultado una relación de vecindad con otras construcciones sobre el sujeto. Este trabajo desde la clínica freudiana trata de responder algunas cuestiones sobre la construcción de un sujeto –muy particular- inaccesible por vía directa, pues se reconoce desde el inconsciente como una fórmula a la que se adhieren infinitas relecturas; por esta razón el compromiso en todo el texto es con un recorrido teórico desde diversas disciplinas que en su relación con el psicoanálisis se ocupan de la cuestión primordial del sujeto; los enlaces que en este texto se presentan son, en cierto modo, la medida del vasto dominio de saber sobre el malestar fundado en su forma más profunda como determinación del inconsciente y que se opone a toda idea de estabilidad orgánica que se presenta como la égida ideológica de la Medicina; esta impronta recorre todo el escrito freudiano y, he allí la importancia de lo aquí propuesto en aras de la construcción de una epistemología del psicoanálisis en su proximidad. Este trabajo aborda la concepción del sujeto desde las Ciencias positivas, incluyendo directamente la relación con la Medicina –sobre todo en el dominio de lo neurológico y psiquiátrico? sobre todo lo correspondiente al conocimiento sobre las enfermedades orgánicas subyacentes en los así llamados “trastornos mentales”. En esta intersección el texto presenta los diferentes argumentos y discusiones que se han sostenido desde que aparecieron los aportes y construcciones teóricas que Freud pone sobre la mesa; por esta razón, el texto participa de la contingencia que implica abrir la Caja de Pandora; especialmente en esos avatares que en última instancia se hace necesario leerlos y releerlos. Lo que está debajo de la epistemología que sostiene a todos los campos del saber aquí se expone a través de toda la textura conceptu\n"}
{"prompt":"Evaluación de los Esquemas de Automatización Industrial de Lógica Cableada y Lógica Programada. ->","completion":" Se evaluó circuitos de automatización industrial de lógica cableada y automática en el laboratorio de Máquinas Eléctricas perteneciente a la Escuela de Ingeniería Electrónica en Control y Redes Industriales, Facultad de Informática y Electrónica de la Escuela Superior Politécnica de Chimborazo. El propósito de esta investigación es evaluar la tecnología disponible para realizar maniobras en la industria además de estudiar las condiciones en que trabajan los dispositivos considerando la tecnología de automatismos cableados y tecnología programada. La investigación partió con la adquisición de datos a través de encuestas dirigidas al personal técnico de diferentes empresas e industrias a nivel nacional, continuamos procesando datos obtenidos para la comprobación de nuestra hipótesis y elección de circuitos. Se elaboraron Módulos para entrenamiento didáctico de automatización industrial, mediante lógica cableada a base de dispositivos electromecánicos así como lógica programada con los controladores Lógicos Programables (PLC). Los módulos constan de una estructura de hierro con aluminio que sirven como soporte de dispositivos eléctricos, se equipó un controlador lógico programable (PLC) marca elemecanique con Software Zelio para automatizar algunas aplicaciones industriales. A demás poseen 4 contactores con cámaras de expansión, 4 contactos auxiliares los cuales sirven para aplicar la técnica cableada; para la señalización de procesos usamos 4 lámparas led piloto rojo, amarillo, verde y azul, empleamos pulsadores de parada tipo Hongo, selectores de 3 posiciones, dos pulsadores de inicio y dos de parada, interruptores automáticos bifásicos como elementos de control para circuitos. Al realizar pruebas en los módulos llegamos a comparar diferencias entre las técnicas mencionadas anteriormente, el correcto manejos de los dispositivos, a partir del método estadístico chi cuadrado se encontró el valor de la hipótesis alternativa correspondiente a 120,79 así como la hipótesis nula de valor 90,53. Por lo tanto se rechazó la hipótesis nula y se aceptó la hipótesis alternativa. Concluimos la similar importancia de las técnicas evaluadas en esta investigación de acuerdo al ambiente en el que se van a desempeñar. Se recomienda a los docentes de la Escuela ingeniería electrónica en Control y Redes Industriales hacer uso de esta investigación juntamente con la aplicación práctica reflejada en los módulos a sus estudiantes para desarrollar un mejor desenvolvimiento en el ámbito industrial.The industrial automation circuits of wired and automatic logic were evaluated in the Electrical Machines Laboratory of Electronics Engineering in Control and Industrial Network School, Faculty of Electronics y Computer Science at Escuela Superior Politécnica de Chimborazo. The purpose of this research is to evaluate the available technology in order to carry out maneuvers in the industry, as well as to study the conditions under which the devices work considering the wired automatisms technology and programmed technology. The research started collecting data by surveys to technical staff from different companies and industries at the national level, after that, we processed data for testing our hypothesis and choice of circuits. Didactic training modules for industrial automation were developed by wired logic based on electromechanical devices as well as programmed logic with programmable logic controllers (PLC). The modules consist of a steel structure with aluminum which serve as a support for electrical devices, elemecanique programmable logic controller (PLC) with software Zelio was equipped to automate some industrial applications. In addition, they have four expansion chambers contactors, 4 auxiliary contacts which serve to implement the wired technique; we used for signaling processes 4 LED lamps red, yellow, green and blue, we use mushroom, Stop pushbuttons, 3 rotary push buttons, two start buttons and 2 stop buttons, two-phase circuit breakers as control elements to circuits. When we tested on the modules, we compare differences between the techniques described above and the proper handling of the devices. Using Chi-Square method, we found the value of the alternative hypothesis corresponding to 120.79as well as he value of the null hypothesis 90.53. There before the null hypothesis was rejected and the alternative hypothesis was accepted. We conclude similar importance of evaluated techniques in the research according to the environment in which they will play. It is recommended that Teachers of Engineering in Control and Industrial Network School use this research as well as the reflected practical application in the modules to their students in order to create a better development in the industrial sector.\n"}
{"prompt":"Lógica simbólica para quinto curso ->","completion":" Profesor de Segunda Enseñanza. Especialidad en Filosofía, Sociología y EconomíaCuenca\n"}
{"prompt":"Estrategias didácticas en la comprensión lógica-matemática. ->","completion":" Durante los últimos periodos lectivos, en la Unidad Educativa Francisco Huerta Rendón se ha registrado falencias en la compresión de lógica matemática por parte del alumnado. Como consecuencia, de la falta de herramientas didácticas, las malas estrategias pedagógicas y las problemáticas sociales que padecen los estudiantes; para ello se dispuso a realizar una guía interactiva que brinde mayor apoyo tanto para el personal docente como para el estudiantado de 9no año de educación básica, quienes ampliarán sus conocimientos mientras aprenden de una manera más activa, fácil y motivadora. Los resultados de la propuesta, son que exista mayor compresión, nuevas formas de aprendizaje y formar jóvenes que les guste aprender más y sean ávidos en conocimiento. He aquí, la relevancia subsiste en que las nuevas generaciones de la institución en estudio podrán aportar en gran magnitud a la sociedad, por medio de su mejora en habilidades de pensamiento lógico y numérico.\n"}
{"prompt":"Razonamiento jurí­dico: Lógica, interpretación y argumentación ->","completion":" RESUMENEl presente trabajo investigará los aspectos más importantes de la lógica de lo razonable, en el cual la argumentación juega un papel fundamental mientras que la interpretación jurídica, no se encuentra ajena a ello. Además, se recurrirá al razonamiento jurídico, el cual pretende como fin último la búsqueda de una solución ante el conflicto, por medio de la aplicación de una proposición normativa, que debe ser justificada y fundada como fruto de una decisión. ABSTRACTThe present work will investigate in the most important aspects of the logic of the reasonable, in which the argument plays a fundamental role and while the juridical interpretation, is not alien. Legal reasoning seeks as the ultimate goal the search for a solution to the conflict, through the application of a normative proposition, which must be justified and founded as the result of a decision. The importance that it has for the juridical world, we can discover with just thinking, in the procedural law that has at last to regulate the form of the dispute or judicial controversy, in which the parties are thrown in a discussion where they argue and debate, In order that an impartial third party of credit to its positions and fails as dictated by the right. KEYWORDS: Legal reasoning, normative proposal, legal interpretation, argumentation, motivation. JEL CODE \/ CLASIFICACIÓN JEL: A14, Y80The present work will investigate in the most important aspects of the logic of the reasonable, in which the argument plays a fundamental role and while the juridical interpretation, is not alien. Legal reasoning seeks as the ultimate goal the search for a solution to the conflict, through the application of a normative proposition, which must be justified and founded as the result of a decision. The importance that it has for the juridical world, we can discover with just thinking, in the procedural law that has at last to regulate the form of the dispute or judicial controversy, in which the parties are thrown in a discussion where they argue and debate, In order that an impartial third party of credit to its positions and fails as dictated by the right. KEYWORDS: Legal reasoning, normative proposal, legal interpreta-tion, argumentation, motivation. JEL CODE: A14, Y80\n"}
{"prompt":"Lo público hoy: lugares, lógicas y expectativas ->","completion":" El siguiente trabajo es un intento por articular algunas reflexiones en torno a la redefinición de lo público en el marco de las transformaciones en la relación sociedad civil-Estado.The following work offers a reflection on how the public sphere has been redefined. These reflections are considered within the parameters of the transformations that have taken place in the relationship between the State and civil society.\n"}
{"prompt":"\"¡Me cago en la lógica del mercado!\" ->","completion":" Entrevista con Alain Touraine acerca del liberalismo - populismo en América Latina y el papel del Estado.\n"}
{"prompt":"Lógica y necesidad del Banco del Sur (Coyuntura) ->","completion":" El autor sitúa el proceso de creación del Banco del Sur y sus peripecias dentro de la tendencia global a una cooperación monetaria y financiera regional incrementada luego de la crisis asiática de 1997, así como también dentro de las tendencias históricas en América Latina.The author locates the process of the creation of the Banco del Sur and it´s ups and down within the global trend of regional monetary and financial cooperation after the Asian crisis in 1997, as well as within the historic tendencies of Latin America.\n"}
{"prompt":"Lógica do lucro, debilidade jurídica e ciência comprada ->","completion":" La historia reciente de la investigación en salud pública está repleta de casos demostrativos de una colusión entre quienes trabajan para fabricar dudas científicas acerca de estudios epidemiológicos y ambientales que demuestran los impactos de sistemas productivos malsanos, y los que manipulan estudios para diluir evidencias de tales problemas, con el fin de prolongar la impunidad jurídica, desgastar la credibilidad de denuncias ante tales daños y confundir la opinión pública. Esta breve recopilación sobre casos emblemáticos de tales disensos, tendenciosamente construidos, pretende ser un elemento de reflexión en homenaje al trabajo científico de tres entidades científicas de indudable respetabilidad científica del Brasil, la Fundación Oswaldo Cruz –FIOCRUZ-, la Asociación Brasileña de Salud Colectiva –ABRASCO y el Instituto Nacional de Cáncer –INCA, cuyos estudios sobre el impacto masivo del uso irresponsable de agrotóxicos, ha desencadenado la vieja argucia de una ciencia vinculada, que se coloca consciente o inconscientemente al servicio de meganegocios malsanos y la impunidad.\n"}
{"prompt":"Modelo Digital de lógica difusa, aplicada a un sistema inteligente ->","completion":" Contenido: Qué es la lógica difusa. En qué se aplica la lógica difusa. Conjuntos difusos. Predicados vagos y conjuntos difusos. Operaciones ógicas sobre conjuntos difusos. Predicados vagos y conjuntos difusos. Etiquetas linguísticas. Especificación de variables.\n"}
{"prompt":"Lógica matemática II, proposiciones y leyes de inferencia. ->","completion":" Definitivamente, la tecnología y el desarrollo de la ciencia cambian vertiginosamente la cotidianidad de las personas. Las ventajas comparativas de una nación sobre otra ya no se concentran en la posesión de recursos naturales o mano de obra barata, hoy, la clave está en el conocimiento. Esa sociedad del conocimiento empieza a construirse sobre la base cierta del desarrollo científico tecnológico de las naciones. Ecuador está a la zaga en esta vertiginosa carrera y las dos vías existentes hasta ahora, son: quedarse ahí o asumir el reto del cambio. Por consiguiente el objetivo primordial de este libro es contribuir al desarrollo académico e intelectual de toda la juventud deseosa de superación en beneficio propio y por consiguiente del país. En esta segunda edición se refleja la experiencia y retroalimentación de gran número de usuarios de la edición anterior.\n"}
{"prompt":"Lógica matemática I, proposiciones y leyes de inferencia. ->","completion":" Definitivamente, la tecnología y el desarrollo de la ciencia cambian vertiginosamente la cotidianidad de las personas. Las ventajas comparativas de una nación sobre otra ya no se concentran en la posesión de recursos naturales o mano de obra barata, hoy, la clave está en el conocimiento. Esa sociedad del conocimiento empieza a construirse sobre la base cierta del desarrollo científico tecnológico de las naciones. Ecuador está a la zaga en esta vertiginosa carrera y las dos vías existentes hasta ahora, son: quedarse ahí o asumir el reto del cambio. Por consiguiente el objetivo primordial de este libro es contribuir al desarrollo académico e intelectual de toda la juventud deseosa de superación en beneficio propio y por consiguiente del país. En esta segunda edición se refleja la experiencia y retroalimentación de gran número de usuarios de la edición anterior.\n"}
{"prompt":"Estructura lógica de la base de datos Oracle 10g ->","completion":" Tomando como antecedente el crecimiento de la sociedad, sus organizaciones y la tecnología en la que se apoyan, al mismo tiempo la velocidad con la cual se incrementan los volúmenes de datos e información dentro de una empresa, se genera un crecimiento tecnológico que crea la necesidad de controlar la estructura lógica de la base de datos. En su gran mayoría las empresas, se ven afectadas por la cantidad de datos que se generan diariamente. En el momento que se comienzan a generar grandes volúmenes de datos, se incrementa el trabajo de los Administradores de la Base de Datos, pues hay un consumo mayor de espacio asignado y problemas en el control de las estructuras lógicas generando demoras en los procesos. Esta investigación propone dar una solución desde un punto de vista tecnológico, usando como principal herramienta Oracle Database 10g, Oracle Form y Reports 10g.\n"}
{"prompt":"Importancia de la enseñanza de la Lógica Matemática ->","completion":" La lógica matemática cuestiona con rigor los conceptos y las reglas de deducción utilizados en matemática; lo que convierte a la lógica en una especie de metamatemática; Una teoría matemática considera objetos definidos enteros, por ejemplo. Y define leyes que relacionan a estos objetos entre sí, los axiomas de la teoría. De los axiomas se deducen nuevas proposiciones: los teoremas, y a veces, nuevos objetos. La construcción de sistemas formales: formalización, piedra angular de la lógica matemática, permite eliminar la arbitrariedad en la elección de los axiomas y definir explícita y exhaustivamente las reglas de la deducción matemática. La lógica matemática es parte de la lógica y las matemáticas, que consiste en el estudio matemático de la lógica y en la aplicación de este estudio a otras áreas de las matemáticas. La lógica matemática tiene estrechas conexiones con la ciencia de la computación y la lógica filosófica. La lógica matemática estudia los sistemas formales en relación con el modo en el que codifican nociones intuitivas de objetos matemáticos como los conjuntos, números, demostraciones y computación. L a lógica matemática suele dividirse en cuatro sub-campos: teoría de modelos, teoría de la demostración, teoría de conjuntos y teoría de la recursiòn. La investigación en lógica matemática a jugado un papel fundamental en el estudio de los fundamentos de la matemática. El proyecto aportará al mejoramiento del rendimiento académico de los estudiantes del tercer año de bachillerato, quienes estarán en capacidad de resolver problemas matemáticos en forma precisa y rápida. XVI RAZONAMIENTO LÒGICO MATEMÀTICO EDUCACIÒN ABSTRACCIÒN\n"}
{"prompt":"Tendencias lógicas en el desarrollo de las inteligencias múltiples. ->","completion":" PDFEl trabajo de investigación inteligencias múltiples propuesta por Howard Gardner y se aplicaron y analizaron los resultados de dos cuestionarios: uno de percepción de autoeficacia en cuanto a tipos de inteligencia y otro de nivel de cultura digital. Por medio de la percepción de autoeficacia de los jóvenes se logró determinar un perfil de inteligencias múltiples distintivo entre los clústeres elaborados para el estudio, donde se encontró que los jóvenes con mayor nivel de actividad tanto digital como presencial obtuvieron una autopercepción de inteligencias múltiples elevada en seis de las nueve inteligencias y se constataron perfiles distintos de actividad digital o adiestramiento integral de docentes y estudiantes, ante la superación de la calidad educativa, pero no sin antes ocasionar una serie de desasosiego que deben ser apreciados con la investigación. Midiendo así los elementos cognitivos del desempeño de los estudiantes: operaciones aritméticas, definir palabras, retención de dígitos e información, razonamiento abstracto, entre otros; el proyecto tiene una factibilidad que beneficia a estudiantes de la asignatura de matemática de primero de Bachillerato General Unificado de la Unidad Educativa “José María Urbina”, en la ciudad de Guayaquil.The research work multiple intelligences proposed by Howard Gardner and applied and analyzed the results of two questionnaires: one of perception of self-efficacy in terms of intelligence types and another level of digital culture. Through the perception of self-efficacy of young people it was possible to determine a distinctive multiple intelligences profile among the clusters elaborated for the study, where it was found that young people with a higher level of both digital and face-to-face activity obtained a self-perception of multiple intelligences. six of the nine intelligences and found different profiles of digital activity or comprehensive training of teachers and students, to overcome the quality of education, but not before causing a series of unrest that should be appreciated with research. Measuring the cognitive elements of student performance: arithmetic operations, defining words, retention of digits and information, abstract reasoning, among others; The project has a feasibility that benefits students of the Mathematics subject of the first Unified General Baccalaureate of the Educational Unit \"José María Urbina\", in the city of Guayaquil.\n"}
{"prompt":"Procedimiento de descarga e indexación de tweets mediante métodos de recuperación de la información ->","completion":" Se investiga un sistema para la obtención e indexación de datos de la red social Twitter basado en Hadoop y la plataforma de búsqueda Solr. Este sistema se diseñó e implementó para el manejo y búsqueda eficiente de vastas cantidades de datos, más en concreto de mensajes cortos o tweets, con la finalidad de alimentar un corpus de texto sobre el cual se pueda realizar operaciones de recuperación de información mediante la plataforma Solr. Hadoop es un framework de computación distribuida de código abierto que ha tomado popularidad en el manejo de big data, que en conjunto al manejo de índices de Solr resultan en un sistema con capacidades de almacenamiento y búsqueda de alto rendimiento.Ingeniero en Sistemas y Telemática\n"}
{"prompt":"Plan maestro de recuperación y fortalecimiento en seguridad de la información para Omnes Ltd. ->","completion":" En el capitulo I, se determinara el marco teórico a seguir para el desarrollo del proyecto, es importante determinar las bases teóricas, base fundamental para el desarrollo de cualquier proyecto que se desea realizar, conocimientos teóricos que permitirán encaminar esfuerzos para el alcance de los objetivos planteados inicialmente. En la actualidad no es suficiente que la empresa se restringa a los campos de higiene y seguridad de trabajo o adquiera una póliza de seguros, como ha sido costumbre. En lugar de soluciones parciales y aisladas, ahora se tiene que buscar soluciones integrales y óptimas para lograr mayor eficiencia dentro de la empresa y prevenir riesgos. Nos hemos referido hasta aquí a la empresa, no sólo a la infraestructura de EDP. Esto se debe a que la empresa es el súper conjunto del centro de cómputo. El procesamiento de datos es una función de apoyo al negocio. Por lo tanto, cualquier tipo de amenaza a la seguridad de la empresa (o cualquier tipo de organización) lo es también para la seguridad de las instalaciones de cómputo. En el capitulo II, el autor de la tesis tuvo como objetivo recolectar toda la información que sea posible, para lo cual se utilizó técnicas ya conocidas para la toma de información como son las entrevista, bibliografía que posee la misma empresa, y la observación de campo, que son principalmente las indicadas y las más idóneas para el desarrollo del proyecto, se encuestaron y entrevistaron a varias personas trabajadores de la empresa para un posterior análisis cualitativo basado en la experiencia y en opiniones de los particulares. Los procesos informales e intuitivos suelen ser más atractivos para la gerencia que los procesos estadísticos y de modelado, la base de las entrevistas y encuestas tuvieron como objetivo, la identificación de registros vitales, procesos y la identificación de las áreas funcionales (departamentos).\n"}
{"prompt":"Configuración de una arquitectura para recuperación de información mediante el uso de una herramienta de Software ->","completion":" Este trabajo se inicia con un análisis general sobre el tema \"Recuperación de Información\", se va a conocer los principales temas que se utilizan en el proceso investigativo.Se diseña una arquitectura de software para el proceso de recuperación de información, la cual posee todas la técnicas y modelos analizados en el proceso investigativo. Todos los componente y subcomponentes trabajan de forma secuencial orientándose al proceso por el pasa la consulta que formula un usuario.This work begins with a general analysis on the topic \"Information Retrieval\", it is going to know the main topics that are used in the investigativo.Ese process is a software architecture for the process of information retrieval, which has all The techniques and models analyzed in the investigative process. All the components and subcomponents work sequentially orienting themselves to the process by passing the query that a user makes.\n"}
{"prompt":"Respaldo y recuperación sobre Oracle Re2ADM ->","completion":" No es ninguna novedad el valor que tiene la información y los datos para nuestros negocios. Lo que resulta increíble de esto es la falta de precauciones que solemos tener al confiar el núcleo de nuestros negocios a una Base de Datos que en la mayoría de los casos resulta ser un sistema pobremente blindado y con poca fidelidad para salvaguardar la integridad de la información. La tecnología no está exenta de fallas o errores, y los respaldos de información son utilizados como un plan de contingencia en caso de que una falla o error se presente. Asimismo, hay empresas, que por la naturaleza del sector en el que operan (por ejemplo Banca) no pueden permitirse la más mínima interrupción informática. Las rutinas utilizadas para la ejecución de respaldos, por lo general hacen uso de los comandos propios del sistema que se esté utilizando ya sea para bajar información o viceversa. Por esto es importante hacer una buena evaluación del sistema de Bases de Datos que mejor se ajuste a nuestras necesidades, tanto en desempeño y gestionabilidad. Debemos revisar la relación costo-beneficio. Ante lo expuesto anteriormente es de vital importancia crear herramientas especializadas que refuercen la tarea de respaldos así como también de recuperación.\n"}
{"prompt":"Las tecnologías de la información y comunicación en la recuperación pedagógica de las matemáticas. ->","completion":" PDFEl presente proyecto educativo propone el diseño de una aplicación digital direccionada a desarrollar una recuperación pedagógica en la asignatura de matemáticas, con adaptaciones curriculares orientada a la educación tecnológica. Es una investigación de campo realizada en el octavo año de educación general básica de la escuela “Daniel Plaza Iglesia” con los estratos, donde se detectó estudiantes con problemas en el aprendizaje. Por medio de esta investigación se busca motivar a nuevas propuestas que implementen la inclusión de la tecnología, para direccionar el uso de estas estrategias metodológicas, se basa en los métodos cuali - cuantitativo, para analizar más a fondo los elementos con inherencia al tema de investigación, se aplicaron técnicas e instrumentos de recolección de datos, tales como, entrevista a los docentes y encuesta a estudiantes; y, por último se platicó con la autoridad el director, sobre el desempeño académico de los estudiantes y comportamiento, y, el desarrollo de las planificaciones curriculares en la asignatura antes mencionada. Con los resultados obtenidos en los diferentes instrumentos aplicados en la investigación, se pudo verificar la necesidad de ejecutar una aplicación digital en la Unidad Educativa “Daniel Plaza Iglesia” con los estudiantes de octavo año de educación general básica.The present educational project proposes the design of a digital application aimed at developing a pedagogical recovery in the subject of mathematics, with curricular adaptations oriented to technological education. It is a field research carried out in the eighth year of basic general education of the school \"Daniel Plaza Church\" with the strata, where students with problems in learning were detected. Through this research we seek to motivate new proposals that implement the inclusion of technology, to direct the use of these methodological strategies, it is based on qualitative - quantitative methods, to further analyze the elements with inherence to the research topic. , techniques and instruments for data collection were applied, such as, interviews with teachers and student surveys; and, finally, the director talked about the academic performance of the students and behavior, and the development of the curricular plans in the aforementioned subject. With the results obtained in the different instruments applied in the research, it was possible to verify the need to execute a digital application in the Educational Unit \"Daniel Plaza Iglesia\" with the eighth grade students of general basic education.\n"}
{"prompt":"Plan de recuperación de servicios ecosistémicos del Campus CEASA en base a información paisajística y espectral ->","completion":" The recovery plan for ecosystem services of the CEASA campus, based on landscape and spectral information at the Technical University of Cotopaxi was oriented to the planned recovery of ecosystem services. The landscape information was based on an AUTOCAD map, and GPS survey of the current area. The spectral information was based on satellite images LANDSAT 8, bands 2 (Blue), 4 (Red), 5 (Near Infrared) and 8 (Panchromatic), corresponding to December 2017. Based on this information, maps of current use were generated and potential soil, with reference to escosystemic services. The current use of land prioritizes agricultural production giving emphasis to the ecosystem services of Food Supply with an area of 16498.71 m2 and Raw Material with an area of 113131.94 m2 and 97957.10 m2 in Infrastructure. 566469.96 m2 are allocated to Habitat Support Services for species, and 33341.12 m2 for carbon sequestration and storage Regulation Services. For Cultural Services Recreation activities and physical and mental health has an area of 17343.98 m2, obtaining 6.78 m2 per person compared to 9 m2 per person recommended by WHO (World Organization for Health). It is recommended for cultural services of recreation and health, physical and mental activities to allocate an area of 21631.24 m2, obtaining 9.85 m2 per person allowing within the ranges recommended by the WHO (World Organization for Health). For aesthetic appreciation and inspiration for culture, art, design and research, an area of 8101.39 m2 should be allocated. The area destined for Regulation is maintained: Carbon sequestration and storage. The vegetation cover shows EVI values for both cultivation areas and EVI for arid areas, shows values of 2.5 to 5 for arboreal and shrub zones, values of 0 for infrastructure. It is recommended to generate the institutional planning within these variables for sustainable campus.El plan de recuperación de servicios ecosistémicos del campus CEASA, en base a información paisajística y espectral en la Universidad Técnica de Cotopaxi estuvo orientada a la recuperación planificada de servicios ecosistémicos. La información paisajística se basó en un mapa AUTOCAD, y levantamiento con GPS del área actual. La información espectral se basó en imágenes satelitales LANDSAT 8, bandas 2 (Azul), 4 (Rojo), 5 (Infrarrojo cercano) y 8 (Pancromática), correspondientes a diciembre del 2017. En función de esta información se generaron mapas de uso actual y potencial del suelo, con referencia a servicios escosistémicos. El uso actual de suelo prioriza la producción agropecuaria dando énfasis a los servicios ecosistémicos de Suministro de Alimentos con un área de 16498.71 m2 y Materia Prima con un área de 113131.94 m2 y 97957.10 m2 en Infraestructura. 566469.96 m2 se destinan a Servicios de Apoyo Hábitat para especies, y 33341.12 m2 para Servicios de Regulación secuestro y almacenamiento de carbono. Para Servicios Culturales Actividades de recreación y salud física y mental se cuenta con un área de 17343.98 m2, obteniendo 6.78 m2 por persona frente a los 9 m2 por persona que recomienda la OMS (Organización Mundial de la Salud). Se recomienda para Servicios Culturales de Actividades de recreación y salud, física y mental destinar un área de 21631.24 m2, obteniendo 9.85 m2 por persona permitiendo dentro de los rangos recomendados por la OMS (Organización Mundial de la Salud). Para Apreciación estética e inspiración para la cultura, el arte, el diseño e investigación se debe destinar un área de 8101.39 m2. Se mantiene la superficie destinada a Regulación: Secuestro y almacenamiento de carbono. La cobertura vegetal muestra valores de EVI tanto para áreas de cultivo y EVI para áreas áridas, muestra valores de 2.5 a 5 para zonas arbóreas y arbustivas, valores de 0 para infraestructura. Se recomienda generar la planificación institucional dentro de estas variables para campus sostenible.\n"}
{"prompt":"Sistema para administración, búsqueda y recuperación de información bibliográfica utilizando el protocolo Z39.50 ->","completion":" Software que implementa el protocolo Z39.50 para intercambio bibliográfico en un entorno geográfico distribuido, con interfaz de acceso a bases de datos CDS\/ISIS. El sistema comprende tres componentes: Servidor Z39.50, Cliente Z39.50 y el módulo de circulación bibliográfica. Está desarrollado con tecnología JAVA para el sistema de comunicaciones Z39.50, y JAVA Server Pages para los servicios disponible en Internet. El producto permite realizar búsquedas simultáneas, pedidos y reservas en los catálogos electrónicos de las instituciones asociadas al sistema, los cuales pueden ser procesados por bibliotecarios desde su lugar de trabajo, desde cualquier computadora conectada a Internet.Ingeniero de SistemasCuenca\n"}
{"prompt":"Desarrollo de un plan de recuperación de desastres para la unidad de tecnología de la EPMAPAP ->","completion":" Esta investigación se basa en el estudio del problema detectado en la Empresa Pública Municipal de Agua Potable y Alcantarillado de Portoviejo EPMAPAP, en la actual no se cuenta con planes de recuperación de desastres. Al ser EPMAPAP una entitad pública del estado ecuatoriano. son e cumplimiento obligatorio las disposiciones emitidas por la Contraloría General del Estado a través de sus normas del control interno 410-11 plan de contingencia la cual establece que corresponde a la unidad de tecnología de información la definición y aprobación e implementacion de un plan de contingencias que describa las acciones a tomar en caso de una emergencia o suspensión en el procesamiento de la información.\n"}
{"prompt":"Desarrollo de un plan de recuperación de desastres para la unidad de tecnología de la EPMAPAP ->","completion":" Esta investigación se basa en el estudio del problema detectado en la empresa pública Municipal de Agua Potable y Alcantarillado de Portoviejo EPMAPAP, en la actual no se cuenta con planes de recuperación de desastres. Al ser EPMAPAP una entitad pública del estado ecuatoriano. son e cumplimiento obligatorio las disposiciones emitidas por la Contraloría General del Estado a través de sus normas del control interno 410-11 plan de contingencia la cual establece que corresponde a la unidad de tecnología de información la definición y aprobación e implementacion de un plan de contingencias que describa las acciones a tomar en caso de una emergencia o suspensión en el procesamiento de la información.\n"}
{"prompt":"Plan de recuperación ante desastres tecnológicos en el Grupo Industrial Graiman ->","completion":" Magíster en Tecnologías de la Información\n"}
{"prompt":"Sistema de agentes móviles para la gestión y recuperación personalizada de información de una biblioteca electrónica distribuida. ->","completion":" En esta tesis se hace un estudio de la tecnología de Agentes Móviles empezando por escoger hacer sistema para una Biblioteca Distribuida para demostrar las ventajas de esta nueva forma de Sistemas Distribuidos, luego se elige los conocimientos adquiridos en la formación de la carrera universitaria que se necesitan para desarrollar este sistema que se llamara BIBLIOMOVIL y también se compara la invocación de métodos remotos, los Applets con los Agentes Móviles. En el capítulo 3 se muestra la teoría la cual es el corazón de esta tesis empezando por el concepto de agente, la clasificación y la evolución de los agentes; y luego se puede ver la concepción de agente móvil y todos las partes necesarias para trabajar con los agentes móviles. En el siguiente capítulo esta el análisis de la arquitectura y herramientas necesarias para el funcionamiento la plataforma Aglet, es decir la teoría de agentes móviles implementada con Java, además también se hace el análisis del sistema orientado a integrarse con los Aglets. En el capítulo 5 se hace la descripción del diseño del sistema dividiéndolo en tres capas usando los Java Server Pages en la interfaz de Usuario, los Aglets en la capa de reglas de negocio y la capa de Base de Datos. Por ultimo en los anexos están las características más importantes del lenguaje de programación, de la base de datos MYSQL, y dos programas para Bibliotecas; y el manual del Servidor de Agentes\n"}
{"prompt":"Sistema de Información Web para el Control Médico, Evolución y Recuperación de los Deportistas de la Federación Deportiva de Pastaza ->","completion":" Con la implementación de del sistema de información web se mejoró el seguimiento y control de la recuperación de los deportistas de la Federación Deportiva de Pastaza, permitiendo ahorrar tiempo y procesos innecesarios en el procesamiento de la información.El presente trabajo investigativo tiene como objetivo la implementación de un sistema de información web para el control médico, evolución y recuperación de los deportistas de la Federación Deportiva de Pastaza, así pretendemos lograr el mejor desempeño y agilizar los procesos garantizando un excelente manejo de la información. Para la elaboración del sistema y el cumplimiento de los objetivos planteados se utilizó como guía la metodología OOHDM basada en diseño de aplicaciones de hipermedia y Web, adicionalmente se utilizaron diversas tecnologías como el lenguaje de programación java, el sistema manejador de bases de datos MySql, el servidor Web GlassFish. Con la automatización del sistema se genera un mejor desempeño de las labores del departamento médico en cuanto a la realización de los procesos de forma automatizada. Finalmente, con la implementación del sistema de información permitirá el manejo y automatización de la información tendiente a mejorar la forma y manejo de los datos de los deportistas (historia médico-deportiva); se ahorra tiempo y procesos innecesarios en el procesamiento de la información.\n"}
{"prompt":"Artículo Científico.- Desarrollo de un plan de recuperación de desastres para la unidad de tecnología de la EPMAPAP. ->","completion":" Esta investigación se basa en el estudio del problema detectado en la Empresa Pública Municipal de Agua Potable y Alcantarillado de Portoviejo EPMAPAP, en la actual no se cuenta con planes de recuperación de desastres. Al ser EPMAPAP una entidad pública del estado ecuatoriano. son e cumplimiento obligatorio las disposiciones emitidas por la Contraloría General del Estado a través de sus normas del control interno 410-11 plan de contingencia la cual establece que corresponde a la unidad de tecnología de información la definición y aprobación e implementacion de un plan de contingencias que describa las acciones a tomar en caso de una emergencia o suspensión en el procesamiento de la información.\n"}
{"prompt":"Herramientas de Análisis Forense y la Recuperación de Información en los Disposotivos de Almacenamiento en los Laboratorios de la Facultad de Ingeniería en Sistemas Electrónica e Iindustrial de la Universidad Técnica de Ambato Durante el Primer Trimestre del 2010 ->","completion":" La investigación sobre “HERRAMIENTAS DE ANALISIS FORENSE Y RECUPERACIÓN DE INFORMACION EN LOS DISPOSITIVOS DE ALMACENAMIENTO, EN LOS LABORATORIOS DE LA FISEI-UTA, DURANTE EL PRIMER TRIMESTRE DEL 2010”, tiene como objetivo general reflexionar sobre la pérdida de información que actualmente existe de manera intencionada, por diferentes fallos físicos en los dispositivos de almacenamiento, virus o por falta de conocimiento, entre otros. Para esto se tratará de analizar diversas herramientas de computación forense las cuales nos brindarán a través de un estudio la posibilidad de obtener evidencias de cuáles son las principales causas de la pérdida de datos, la posibilidad de su recuperación mediante distintos escenarios realizados ya que cada caso es único, de darse la posibilidad de un ataque mediante un informe este punto se tratará judicialmente de acuerdo a las normas establecidas en el Ecuador. Además se intentará brindar un completo estudio de tareas de análisis forense, que nos brinden la solución casi en su totalidad, permitiéndonos saber cuál es la herramienta más adecuada de acuerdo a sus características según el caso.\n"}
{"prompt":"Las Bases de Datos Distribuidas y su importancia en la recuperación, actualización y administración de la información en el Centro Educativo Diocesano San Pío X ->","completion":" El trabajo de investigación tiene como tema: Las Bases de Datos Distribuidas y su importancia en la recuperación, actualización y administración de la información en el Centro Educativo Diocesano San Pío X. Su importancia radica en la necesidad de contar con una configuración de información respaldada y asegurada en caso de cualquier fallo posible. El plan de tesis está estructurado por capítulos: El capítulo I denominado El Problema contiene: contextualización, análisis crítico, prognosis, formulación del problema, interrogantes de la investigación, delimitación del objeto de investigación, delimitación de contenido, delimitación espacial, delimitación temporal, unidades de observación, justificación, objetivo general, objetivos específicos. El capítulo II llamado Marco Teórico se estructura con los antecedentes investigativos, las fundamentaciones filosófica, tecnológica, legal, red de inclusiones contextuales, constelaciones de ideas, hipótesis con sus respectivas variables. El capítulo III llamado Metodología contiene: investigación de campo, investigación documental-bibliográfica, investigación experimental, proyectos factibles o de intervención social, proyectos especiales, niveles o tipos de investigación, exploratorio, descriptivo, asociación de variables, explicativo, población y muestra, operacionalización de variables, operacionalización de la variable independiente, operacionalización de la variable dependiente, plan de recolección de información, plan de procesamiento de información. El capítulo IV denominado Análisis e interpretación de resultados se presenta los datos recogidos en las encuestas buscando una solución efectiva al problema de investigación, adicionalmente se comprueba la hipótesis proponiendo varios métodos de recuperación y respaldo de información, que permitirá una mejor administración de los datos organizados en forma distribuida. 1 El capítulo V denominado Conclusiones y recomendaciones servirá de base a la propuesta, mediante una solución factible. El capítulo VI denominado Propuesta plantea la solución basada en una implantación y configuración de un sistema de replicación de tipo open source o licenciado que permitirá mantener la consistencia de la información distribuida a través de los diferentes departamentos, respaldos automáticos a través de sistema operativo, y el aprovechamiento de las herramientas propias del motor de base de datos para crear espejos de información. Finalmente se presentará la bibliografía utilizada en la presente investigación, así como también los anexos y se mostrará tanto las fichas de instrumentación como los planos de las configuraciones que forman parte de la investigación.\n"}
{"prompt":"Desarrollo e implementación de un motor de búsqueda para la recuperación de información de internet, desde el portal de la Universidad Nacional de Loja. ->","completion":" The present investigation with the subject “DESIGN AND IMPLEMENTATION OF MOTOR SEARCH FOR the INFORMATION RETRIEVAL OF Internet, FROM the VESTIBULE OF the NATIONAL UNIVERSITY OF LOJA”, is directed to solve the difficult task always of looking for information in Internet and with the intention with contributing to the technological advance of our dear university. The design of all the application is designed by means of the paradigm OO, reason why it was necessary to realise the diagrams of Uses CASE, Diagram of Classes, Prototype of Screens, Diagrams of Robustness and Diagrams of Sequence by each Use CASE, for it was used the tool of modeled UML, Enterprice Architect. It is possible to indicate that the design of our application is conformed of two surroundings of work: the first denominated Web Seeking and a second, programs RastradorUNL. As programming tool were used NetBeans 6,8, that is an IDE available free that helps to the facility of the programming in the Java language. As far as the Web server, we chose the servant with whom works the National University of Loja that is Jboss 5.1.0, because it is where the application lodged. It is possible to emphasize that this application properly is documented with the manuals of programmer and user for one better understanding, as much in form as in design.La presente investigación con el tema: “DISEÑO E IMPLEMENTACIÓN DE MOTOR DE BÚSQUEDA PARA LA RECUPERACIÓN DE INFORMACIÓN DE INTERNET, DESDE EL PORTAL DE LA UNIVERSIDAD NACIONAL DE LOJA”, está dirigida a solucionar la difícil tarea de buscar información en Internet y con el propósito siempre con contribuir al avance tecnológico de nuestra querida universidad. El diseño de toda la aplicación está diseñada mediante el paradigma orientado a Objetos, por lo que fué necesario realizar los diagramas de Use Case, Diagrama de Clases, Prototipo de Pantallas, Diagramas de Robustez y Diagramas de Secuencia por cada Use Case, para ello se utilizó la herramienta de modelado UML, Enterprice Architect. Cabe indicar que el diseño de nuestra aplicación está conformado de dos entornos de trabajo: el primero Web denominado Buscador y un segundo de Escritorio, programa RastradorUNL. Como herramienta de programación se utilizó NetBeans 6.8, que es un IDE disponible de forma gratuita que ayuda a la facilidad de la programación en el lenguaje Java. En cuanto al servidor Web, escogimos el servidor con el que trabaja la Universidad Nacional de Loja que es Jboss 5.1.0, pues es donde se alojara la aplicación. Cabe destacar que esta aplicación está debidamente documentada con los manuales de programador y de usuario para una mejor comprensión, tanto en forma como en diseño.\n"}
{"prompt":"Diseño de un plan de recuperación de desastres (DRP) para el departamento de tecnologías de información de una empresa procesadora y comercializadora de alimentos ->","completion":" The present project proposes the Design of a Disaster Recovery Plan for the department of Information Technology (IT) of PRONACA Company, as a solution for the organization to protect the information and infrastructure to give continuity of the business process before some event could affect the normal operation. Chapter I defines the Disaster Recovery Plan, the objective and the importance of it, identifies the types of plans for business continuity. Finally describes the stages of the methodology proposed by ITIL for the IT continuity services management. Chapter II explains the history of the company, from the beginning and evolution in the different business; very important aspects are mentioned for its success based in the philosophy, principles and values. Specifies the organizational structure, the IT flowchart and the chain value to give us a global vision of the type of company. Chapter III develops the business impact analysis, where it is identified and evaluated the economic, commercial, operational, reputational, image and legal impact of four critical processes; also determinates the maximum tolerable downtime of the organization without the IT services, the recovery time objective and the recovery point objective. Besides, the risk analysis permitted to identify the assets, vulnerabilities, threats and existing controls to; finishing with the estimation and risk evaluation. Chapter IV applies the strategy of continuity IT services which consists of defining the measures of response to risks and the options of recovery after a disaster. Makes an analysis of cost and benefit of the suggested solution and defines the procedures and equipment needed for the disaster recovery. Chapter V presents the conclusions and recommendations of the project.El presente proyecto propone el Diseño de un Plan de Recuperación de Desastres para el departamento de Tecnología de Información (TI) de la empresa PRONACA, como una solución para la organización de proteger su información e infraestructura y dar continuidad a los procesos de negocio ante algún evento que pueda afectar su normal operación. En el Capítulo I se define el Plan de Recuperación de Desastres, su objetivo e importancia y se identifican los tipos de planes para la continuidad de negocio. Finalmente se describen las etapas de la metodología propuesta por ITIL para la gestión de la continuidad de los servicios de TI. Para el Capítulo II se describe la historia de la empresa, desde sus inicios y evolución en los diferentes negocios; se mencionan aspectos muy importantes para su éxito como son su filosofía, principios y valores. También se especifica la estructura organizacional, el organigrama de TI y la cadena de valor para tener una visión global del tipo de empresa. En el Capítulo III se realiza el análisis de impacto en el negocio, donde se identifica y evalúa el impacto económico, comercial, operacional, imagen y legal de cuatro procesos críticos, también se determina el tiempo máximo de inactividad tolerable de la organización sin contar con los servicios de TI, los tiempos objetivos de recuperación y los puntos objetivos de recuperación. Adicionalmente se hizo un análisis de riesgo donde se identificó los activos, las vulnerabilidades, amenazas y los controles existentes; finalizando con la estimación y evaluación de riesgos. Para el Capítulo IV se plantea la estrategia de continuidad de los servicios de TI la cual consiste en definir las medidas de respuesta a riesgos y las opciones de recuperación ante un desastre. Se realiza un análisis de costo beneficio de la solución planteada y se definen los procedimientos y equipos de recuperación de desastres. En el Capítulo V se presentan las conclusiones y recomendaciones del proyecto.\n"}
{"prompt":"Estudio comparativo de técnicas File Carving para la recuperación de información perdida por daños de impacto y humedad en dispositivos de almacenamiento SSD ->","completion":" En el presente trabajo se realiza un análisis comparativo de dos técnicas File Carving utilizadas en las investigaciones forenses digitales aplicadas a dispositivos de almacenamiento SSD. Su principal objetivo es determinar la técnica que permita recuperar la mayor cantidad de información de forma íntegra. La primera parte de esta investigación se encuentra contenida en los capítulos 1 y 2, que presentan el marco teórico y el estado del arte acerca de los dispositivos de almacenamiento, técnicas de recuperación de datos y su funcionamiento. El capítulo 3 detalla la metodología a seguir para la recuperación de datos, la parte fundamental del proyecto se detalla en el capítulo 4, donde, se realiza la selección, preparación y aplicación de los escenarios en que los dispositivos de almacenamiento SSD han sufrido daños físicos como golpes, aplastamiento o humedad. A continuación, en el capítulo 5 se presenta los resultados del análisis de datos recopilados durante el capítulo anterior, finalmente en el capítulo 6 se detalla las conclusiones, recomendaciones y trabajo futuro.\n"}
{"prompt":"Desarrollo de un plan de recuperación ante desastres (DRP) para la unidad de T.I. de la Corporación AMCO ->","completion":" El Plan de Recuperación ante Desastres para la Unidad de T.I. de la Corporación AMCO, tiene su origen en los hallazgos encontrados en la última auditoría, en la que menciona la carencia de planes de recuperación de los servicios de T.I. que brinda la Corporación, además del desastre natural ocurrido el 16 de abril de 2016 en la provincia de Manabí. Debido a esto, el presente trabajo de investigación tiene como fin el desarrollo del Plan de Recuperación para la continuidad de los servicios de T.I. de AMCO, tomando como base el estándar ISO 22301:2012, lo que ayudará a la Corporación al aseguramiento de la disponibilidad de sus servicios de T.I garantizando la continuidad de sus operaciones.GuayaquilMagíster en Seguridad Informática Aplicada\n"}
{"prompt":"Implementación de un esquema de respaldo y recuperación de las bases de datos principales de una empresa comercial ->","completion":" Implementación de una herramienta de respaldos para las principales bases de datos de una empresa comercial. Se presenta el esquema tradicional en que cada servidor tiene o comparte una unidad de lectura\/grabación de cintas. La descripcon de la solución propuesta utilizando una herramienta de respaldos como lo es netbackup 7.6. analisis de los resultados comparando el método anterior sin la herramienta y el actual con la herramienta.GuayaquilMagíster en Sistemas de Información Gerencial\n"}
{"prompt":"Detección automática de eventos sísmicos en el volcán Cotopaxi mediante técnicas de aprendizaje de máquinas ->","completion":" Los volcanes con un alto riesgo de futuras erupciones pueden causar algún tipo de catástrofe. Con el propósito de preservar vidas humanas y pérdidas materiales, se desarrolló un sistema de detección automática de eventos sísmicos en el volcán Cotopaxi mediante técnicas de aprendizaje de máquinas. Inicialmente, un estudio se realizó de los registros y las etiquetas de señales sísmicas monitorizadas por el Instituto Geofísico de la Escuela Politécnica Nacional (IGEPN) durante el 2012; los datos en formato .SAC y las etiquetas de los eventos sísmicos se extrajeron automáticamente mediante código en MATLAB® para su lectura, concatenación, visualización y posterior procesamiento de la señal. El sistema continúa con el procesamiento digital de señales y segmentado de la señal en ventanas, para cada ventana se extrajeron características en el dominio del tiempo y la frecuencia, que posteriormente sirven para la selección de características relevantes con filtros. Las etiquetas de los eventos se crearon con: etiquetas del IGEPN, técnica STA\/LTA, la unión y las coincidencias de ambos. La detección de eventos sísmicos aplicando Redes Neuronales y SVM se realizaron con la matriz que contiene las características y respectivos etiquetados, se evaluaron mediante diferentes técnicas. Los resultados se presentaron en términos de exactitud, sensibilidad, especificidad, capacidad predictiva y BER, alcanzando porcentajes del 95.35% y 96.92% en exactitud para SVM y Redes Neuronales respectivamente.\n"}
{"prompt":"Predicción de crisis epilépticas utilizando técnicas de procesamiento de señales electroencefalográficas y aprendizaje de máquina ->","completion":" La epilepsia es una enfermedad que se caracteriza por un mal funcionamiento repentino y recurrente del cerebro, denominado \"convulsión\". Las convulsiones epilépticas reflejan los signos clínicos de una actividad excesiva e hipersincrónica de las neuronas en el cerebro, y pueden ir acompañadas de un deterioro o pérdida de la conciencia, síntomas psíquicos, sensoriales, o fenómenos motores. Uno de los aspectos más incapacitantes de la epilepsia es la naturaleza aparentemente impredecible de las convulsiones. Un método capaz de predecir la aparición de crisis epilépticas a partir del electroencefalograma (EEG) de pacientes con epilepsia abriría nuevas posibilidades terapéuticas. Con este enfoque, el presente proyecto contempla el desarrollo de un algoritmo de predicción de crisis epilépticas, usando técnicas de procesamiento de señales electroencefalográficas y aprendizaje de máquina. El algoritmo identifica el estado preictal (pre-crisis), y lo diferencia del estado interictal (sin crisis), basado en los cambios dinámicos espacio-temporales en el registro EEG, que empiezan varios minutos antes de la convulsión. Se emplea una base de datos que consta de registros EEG intracraneales (iEEG) de dos pacientes con epilepsia. Estos registros son analizados en el dominio tiempo-escala empleando la transformada wavelet, y extrayendo una serie de características. Para la clasificación se empleó aprendizaje de máquina supervisado, por medio de los siguientes algoritmos: regresión logística, análisis discriminante, k-vecinos más cercanos (kNN), árboles de decisión, máquina de vectores de soporte (SVM) y conjunto de clasificadores redundantes (ensemble). El algoritmo obtiene una exactitud total de 99.1%, sensibilidad de 99%, especificidad de 99.1% y capacidad predictiva (AUR) de 0.98.\n"}
{"prompt":"Predicción de alertas de incidentes para un servicio integrado de seguridad mediante aprendizaje de máquinas ->","completion":" Un Servicio Integrado de Seguridad se encarga de atender las llamadas de emergencia de la ciudadanía para prestar la debida atención mediante la asignación de los recursos necesarios que requiera el incidente, a través de las instituciones de policía, bomberos, sanidad, militares, salud, etc.; por el hecho de que se debe atender la solicitud de una gran cantidad de emergencias no previstas, hay ocasiones en que no se tienen los recursos listos, resultando en consecuencias fatales. Para que el sistema mencionado pueda ser más eficiente en el aspecto de disponibilidad de recursos y por lo tanto en la atención de emergencias, se implementa un software capaz de predecir el número y el tipo de incidentes que puedan suscitarse en un distrito, mes, día de la semana y turno (horario) específicos, para lo cual se toma como ejemplo el Servicio Integrado de Seguridad ECU 911 y el centro zonal Quito específicamente. Dicho objetivo se realiza mediante la aplicación de aprendizaje de máquinas, exactamente las máquinas de vectores soporte (SVM) de clasificación y regresión, utilizando bases de datos de llamadas de emergencias del año 2014 proporcionada por la empresa. Después de realizar una serie de pruebas de diferentes modelos SVM con distintos métodos de tratamiento de datos y basándose en el mejor rendimiento de acuerdo al MAE y al error relativo, se elige el mejor modelo con respuestas cuantificadas a escala exponencial a 512 niveles y kernel gaussiano, con el cual se crea una interfaz gráfica amigable para manejo de cualquier usuario.\n"}
{"prompt":"Implementación de un detector de coral utilizando filtros Gabor Wavelets y máquinas de aprendizaje ->","completion":" Este trabajo se enfoca en la implementación de un detector de arrecife de coral de desempeño rápido que se utiliza para un vehículo autónomo submarino (Autonomous Underwater Vehicle, AUV, por sus siglas en inglés). Una detección rápida de la presencia de coral asegura la estabilización del AUV frente al arrecife en el menor tiempo posible, evitando colisiones con el coral. La detección de coral se hace en una imagen que captura la escena que percibe la cámara del AUV. Se realiza una clasificación píxel por píxel entre dos clases: arrecife de coral y el plano de fondo que no es coral. A cada píxel de la imagen se le asigna un vector característico, el mismo que se genera mediante el uso de filtros Gabor Wavelets. Éstos son implementados en C++ y la librería OpenCV. Los vectores característicos son clasificados a través de nueve algoritmos de máquinas de aprendizaje. El desempeño de cada algoritmo se compara mediante la precisión y el tiempo de ejecución. El algoritmo de Árboles de Decisión resultó ser el más rápido y preciso de entre todos los algoritmos. Se creó una base de datos de 621 imágenes de corales de Belice (110 imágenes de entrenamiento y 511 imágenes de prueba).This work focuses on the implementation of a fast coral reef detector that is used for an Autonomous Underwater Vehicle (AUV, its acronym in English). A fast detection of the presence of coral ensures the AUV stabilization in front of coral reef in the shortest possible time, avoiding collisions with coral. The coral detection is carried out on an image that captures the scene that the AUV’s camera perceives. A pixel-by-pixel classification is performed between two classes: coral reef and the background that is non-coral reef. Each pixel of the image is assigned to a feature vector, which is generated by using Gabor Wavelet filters. These are implemented in C++ and the OpenCV library. The feature vectors are classified using nine machine learning algorithms. The performance of each algorithm is compared with the accuracy and execution time. The Decision Tree algorithm proved to be the fastest and most accurate of all the algorithms. We created a database of 621 images of coral reefs in Belize (110 of training images and 511 of testing images).CuencaVolumen 5 (2014)\n"}
{"prompt":"Sistema electrónico de detección de problemas en pisada mediante algoritmos de aprendizaje de máquina ->","completion":" Desarrollar un sistema electrónico de detección de pisada basado en algoritmos de decisión supervisados, con el fin de determinar tres tipos de pisadas.El presente proyecto consiste en el desarrollo de PIEMEG, el cual es un sistema electrónico de problemas en pisada mediante algoritmos de Machine Learning (ML), el objetivo de este prototipo es la detección de tres diferentes tipos de pisadas, con lo cual busca convertirse en un sistema tecnológico de apoyo para los especialistas en el área de la podología. El sistema está formado por sensores piezoresistivos de presión que miden las presiones plantares de cada pie. PIEMEG consta de un sistema de visualización, a través del cual se muestra información sobre el tipo de pisada y los valores en porcentajes de presión que reciben los pies. Para el diseño del dispositivo se aprovechan las ventajas del uso de hardware y software libre, el correcto ciclo de vida de desarrollo de PIEMEG, está basado en la metodología del modelo en V, garantizando un proceso adecuado en el diseño y la implementación del sistema. Para finalizar, la funcionalidad del sistema es evaluada en el apartado final de este documento a través de pruebas realizadas al prototipo, buscando que la calidad y efectividad de PIEMEG sea la mejor posible\n"}
{"prompt":"Estimación de número de personas en imágenes de multitudes usando aprendizaje de máquina ->","completion":" Desarrollar una aplicación de estimación de número de personas, mediante el uso de técnicas de aprendizaje de máquina y visión por computador, bajo una plataforma de software libre.Actualmente, existe una gran demanda de sistemas de monitoreo de multitudes para su análisis y seguimiento. El conteo de personas en aglomeraciones ha adquirido una gran relevancia en el campo de la seguridad pública. Por lo tanto, el objetivo del presente trabajo de grado es desarrollar un sistema que permita detectar y estimar el número de personas presentes en imágenes de multitudes, usando aprendizaje de máquina y visión por computador. El núcleo de este enfoque se basa principalmente en el uso de un descriptor de características Histogramas de Gradientes Orientados (HOG) y un modelo de clasificación supervisado Máquinas de Vectores de Soporte (SVM). Estos algoritmos son implementados en una plataforma de software libre, utilizando el lenguaje de programación Python y bibliotecas libres. La evaluación del rendimiento del modelo de clasificación se realiza usando las métricas orientadas a estos modelos, por otro lado, para el algoritmo de detección y conteo se realiza pruebas experimentales en imágenes de un conjunto de datos de libre acceso, orientado al análisis de multitudes de diferentes densidades. Estas imágenes son de distintas dimensiones y presentan diferentes perspectivas de cámara, variaciones de iluminación y diversos fondos. Por último, mediante las pruebas realizadas se puede deducir que el sistema presenta un mejor desempeño en imágenes de multitudes con un ángulo de cámara normal y una densidad uniforme.Ingeniería\n"}
{"prompt":"Implementación de un detector de coral utilizando filtros Gabor Wavelets y máquinas de aprendizaje ->","completion":" RESUMENEste trabajo se enfoca en la implementación de un detector de arrecife de coral de desempeño rápido que se utiliza para un vehículo autónomo submarino (Autonomous Underwater Vehicle, AUV, por sus siglas en inglés). Una detección rápida de la presencia de coral asegura la estabilización del AUV frente al arrecife en el menor tiempo posible, evitando colisiones con el coral. La detección de coral se hace en una imagen que captura la escena que percibe la cámara del AUV. Se realiza una clasificación píxel por píxel entre dos clases: arrecife de coral y el plano de fondo que no es coral. A cada píxel de la imagen se le asigna un vector característico, el mismo que se genera mediante el uso de filtros Gabor Wavelets. Éstos son implementados en C++ y la librería OpenCV. Los vectores característicos son clasificados a través de nueve algoritmos de máquinas de aprendizaje. El desempeño de cada algoritmo se compara mediante la precisión y el tiempo de ejecución. El algoritmo de Árboles de Decisión resultó ser el más rápido y preciso de entre todos los algoritmos. Se creó una base de datos de 621 imágenes de corales de Belice (110 imágenes de entrenamiento y 511 imágenes de prueba).Palabras clave: AUV, arrecife de coral, máquinas de aprendizaje, filtros Gabor Wavelets, OpenCV.ABSTRACTThis work focuses on the implementation of a fast coral reef detector that is used for an Autonomous Underwater Vehicle (AUV, its acronym in English). A fast detection of the presence of coral ensures the AUV stabilization in front of coral reef in the shortest possible time, avoiding collisions with coral. The coral detection is carried out on an image that captures the scene that the AUV’s camera perceives. A pixel-by-pixel classification is performed between two classes: coral reef and the background that is non-coral reef. Each pixel of the image is assigned to a feature vector, which is generated by using Gabor Wavelet filters. These are implemented in C++ and the OpenCV library. The feature vectors are classified using nine machine learning algorithms. The performance of each algorithm is compared with the accuracy and execution time. The Decision Tree algorithm proved to be the fastest and most accurate of all the algorithms. We created a database of 621 images of coral reefs in Belize (110 of training images and 511 of testing images).Keywords: AUV, coral reef, machine learning, Gabor Wavelets filters, OpenCV.\n"}
{"prompt":"Reconocimiento de cáncer de mama utilizando técnicas de procesamiento digital de imágenes mamográficas y aprendizaje de máquina ->","completion":" La elaboración del presente trabajo de investigación tiene como finalidad la identificación del cáncer de mama en imágenes mamográficas, debido a que esta patología afecta a una gran cantidad de mujeres en nuestro país. Para llegar a la identificación de células cancerígenas en la mamografía, es necesario un análisis previo en el área de procesamiento digital de imágenes y especialmente en técnicas de segmentación, las mismas que ayudan a buscar e identificar las regiones de interés por medio de la eliminación de pixeles adyacentes. Las técnicas de segmentación que se implementaron para la detección de cáncer son la dilatación y erosión que se fundamentan en la simplificación de las imágenes por medio de la forma geométrica que dichas células poseen. Ya obtenidas las regiones establecidas por las operaciones morfológicas se procedió a identificar la presencia de cáncer o no, mediante el uso de algoritmos de aprendizaje de máquina, los cuales son aptos en crear sistemas autónomos de decisión dependientes del modelamiento de la base de datos, para generar un resultado que se verifica con el análisis de exámenes de mamografías existentes, utilizando así diferentes algoritmos de aprendizaje de máquina como son: árbol de decisiones, bayes ingenuo, vecino más cercano y redes neuronales artificiales (ANN). Los resultados obtenidos en la etapa anterior, fueron analizados cuidadosamente mediante el uso de variables como: la exactitud, la sensibilidad, la eficiencia, etc., llegando a encontrar en todos los sistemas propuestos un valor cercano al 98% de exactitud en la identificación de cáncer de mama.\n"}
{"prompt":"Comparación de nueve algoritmos de máquinas de aprendizaje con alicaciones en la detección de Arrecife de Coral. ->","completion":" This work focuses on the comparison of nine algorithms learning machines for the development of a detector coral this detector comprises a extraction portion eigenvectors , which is performed with filters Gabor Wavelets , and a sorting vector using learning machines based on neural networks comparing the accuracy and runtime nine machine learning algorithms , the result was realized that the algorithm selection decision trees.Este trabajo se enfoca en la comparación de nueve algoritmos de máquinas de aprendizaje para el desarrollo de un detector de coral este detector consta de una parte de extracción de vectores característicos, la cual se realiza con filtros Gabor Wavelets, y una parte de clasificación de vectores que usan máquinas de aprendizaje basado en redes neuronales se realizó la comparación de la precisión y el tiempo de ejecución de nueve algoritmos de máquinas de aprendizaje, cuyo resultado que la selección del algoritmo de árboles de decisión.\n"}
{"prompt":"Análisis comparativo de técnicas basadas en máquinas de aprendizaje para predecir la excursión de frecuencia en sistemas eléctricos de potencia. ->","completion":" El presente trabajo de titulación desarrolla una metodología con el objetivo de realizar un análisis comparativo de los distintos algoritmos utilizados en las Máquinas de Aprendizaje (MA) para la predicción de la excursión de frecuencia de un Sistema Eléctrico de Potencia luego de ocurrida una perturbación, sin hacer uso de las simulaciones en el dominio del tiempo y así evitar los impactos negativos a consecuencia de dichas perturbaciones, siendo estos sociales o económicos, con el fin de garantizar la continuidad del servicio eléctrico manteniendo al sistema con un servicio confiable y continuo. El proyecto incluye el modelamiento de un test system modificado considerando la inserción de energías renovables no convencionales (ERNC) como la energía eólica y energía solar fotovoltaica. Mediante uso de herramientas computacionales usadas en el campo eléctrico, se obtuvieron los datos sintéticos del sistema, esto mediante el uso de simulaciones en el dominio del tiempo (TDS) considerando como entradas las condiciones operacionales obtenidas del despacho económico previamente desarrollado en un periodo de tiempo definido; estos datos sintéticos del sistema permitieron entrenar las MA para predecir la excursión de frecuencia luego de ocurrida una contingencia. Una vez obtenidos los datos, se procedió a la selección de características relevantes que influyeron en la excursión de frecuencia para obtener información para el correcto entrenamiento de las distintas MA y finalmente se realizó el análisis comparativo entre los resultados obtenidos, verificando cuál de ellas tiene el mejor desempeño en términos de aproximación a los valores obtenidos de manera tradicional.ESPE-L\n"}
{"prompt":"Análisis comparativo de técnicas basadas en máquinas de aprendizaje para predecir la estabilidad de voltaje en sistemas eléctricos de potencia. ->","completion":" El presente trabajo de titulación propone un análisis comparativo de máquinas basadas en Machine Learning (ML) implementadas para el estudio de estabilidad de voltaje, con el propósito de predecir su comportamiento en diferentes barras del sistema eléctrico luego de ocurrida una contingencia, evitando así el uso de simulaciones que requieren gran demanda computacional como las de dominio del tiempo (TDS). De esta forma se optimizan recursos económicos, computacionales y tiempo. Para este trabajo se utilizó un sistema de prueba modificado, el cual considera generación tradicional junto con inserción de energías renovables no convencionales (ERNC). Esta investigación parte con la implementación del modelo en estado estacionario del sistema, utilizado para resolver el problema de despacho económico. Adicionalmente, para el análisis de estabilidad de voltaje y debido a su naturaleza variante en el tiempo, mediante el uso de herramientas computacionales del área eléctrica se realiza el modelamiento en estado dinámico del sistema junto con el modelamiento detallado de ciertos elementos, de manera que se puedan realizar las TDS en las cuales se consideran eventos de cortocircuito en líneas de transmisión necesarios para la obtención de los datos sintéticos. Estos datos pasan por una etapa de pre-procesamiento, de manera que puedan ser utilizados para el entrenamiento y validación de los algoritmos de ML. Para el análisis comparativo de dichos algoritmos y sus respectivas predicciones se utiliza la métrica del error cuadrático medio (RMSE).ESPE-L\n"}
{"prompt":"Experimentando a toda máquina ->","completion":" Este proyecto se enfoca en la creación de una página web como herramienta de aprendizaje. En donde se exponen temas de física a través de diferentes recursos dinámicos, como un experimento que será la base principal de la página, ya que las experimentaciones a más de proporcionarnos un concepto más claro sobre el tema que se quiere explicar, ayudan a entender de forma gráfica cómo se presentan los fenómenos en la vida real. Es por eso por lo que en la página web se ha detallado todo lo que se necesita para realizar el experimento y también se explica, paso a paso, cómo realizarlo, para que las personas interesadas en aprender puedan llevarlo a cabo en sus casas sin inconvenientes. Así es como con la página web se busca crear un respaldo, que ayude tanto a los profesores a explicar mejor a sus estudiantes como a los estudiantes a reforzar sus conocimientos; especialmente en este tiempo de pandemia que cambió la forma de educación a virtual, la cual ha dificultado el aprendizaje de muchos alumnos. Pensando en esta situación, se realizó un experimento fácil, además con materiales caseros. Con respecto a la creación de la página web, se utilizó WIX debido a las varias funciones de personalización que ofrece, y de este modo, obtener una página que sea más llamativa para los usuarios que ingresen a la página, en busca de reforzar sus conocimientos.\n"}
{"prompt":"Sistema biofeedback de sensores de detección de estrés mediante algoritmos de aprendizaje de máquinas en estudiantes universitarios ->","completion":" Diseñar un sistema biofeedback de sensores de detección de estrés mediante algoritmos de aprendizaje de máquinas en estudiantes universitarios.En este trabajo de titulación se desarrolla el sistema BIOSTRESS, este es un sistema Biofeddback de sensores que predice el nivel de estrés mediante algoritmos de aprendizaje de máquinas, el objetivo de este sistema es detectar estos niveles y ayudar a controlarlo mediante un posible tratamiento, sirviendo de apoyo para el trabajo que realizan los psicólogos. El diseño del sistema se basó en la metodología denominada Modelo en V y se encuentra conformado principalmente por la placa MySignals ya que sirve de ayuda para desarrollar sistemas e-Health. Además, cuenta con sensores biomédicos para detectar los cambios fisiológicos de los estudiantes y así obtener su información, con ello, se continua al procesamiento de los datos para determinar el nivel de estrés que posee el paciente, pudiendo visualizar mediante la interfaz de una aplicación desarrollada en el software Processing. Finalmente, la funcionalidad del sistema es analizado mediante pruebas a un grupo de 10 estudiantes de diferentes carreras entre hombres y mujeres, lo que ayudó a lograr la factibilidad del sistema, puesto que se obtuvo diferentes resultados entre los cuales el 70% de los sujetos de prueba presentan un nivel de estrés diferente del normal y con la ayuda del Biofeedback estos niveles se pueden normalizar. BIOSTRESS sería de gran utilidad a los profesionales en el tema para que el diagnóstico de las personas sea mucho más preciso.Ingeniería\n"}
{"prompt":"Diseño y construcción y pruebas de un maniquí publicitario autónomo basado en sistemas de razonamiento-aprendizaje ->","completion":" El presente proyecto representa una variante de publicidad no común o conocida como BTL, este modelo propuesto capta la atención del cliente mediante un maniquí autónomo, el prototipo realiza movimientos parecidos a los de un humano, los cuales están centrados en la cabeza y brazo derecho. El maniquí consta además de un sistema de reconocimiento para niños y adultos, esto nos permitirá generar un saludo distinto para cada uno. El movimiento de la cabeza capta toda la atención de la persona que se acerca, gira su cabeza de derecha a izquierda y como toque final realiza un destello por sus ojos, el maniquí una vez que ha reconocido si la persona es adulto o niño alza el brazo simulando dar la mano y en seguida dice un saludo personalizado dependiendo de la persona.\n"}
{"prompt":"Herramientas tecnológicas como factores estratégicos de mejora continua de modelo de negocios para un portal inmobiliario de la empresa Plusvalia.Com a nivel nacional ->","completion":" El presente trabajo se trata de establecer un mecanismo que apoye al área comercial de Plusvalia.com para que pueda asesorar sobre sus servicios a sus clientes y futuros clientes; en base a la experiencia de sus actuales clientes; conocer qué servicio satisface más las necesidades de cada uno; dependiendo de las características que cada uno maneje. En base al programa Machine Learning Studio, programa de Microsoft, se pretende realizar el análisis de datos y sugerir el o los servicios que mejor efectividad tengan para un cliente; el área comercial de Plusvalia.com; se ve beneficiada al tener una referencia que pueda brindar a un cliente; siendo el consultor comercial o no un experto en el área de bienes raíces; se podrán establecer métricas que lo guíen en el asesoramiento a sus clientes.The present work is about establishing a mechanism that supports the commercial area of Plusvalia.com so that it can advise on its services to its clients and future clients; based on the experience of its current customers; know which service best meets the needs of each one; depending on the characteristics that each one manages. Based on the Machine Learning Studio program, Microsoft's program, it is intended to perform data analysis and suggest the service (s) that are most effective for a client; the commercial area of Plusvalia.com; It is benefited by having a reference that can provide a client; being the commercial consultant or not an expert in the area of real estate; You can establish metrics that guide you in advising your clients.Tesis\n"}
{"prompt":"Implementaci?n de un detector de coral utilizando filtros Gabor Wavelets y m?quinas de aprendizaje ->","completion":" This work focuses on the implementation of a fast coral reef detector that is used for an Autonomous Underwater Vehicle (AUV, its acronym in English). A fast detection of the presence of coral ensures the AUV stabilization in front of coral reef in the shortest possible time, avoiding collisions with coral. The coral detection is carried out on an image that captures the scene that the AUV?s camera perceives. A pixel-by-pixel classification is performed between two classes: coral reef and the background that is non-coral reef. Each pixel of the image is assigned to afeature vector, which is generated by using Gabor Wavelet filters. These are implemented in C++ and the OpenCV library. The feature vectors are classified using nine machine learning algorithms. The performance of each algorithm is compared with the accuracy and execution time. The Decision Tree algorithm proved to be the fastest and most accurate of all the algorithms. We created a database of 621 images of coral reefs in Belize (110 of training images and 511 of testing images).Este trabajo se enfoca en la implementaci?n de un detector de arrecife de coral de des empe?o r?pido que se utiliza para un veh?culo aut?nomo submarino (Autonomous Underwater Vehicle, AUV, por sus siglas en ingl?s). Una detecci?n r?pida de la presencia de coral asegura la estabilizaci?n del AUV frente al arrecife en el menor tiempo posible, evitando colisiones con el coral. La detecci?n de coral se hace en una imagen que captura la escena que percibe la c?mara del AUV. Se realiza una clasificaci?n p?xel por p?xel entre dos clases: arrecife de coral y el plano de fondo que no es coral. A cada p?xel de la imagen se le asigna un vector caracter?stico, el mismo que se genera mediante el uso de filtros Gabor Wavelets. ?stos son implementados en C++ y la librer?a OpenCV. Los vectores caracter?sticos son clasificados a trav?s de nueve algoritmos de m?quinas de prendizaje. El desempe?o de cada algoritmo se compara mediante la precisi?n y el tiempo de ejecuci?n. El algoritmo de ?rboles de Decisi?n result? ser el m?s r?pido y preciso de entre todos los algoritmos. Se cre? una base de datos de 621 im?genes de corales de Belice (110 im?genes de entrenamiento y 511 im?genes de prueba).Universidad T?cnica De Machalahttp:\/\/dspace.ucuenca.edu.ec\/bitstream\/123456789\/21345\/1\/MATCH%2714_07_Tusa%20et%20al.pdf\n"}
{"prompt":"Desarrollo de un modelo predictivo basado en aprendizaje de máquina supervisado, para el análisis de datos de trisomía 21 en procesos de salud prenatal. ->","completion":" PDFLa trisomía 21 es un problema de salud pública tanto en Ecuador como a nivel mundial, razón por la cual el presente trabajo investigativo plantea el desarrollo de un modelo computacional predictivo mediante la aplicación de algoritmos de aprendizaje supervisado de Machine Learning, se seleccionó trabajar con el aprendizaje automático fundamentándose en un modelo predictivo el cual posibilite analizar los factores de riesgos presentes en la trisomía 21. Mencionado modelo se encuentra basado en “Arboles de decisión” y “Redes Neuronales”, los mismos que a partir de los factores de riesgos, presentaran el riesgo que tiene el paciente de desarrollar trisomía 21. De la misma manera se aplico metodología de investigación documental con el propósito de que brinde un aporte en el momento de adquirir conocimientos relevantes en los avances del proyecto, con dicha metodología se efectuaron pruebas para comprobar el comportamiento con el que contaba cada una de las variables aplicadas en el modelo predictivo, el cual desempeña la funcionalidad de apoyo en la toma de decisiones médicas, con la finalidad de adquirir un diagnostico eficiente y como resultado se obtendrá un control prenatal temprano en pacientes con riesgo a desarrollar embarazos con trisomía 21.Trisomy 21 is a public health problem both in Ecuador and worldwide, which is why this research project proposes the development of a predictive computer model through the application of supervised learning algorithms from Machine Learning. We selected to work with automatic learning based on a predictive model that makes it possible to analyze the risk factors present in trisomy 21. This model is based on \"Decision Trees\" and \"Neuronal Networks\", the same ones that, based on the risk factors, present the risk that the patient has of developing trisomy 21. In the same way, documentary research methodology was applied with the purpose of providing a contribution at the moment of acquiring relevant knowledge in the advances of the project. With this methodology, tests were carried out to verify the behavior of each one of the variables applied in the predictive model, which carries out the support functionality in the medical decision making process, with the purpose of acquiring an efficient diagnosis and as a result, an early prenatal control will be obtained in patients with risk of developing pregnancies with trisomy 21.\n"}
{"prompt":"Sistema de extracción de características y análisis de texto lírico musical en contenidos web mediante aprendizaje de máquinas para brindar recomendaciones a compositores latinoamericanos ->","completion":" El procesamiento del lenguaje natural es un campo que combina las ciencias computacionales como el aprendizaje automático con la lingüística aplicada, con el fin de lograr el procesamiento asistido por computador de cierta información expresada en lenguaje corporal para llevar a cabo ciertas tareas que imitan comportamientos inteligentes. Por esta razón, y en base a los procesos de aprendizaje que tiene el ser humano, se puede llegar a implementar el reconocimiento de texto utilizando las computadoras y el potencial analítico de algoritmos que forman parte de la herramienta Weka, minimizando el error en la clasificación de texto. Para ello, el desarrollo del prototipo propuesto en el trabajo de titulación parte de un estudio de características que contiene la web, en base a los recursos seleccionados se llegó a la construcción de un web crawler que permite la extracción y almacenamiento de texto por género musical de artistas latinoamericanos. Seguidamente, se muestra un análisis de los algoritmos que forman parte de la clusterización de datos indicando los porcentajes de instancias correctamente agrupadas. Para finalizar con el proceso de desarrollo, se elabora una página web que contiene el resultado del estudio que se llevó a cabo dentro de la investigación, logrando brindar recomendaciones en base a las canciones más populares de cada género musical.\n"}
{"prompt":"Detección de Mascarilla para COVID-19 a través de Aprendizaje Profundo usando OpenCV y Cascade Trainer GUI. ->","completion":" La pandemia del covid-19 está provocando una crisis de salud a nivel mundial, una de las recomendaciones de los científicos y gobiernos para evitar contagios es el uso de mascarilla. Basados en esta precisión, el presente artículo muestra el desarrollo de un software que permite detectar la mascarilla en distintos escenario usando el lenguaje de programación de Python mediante las librerías de cv2, os, Numpy y Imutils, utilizando redes neuronales convolucionales más eficaces que las redes neuronales comunes, las cuales fueron entrenadas con el software Cascade Trainer GUI, usando diferentes cantidades de bases de datos desde 400 hasta 1400 imágenes para comparar los distintos tipos de precisión del sistema de detección de la mascarilla. Sin embargo, de la primera base de datos no se obtuvo una buena presión por una baja cantidad de falsos positivos, por lo cual a medida que se usa más datos la precisión fue aumentando considerablemente hasta obtener una precisión de 92 % con mascarilla y un 100% sin mascarilla.\n"}
{"prompt":"Modelado, simulación y control de velocidad de un rotor excéntrico. ->","completion":" El trabajo de titulación consistió en la simulación numérica de un sistema PID (Proporcional-Integrativo-Derivativo) para controlar la velocidad excéntrica de un rotor, cuyo propósito final era presentar el control de un rotor excéntrico. Primero, se aprendieron sobre las propiedades físicas y se estudió el movimiento de tal rotor, luego se enfoca en la fundamentación teórica de operación del sistema de control PID. También, se muestra el curso de la búsqueda numérica para la solución de la ecuación de movimiento del rotor excéntrico. En lugar de realizar experimentos en el rotor real, el análisis se lleva a cabo mediante simulación numérica sobre la plataforma MatLab. La tarea en sí también presenta el proceso de implementación de esta simulación y la obtención de resultados. Finalmente, los resultados también son analizados e interpretados. Se observó cómo el sistema de control responde a los rápidos cambios en la velocidad de rotación del rotor excéntrico.\n"}
{"prompt":"Modelado y simulación dModelado y simulación de reactores CSTR para tratamiento aerobio de aguas residuales domésticas, generadas por las Cdlas. Entre Ríos y Los Arcos ->","completion":" En la actualidad el problema de contaminación ambiental referido al tratamiento de aguas residuales domesticas son generadas por las comunidades organizadas de los países latinoamericanos. El estudio que se realizó determina in situ la recolección para la caracterización de estas aguas a la entrada y la salida de las plantas de tratamiento de aguas residuales domesticas con el fin de analizar la relación de aproximación del diseño del modelado de los diferentes equipos (reactor CSTR, equipo de aireación y oxigenación) y la simulación para obtener cual es el mejor diseño con respecto a las ciudadelas seleccionadas. De acuerdo con la interpretación de los resultados se observa que hay una mayor contaminación en la ciudadela Los Arcos en comparación con la ciudadela Entre Ríos. El parámetro más crítico se analiza en la DBO5, la cual se observa que la ciudadela los arcos presenta mayor contaminación de carga orgánica en un 90.38% lo que podemos inferir que el agua de los arcos presenta mayor contaminación esto se debe a que esta planta de tratamiento no solo trata el agua de los Arcos, sino que trata ciudadelas cercanas, todos los parámetros que se han analizados están por encima del límite de máximo permisible el único parámetro que está cumpliendo el estándar en el pH.\n"}
{"prompt":"Modelado y simulación de la extrusora tipo husillo mediante el uso del software Ansys Cfd Simulation ->","completion":" El objetivo del modelado y simulación de la extrusora tipo husillo mediante el uso del Software ANSYS CFD permitió realizar una simulación en tiempo real del proceso de extrusión del Polipropileno, además de determinar las propiedades del material plástico cuando el mismo es sometido bajo ciertas condiciones. La principal ventaja del uso de este programa es que facilita el desarrollo y solución de problemas de cálculo y diseño, acorta tiempos y permite observar además de verificar el proceso del fluido, el cual pasa por varias etapas entre ellas: la zona de alimentación, plastificación, dosificación y descarga. El diseño del equipo se lo realiza con medidas reales, esto a fin de que los resultados obtenidos se encuentren lo más cercano posible a la realidad. Con el modelo generado de la extrusora se procede a ingresar datos (inputs) del Polipropileno entre los que constan valores de densidad, viscosidad dinámica, Cp y conductividad térmica como parte del fluido, y como parte de equipo se configura el material de construcción propio de la extrusora. Con todos los parámetros ya establecidos se fijan las condiciones de frontera donde se configuran valores de presión ambiental y temperatura de 3 resistencias que alcanzan los 500 grados Celsius. Finalmente se procede a ejecutar el Simulador en primera instancia para el precalentamiento del equipo en donde el fluido netamente es aire, y posterior a esto cuando alcanza la temperatura seteada de 175 grados Celsius de extrusión del Polipropileno se procede a ingresar el nuevo fluido preestablecido del material plastificante para observar su comportamiento en el transcurso del tiempo, cabe mencionar que para alcanzar esta meta se trabajó con un determinado número de iteraciones y tiempo establecidos por el usuario. Las principales variables de análisis proporcionadas por el software al concluir el análisis de fluidos fueron: presión, temperatura y velocidad. Además, se procedió a realizar un análisis del material que entra al equipo el cual posee ciertas propiedades que pueden influir en el proceso de extrusión. Se recomienda considerar para el análisis las pérdidas de calor existentes durante el proceso.The objective of the modeling and simulation of the screw extruder by using the ANSYS CFD software allowed a real-time simulation of the extrusion process of the Polypropylene in addition to determining the properties of the plastic material when it is submitted under certain conditions. The main advantage of the use of this program is that it facilitates the development and solution of calculation and design of problems, shortens times and allows observing as well as verifying the process of the fluid, which goes through several stages such as: the feeding, plasticizing, dosing and unloading area. The design of the equipment is carried out with real measurements so that the results obtained are as close as possible to reality. With the model generated of the extruder, data (inputs) of the Polypropylene are entered, among which are values of density, dynamic viscosity, Cp and thermal conductivity as part of the fluid, and as part of the equipment, the extruder's construction material is configured. With all the parameters already established, the boundary conditions are set where the values of environmental pressure and temperature of 3 resistances reaching 500 degrees Celsius are configured. Finally, the Simulator is run first to preheat the equipment where the fluid is clear air, and then when it reaches the set temperature of 175 degrees Celsius of the polypropylene extrusion, the new pre-established fluid of the plasticizing material is introduced to observe its behavior over time. It is worth mentioning that to achieve this goal, a certain number of iterations and time established by the user were used. The main analysis variables provided by the software at the end of the fluid analysis were: pressure, temperature, and speed. Besides, an analysis of the material entering the equipment was carried out, which has certain properties that can influence the extrusion process. It is recommended to consider for the analysis the heat losses existing during the process.\n"}
{"prompt":"Modelado y Simulación Robótica de la Extremidad Superior Humana en Open Source. ->","completion":" Se diseñó un prototipo de brazo robótico antropomórfico de 6 grados de libertad para simular los movimientos del brazo humano mediante programas de código abierto como son OpenRAVE y FreeCAD sobre la plataforma Linux, con lo cual se determinó que la arquitectura OpenSource permite un mejor desarrollo en la simulación de robots y brindara asistencia en el cálculo de la cinemática directa. Considerando la altura de un hombre de 1.70 m y las fórmulas de Sjøvold se calculó las medidas de cada segmento del brazo humano: brazo 31.63 cm, antebrazo 23.88 cm, para la mano se utilizó tablas de ergonomía determinando 17.4 cm como largo total, por cada dedo existen falanges proximal, medial y distal sus valores oscilan entre 3.6-5, 2.5-3.5 y 2.2-2.8 cm respectivamente; también se examinó los movimientos anatómicamente permitidos por las articulaciones hombro, codo y muñeca con sus respectivos límites de movilidad; el software de Modelado FreeCAD permitió crear las piezas del brazo con las características de tamaño y funcionalidad descritas. En el simulador OpenRAVE se ensambló el robot definiendo al manipulador desde el hombro hasta la muñeca y la mano como su efector final. Se escribieron varios programas en C++ para realizar pruebas utilizando algunas funciones que brinda el simulador. En el programa general se realizó el movimiento del manipulador mediante el ingreso de parámetros por teclado: la articulación y los grados, obteniendo en la terminal el tiempo y velocidad en cada punto de la trayectoria para representarlos en graficas de posición, velocidad y aceleración angular comprobando que el robot opera efectivamente sin ninguna interrupción hasta llegar a su meta en un 95%; mientras que en el simulador se observa la posición del efector final en relación al sistema de coordenadas global demostrando así la cinemática directa del robot en forma visual. El robot diseñado puede ser utilizado como un “asistente personal” de personas con discapacidad o que no puedan movilizarse por sí mismas.We designed a protitype of an anthropomorphic robotic arm of 6 degrees of freedom to simulate the movements of the human arm, using OpenSource programs such as OpenRAVE and FreeCAD on the Linux plataform, with which it was determined the architecture OpenSource allows a better development in the simulation of robots and it would provide assistance in the calculation of the direct kinematics. Considering the height of a man of 1.70 m and Sjovold formulas calculated measures of each segment of the human arm 31.63 cm. forearm 23.88 cm., hand used ergonomics tables determining 17.4 cm. As total length, each finger there are the proximal, medial and distal phalanges values oscillate between 3.6-5, 2.5-3.5 and 2.2-2.8 cm. respectively; also examined anatomically allowed by joint movements shoulder, elbow, and wrist their respective boundaries of mobility model FreeCAD software allowed us to create parts of the arm with the described characteristics of size and functionality. In the Simulator OpenRAVE is assemble the robot defining the handler from the shoulder to the wrist and the hand as their final effector, several programs were written in C++ to perform test using some functions that provides Simulator. The general programme was the motion of the manipulator by entering parameters by keyboard: articulation and grades, getting into the terminal time and speed at every points of the path to represent them in position graphics, speed and angular acceleration by checking that the robot operates effectively without any interruption to reach its goal in 95%; While the Simulator shows the position of the end effector in relation to the global coordinate system showing the direct kinematics of the robot in a visual way as well the designed robot can be used as a “personal assistant” of people with disabilities or who cannot move by themselves\n"}
{"prompt":"Modelado, simulación y control de un sistema dinámico mediante el uso de componentes análogos simples ->","completion":" El diseño, construcción y operación del péndulo invertido se hace con el fin de practicar los principios de la mecatrónica y con ello mostrar el poder de un mecanismo de control a estudiantes de dinámica y control. Para estabilizar el péndulo invertido se procura controlarlo por medio del uso de simples componentes analógicos tales como potenciómetros y amplificadores operacionales.GuayaquilIngeniero Mecánico\n"}
{"prompt":"Modelado, simulación y control de un sistema dinámico mediante el uso de componentes análogos simples ->","completion":" Un péndulo invertido es un dispositivo físico que consiste en una barra cilíndrica con libertad de oscilar alrededor de un pivote fijo. Este pivote es montado sobre un carro el cual en su giro puede seguir una trayectoria horizontal, Nuestro propósito final es conservar el péndulo perpendicular ante la presencia de perturbaciones, donde el péndulo inclinado regresa a la posición vertical cuando se aplica al carro una fuerza de control apropiada y al final de cada proceso de control, se pretende regresar el carro a la posición de referencia. La fuerza correcta es establecida a través de las mediciones de los valores instantáneos de la posición horizontal y el ángulo de inclinación del péndulo, por lo que hacemos uso del diseño de un observador de orden mínimo. El diseño es solventado bajo el uso de Matlab y Simulink, cuyo análisis, modelado y simulación nos conduce a concretar los objetivos planteados, sin embargo al ser la simulación un aspecto importante pero bajo ningún aspecto un sustituto de un hardware real, proponemos la construcción de nuestro controlador como propósito final con uso de componentes análogos simples, el cual nos suministra claras diferencias en nuestro modelo analizado y el real, especialmente por factores tomados bajo asunciones, tales como fricción, ruido y no linealidades del sistema.\n"}
{"prompt":"Modelado, simulación y control de un sistema dinamico mediante el uso e componentes análogos simples ->","completion":" Un péndulo invertido es un dispositivo físico que consiste en una barra cilíndrica con libertad de oscilar alrededor de un pivote fijo. Este pivote es montado sobre un carro el cual en su giro puede seguir una trayectoria horizontal, Nuestro propósito final es conservar el péndulo perpendicular ante la presencia de perturbaciones, donde el péndulo inclinado regresa a la posición vertical cuando se aplica al carro una fuerza de control apropiada y al final de cada proceso de control, se pretende regresar el carro a la posición de referencia. La fuerza correcta es establecida a través de las mediciones de los valores instantáneos de la posición horizontal y el ángulo de inclinación del péndulo, por lo que hacemos uso del diseño de un observador de orden mínimo. El diseño es solventado bajo el uso de Matlab y Simulink, cuyo análisis, modelado y simulación nos conduce a concretar los objetivos planteados, sin embargo al ser la simulación un aspecto importante pero bajo ningún aspecto un sustituto de un hardware real, proponemos la construcción de nuestro controlador como propósito final con uso de componentes análogos simples, el cual nos suministra claras diferencias en nuestro modelo analizado y el real, especialmente por factores tomados bajo asunciones, tales como fricción, ruido y no linealidades del sistema.\n"}
{"prompt":"Modelado y simulación de sistemas digitales de comunicaciones en Matlab\/ Simulink. ->","completion":" El presente trabajo de titulación tiene como finalidad modelar y simular las distintas modulaciones digitales que son utilizados en los sistemas de comunicación como ASK, FSK y PSK mediante programación en Matlab\/Simulink como se describe en el capítulo 3. Se obtuvieron bueno resultados de las simulaciones realizadas y se pudo evidenciar el comportamiento que tiene cada tipo de modulación sin necesidad de algún equipo costoso. Previamente en el capítulo 1, se presentan las generalidades del trabajo de titulación donde describimos los antecedentes, la definición y justificación del problema, los objetivos planteados, hipótesis y la metodología que se utilizara. En el capítulo 2, se realiza la descripción básica del estado de arte de las modulaciones digitales que serán desarrolladas en el presente trabajo. En el capítulo 3, se realiza la programación script de MatLab y el diseño en simulink que nos permite evidenciar el proceso de modulación y demodulación digital en los sistemas de comunicaciones. Finalmente en el capítulo 4, se exponen las conclusiones y recomendaciones del trabajo de titulación.\n"}
{"prompt":"Modelado y simulación de un brazo robótico de 6 gdl para aplicaciones industriales utilizando MatLab ->","completion":" El presente trabajo de titulación permitió desarrollar una herramienta de simulación a través del modelado de un robot manipulador o brazo robótico con 6 grados de libertad utilizando el software MatLab. La primera parte del documento consiste en la descripción general del trabajo de titulación, entre lo más importante la definición y justificación del problema, objetivo general y específicos, y la metodología de investigación que se utilizó en el presente proyecto. La segunda parte, se procedió a describir los fundamentos teóricos de la robótica, en especial de la parte industrial en lo que los brazos robóticos o robots manipuladores, también fueron analizados la parte cinemática directa e inversa a través del método IIK, también fue considerado los parámetros de DH. Finalmente, se desarrollaron las expresiones matemáticas que permiten modelar y simular el brazo robótico con 6 gdl utilizando MatLab. Los resultados obtenidos dependieron de la movilidad y trayectoria del manipulador considerando las articulaciones del mismo.\n"}
{"prompt":"Simulación y modelado del sistema de producción en el campo Singue ->","completion":" El campo Singue se localiza en la parte noreste de Ecuador correspondiente al Bloque 53, cerca de Colombia. La licitación de contratos para la exploración y explotación de hidrocarburos regularmente se realizan para un largo periodo de tiempo. A partir de su firma, los contratistas son responsables de cubrir todos los costos, personal, materia prima, tecnología y financiamiento necesarios para la ejecución de las actividades petroleras. Por aquello, es fundamental realizar un plan anual integral de desarrollo del campo, donde el principal desafío es encontrar cuellos de botella en el sistema de producción. Dicho proyecto incorpora la evaluación del sistema de producción desde los pozos y las facilidades de superficie de acuerdo al comportamiento dinámico del reservorio; para lo cual, es necesario simular el reservorio, realizar análisis nodal presente y futuro y dimensionar los equipos de superficie. Adicionalmente permite seleccionar el mejor caso de desarrollo de acuerdo al petróleo acumulado, factor de recobro y evaluación económica.Singue field is located in the northeastern part of Ecuador corresponding to Block 53, near Colombia. Tendering for exploration and exploitation hydrocarbons contracts are commonly granted for a long period of time. Upon its signature, contractors are liable for expenses, labor force, equipment, technology, and required funding for the performance of petroleum activities. Therefore, it is essential to make a comprehensive annual development plan, where the main challenge is to detect bottlenecks in the production system. The project assesses the production system include wells and surface facilities according to the reservoir dynamics; by simulating the reservoir, performing present and future nodal analysis, and sizing surface equipment. Furthermore, it lets you select the best development case related to the cumulative oil, recovery factor, and economic evaluation.Cerón Guerra, Ignacio Bladimir, director\n"}
{"prompt":"Modelado y simulación de una planta de tratamiento de aguas residuales empleando modelos ASM ->","completion":" La contaminación del agua es una de las problemáticas de mayor magnitud en el medio ambiente. El tratamiento de las aguas residuales, producto de las actividades del ser humano, es fundamental para mantener un equilibrio sano en los ecosistemas. Para la presente investigación se aplicó el modelo ASM1, en la PTAR de la empresa EMRAQ-EP, con la ayuda del software GPS-X. Se realizó la caracterización física, química y biológica de las aguas residuales generadas por el faenamiento del camal metropolitano de Quito. En base a los parámetros establecidos en el modelo de lodos activados ASM1, se obtuvieron los datos de entrada para generar un modelo cercano a la realidad para efectuar la simulación, logrando la validación de la investigación. A partir de un pre-muestreo, se concluyó realizar dos campañas para la caracterización del influente y determinar las fracciones del modelo, para lo cual se aplicaron protocolos de caracterización. Las entradas en el software GPS-X se determinaron a partir de los resultados obtenidos en campaña y de los cálculos realizados posteriormente. Se empleó el programa Influent Advisor para determinar las condiciones iniciales y modelar el biorreactor. Las simulaciones se realizaron en estado dinámico, con las fracciones calculadas y calibradas, para estimar el comportamiento de la PTAR. Se calculó R2 para determinar la validez de los resultados obtenidos.Water pollution is one of the biggest problems in the environment. The treatment of wastewater, resulting from human activities, is essential to maintain a healthy balance in ecosystems. For this research, the ASM1 model was applied in WTP of the EMRAQ-EP, with the help of GPS-X software. The physical, chemical and biological characterization of the wastewater generated by the work of the Metropolitan Camal of Quito was performed. Based on the parameters set in the ASM1 activated sludge model, the input data was obtained to generate a model close to reality to perform the simulation, achieving the validation of the research. Based on pre-sampling, two campaigns were concluded for the characterization of the influent and the model's fractions were determined, for which characterization protocols were applied. The entries in the GPS-X software were determined from the results obtained in the campaign and the calculations made later. The Influent Advisor program was used to determine initial conditions and model the bioreactor. The simulations were performed in a dynamic state, with the fractions calculated and calibrated, to estimate the behavior of the PTAR. R2 was calculated to determine the validity of the results obtained.\n"}
{"prompt":"Modelado y simulación de un sistema automático de adquisición de datos en centrales hidroeléctricas pequeñas ->","completion":" This paper has developed a measurement system by means of facilities and potential that gives us the computer and microcontroller obtaining study records of interest to know the behavior of the different parameters of electric power. Analysis and validation of results obtained through simulations existing software like Matlab and LabVIEW, creating patterns that in reality are presented today in the production of electricity will take place. Specifically, it has posed a data acquisition system for monitoring electrical parameters in small hydropower using the PIC18F452 microcontroller. The development environment will be characterized in Labview in conjunction with automated validation system with Matlab. Research will develop a design of a Data Acquisition System for the measurement and monitoring of electrical parameters in a min-hydro. Using a microcontroller that allows the development of an automated system that allows better handling of the variables and their transmission to a PC, increasing the facilities and services for control and supervision. In developing this work a characterization of data acquisition systems using the Microcontroller PIC18F452 be made by exploiting the RS232 serial communication system. It is noteworthy that the parameters studied are ideal values, as it is monitoring the magnitudes a central delivery to transform mechanical energy into electricity, without charge.El presente trabajo ha desarrollado un sistema de medición aprovechando las facilidades y potencialidades que nos brinda la computadora y el microcontrolador obteniendo registros de interés de estudio para saber el comportamiento de los diferentes parámetros de la energía eléctrica. Se realizará el análisis y la validación de los resultados obtenidos a través de simulaciones en programas informáticos existentes como Matlab y labview, creando esquemas que en la realidad se presentan en el hoy por hoy de la producción de energía eléctrica. Específicamente se ha planteado un sistema de adquisición de datos para el monitoreo de parámetros eléctricos en pequeñas centrales hidroeléctricas usando el microcontrolador PIC18F452. Se caracterizará el entorno de desarrollo en Labview en conjunto con la validación del Sistema automatizado con Matlab. Se desarrollará en la investigación un diseño de un Sistema de Adquisición de Datos para la medición y monitoreo de parámetros eléctricos en una min-hidroeléctrica. Usando un microcontrolador que permita el desarrollo de un sistema automatizado que permita un mejor procesamiento de las variables y su transmisión hacia una PC, aumentando las facilidades y prestaciones para su control y supervisión. En el desarrollo de este trabajo se realizará una caracterización de los sistemas adquisición de datos mediante el Microcontrolador PIC18F452, explotando el sistema de comunicación serie RS232. Cabe mencionar que los parámetros estudiados son valores ideales, ya que se está monitoreando las magnitudes que una central entrega al transformar la energía mecánica en eléctrica, sin carga alguna.\n"}
{"prompt":"Desarrollo de un software para el modelado y simulación de infraestructuras de cloud computing utilizando Cloudsim ->","completion":" En la actualidad las empresas requieren almacenar su información, procesarla y mantener disponible la mayor cantidad de tiempo posible; tener centros de datos propios, requiere grandes inversiones económicas, la mejor alternativa es el cloud computing, antes de utilizarlo, se debe realizar un correcto dimensionamiento de los recursos requeridos.Currently, companies need to store their information, process it and keep it available for as long as possible; having your own data centers requires large financial investments, the best alternative is cloud computing, before using it, a correct dimensioning of the required resources must be carried out.\n"}
{"prompt":"Diseño, modelado y simulación de un sistema fotovoltaico para abastecimiento de energía del cerro Curiquinga ->","completion":" El propósito del presente trabajo está enfocado en realizar el diseño, modelado y simulación de un sistema fotovoltaico para luego implementarlo en la imagen de la Virgen en el Cerro Curiquingue de la Parroquia Quingeo, cantón Cuenca, provincia del Azuay. Para el análisis de factibilidad se procesó datos tomados por la estación meteorológica ubicada en dicho sector en los cuales consta de radiación solar y temperatura existente durante un lapso de un año. Posteriormente, se construyó un modelo matemático para realizar simulaciones con MATLAB para diferentes valores de entrada que permita diseñar un sistema fotovoltaico que cubra la demanda eléctrica. Se realizan las simulaciones en diferentes condiciones de operación del sistema fotovoltaico y luego se compara con los resultados experiméntales, llegando a la conclusión que tenemos condiciones favorables para la producción de energía eléctrica en Quingeo a través de este sistema fotovoltaico aislado que impulsa el turismo en la comunidad. Dado el ferviente catolicismo en el sector es posible aportar a que mediante este proyecto se pueda mantener esta cultura religiosa y a la postre se pueda analizar el impacto del proyecto mediante una nueva investigación.Tesis\n"}
{"prompt":"Modelado y simulación para el abastecimiento de energía eléctrica mediante sistemas solares a monumentos. Caso de estudio Punta Hacienda, Quingeo ->","completion":" Dada la situación sobre el uso de fuentes de energía renovables y con la finalidad de aportar conocimientos profundizados, se plasma en el presente documento un análisis teórico- práctico sobre la utilidad de la energía solar en monumentos. Para este propósito se ha diseñado un modelo matemático el mismo que nos permite realizar las simulaciones en diferentes condiciones para finalmente contrastar con las mediciones efectuadas en campo. Las pruebas concernientes al monumento se efectuaron en la Comunidad Rural de Puntahacienda de Quingeo, donde se dispone de un área despejada, completamente libre de sombras y que permite apreciar en horas nocturnas el majestuoso monumento donde entre sus particularidades se aprecia el globo terráqueo con sus continentes. La finalidad de esta implementación es dar valor a estos sectores pobres donde en un futuro cercano es posible que tengan como principal aliado el turismo ya que sus campos cada vez van en deterioro por la creciente erosión de sus suelos y que el calentamiento global empieza a generar efectos adversos en estas áreas rurales. El modelo matemático construido en MATLAB\/SIMULINK predijo bastante bien en relación a las pruebas realizadas por lo que es posible tener como una herramienta importante de diseño para este tipo de proyectos donde se ven involucrados proyectos de índole cultural y paisajística. Adicionalmente se complementa bien con el estudio de iluminación con el apoyo de software especializado como es el DIALUX, podemos identificar los niveles de iluminación al ser seleccionada dos lámparas tipo led de 50 W cada una las mismas que se activará automáticamente con un sistema de temporización. Las pruebas respectivas garantizan que la batería suministrará la energía suficiente para estas horas nocturnas. El proyecto genera expectativa para nuevos desarrollos en la parte artística y cultural, sobre todo da pautas sobre la disponibilidad y confiablidad constructiva de sus elementos, los mismos que pueden llegar a ser implementados en áreas rurales como también urbanas, consideradas totalmente autónomas de las redes eléctricas de distribución. El impacto final que sobrelleva este proyecto es darle la iniciativa a las nuevas generaciones de que amplíen su campo de acción y que aprovechen los recursos renovables disponibles, en este caso con el uso de fuentes de energía solar que se aborda en el presente documento.Tesis\n"}
{"prompt":"Modelado y Simulación de un Robot Manipulador de 3 GDL para el Control de la Trayectoria Mediante Inteligencia Artificial ->","completion":" Debido al crecimiento industrial, la inclusión de robots en sus procesos y la complejidad de las tareas que estos deben realizar, se requieren controladores de alto rendimiento. Por esta razón, se modeló y simuló un robot manipulador de 3 grados de libertad (GDL) para el control de la trayectoria utilizando controladores basados en inteligencia artificial: PD+I Difuso y redes neuronales. Estos, incluyendo un PID convencional, fueron evaluados al seguir dos tipos de trayectorias, resultando el PD+I difuso como el más eficaz sin importar la presencia de cambios bruscos de dirección en las trayectorias planteadas.Ingeniero Electrónico\n"}
{"prompt":"Análisis, modelado y simulación de algoritmos sobre técnicas de comunicación tolerante a fallas aplicadas en sistemas industriales ->","completion":" El objetivo de este trabajo es analizar, modelar y simular algoritmos para las diferentes técnicas en el ámbito de las comunicaciones industriales de tal manera de conseguir que los sistemas de comunicación continúen funcionando correctamente a pesar de diferentes fallas. Primero se realizó una descripción de las diferentes redes de comunicación industrial y las fallas que presentan, para luego describir, desarrollar y visualizar algunas aplicaciones entre un maestro y un esclavo utilizando el protocolo ModBus que es el más utilizado a nivel industrial Por medio de MatLab se analizó, modeló y simuló las diferentes técnicas en el ámbito de las comunicaciones industriales como son las técnicas Backwards Error Correction BEC y Forward Error Correction, FEC Como conclusión de este trabajo he llegado a obtener algunos comportamientos del código BCH para diferentes valores de trama como también he realizado una comparación entre tres técnicas de corrección de errores: BCH, Hamming y Convolucional.Magister en Telemática\n"}
{"prompt":"Modelado de circuito eléctricos en CC y AC a través de la plataforma de simulación Matlab\/Simulink. ->","completion":" El trabajo de titulación se ha desarrollado en base a las plataformas de simulación Matlab\/Simulink, ya que nos permitirán ahorrar tiempo y gastos al momento de diseñar y realizar modificaciones, este programa nos ayuda a generar una mejor simulación de circuitos eléctricos ya sea en corriente continua u corriente alterna debido a que sus herramientas son más fuertes y robustas que las otras plataformas de simulación relacionadas con las materias de circuitos eléctricos y electrónicos (análogos y digitales). Simulink es una plataforma integrada en Matlab, Simulink, ya que dispone de una extensa librería de diagramas de bloques lo que nos permite realizar diferentes aplicaciones de la Ingeniería Eléctrica, Eléctrico-Mecánica, Electrónica, Telecomunicaciones, Mecánica, lo que permitirá a los docentes y estudiantes conocer y descubrir las bondades que nos ofrece esta herramienta de simulación.\n"}
{"prompt":"Modelado y simulación numérico-matemático de parámetros de funcionamiento para un vehículo eléctrico en la ciudad de Cuenca-Ecuador ->","completion":" Se ha desarrollado una herramienta para el comportamiento de un vehículo eléctrico en función de la configuración de parámetros de funcionamiento en un ciclo de conducción establecido para conseguir una aproximación de la disponibilidad de autonomía del vehículo eléctrico, a través de un modelo numérico matemático obtenido por regresiones múltiples.In a driving cycle estabilished to achieve an approximation of an electric vehicle's autonomy availability, a tool has been developed for the behavior of an electric vehicle based on operating parameters configuration, through numerical model obtained by multiple regressions.\n"}
{"prompt":"Modelado y simulación para la instalación de un sistema solar fotovoltaico en la escuela rural Antonio Neumane de Puntahacienda Quingeo. ->","completion":" La presente investigación se desarrolló con la finalidad de implementar un sistema solar fotovoltaico en la escuela de educación básica Antonio Neumane ubicado en la parroquia de Quingeo, este proyecto considera el abastecimiento de los circuitos de iluminación y fuerza existentes en los salones de clases y en una etapa futura, energía para las computadoras y equipos eléctricos. Alrededor del mundo se ha demostrado el potencial de los sistemas de energía solar en proyectos de electrificación rural, especialmente para servicios sociales, comunales de agricultura y otras actividades productivas. Su incidencia repercute significativamente en el desarrollo rural, gracias a la constante disminución de sus precios, así como por la experiencia obtenida en su aplicación para otros sectores. Esta es la razón por la cual tomamos la decisión de diseñar, modelar, simular y de validar un sistema solar fotovoltaico que sirva de respaldo al suministro de energía eléctrica en las aulas de clases de la Unidad Educativa Antonio Neumane, el sistema se diseñó para montarlo sobre el techo de las aulas.Tesis\n"}
{"prompt":"Desarrollo de una interfaz humano-computador mediante la animación de avatares generados a partir de fotogrametría ->","completion":" Este trabajo presenta el desarrollo de una interfaz Humano-Computador. Se muestra el diseño de la aplicación móvil para el entrenamiento emocional, el desarrollo de dos avatares generados a partir de técnicas de fotogrametría, así como el desarrollo del reconocimiento facial. Además de los diferentes softwares y librerías utilizadas para el desarrollo.This work presents the development of a Human-Computer interface. The design of the mobile application for emotional training is shown, the development of two avatars generated from photogrammetry techniques, as well as the development of facial recognition. The different software and libraries used for development are shown.\n"}
{"prompt":"Estudio de la notación ConcurTaskTrees para el análisis de tareas en el desarrollo de la interacción humano-computador y su aplicación en el entorno CTTE ->","completion":" El presente proyecto tiene como objetivo realizar un estudio de la notación ConcurTaskTrees para el análisis de tareas en el desarrollo de la interacción humano-computador y su aplicación en el entorno CTTE (ConcurTaskTrees Environment). Para lo cual se realizó a una investigación detallada en donde se recopiló extractos importantes de artículos técnicos con respecto al tema, los cuales entrarán en un estudio de exclusión con el propósito de obtener información valedera y real. Con el fin de que el proceso de desarrollo de software este centrado en el usuario, se hizo un análisis de tareas de una Banca Virtual para que con los cuyos resultados del mismo se ingresaron en la herramienta CTTE con el objetivo principal de ver visualizar la el modelo de interacción que resulte más factible y amigable para el usuario.\n"}
{"prompt":"Investigación descriptiva de lenguaje basado en modelos \"María\" para el análisis de tareas en el proceso de interacción humano computador y su aplicación en una herramienta CASE ->","completion":" A pesar de los problemas que presentan los sistemas informáticos actuales, estos se han convertido en una herramienta de apoyo en la vida cotidiana de las personas, debido a que intervienen en la mayoría de sus actividades. Algunos de los problemas identificados están asociados a la dificultad de uso del sistema, los cuales generalmente son defectos a nivel de sus modelos de HCI (de las siglas en inglés Human Computer Interaction) (por ejemplo: de interacción, interfaz gráfica, tareas, etc.). Por lo tanto, a un mediano o corto plazo, se precisa de mayor cantidad de recursos para corregir estos errores y mejorar la funcionalidad de los sistemas. El presente estudio se enfoca en el uso de la técnica de Análisis de tareas, que ayuda a obtener una mayor compresión del problema en la fase de Análisis; así como también a realizar de mejor manera el diseño de interacción de la fase de diseño del desarrollo Software. En este contexto, se pueden identificar varias formas para realizar el Modelado de tareas; sin embargo, lo deseable sería utilizar un lenguaje que maximice las características principales del proceso HCI, con la finalidad de que el prototipo resultante se ejecute en varias plataformas y obtener múltiples niveles de abstracción (Xavier, 2003).\n"}
{"prompt":"Interacción humano computador para promover actividad física y rediseñar los hábitos alimenticios de jóvenes estudiantes en una institución educativa de Cuenca ->","completion":" Este trabajo de titulación presenta la construcción de un portal web interactivo, desarrollado mediante un proceso de Diseño Centrado en Personas (HCD) con la participación de estudiantes adolescentes, posteriormente, se llevan a cabo estudios basados en Interacción Adolescente-Computador (TeenCI), rama de la Interacción Humano-Computador (HCI) que involucra a individuos de un rango de edad específica. Los estudios TeenCI, se ejecutan con la finalidad de promover hábitos saludables en los estudiantes de un colegio de la ciudad de Cuenca, dichos estudiantes son partícipes del experimento que se realiza para evaluar el portal web interactivo desarrollado. El proceso HCD inicia con el análisis de las características de los usuarios potenciales mediante la técnica Personas, continuando con la obtención de requerimientos de usuario, lo cual permite elaborar las soluciones de diseño que son evaluadas por los participantes del proceso HCD. Con dichas soluciones, se procede a la implementación del portal web, incorporando elementos interactivos que promuevan el uso de este por parte de los usuarios. El experimento realizado tiene como finalidad validar hipótesis referentes a los hábitos saludables de los participantes, así como validar la usabilidad del portal web y la experiencia de los usuarios partícipes de dicho experimento. El experimento comienza por el análisis de los parámetros de actividad física de los sujetos experimentales para obtener datos que puedan ser comparados posteriormente y evaluar si existe un grado de mejora. Luego, se aplican cuestionarios reconocidos por la comunidad HCI\/TeenCI, para validar la usabilidad del portal web y la experiencia de usuario. Una vez finalizado el experimento, se procede a analizar los resultados que permitan dar respuesta a las preguntas de investigación demostrando la validez de las hipótesis, o descartándolas en base a dichos resultados. Finalmente, se incluyen las conclusiones del trabajo realizadoThis work presents the construction of an interactive web portal, developed through a Human Centered Design (HCD) process with the participation of adolescent students, subsequently, studies based on Teen-Computer Interaction (TeenCI), a branch in HumanComputer Interaction (HCI) that involves individuals of a specific age range. The TeenCI studies are carried out to promote healthy habits in the students at a school in the city of Cuenca, these students are participants in the experiment carried out to evaluate the interactive web portal developed. The HCD process begins with the analysis of the characteristics of the potential users through the Personas technique, continuing with the obtaining of user requirements, which allows the elaboration of the design solutions that are evaluated by the participants of the HCD process. With these solutions, the web portal is implemented, incorporating interactive elements that promote its use by users. The purpose of the experiment carried out is to validate hypotheses regarding the healthy habits of the participants, as well as to validate the usability of the web portal and the experience of the users participating in the experiment. The experiment begins with the analysis of the physical activity parameters of the experimental subjects to obtain data that later can be compared and evaluate if there is a degree of improvement. Then, questionnaires recognized by the HCI\/TeenCI community are applied to validate the usability of the web portal and the user experience. Once the experiment is finished, the results that allow answering the research questions are analyzed, demonstrating the validity of the hypotheses, or discarding them based on these results. Finally, the conclusions of the work carried out are includedIngeniero de SistemasCuenca\n"}
{"prompt":"Creación de un lenguaje de dominio específico (DSL) para la especificación de interacciones humano computador, a través de dispositivos de captura de movimiento, en soluciones tecnológicas para entrenamiento cognitivo orientadas al adulto mayor ->","completion":" últimos años la población de adultos mayores ha aumentado significativamente, debido al incremento en la expectativa de vida de las personas, lo cual ha generado la necesidad de cuidado y asistencia hacia este sector de la sociedad. En este sentido ha tomado gran relevancia el uso de nuevas tecnologías que aporten significativamente a la mejora de la calidad de vida de los adultos mayores. Además de brindar al adulto mayor de prolongar el periodo de autovalencia frente a tareas de la vida cotidiana, incluyendo también a personas con discapacidades físicas y cognitivas, tanto dentro como fuera de su hogar, así como en centros de cuidado especializados. En este sentido nace la inteligencia ambiental (AmI), en la cual las personas toman control de sus tareas a través de un entorno digital que no solo es consciente de su presencia, sino que, responde a sus necesidades; esta área del conocimiento ha sido creada para ayudar a los adultos mayores con las actividades de su vida diaria mediante el uso de dispositivos inteligentes y servicios, además de permitir la monitorización al personal de salud encargado de su cuidado. Varias investigaciones respaldan la construcción de sistemas para el apoyo y soporte para adultos mayores, por tal razón, se usan los ambientes de vida asistida por el entorno (AAL) que tienen como objetivo apoyar a la mejora de la situación y calidad de vida de las personas en su entorno ya sea familiar o casa asistencial, aumentando su autonomía usando dispositivos inteligentes. Los sistemas AAL proporcionan un ecosistema de sensores médicos y ambientales que están interconectados para intercambiar datos y proporcionar servicios. Para tratar de minimizar las dificultades que presentan los adultos mayores, es importante contar con herramientas tecnológicas que faciliten las actividades de su entorno; por esta razón, se crean componentes físicos y digitales. En este contexto, los Lenguajes de Dominio Específico (Domain Specific Language - DSL) permiten especificar las necesidades del experto del dominio a través de una herramienta gráfica con la suficiente semántica. Además, de hacer uso de dispositivos de captura de movimiento que se integran dentro de la estructura del DSL e interacciones que, en este caso específico pueden contribuir favorablemente en la representación de los elementos constitutivos de un entorno AAL para adultos mayores. En consecuencia, este trabajo de titulación presenta el desafío de crear un lenguaje de dominio específico (DSL) que haga uso de dispositivos de captura de movimiento (MoCap) y que, a la vez realice rehabilitación de personas con problemas de movilidad total o parcial, física o cognitiva, utilizando interacciones o gestos como una forma natural de comunicación no invasiva para los pacientes. Además, se ofrece un juego serio a modo de aplicativo producto de la instanciación del modelo creado a partir del DSL-MoCap, cuyo objetivo es la educación y el entrenamiento usando diferentes formas de comunicación e interacción. Finalmente, el DSL y el juego serio son evaluados mediante un cuasi experimento y caso de estudio respectivamente aplicando diferentes metodologías que validen su utilidad y aplicabilidad, analizando la percepción de uso por parte de expertos del dominio y pacientes; cuyos resultados han sido positivos dentro de este proyecto.In recent years, the elderly population has increased significantly, due to the increase in people's life expectancy, which has generated the need for care and assistance to this sector of society. In this sense, the use of new technologies that significantly contribute to improving the quality of life of older adults has taken on great relevance. In addition to providing the elderly with prolonging the period of self-sufficiency in the face of daily life tasks, also including people with physical and cognitive disabilities, both inside and outside their home, as well as in specialized care centers. In this sense, environmental intelligence (AmI) is born, in which people take control of their tasks through a digital environment that is not only aware of their presence, but also responds to their needs; This area of knowledge has been created to help older adults with the activities of their daily life through the use of smart devices and services, in addition to allowing the health personnel in charge of their care to monitor them. Several investigations support the construction of support and support systems for older adults, for this reason, environment-assisted living environments (AAL) are used, which aim to support the improvement of the situation and quality of life of the elderly. people in their environment, whether family or nursing home, increasing their autonomy using smart devices. AAL systems provide an ecosystem of medical and environmental sensors that are interconnected to exchange data and provide services. To try to minimize the difficulties that older adults present, it is important to have technological tools that facilitate the activities in their environment; for this reason, physical and digital components are created. In this context, Domain Specific Language (DSL) allows specifying the needs of the domain expert through a graphical tool with sufficient semantics. In addition, to make use of motion capture devices that are integrated into the DSL structure and interactions that, in this specific case, can contribute favorably to the representation of the constituent elements of an AAL environment for older adults. Consequently, this degree work presents the challenge of creating a domain-specific language (DSL) that makes use of motion capture devices (MoCap) and that at the same time performs rehabilitation of people with total or partial mobility problems, physical or cognitive, using interactions or gestures as a natural form of non-invasive communication for patients. In addition, a serious game is offered as an application product of the instantiation of the model created from the DSL-MoCap, whose objective is education and training using different forms of communication and interaction. Finally, DSL and serious game are evaluated through a quasi-experiment and case study, respectively, applying different methodologies that validate their utility and applicability, analyzing the perception of use by domain experts and patients in the case of serious game; whose results have been positive within this project.Ingeniero de SistemasCuenca\n"}
{"prompt":"Diseño y construcción de un sistema de generación de imágenes holográficas interactivo ->","completion":" El mundo de la tecnología avanza de manera rápida, brindándonos nuevas herramientas que facilitan nuestra vida diaria. El objetivo es usar estas herramientas para dar una solución a problemas reales actuales, siendo en este caso, la saturación y la falta de personal para brindar asistencia continua en un centro de atención. En un sistema de asistencia clásico nos encontramos con 2 elementos importantes: El humano y la información del centro de asistencia. El humano brinda la información a quien lo requiera y esto se ha mantenido así desde que se implementaron por primera vez los centros de atención al cliente. La propuesta del presente trabajo es implementar un sistema híbrido entre un avatar y robot con características antropomórficas, que brinde información en el Laboratorio de Mecatrónica y Sistemas dinámicos de la Universidad de las Fuerzas Armadas – ESPE, Matriz Sangolquí; además de realizar procesos y tareas que mejoren la experiencia y automaticen el uso del entorno de trabajo en el que se encuentra el asistente, como el encendido de las luces del laboratorio, guardar un mensaje de voz, etc. Este prototipo es el primero en ser implementado en una institución de educación superior en el Ecuador y existe un largo campo de investigación en el tema\n"}
{"prompt":"Desarrollo de una APP móvil multiplataforma, aplicando el diseño de experiencia de usuario para Liga Deportiva Universitaria de Quito ->","completion":" Conocida mundialmente por sus siglas en inglés (HCI, Human-Computer Interaction), la Interacción Humano-Computador es la disciplina que estudia el intercambio de información que existe entre los usuarios y los ordenadores. Por el lado del usuario puede referirse a un usuario individual, un grupo de usuarios que trabajan en conjunto o una secuencia de usuarios dentro de una organización; el usuario es el que está realizando el trabajo con la tecnología existente a su alcance. Por el lado del ordenador hace referencia a cualquier tecnología desde un computador de escritorio a un sistema informático a gran escala, dicho sistema puede o no incluir partes computarizadas, incluyendo a otras personas. Y por interacción se refiere a cualquier comunicación entre un usuario y una computadora, ya sea una comunicación directa o indirecta; lo importante es que el usuario está interactuando con la computadora con el fin de lograr un objetivo o meta A través del análisis de HCI, lo que se busca es incrementar la satisfacción del usuario final y a su vez reducir el esfuerzo que realiza el usuario al momento de tener interacción con los ordenadores.\n"}
{"prompt":"Integración del entorno virtual de aprendizaje y redes sociales educativas utilizando estándares de calidad para contribuir a la comunicación virtual entre docentes y estudiantes del Instituto Tecnológico Superior Ibarra ->","completion":" Integrar el entorno virtual de aprendizaje y redes sociales utilizando estándares de calidad para contribuir a la comunicación virtual entre docentes y estudiantes del Instituto Tecnológico Superior Ibarra.La evolución de la tecnología muestra que la interacción persona-computador presenta como principales objetivos: \"hacer la vida fácil\" y que sea “fácil de usar” para los usuarios, reduciendo al mínimo las dificultades de uso inherentes a los productos y servicios basados en software (Pintos Fernández, 2014). Alfonso Cuba (2012) define a la usabilidad del software como una ciencia nueva (Pintos Fernández, 2014) que trata de aproximar la tecnología a las personas, independiente del área al cual se dedique. El propósito de la interacción humano-computador es unir diferentes ramas profesionales, industriales, empresariales y gubernamentales con un objetivo común, hacer una interfaz entendible, amigable y sobretodo fácil de usar en ambientes web, aplicaciones cliente servidor, móviles, etc.\n"}
{"prompt":"Obtención, procesamiento y análisis de las ondas cerebrales alfa y beta de un militar, para determinar su capacidad de tomar decisiones en situaciones de estrés y presión ->","completion":" En los últimos años las computadoras, las aplicaciones móviles y la adquisición de ondas cerebrales han sido una fuente fundamental para mejorar la interacción humano-computador, ya que permiten conocer varios trastornos y problemas de salud de un individuo como son: enfermedades mentales, psicológicas o discapacidades, generando alternativas de software y hardware para solucionar estos problemas, brindando así un mejor estilo de vida. El presente proyecto de investigación tiene como objetivo la obtención, procesamiento y análisis de las señales cerebrales de un militar, colocando primeramente en el córtex cerebral el dispositivo electroencefalograma (EEG) Emotiv EPOC+, para obtener los datos de las señales cerebrales Alfa (estado de relajación) y Beta (estado activo) mediante la Interface Cerebro Computador (BCI) EmotivPRO, al inicio de la experimentación se aplican estímulos auditivos para relajar a la persona, acompañada de una prueba de razonamiento abstracto y luego estímulos visuales para generar estrés con una segunda prueba de razonamiento abstracto, con el fin de verificar la capacidad de resolución de problemas en un tiempo limitado. Estas señales cerebrales obtenidas antes y después de los estímulos, serán procesadas y analizadas en un software desarrollado, el cual nos permitirá visualizar el nivel de estrés de la persona durante las dos etapas de la experimentación y verificar la influencia del estrés en las personas para la resolución de problemas\n"}
{"prompt":"Interfaz gemelo digital de un brazo robótico UR3 para repasar el marcado de piezas para corte de superficies. ->","completion":" Hoy en día la industria manufacturera tiene que hacer frente a cambios paradigmáticos de producción, donde la personalización en masa son pilares fundamentales para adaptarse a la demanda cambiante del mercado. La tecnología actual brinda las herramientas necesarias que, al integrarse con las habilidades humanas, da paso a las Smart Industry entrando así a un entorno de revolución industrial 4.0. En el presente trabajo se propone el diseño de una interfaz Digital Twin que apoya la actividad de supervisión del brazo robótico UR3 mientras este realiza el marcado para corte de superficies en el contexto de producción flexible. La interfaz se logra a través de una interacción Humano-Computador Máquina (HCMI) mientras que la autoadaptación a la producción y cambios ambientales se consigue mediante un algoritmo cut and packing y una cámara adaptada al robot respectivamente. La interfaz se implementa y valida mediante un estudio de caso de laboratorio virtual en el que se observa que el Digital Twin replica el movimiento del robot con un tiempo de latencia insignificante.Nowadays manufacturing industry is facing paradigm production changes, where mass customization is a fundamental pillar in adapting to changing market demands. Today's technology provides the necessary tools that, when integrated with human skills, give way to the Smart Industry thus entering an environment of industrial revolution 4.0. This paper proposes the design of a Digital Twin interface that supports the monitoring activity of the UR3 robotic arm while it performs the marking for surface cutting in the context of flexible production. The interface is achieved through a HumanComputer-Machine interaction (HCMI), while the self-adaptation to production and environmental changes is achieved through a cut and packing algorithm and a camera adapted to the robot respectively. The interface is implemented and validated through a virtual laboratory case study in which it is observed that the Digital Twin replicates the movement of the robot with a negligible latency time.\n"}
{"prompt":"Diseño de un sistema interfaz para el reconocimiento y traducción de gestos corporales al lenguaje natural (escrito, hablado) mediante el sensor Kinect de Microsoft, para personas con capacidades diferentes. ->","completion":" El presente proyecto de tesis se encuentra orientado hacia la comunicación mediante el uso de la informática y las telecomunicaciones, usando el dispositivo kinect que sirve como una herramienta traductora de gestos corporales más comunes que realizan las personas con capacidades diferentes, el trabajo de investigación está compuesto por 3 capítulos en el cual se detalla a continuación. En el primer capítulo se describe el proyecto de intervención en donde se plantea la problemática, la justificación al problema, se establecen los objetivos tanto general y específicos, la posible solución al problema a través de la hipótesis y que metodología que se empleó para el desarrollo de la tesis. En el segundo capítulo se expone todos los fundamentos teóricos que llevara el proyecto, se inicia con la interacción humano computador, la interfaz de usuario, introducción a las comunicaciones inalámbricas, la arquitectura, la captura de movimientos, sensores infrarrojos, adicional se realiza la descripción del dispositivo kinect y su importancia para Windows. En el último capítulo se lleva a cabo el análisis de los resultados que fue ron obtenidos a través de sistema de comunicación desarrollado, para finalizar el proyecto de tesis se detalla las recomendaciones y conclusiones.The present thesis project is oriented toward the communication through the use of informatics and telecommunications, using the Kinect device that serves as a translator for the most common body gestures that people with different abilities, this research work is composed of 3 chapters in which is detailed below. As the first chapter describes the intervention project where the problem arises, the justification to the problem, laying down the objectives of both general and specific, a possible solution to the problem through the assumptions and methodology that was used for the development of the thesis. In the second chapter presents all the theoretical foundations that will lead the project, starts with the human computer interaction, the user interface, introduction to wireless communications, architecture, motion capture, additional infrared sensors, the description of the device kinect and its importance for Windows. In the last chapter is carried out the analysis of the results that were obtained through communication system developed, to finalize the draft thesis outlined the recommendations and conclusions.\n"}
{"prompt":"El pensamiento mitológico como sistema cognitivo de las etnociencias ->","completion":" El tratamiento de diversos conocimientos geométricos, algebraicos o simplemente aritméticos de las sociedades a las que se consideran ágrafas, ha dejado de ser una subdisciplina nacida de la antropología e inserta en las matemáticas y pretende convertirse en una nueva ciencia. Dos inquietudes suscitan esta pretensión: en primer lugar, si el episteme o sistema cognitivo de las etnomatemáticas encuentra soporte válido en el pensamiento mitológico que figura como antecedente y, a la vez, fundamento de las etnociencias; y, en segundo lugar, si las etnomatemáticas admiten una teoría, y si ésta, de ser factible, reuniría los requisitos de una teoría autónoma. Los autores analizan estas inquietudes asumiendo como referente la literatura producida por etnólogos, filósofos y etnomatemáticos que han abordado, desde diversas perspectivas, temas involucrados en este artículo.\n"}
{"prompt":"Sistema de recomendación de asignaturas mediante mapas cognitivos difusos basados en el récord académico del estudiante universitario ->","completion":" Trabajo propuesto para desarrollar un modelo inteligente de recomendación para la orientación curricular de asignaturas en el registro académico de los diferentes niveles de educación superior. Está basado en la combinación de algoritmos de agrupamiento, análisis y simulación de mapas cognitivos difusos; de esta manera se podrá predecir el comportamiento y a su vez el impacto sobre el futuro aprovechamiento académico del estudiante.GuayaquilMagíster en Investigación Matemática\n"}
{"prompt":"Sistema de recomendacion de asignaturas mediante mapas cognitivos difusos basados en el record academico del estudiante universitario ->","completion":" Los sistemas de recomendacion resultan de gran utilidad en la seleccion de alternativas para un individuo, en cualquier contexto. de esta manera se tienen más opciones para tomar una decision importante en beneficio de sus gustos y preferencias y asi mejorar resultados. en los diferentes niveles de formacion de un estudiante universitario, la eleccion de asignaturas se hace compleja, debido a la poca informacion que disponen y la limitada experiencia para tomar decisiones trascendentales en su vida academica.GuayaquilMAESTRÍA EN INVESTIGACIÓN MATEMÁTICA\n"}
{"prompt":"Sistema para monitoreo de ondas cerebrales en estudios de pulsos binaurales con ritmo theta sobre los procesos cognitivos y emocionales ->","completion":" The aim of this work is to implement a graphical user interface developed in LabVIEW to facilitate the manipulation of binaural sounds often theta (6 Hz) to examine the relationship between exposure to binaural beats and the performance of individuals in cognitive and emotional processes. The frequency of binaural sounds vary within a range from 4 to 8 Hz, these sounds were inserted in background music that can be heard for an individual during a test session. Brain activity produced by Binaural sounds will be monitored by using a brain computer interface (Emotiv), using this device, the brain waves generated during the testing process will be observed.En el presente trabajo tiene como finalidad implementar una interfaz gráfica, elaborada en el programa LabVIEW, que facilite la manipulación de sonidos binaurales con frecuencia theta (6Hz) para examinar la relación entre la exposición de pulsos binaurales y el rendimiento de individuos en procesos cognitivos y emocionales. La frecuencia de sonidos binaurales variaran dentro de un rango de 4 a 8 Hz y dichos sonidos se insertan en música de fondo que pueda ser escucha por un individuo durante una sesión de prueba. Una vez que se apliquen los sonidos binaurales, la actividad cerebral del sujeto bajo prueba será monitoreada por medio de una interfaz cerebro computadora (Brain Computer Interface) EMOTIV, con el cual se observara las ondas cerebrales generadas durante el proceso de prueba.\n"}
{"prompt":"Hombre de 76 años con deterioro cognitivo rápidamente progresivo ->","completion":" The human Prion Diseases or transmissible spongiform encephalopathies make up a group of rare neurological disorders that course with a rapidly progressive and imminent impairing of cognitive and motor functions. This group of diseases are classified according to the cause of the illness...Las enfermedades por priones o también conocidas como encefalopatías espongiformes transmisibles conforman un grupo de desordenes neurológicos raros, que cursan con un deterioro rápidamente progresivo e inminente de las funciones cognitivas y motoras...\n"}
{"prompt":"Implementación de un prototipo de seguridad física utilizando servicios cognitivos de Azure aplicado al datacenter experimental de la UDLA ->","completion":" Security is a fundamental variable that must be taken into account in the implementation of a data center, since, having expensive and highly available equipment, the minimum that is expected is to protect its integrity in some way. In this way, the present title work has the purpose of implementing a prototype of physical security applied to the experimental data center of the University of the Americas using Azure cognitive services and taking advantage of the computation offered by this platform. Research is done on the cognitive services that are hosted on the Microsoft Azure platform, the applications it offers, its specifications, features, forms of applications, advantages and success stories through cloud computing and its benefits. A cost breakdown is made of the applications and compatible devices that could be used in the process to achieve the implementation of the physical security prototype in the UDLA data center. In order to know the current situation of the data center, a survey of the information and current situation presented in it is carried out. Focusing on the security that counts and the improvement that this project will provide. It is necessary to deepen and know the internal and external regulatory framework related to the equipment and the implementation of the device under the legal parameters of the country and the University. To comply with the implementation, a prototype and tests of the operation of the equipment were created together with the chosen service to be used after the analysis of each application, the operating tests are documented.La seguridad es una variable fundamental que se debe tomar en cuenta en la implementación de un centro de datos, ya que, al tener equipos costosos y de alta disponibilidad lo mínimo que se espera es proteger su integridad de alguna manera. De esta forma, el presente trabajo de titulación tiene como finalidad la implementación de un prototipo de seguridad física aplicado al centro de datos experimental de la Universidad de las Américas utilizando servicios cognitivos de Azure y aprovechando el cómputo que ofrece está plataforma. Se realiza una investigación acerca de los servicios cognitivos que se alojan en la plataforma de Microsoft Azure, las aplicaciones que ofrece, sus especificaciones, características, formas de aplicaciones, ventajas y casos de éxito por medio de cómputo en la nube y sus beneficios. Se realiza un desglose de costo sobre las aplicaciones y los dispositivos compatibles que podrían ser utilizados en el proceso para lograr la implementación del prototipo de seguridad física en el centro de datos de la UDLA. Para conocer la situación actual de centro de datos se realiza un levantamiento de la información y situación actual que se presenta en el mismo. Enfocándose en la seguridad con la que cuenta y el mejoramiento que proporcionará este proyecto. Es necesario ahondar y conocer el marco regulatorio interno y externo relacionado a los equipos y la implementación del dispositivo bajo los parámetros legales del país y de la Universidad. Para cumplir con la implementación se creó un prototipo y pruebas del funcionamiento de los equipos juntamente con el servicio elegido a utilizar luego del análisis sobre cada aplicación, se documenta las pruebas de funcionamiento.\n"}
{"prompt":"Los recursos didácticos en el proceso cognitivo de la asignatura de Ciencias Naturales. ->","completion":" PDFEl propósito de esta investigación es demostrar cómo afecta la ausencia de un sistema didáctico en las notas diseñando un software educativo de ciencias naturales. La fundamentación teórica está sustentada en computadora, calificaciones, sistema. La fundamentación legal está basada en la Constitución Política de la República del Ecuador, la ley de Educación Superior, reglamento General de la ley de Educación Superior. Este trabajo se identifica con la modalidad de proyectos factibles, se apoyó en la investigación bibliográfica y se acudió a las técnicas descriptiva, en la investigación de campo se aplicó las encuestas a través de un cuestionario estandarizado y estructurado dirigido a la población. El manejo tabulación y organización de los datos se realizó mediante la utilización de un paquete Excel. El contenido de esta propuesta consta de: El diagnóstico, la fundamentación teórica, las actividades, los recursos, la evaluación, cronogramas, visión, visión, objetivo general, objetivo específico. Los beneficiarios de esta investigación son los estudiantes y profesores del décimo año de educación básica. Descriptores: Laboratorios, computadoras, calificaciones, sistema didáctico. Como objetivo general tenemos mejorar el proceso de aprendizaje de los estudiantes en la asignatura de ciencias naturales, mediante la implementación de un software educativo lo escogí porque es muy interesante e importante, tanto para docentes como estudiantes aprender e impartir clases por medio de recursos tecnológicos, porque es parte primordial de nuestra sociedad y que ayuda al desarrollo de la humanidad. Como objetivo específico tenemos observar detenidamente porque y donde está la verdadera falencia de los estudiantes de la institución educativa donde se va implementar el proyecto para saber y poder obtener información acerca de los problemas que tengan, describir paso a paso los puntos más conflictivos o problemáticos que tengan los estudiantes para con la asignatura de ciencias naturales, le gustará aprender con este software educativo para el aprendizaje que la actualidad la tecnología nos ofrece.He purpose of this research is to demonstrate how the absence of a didactic system affects the notes designing an educational software of natural sciences. The theoretical foundation is based on computer, qualifications, system. The legal basis is based on the Political Constitution of the Republic of Ecuador, the Law of Higher Education, General Regulation of the Law of Higher Education. This work is identified with the modality of feasible projects, supported by bibliographic research and attended To the descriptive techniques, in the field research the surveys were applied through a standardized and structured questionnaire directed to the population. The handling tabulation and organization of the data was done by using an Excel package. The content of this proposal consists of: The diagnosis, the theoretical foundation, the activities, the resources, the evaluation, timelines, vision, vision, general objective, specific objective. The beneficiaries of this research are the students and teachers of the tenth year of basic education. Descriptors: Laboratories, computers, qualifications, didactic system. As a general objective we have to improve the learning process of the students in the subject of natural sciences, through the implementation of an educational software I chose it because it is very interesting and important, both for teachers and students to learn and teach through technological resources, because it is a primordial part of our society and that it helps the development of humanity. As a specific objective we have to carefully observe why and where is the true fault of the students of the educational institution where the project will be implemented to know and be able to obtain information about the problems they have, describe step by step the most conflictive or problematic points that have the students for the subject of natural sciences, you will like to learn with this educational software for learning that the current technology offers us.\n"}
{"prompt":"Sanamentics - sistema web para el control del deterioro cognitivo enfocado en terapias para la estimulación cognitiva en adultos mayores. ->","completion":" El objetivo principal del sistema es el ayudar al control del deterioro cognitivo gracias a la implementación de ejercicios de estimulación sugeridos por autores reconocidos, brindando a los pacientes residentes del Hogar Corazón De Jesús la posibilidad de acceder a estas terapias. Estos ejercicios inducen al paciente el uso de sus capacidades cognitivas, manteniendo su mente ejercitada. A su vez también cuenta con un test que permite tener un indicio de las personas que se encuentran padeciendo de deterioro cognitivo el cual está basado en el Test Mini Examen Cognoscitivo (MEC) creado por Ed Lobo en 1979, entre otras funcionalidades como lo son obtener gráficos estadísticos de los puntajes obtenidos por cada uno de los pacientes.The main objective is to help control cognitive deterioration thanks to stimulation exercises suggested by recognized authors, providing resident patients of the Hogar Corazón de Jesús with the possibility of accessing these therapies. These exercises induce the patient to use their cognitive abilities, keeping their mind exercised. At the same time it also has a test that allows to have an indication of the people who are suffering from cognitive deterioration which is based on the Test Mini Cognitive Examination (MEC) created by Ed Lobo in 1979, among other functionalities as they are obtaining statistical graphs of the scores obtained by each of the patients.\n"}
{"prompt":"“Diseño e implementación de un sistema autónomo para el desarrollo cognitivo para niños de 2 a 3 años ” ->","completion":" The cognitive field is an essential aspect of the development of the child from two to three years, the child is consolidating the language, begins to understand abstract concepts and relate some concepts with others, improves their attention span, memory and progresses in knowledge and control of his\/her own body. Technologies affect the development of children, either positively or negatively, but the use of these new technologies must be a learning experience. Therefore, in this research project it is intended to design and implement an autonomous system for cognitive development in children from 2 to 3 years, allowing a direct interaction with the computer, providing the child with various activities that influence their cognitive development in a positive way. One of the first tasks in the present project was to review the contributions of the different psychological theories of cognitive nature by Pozo, Bruner, Vygotski and Jean Piaget; without leaving aside the investigation of the different cognitive skills developed by children ages 2 to 3 years. To achieve this goal, it was decided to design a graphical GUIDE interface for Matlab in its ®17 version, within it algorithms for digital image processing and speech recognition were implemented, fundamental pillars for the development of each of the activities within the interface, which will improve the cognitive abilities of children put to the test. Based on this, the different resources necessary for the development of each activity were designed, simulated and constructed, such as the TET (Early Stimulation Cards), the interactive keyboard and the reading box. Finally, the tests of the autonomous system for cognitive development were carried out in a group of children ages 2 to 3 years old from the city of Riobamba. Significant results were obtained when using the proposed system.El ámbito cognitivo es un aspecto esencial del desarrollo del niño de dos a tres años, el niño va consolidando el lenguaje, comienza a comprender conceptos abstractos y a relacionar unos conceptos con otros, mejora su capacidad de atención, memoria y progresa en el conocimiento y control de su propio cuerpo. Las tecnologías inciden en el desarrollo de los niños, ya sea positiva o negativamente pero el uso de estas nuevas tecnologías debe ser una experiencia más de aprendizaje. Por ello, en el presente proyecto de investigación se pretende diseñar e implementar un sistema autónomo para el desarrollo cognitivo en niños de 2 a 3 años, permitiendo una interacción directa con el ordenador, proporcionando al niño diversas actividades que influyan de manera positiva en su desarrollo cognitivo. Una de las primeras tareas en el presente proyecto fue revisar los aportes de las diferentes teorías psicológicas, de carácter cognitivo por Pozo, Bruner, Vygotski y Jean Piaget; sin dejar a un lado la investigación de las diferentes habilidades cognitivas desarrolladas por los niños en edades entre 2 a 3 años. Para cumplir con este objetivo se decidió diseñar una interface gráfica en GUIDE de Matlab en su versión ®17, dentro del mismo se implementó algoritmos para el procesamiento digital de imágenes y reconocimiento de voz, pilares fundamentales para el desarrollo de cada una de las actividades dentro de la interface, que mejoraran las habilidades cognitivas de los niños puestos a prueba. A partir de ello se diseñó, simuló y construyó los diferentes recursos necesarios para el desarrollo de cada actividad como: las TET (Tarjetas de Estimulación Temprana), el teclado interactivo y la caja lectora. Finalmente, las pruebas del sistema autónomo para el desarrollo cognitivo se realizaron en un grupo de niños con edades de entre 2 a 3 años de la ciudad de Riobamba. Se obtuvieron resultados bastante significativos al usar el sistema propuestoUNACH, Sede Ecuador\n"}
{"prompt":"“Factores que inciden en el deterioro cognitivo del adulto mayor bajo un enfoque de mapas cognitivos difusos” ->","completion":" ADOBEEn la presente investigación se puede constatar el proceso realizado para determinar y evaluar los factores que inciden en el deterioro cognitivo de los adultos mayores descubriendo un ambiente de incertidumbre que empuja a la existencia del ya mencionado declive cognitivo, la investigación nos abre puertas al conocimiento de nuevos conceptos y ayudar de esta manera a la explicación de una lógica fuera de lo convencional como lo es la lógica difusa o lógica borrosa, la misma que nos ayuda en la toma de decisiones mediante la asociación de criterios confiables. Se escogió la lógica difusa por motivos de considerarla una herramienta útil que modela la forma en que se llega a una decisión la confiabilidad que brinda en el momento de arrojar resultados, modelación de factores complejos, todo ello dada en una escala de incertidumbre. La finalidad de todo el proceso de investigación que se realizó fue para demostrar la efectividad de los conceptos principales que se ligan a la lógica difusa.In the present investigation we can verify the process performed to determine and evaluate the factors that affect the cognitive deterioration of the elderly, discovering an environment of uncertainty that pushes the existence of the aforementioned cognitive decline, the investigation opens the door to the knowledge of new concepts and help in this way the explanation of an out-of-the-way logic such as fuzzy logic or fuzzy logic, the same one that helps us in making decisions by associating reliable criteria. Fuzzy logic was chosen because it is considered a useful tool that models the way in which a decision is reached on the reliability it provides at the moment of producing results, modeling complex factors, all given on an uncertainty scale. The purpose of the entire research process was to demonstrate the effectiveness of the main concepts that are linked to fuzzy logic.\n"}
{"prompt":"Factor psicológico en el proceso cognitivo. ->","completion":" La presente investigación se refiere a factor psicológico en el proceso cognitivo propuesta guía didáctica, tema que se encuentra enfocado en el mejoramiento del sistema educativo, de esta manera podemos ayudar al desarrollo psicológico de los estudiantes, es fundamental para un crecimiento más óptimo en el proceso educativo. Afrontando la problemática que afecta a los estudiantes de 1ero. Bachillerato de la Unidad Educativa Universitaria Dr. Francisco Huerta Rendón. Este proyecto se realiza mediante el proceso investigativo de tipo bibliográfico y de campo, además de recopilar datos a través de entrevista realizada a la autoridad del Plantel y expertos en el tema; así como la aplicación de encuestas de los resultados de la investigación se presenta una guía didáctica con la cual se busca transmitir información importante al estudiante para poder manejar esta problemática que los aquejas y de esta manera poder obtener los resultados esperados.\n"}
{"prompt":"Estudio comparativo de la conciencia fonológica en niños y niñas del primer año de educación general básica ->","completion":" Esta investigación tiene como objetivo determinar el nivel del desarrollo de la conciencia fonológica en niños y niñas de 5 y 6 años que no presentan discapacidad intelectual y\/o trastorno de lenguaje, que se encuentran culminando el primer año de educación básica, mediante la aplicación de la Prueba de Segmentación Lingüística de Jiménez y Ortiz , se llevó a cabo el estudio de 105 niños que pertenecen a tres escuelas ubicadas en la ciudad de Cuenca, de los cuales 46 son hombres y 59 son mujeres, para así contrastar los resultados en base a los dieciséis factores del test, y de esta manera determinar si hay diferencias significativas, con la variable sexo. Para llegar a los resultados se utilizó el método cuantitativo a través de cuadros estadísticos comparando cada factor, este estudio fue realizado para conocer si hay diferencias del desarrollo fonológico entre niños y niñas, ya que investigaciones previas nos dan a conocer la relación directa del desarrollo del lenguaje con la conciencia fonológica encontrando diferencias del lenguaje entre niños y niñas especialmente en edades tempranas, siendo las niñas las que presentan un mayor desarrollo, pero en relación a la conciencia fonológica se pudo determinar a través de esta investigación, que no hay diferencia significativa. A nivel general los porcentajes de ambos grupos se encuentran en el nivel medio con el 20%, y a nivel de cada factor solamente el tres y dieciséis tuvieron diferencias significativas, los resultados fueron socializados con docentes y directivos para que tengan un conocimiento de los porcentajes y del nivel de desarrollo fonológico en que se encuentra cada escuela, para mejorar y desarrollar actividades fonológicas necesarias e indispensables para el proceso de la lecto escritura.Magíster en Educación Especial\n"}
{"prompt":"Creación de una base de datos emocional multimodal de personas cognitivamente normales y personas con daño cognitivo. ->","completion":" El trabajo de fin de titulación ilustra la creación de una base de datos emocional multimodal de personas cognitivamente normales y con daño cognitivo. Luego de un meticuloso estudio de investigación bibliográfica donde se describen diferentes trabajos realizados sobre base de datos emocionales. Se realiza un proceso metodológico para la creación de la base de datos la cual consta de tres fases: diseño de la investigación, análisis del audio por medio de parámetros de voz y por último los resultados obtenidos por el método de clasificación utilizado. Finalmente se resaltan algunas de sus utilidades y trabajo futuro.The end-of-degree work illustrates the creation of a multimodal emotional database of cognitively normal people with cognitive impairment. After a meticulous bibliographic research study where, different works are described based on emotional data. A methodological process is carried out for the creation of the database which consists of three phases: research design, analysis of the audio by means of voice parameters and finally the results obtained by the classification method used. Finally, some of its utilities and future work are highlighted.\n"}
{"prompt":"El impacto de las Tecnologías de la Información y Comunicación en el desarrollo del sistema cognitivo de los niños de cuarto año de Educación General Básica. ->","completion":" The present research was develop to solve the following problem: What is the impact of the information and communication technologies to development of the cognitive system of the fourth year of Basic General Education of the School \"Mulaló\" period 2020 - 2021? For that reason, it is established as general objective to apply strategies of mediation technology in the teaching-learning process to determine the impact on the cognitive system of the students. It has an approach quant using the following methods and techniques. The methodology used is inductive and deductive method, interview, survey, the criteria of specialists, questionnaire, the impact assessment sheet and the analysis of the products of the activity. It was possible to carry out the research and arrive at the following conclusions. As a result, the application was found in the cognitive development of students goes hand in hand with social affective. The physical factors depend to a great extent on the coexistence with the people who are next to the student. For this reason, the involvement of parents were paramount in achieving very high results in the implementation of technology mediation strategies, because they were responsible for providing: internet service, computers, smartphones or tablets, providing the necessary follow-up for the development and success of activities with learners. Additional, the results of the impact of technology mediation strategies on the cognitive system of fourth year students of Basic General Education. According to the technological, mediation strategies are applied to have an impact on students of 89.6%. Therefore, it can be a positive impact when they use strategies of information and communication technologies.La presente investigación se orienta a resolver el siguiente problema: ¿Cuál es el impacto que tienen las tecnologías de la información y comunicación en el desarrollo del sistema cognitivo de los niños de cuarto año de Educación General Básica de la Unidad Educativa “Mulaló” período 2020 – 2021?; para lo cual se establece como objetivo general aplicar estrategias de mediación tecnología en el proceso de enseñanza-aprendizaje para la determinación del impacto en el sistema cognitivo de los estudiantes; desde un enfoque cuanti-cualitativo, utilizando los siguientes métodos y técnicas: Método Inductivo-Deductivo, la entrevista, la encuesta, el criterio de especialistas, el cuestionario, ficha de evaluación de impactos y análisis de los productos de la actividad; los cuales permitieron realizar la investigación y arribar a las siguientes conclusiones: como resultado de la aplicación se pudo comprobar que el desarrollo cognitivo de los estudiantes van de la mano con los factores sociales, afectivos y físicos ya que cada uno de estos dependen en gran medida de la convivencia con las personas que se encuentran junto al estudiante, por esta razón la participación de los padres de familia fue primordial para alcanzar resultados muy altos en cuanto a la aplicación de las estrategias de mediación tecnológica, porque fueron los encargados de dotar de servicio de internet, computadoras, teléfonos inteligentes o tablets y dar el seguimiento necesario para el desarrollo y éxito de las actividades realizadas con los educandos; adicional, se presentan los resultados del impacto de las estrategias de mediación tecnología en el sistema cognitivo de los estudiantes de cuarto año de Educación General Básica, de acuerdo a las estrategias de mediación tecnológica aplicadas tuvieron un impacto en los estudiantes del 89,6%, por lo tanto se puede afirmar que existe un impacto positivo al usar las estrategias y por consiguiente las tecnologías de la información y comunicación.\n"}
{"prompt":"Método para el Análisis Estático y Dinámico en Mapas cognitivos difusos ->","completion":" En la actualidad la toma de decisiones en los distintos ámbitos tecnológicos y científicos resulta un gran reto debido a los grandes avances que existen en ellos, por lo tanto, sus sistemas contienen gran cantidad de información dinámica y compleja y, en consecuencia, es muy complicado llevar a cabo su análisis. Para contrarrestarlo se usan herramientas como son los modelos causales. Entre los modelos causales más usados se encuentran los MCD (Mapas Cognitivos Difusos) que son herramientas que sirven para efectuar el análisis de sistemas complejos de forma sencilla. Los resultados conseguidos demuestran que los métodos usados son confiables y factibles.Currently, decision-making in the different technological and scientific fields is a great challenge due to the great advances that exist in them, therefore, their systems contain a large amount of dynamic and complex information and, consequently, it is very complicated carry out your analysis. To counteract it, tools such as causal models are used. Among the most used causal models are the MCD (Fuzzy Cognitive Maps) which are tools that are used to carry out the analysis of complex systems in a simple way. The results obtained show that the methods used are reliable and feasible.\n"}
{"prompt":"Desarrollo de una Aplicación Móvil utilizando los servicios cognitivos para personas con discapacidad visual ->","completion":" 1. Fundamentos Teóricos. --2. Metodología. --3. Resultados.--4. Conclusiones Y Recomendaciones.El presente proyecto tiene como objetivo el desarrollo de una aplicación móvil utilizando los servicios cognitivos con el fin de brindar a las personas con discapacidad visual una mayor seguridad al establecer una comunicación con los demás. Con las distintas técnicas e instrumentos de investigación, se pudieron definir los requisitos iniciales y con la ayuda de la metodología Mobile-D se desarrolló la aplicación móvil. Como complemento a la metodología antes mencionada se tomó en cuenta la norma española UNE 139803-2012, de la cual se consideraron algunos requisitos de nivel A y nivel AAA dado que la norma es para todas las discapacidades, esto permitió que la persona con discapacidad visual pueda acceder de una forma más sencilla y rápida a la aplicación. El producto final es una aplicación móvil para personas con discapacidad visual, que cuenta con una guía que facilita a la persona la toma de fotografías dándole una breve descripción como: el género de la persona, la edad estimada y el reconocimiento de emociones. Su efectividad se midió en base a las encuestas realizadas en la escuela de discapacidad visual en Ambato, los resultados obtenidos de dicha encuesta permiten asegurar que la aplicación cumple con las expectativas de los usuarios.Pontificia Universidad Católica del Ecuador, Escuela de SistemasIngeniero\/a en Sistemas y Computación\n"}
{"prompt":"Modelo para el Análisis de Escenarios en Tràfico Vehicular Mediante Mapas Cognitivos Difusos. ->","completion":" ADOBEEl presente proyecto Investigativo aborda un tema que involucra especialmente al sector social, en relación al tráfico terrestre en la ciudad de Guayaquil. El objetivo principal planteado consta en identificar el modelo para el análisis de escenarios mediante mapas cognitivos difusos que permita brindar alternativas de calles o avenidas que no tengan mucha congestión al momento de dirigirse hacia un determinado lugar dentro de la ciudad. El proyecto Investigativo se basa en la recopilación de información de varias fuentes bibliográficas así como en la fundamentación legal basada en las ordenanzas municipales que rigen el tráfico vehicular en la ciudad. La investigación es un proceso sistemático, organizado y objetivo destinado a responder a una pregunta problema de investigación. La unidad básica del proceso investigativo es el proyecto de investigación, documento que recoge de manera pormenorizada la organización que se ha dado a esta actividad y la forma en que se ejecutará la misma. Para el procesamiento de la información se utilizara el método descriptivo y la técnica de encuesta a expertos en tránsito y agentes municipales de la Agencia de tránsito municipal de Guayaquil, también se utilizara la herramienta Mental Modeler ya que permitirá mostrar el análisis de escenarios para los diferentes casos que se pueden presentar en el tráfico vehicular. Primero se creara el modelo que llevara el nombre de Predicción de congestionamiento, este modelo tendrá varios componentes que interactuaran entre sí.This research project addresses an issue that involves the social sector especially in relation to road traffic in the city of Guayaquil. The main objective set consists in identifying the model for scenario analysis using fuzzy cognitive maps that allows providing alternative avenues or streets that do not have much congestion when heading to a location within the city. The research project is based on gathering information from various literature sources as well as the legal foundation based in municipal ordinances governing vehicular traffic in the city. Research is a systematic, organized and objective process to answer a question research problem. The basic unit of the research process is the research project document outlining in detail the organization that has been given to this activity and how it will run. For information processing descriptive technique survey of experts in transit and municipal officers of the Agency municipal transit of Guayaquil method and is used, the Mental Modeler tool is also used as it will show the scenario analysis for different cases that may occur in vehicular traffic. First the model that bore the name was created Prediction congestion, this model will have several components that interact with each other.\n"}
{"prompt":"Diseño de un prototipo Web en base a técnicas de personalización de enseñanza-aprendizaje en la asignatura de inteligencia artificial (mapas cognitivos y la teoría de conjuntos difusos), para los Estudiantes de la Carrera de Ingeniería en Sistemas Computacionales. ->","completion":" PDFEl presente proyecto de titulación trata sobre la inclusión de la tecnología en la educación para obtener mejores resultados en el proceso, el uso adecuado de la metodología en la enseñanza es para poder lograr plasmar el conocimiento más oportuno de un tema específico en la mente de los estudiantes; para lograr esto se realizó el estudio mediante la herramienta de meta-análisis para comparar las diferentes metodologías aplicadas en las asignaturas del área técnica, de esta manera mejorar el proceso de enseñanza mediante el prototipo web, el mismo que será de gran ayuda tanto a estudiantes como docentes al recibir o impartir sus clases; también se realizó un estudio a los temas de lógica difusa y mapas cognitivos, utilizando la metodología ABP para realizar un proyecto, en el cual, los estudiantes deberán aplicar los conocimientos adquiridos en el aula de clases para resolver un problema planteado por ellos mismos, para esto la aplicación cuenta con un módulo para el desarrollo del proyecto.The present degree project deals with the inclusion of technology in education to obtain better results in the process, the proper use of the methodology in teaching is to be able to achieve the most appropriate knowledge of a specific topic in the minds of the students. students; To achieve this, the study was carried out using the meta-analysis tool to compare the different methodologies applied in the subjects of the technical area, thus improving the teaching process through the web prototype, which will be of great help to students as teachers when receiving or teaching their classes; A study was also made to the topics of fuzzy logic and cognitive maps, using the ABP methodology to carry out a project, in which students must apply the knowledge acquired in the classroom to solve a problem posed by themselves, for this the application has a module for the development of the project.\n"}
{"prompt":"Prototipo de un Sistema Web inteligente basado en redes neuronales difusas para medir el estado cognitivo del Estudiante en la asignatura Simulación de Sistemas por parte del Docente de la Cátedra. ->","completion":" PDFEl presente trabajo de titulación contempla el desarrollo de un sistema web, basado en lógica difusa y redes neuronales, como herramienta de apoyo a los docentes de la Carrera de Ingeniería en Sistemas Computacionales de la Universidad de Guayaquil. A través de la aplicación de estas técnicas de inteligencia artificial se busca llegar a obtener la medición del estado cognitivo de un estudiante, especialmente de la asignatura de Simulación de Sistema. Para alcanzarlo se indago las mejores tecnologías para sustento de base de este proyecto y poder así resolver la problemática de los docentes. Se desarrolló una aplicación con tecnología open source y módulos de inteligencia artificial con la aplicación de lógica difusa y redes neuronales. Se comprueba que por medio de esta aplicación web se puede obtener de forma más rápida el estado cognitivo del estudiante, con base en los datos recolectados y sometidos a pruebas.This paper contemplates the development of a web system, based on diffuse logic and neural networks. These supports tool for teachers of the Computer Systems Engineering Degree at the University of Guayaquil. Through the application of these artificial intelligence techniques, the aim is to obtain the measurement of the cognitive status of a student, especially the subject of System Simulation. We use the best technologies for basic support of this project were investigated and thus be able to solve the problem of teachers. An application with open source technology and artificial intelligence modules was developed with the application of fuzzy logic and neural networks. It is verified that through this web application the student's cognitive status can be obtained more quickly, based on the data collected and testing.\n"}
{"prompt":"Sistema metodológico para el desarrollo cognitivo en los niños de 5 años de la escuela de educación básica Veinticuatro de Julio, cantón Santa Elena, provincia Santa Elena, período lectivo 2015-2016. ->","completion":" El siguiente trabajo de investigación se lo realizó en la institución Veinticuatro de Julio que se encuentra ubicada en el cantón Santa Elena, se investigó y como resultado se encontró que existe poco estímulo en el desarrollo cognitivo de los niños de 5 años repercutiendo en su aprendizaje, por esa razón es importante implementar un sistema metodológico que ayude en su proceso de evolución a través de estrategias permitiendo un aprendizaje significativo, y a la vez accede a que los niños tengan la capacidad de pensar, razonar y resolver situaciones diarias. Se realizó la investigación con un enfoque cualitativo-cuantitativo, que permitió describir las características de la situación que incide en el desempeño del aprendizaje. Además se utilizó la investigación descriptiva, de campo y bibliográfica respaldado en los instrumentos de recolección de datos como son la entrevista, ficha de observación y encuesta que permitió obtener información relevante sobre el tema de investigación gracias a la colaboración de la docente, estudiantes y padres de familia. Mediante el análisis de la información obtenida se planteó realizar la elaboración de un sistema metodológico para desarrollo cognitivo en los niños de 5 años. El sistema metodológico es un material de gran importancia y de ayuda tanto para el estudiante como para el docente que permitirá mejorar el proceso de aprendizaje y buscar estrategias acordes que ayuden al desarrollo de la percepción, la memoria, el razonamiento y la reflexión hasta llegar a una conclusión con facilidad de manera exitosa, proporcionando el progreso de las actividades escolares, generando ideas y formando estudiantes aptos acorde a las necesidades que exige el medio escolar y el que les rodea.\n"}
{"prompt":"Instalación de sistemas inteligentes para edificios ->","completion":" El presente trabajo se desarrolló con la finalidad de que el Ingeniero Civil y todas las personas involucradas en la construcción, puedan contar con una guía práctica y completa para construir o fiscalizar las instalaciones que en la actualidad son de mucha utilidad y que cada vez serán implementadas en los proyectos de edificios con mayor frecuencia. El Ingeniero Civil, especialmente el Ingeniero de la P.U.C.E. posee un basto conocimiento en lo referente a técnicas y procesos de construcción de los diferentes elementos arquitectónicos y estructurales, no así en lo referente a otro tipo de instalaciones principalmente de sistemas inteligentes, y es por esto que se ve la necesidad de brindar una guía en lo referente a la construcción de este tipo de instalaciones.....\n"}
{"prompt":"Sistema tutorial inteligente ->","completion":" In the teaching-learning process four key elements intervene: the student, the educational one, the information and the means that it surrounds the student. The students are related from early age with the handling of the technology, they find very motivante; for this reason always they are willing to give bigger time to activities that use the computer with the only recompense of using them. In other societies to the daily activity of the students in the class living room, he\/she has been united the interaction with you scheme intelligent, in this relationship, the systems intelligent tutoriales have entered (STI) whose characteristic main they are: to promote an active answer in the student, to inform the acting, to allow an autonomous learning, to promote the efficiency and effectiveness. The STIs the same as the teacher thinks about queries like: what to teach?, when to teach? and how to teach?. Does he\/she think about then if in our society it will Improve the activity of the class the use of a system intelligent tutorial for the learning of the Physics, specifically in the topic of the half speed of the particle? The answer to this query is affirmative, this it is based on the high degree of acceptance and satisfaction of the group in study toward the use of a prototype of system tutorial.\n"}
{"prompt":"Contenedores para jardinería interior basados en sistemas inteligentes ->","completion":" 1. Planteamiento del Problema. --2. Marco Teórico. --3. Metodología. --4. Propuesta. --5. Evaluación Preliminar. --6. Prototipo Virtual y\/o Físico. --7. Conclusiones y Recomendaciones.En la actualidad el hombre urbano vive aislado del entorno natural, pero al ser un ente natural necesita un contacto directo con el entorno natural, es por ello que el objetivo del presente proyecto de investigación es facilitar la creación de espacios verdes dentro de la urbe, aprovechando superficies verticales inutilizadas dentro de su arquitectura. El sistema también pretende hacer el cuidado de las plantas más fácil y automático mediante el uso de sistemas de control que otorguen la autonomía suficiente al equipo, para que el sistema supla de manera automática y más acertada las tareas de cuidado, antes llevadas por el usuario como riego, temperatura e iluminación, procurando así la supervivencia y preservación del jardín. Para ello se realizó una recopilación de información teórica enfocada a los sistemas para el cultivo de jardines en interiores, plantas aptas para este entorno, cuidados de las mismas y materiales utilizados en dichos sistemas. Adicionalmente se aplicó una investigación de campo hacia técnicos e ingenieros electrónicos con base en entrevistas para determinar la arquitectura y componentes de un sistema inteligente de este tipo además de su funcionamiento e integración dentro del producto. Además, se llevó a cabo la experimentación y la observación para determinar dimensiones óptimas para el producto en cuanto al tamaño y morfología de las plantas para que estas tengan un desarrollo normal. De esta forma llegamos a un sistema que protege y preserva el ciclo de vida de una planta dentro de un jardín interior.Pontificia Universidad Católica del Ecuador, Escuela de Diseño IndustrialIngeniero\/a en Diseño Industrial\n"}
{"prompt":"Sistemas inteligentes para la gestion de la actividad acuícola ->","completion":" El presente trabajo de ingeniería fue llevado a cabo en una industria papelera y a través del mismo se logró mejorar la capacidad de producción de uno de sus molinos por medio de la implantación de una segunda línea de batido. Se describen todos los trabajos realizados con relación al tipo de maquinaria que se seleccionó, los cálculos efectuados para ajustar su capacidad midiendo la eficiencia energética, los costos de montaje y de igual forma los costos de las pruebas y el arranque de la línea nueva. Se cumplieron el objetivo general y los objetivos específicos planteados en la introducción y en algunos casos se superaron las expectativas generadas por un experto internacional contratado que actuó como asesor de la empresa y dio las líneas maestras para mejorar la instalación fabril. La nueva línea aumentó en 2% el flujo másico de la pulpa de papel, el refinador de fibra corta mejoró la drenabilidad de la pulpa y llegó a 341 CSF, aumentó la resistencia del papel en los ensayos al estallido y al rasgado. Se recomienda intensificar la tecnología usada y aplicarla en otros molinos que se tienen en la instalación.\n"}
{"prompt":"Implementación de sistemas analámbricos e inteligentes en un vehículo ->","completion":" Thanks to the knowledge acquired during these years of study in Automotive Electromechanical at the University San Francisco de Quito and currently existing technology, this project will proceed to remove the original radio of the vehicle and to adapt an IPad and \/ or IPhone and an audio system, in this case in a BMW M3 of 1993, under the inner cover of a Bluetooth system connecting these devices with the vehicle's audio system. These devices have 3G and Wi-fi connections that allow us to connect to the internet anywhere there is coverage of them,this benefit us to use the applications of the devices to the fullest: GPS, music and video, radios online, Internet browsers, location devices, etc. Also a Bluetooth system installed in the vehicle that serves as a bridge between the devices and the audio system of the vehicle, thanks to this system can handle calls and any other type of application that is related to audio without need to take into our hands the IPad or IPhone, automatically listening to the audio from the speakers thereof.Gracias a los conocimientos adquiridos durante estos años de estudio en Electromecánica Automotriz en la Universidad San Francisco de Quito y a la tecnología existente en la actualidad, en este proyecto procederé a retirar la radio original del vehículo y a la adaptación de una IPad y\/o un IPhone con un sistema de audio, en este caso en un BMW M3 de 1993 bajo la cobertura interna de un sistema Bluetooth que conecta estos dispositivos con el sistema de audio del vehículo. Estos dispositivos disponen de conexiones 3G y Wi-Fi que permiten la conexión a internet en cualquier lugar que exista cobertura de las mismas, lo que me beneficia para poder utilizar las aplicaciones de los dispositivos al cien por ciento como: GPS, reproductores de música y video, radios online, navegadores de internet, localización de los dispositivos, etc. También se instalará un sistema Bluetooth en el vehículo que me servirá de puente de conexión entre los dispositivos y el sistema de audio del vehículo, es decir gracias a este sistema se podrá controlar las llamadas y cualquier otro tipo de aplicación que tenga relación con el audio sin la necesidad de tomar en mis manos el IPad o IPhone, escuchando automáticamente en los parlantes el audio proveniente de los mismos.\n"}
{"prompt":"Sistema de integración para objetos inteligentes ->","completion":" En el ámbito de internet de las cosas, un objeto inteligente es un objeto cotidiano como cafetera, lámpara, puerta de garaje, etc. conectados a inteligentes controlados por personas mediante su smartphone. El usuario identifica a los objetos inteligentes mediante una etiqueta, etiqueta que tiene que ser única con la que pueda diferenciar e identificar al dispositivo. En una situación en la que el usuario se encuentre en la necesidad de interactuar con el objeto inmediatamente, no es eficiente que el usuario tenga que recordar que identificador le asignó al dispositivo, además en el caso de que si el usuario quiere realizar acciones en cadena con los dispositivos que tiene a disposición, el usuario tendría que acceder a cada dispositivo y cambiar el estado de dichos objetos, este proceso es efectivo pero no es eficiente.GuayaquilIngeniero en Ciencias Computacionales Orientación Sistemas Multimedia\n"}
{"prompt":"Sistema inteligente de monitoreo de enfermedades cardiovasculares ->","completion":" PDFEn la presente investigación se muestra un sistema inteligente que nos ayudará a realizar el monitoreo de enfermedades cardiovasculares comenzando desde el estudio del problema, el cual es prevenir los efectos que se puedan exponer en la enfermedad cardiovascular y cuáles serían los beneficios que tendrían los diferentes centros de salud pública en el Ecuador. En esta investigación se explica el proyecto a realizar desarrollando un prototipo funcional que nos permitirá obtener la información de las pulsaciones de los pacientes, dicho prototipo nos permitirá alertar cualquier anomalía que tenga el usuario cabe indicar que las pulsaciones que se generen serán en tiempo real y se les enviara un mensaje indicando cada información detectada al paciente y a sus familiares para mayor control. Adicionalmente, se desarrolla un sistema en donde principalmente podremos visualizar un reporte de pulsaciones del paciente para el debido análisis del médico profesional.The current investigation shows an intelligent system that will helps us monitor cardiovascular diseases starting with the study of the problem, which is preventing the effects that may be exposed by the cardiovascular disease and what benefits would be provided to the different health centers of Ecuador. This investigation explains how to project works by developing a functional prototype that obtains information of the patients pulse. The prototype will allow us to alert any anomaly that the user could present. It should be noted that for a better control, a message will be sent to the patient and relatives showing a real time pulse and all type of information that would be detected. Additionally, a system will be developed in which we’ll primarily visualize the patient’s heartbeat report for a proper analysis of the professional doctor.\n"}
{"prompt":"Estudio de un sistema de control ambiental inteligente para un campus inteligente. ->","completion":" Este documento contiene archivo en PDF.Las universidades diariamente realizan gestiones o actividades, las cuales deben ser analizadas para verificar las afectaciones ambientales que estas generan. Debido a la problemática presente llamada contaminación ambiental, se tiene la necesidad de transformar la visión sustentable de la comunidad universitaria considerando el aspecto social, ambiental y económico. Se establece una propuesta tecnológica para un sistema de control ambiental inteligente enfocado para un smart campus, se identifican aspectos a considerar, indicadores ambientales y soluciones complementadas con tecnologías como WSN y IoT desde un análisis bibliográfico para mitigar la contaminación y contribuir a un ambiente más limpio para la comunidad universitaria. Se realiza un estudio de campo en el cual se compara los estándares o normativas relacionadas con gestión ambiental y los sistemas con enfoques ambientales implementados en universidades internacionales para establecer las características generales y requerimientos que debe tener un sistema de control ambiental para un campus inteligente.Universities carry out daily arrangements or activities, which must be analyzed to verify the environmental effects that they generate. Due to the present problem called environmental pollution, there is the need to transform the sustainable vision of the university community considering the social, environmental and economic aspects. A technological proposal is established for an intelligent environmental control system has been established, focused on a smart campus, identifying aspects to be considered, environmental indicators and solutions complemented with technologies such as WSN and IoT from a bibliographic analysis to mitigate pollution and contribute to a cleaner environment for the university community. A field study is carried out in which the standards or regulations related to environmental management and the systems with environmental approaches implemented in international universities are compared to establish the general characteristics and requirements that an environmental control system must have for a smart campus.\n"}
{"prompt":"Alacena inteligente ->","completion":" La domótica o construcción de casas automatizadas es muy común hoy en día, esto ha dado espacio al desarrollo y uso de aplicaciones que permitan manejar los diferentes sistemas que se encuentra en un hogar. Tener una aplicación centralizada que se encargue de la iluminación, seguridad, climatización, entre otros, optimiza el tiempo de las personas. Un problema que se puede solucionar con las aplicaciones inteligentes es el inventario de los productos de la cocina de un hogar. Conocer qué productos, las cantidades, la fecha de expiración de los mismos, ayuda a tener un mejor control sobre éstos y evita que haya alimentos que tengan que ser desechados debido a que ya llegaron a su fecha de caducidad o en su defecto no permitir que un producto necesario llegue a su stock mínimo.GuayaquilIngeniera en Ciencias Computacionales con especialización en Sistemas de Información\n"}
{"prompt":"Alacena inteligente ->","completion":" El propósito de esta aplicación es resolver el problema de tener que llevar un control mental o escrito de los productos alimenticios en una alacena por parte de la ama de casa o chef, además de tener que recordar las innumerables recetas que conoce o tiene en alguna revista de cocina y ver si estas se pueden preparar o no conforme a lo disponible en su alacena de manera eficiente. Para la solución de este problema he desarrollado una aplicación de “Alacena Inteligente” que provee una serie de consultas que facilitan al usuario el ver que receta se puede preparar ya sea por número de comensales, por nombre de receta o por ingrediente o una búsqueda de entre todas las recetas.GuayaquilIngeniero en Ciencias Computacionales Orientación Sistemas de Información\n"}
{"prompt":"Sistema supervisor inteligente para procesos de producción de etróleo ->","completion":" RESUMENMaximizar la producción de pozos de crudo pesado y extra pesado es el principal beneficio que se desea obtener de los sistemas de control que están corrientemente operativos en empresas de petróleo. Dada la naturaleza compleja y cambiante con el tiempo de los métodos existentes de levantamiento artificial para extracción de crudo, se dificulta el cumplimiento de las especificaciones pre establecidas para el procesamiento del crudo por parte de los lazos de control regulatorios. Tomando esto en cuenta, en éste trabajo se propone un sistema de supervisión inteligente que permite detectar cambios en las condiciones de operación del proceso productivo y realizar ajustes automáticos de sus consignas. Además, el sistema supervisor propuesto tiene la capacidad de detectar fallas en los sensores involucrados en los lazos de control, garantizando de esta manera una operación confiable del proceso. La propuesta fue probada en un pozo de petróleo real obteniéndose resultados que superaron las expectativas iniciales.Palabras clave: Sistema supervisor inteligente, detector de eventos, modelo cualitativo, sistema de toma de decisión, detección y diagnóstico de fallos, métodos de levantamiento artificial.ABSTRACTThe production maximization of heavy and extra heavy oil wells is the main benefit to be obtained from the control systems that are currently operating on oil companies. Given the complex and changing nature over time of existing artificial lift methods for oil extraction, meeting the specifications set for the processing of crude using conventional regulatory control is a difficult task. Taking this into account, this paper presents an intelligent supervisory system that detects changes in the operating conditions of the production process and makes automatic adjustments in its set points. Furthermore, the proposed supervisory system has the ability to detect faults in the sensors involved in the control loops, thus ensuring reliable operation of the process. The proposed supervisory system was tested in a real oil well, yielding results that exceeded expectations.Keywords: Intelligent supervisory system, event detector, qualitative model, decision system, fault detection and diagnostic system, artificial lift method.\n"}
{"prompt":"Sistema de control inteligente de semáforos mediante simulación ->","completion":" Introducción. Marco teórico. Análisis del sistema. Diseño del sistema. Desarrollo y pruebas\n"}
{"prompt":"Sistema de seguimiento inteligente para un robot manipulador ->","completion":" Capítulo I. El problema de la investigación. Capítulo II. Marco teórico. Capítulo III. Metodología. Capítulo IV. Análisis e interpretación de resultados. Capítulo V. Conclusiones y recomendaciones. Capítulo VI. La propuesta. Bibliografía. Anexos.\n"}
{"prompt":"Sistema supervisor inteligente para procesos de producción de petróleo ->","completion":" Maximizar la producción de pozos de crudo pesado y extra pesado es el principal beneficio que se desea obtener de los sistemas de control que están corrientemente operativos en empresas de petróleo. Dada la naturaleza compleja y cambiante con el tiempo de los métodos existentes de levantamiento artificial para extracción de crudo, se dificulta el cumplimiento de las especificaciones pre establecidas para el procesamiento del crudo por parte de los lazos de control regulatorios. Tomando esto en cuenta, en éste trabajo se propone un sistema de supervisión inteligente que permite detectar cambios en las condiciones de operación del proceso productivo y realizar ajustes automáticos de sus consignas. Además, el sistema supervisor propuesto tiene la capacidad de detectar fallas en los sensores involucrados en los lazos de control, garantizando de esta manera una operación confiable del proceso. La propuesta fue probada en un pozo de petróleo real obteniéndose resultados que superaron las expectativas iniciales.The production maximization of heavy and extra heavy oil wells is the main benefit to be obtained from the control systems that are currently operating on oil companies. Given the complex and changing nature over time of existing artificial lift methods for oil extraction, meeting the specifications set for the processing of crude using conventional regulatory control is a difficult task. Taking this into account, this paper presents an intelligent supervisory system that detects changes in the operating conditions of the production process and makes automatic adjustments in its set points. Furthermore, the proposed supervisory system has the ability to detect faults in the sensors involved in the control loops, thus ensuring reliable operation of the process. The proposed supervisory system was tested in a real oil well, yielding results that exceeded expectations.CuencaVolumen 5 (2014)\n"}
{"prompt":"Campus inteligente prototipo para sistema RFID de control de acceso ->","completion":" This paper reports the design and construction of an RFID Access Control Prototype. The system meets the needs for places that require an effective control of people allowed to enter the premises. The paper includes a description of the different stages taken place in the design and construction of the prototype, as well as the theoretical background to understand the operation of the system. Concepts such as Radio Frequency, Access Control, Wi-Fi, and database control are included, all of this integrated in an RFID tag access control system. This work is a practical project to understand and apply the concepts to design and implement the system previously described.El siguiente trabajo escrito reporta el diseño y construcción de un prototipo para Sistema RFID de control de acceso. Este prototipo se ajusta a las necesidades de lugares que requieren un control de acceso. El escrito detalla las diferentes etapas llevadas en el diseño y construcción del sistema, así como los conceptos teóricos para poder comprender el trabajo. Se trabaja conceptos como Radio Frecuencia, control de acceso, WI-FI, y control de Base de Datos. Todo esto integrado en un sistema de control de acceso por etiquetas de radio frecuencia. El presente trabajo es un proyecto práctico para comprender y diseñar el sistema descrito anteriormente, explicando la teoría atrás del diseño del mismo.\n"}
{"prompt":"Humanoide Inteligente que Interactue con Multiusuarios Mediante Comandos de Voz ->","completion":" 1. El problema 2. Marco teórico 3. Metodología de investigación 4. Conclusiones y recomendaciones.Este proyecto de tesis consiste en brindar información a través de un robot inteligente que reconoce la voz de las personas y va a emitir una respuesta dependiendo del contenido o tema de la pregunta. De esta manera el robot va a entablar una conversación puntual de temas relacionados con la carrera de ingeniería en sistemas y como contiene una base de datos que en el futuro se estima va a contener información de toda la universidad.Disertación (Ingeniería en sistemas)Ingeniería en sistemas\n"}
{"prompt":"Móvil inteligente entrenado por computadora ->","completion":" La importancia de este estudio basada en la implementación de un \"Móvil Inteligente\" entrenado por computador; es demostrar el gran potencial que pueden desarrollar las redes neuronales frente a diversos problemas; que, para su resolución antiguamente se tenía que disponer de muchos recursos tanto materiales, económicos y de procesamiento. A través de un enlace inalámbrico se dará movilidad y flexibilidad al móvil (robot), ya que no dependerá de un cable umbilical que realice la transferencia de datos entre el PC y el robot.\n"}
{"prompt":"Identificación de técnicas alternativas de construcción de casas modernas utilizando sistemas y elementos prefabricados de hormigón ->","completion":" In this paper, analyzed three types of construction techniques in the dwellings of a plant. Techniques to be tested will be of three types: prefabricated panels of concrete, material adhere-2 modular systems and conventional structures of concrete and masonry block construction technique. The website was established by two methods: bibliographical research and visits by field, complementary to this, contacted four professionals with experience in structural systems and building techniques: •Engineer Pablo Borja Recalde: Private consultant specialized in structures of concrete, steel and wood. 0995808794 •Architect Julio Grijalva: Professional Builder currently holds the position of resident work altogether \"Villa Florida\". 0993585009 •Architect Ana of Vasquez: officer of “Mutualista Pichincha”, area of homes \"Casa lista\". 2395887. •Architect Luis Silva: head of production and armed in the area of housing \"Casa lista\" of “Mutualista Pichincha”. 2395887. •Architect Fernando Castillo: Constructor, resident of work in joint \"Villa Fontana\": 0998369234 By means of the information provided by each one of these technical and of them results of it research theoretical and practice, is developed them frames conceptual and theoretical respectively, in the observations of field is obtained documentation photographic that supports the explanation textual. Completed once the theoretical framework, by the method of \"comparative tables\" most notable of each of the three techniques, data are extracted by two types of analysis: qualitative analysis and quantitative analysis of where the most important conclusions in the aspects will be developed: structural, environmental, construction and construction costs. The part of \"attachments\" included material that provided information for the calculation of costs.En el presente trabajo, se analizaron tres tipos de técnicas constructivas en las viviendas de una planta. Las técnicas a analizarse serán de tres tipos: Paneles prefabricados de hormigón, sistemas modulares de material Hormi-2 y la técnica de construcción convencional de estructuras de hormigón y mampostería de bloque. Se estableció el análisis por dos métodos: investigación bibliográfica y visitas de campo, complementario a esto, se contactó a cuatro profesionales con experiencia en sistemas estructurales y técnicas de construcción: Ingeniero Pablo Borja Recalde: Consultor privado, especializado en estructuras de hormigón, acero y madera. 0995808794 Arquitecto Julio Grijalva: Profesional constructor, actualmente ocupa el cargo de residente de obra en el conjunto “Villa florida”. 0993585009 .Arquitecta Ana de Vásquez: Gerente de producto 2 Casa Lista” de Mutualista Pichincha. 2395887. Arquitecto Luis Silva: Jefe de producción y armados “Casa Lista” de Mutualista Pichincha. 2395887.Arquitecto Fernando Castillo: Constructor, residente de obra en conjunto “Villa Fontana”: 0998369234 Por medio de la información proporcionada por cada uno de estos técnicos y de los resultados de la investigación teórica y práctica, se elaboraron los marcos conceptual y teórico respectivamente, en las observaciones de campo se obtuvo documentación fotográfica que respalda la explicación textual. Una vez finalizado el marco teórico, por el método de “cuadros comparativos” se extraen los datos más notables de cada una de las tres técnicas por dos tipos de análisis: Análisis cualitativo y análisis cuantitativo de donde se elaborarán las conclusiones más importantes en los aspectos: estructural, ambiental, constructivo y de costos de construcción. En la parte de “anexos” se incluyó material que proporcionó información para el cálculo de costos.\n"}
{"prompt":"Implementación de un sistema de automatización para el control de semáforos inteligentes ->","completion":" Implementar un sistema de automatización inteligente y control en los semáforos instalados en la intersección de la Avenida 17 de Julio y General José María Córdova de la ciudad de Ibarra, mediante la instalación de un Sensor Loop con la finalidad de mejorar la fluidez del tránsito vehicular.El presente proyecto consiste en desarrollar el estudio e implementar un sistema de automatización para el control de semáforos inteligentes instalados en la ciudad de Ibarra – Imbabura, específicamente en la intersección de la Avenida 17 de Julio y General José María Córdova, el cual permitirá mejorar la fluidez del tránsito vehicular y reducir tiempos muertos en la espera de habilitación de la vía. El diseño que tendrá además una comunicación por medio de una interfaz vía bluetooth para controlar los tiempos de cambio de luces y también modificar el comportamiento de la vía principal o secundaria de acuerdo a las necesidades viales, como por ejemplo en horas pico. El proyecto se lo ha realizado previo a un estudio y análisis de la situación vial actual del sector de la Universidad Técnica del Norte en la intersección de la Avenida 17 de Julio y General José María Córdova, para el cual se tomaron indicadores de tiempo de respuesta de los semáforos instalados, presencia del congestionamiento vehicular y que tan factible han sido ante las necesidades de los conductores en transitar por esta vía. El presente proyecto tiene como objetivo mejorar por completo la fluidez vehicular tanto en la vía principal como secundaria ya que esta es una vía de desfogue de la carretera E35. El diseño del proyecto está basado en la detección de vehículos en la vía secundaria de la intersección “T” mediante un detector de bucle de inducción o Sensor Loop, el cual es controlado mediante Arduino permitiendo generar los tiempos adecuados para la activación de las luces rojo, verde y amarillo, dependiendo del sistema de semaforización. Al final se realiza un análisis de aporte y beneficio para el departamento encargado de transito de la ciudad, Empresa Pública de Movilidad del Norte (MOVILDELNOR) para la implementación de este sistema.\n"}
{"prompt":"Implementación de un Sistema de Almacenamiento Inteligente en Dos Ejes X - Y. Caso Práctico: Laboratorio de Automatización Industrial EIS ->","completion":" Se ha construido un sistema mecatrónico para el almacenamiento inteligente de palets en dos ejes x-y, el mismo que estará implementado en la ESPOCH en el Laboratorio de Automatización Industrial, con la finalidad de optimizar la gestión de almacenamiento e inventario de los mismos. Para el desarrollo se adaptó la metodología de desarrollo de software XP (Xtreme Programming), incluyéndose fases de desarrollo e implementación mecánica, electrónica y neumática. La parte lógica del almacén está conformada por un panel frontal desarrollado en Labview, que facilita al administrador, el control del sistema mecatrónico, además, se diseñó una aplicación web en ASP.NET, facilitando la distribución de productos almacenados, gracias a la implementación de la base de datos en SQL Server 2005. Para el ingreso del palet al sistema, los sensores determinan su tipo, se almacena físicamente y en la base de datos, estableciéndose su estado a disponible, una vez que el palet es extraído, su estado cambia a despachado. El proceso redujo el tiempo de almacenamiento y despacho a menos de 2 minutos, el inventario se lo realiza en menos de 3 segundos, además el personal necesario para su operación es de una persona. Con la implementación del sistema mecatrónico para el almacenamiento inteligente de palets, se optimizó la gestión de almacenamiento e inventarios, lo cual se reflejó en la reducción de costos de operación. Se recomienda para la correcta instalación y utilización del sistema de almacenamiento se apliquen los manuales técnico y de usuario adjuntos a esta tesis.\n"}
{"prompt":"Estudio de los algoritmos de reconocimiento de patrones para la automatización de un semáforo inteligente mediante FPGAs ->","completion":" Se diseñó e implementó un prototipo de semáforo inteligente mediante una tarjeta electrónica de arreglos de compuertas programables en campo (FPGA), para minimizar la congestión vehicular. Para su diseño se empleó LabView 2012 ya que facilita la unión de la visión artificial con la tarjeta electrónica de arreglos de compuertas programables en campo (FPGA); en su implementación se utilizó madera MDF, pistas eléctricas, sensores de contacto, fuente de computadora, cámara, tarjeta electrónica de arreglos de compuertas programables en campo (FPGA) y Arduino. El control automático del semáforo, se realizó con la tarjeta Spartan 3-E, la cual se encarga de procesar mediante el algoritmo de coincidencia de colores la información adquirida por la cámara. Como resultado se obtuvo que en el sistema inteligente el tiempo de espera aproximado para 2 autos fue 18,75 ms, mientras que en el sistema tradicional el tiempo de espera aproximado para la misma cantidad de autos fue 60 ms. Se concluye que el prototipo de semáforo inteligente diseñado e implementado, actúa en función de la cantidad de autos, disminuyendo los tiempos de espera y minimizando la congestión vehicular. Se recomienda probar el prototipo diseñado en condiciones reales.\n"}
{"prompt":"Estudio de factibilidad para la implementación del sistema de automatización de subestaciones en la EmelNorte mediante tecnología inteligente ->","completion":" In the last decade the electricity industry has undergone significant changes to the use and implementation of new technologies to enable better utilization and increased efficiency in the generation, transmission and distribution of electricity in many places these changes have culminated on the appearance of a higher electricity market. Thus it is that this paper focuses on taking a look and introduction of technologies that are in pursuit of achieving a Smart Grid network and implement systems and distribution of electricity, as Smart Grid in its generality is a very inclusive subject, this paper will focus on helping identify, classify and characterize some of the confusing diversity of approaches that can be found in the technical literature on Smart Grid, and analyze the possible introduction to a distribution system. The paper presents a study of the relevant literature regarding the development and use of Smart Grid technology.En la última década la industria eléctrica ha experimentado cambios importantes hacia la utilización e implementación de nuevas tecnologías con el objetivo de permitir un mejor aprovechamiento y una mayor eficiencia en la generación, transmisión y distribución de la energía eléctrica, en muchos lugares estos cambios han culminado en la aparición de un mayor mercado eléctrico. De esta manera es que este documento se centra en dar una mirada e introducción de las tecnologías que van en búsqueda de la lograr una red Smart Grid y aplicarlas así en los sistemas de distribución de energía eléctrica, dado que Smart Grid en su generalidad es un tema muy incluyente, este trabajo se centrara en ayudar a identificar, clasificar y caracterizar un poco de la confusa diversidad de enfoques que se pueden encontrar en la literatura técnica sobre Smart Grid, y analizar la posible introducción en un sistema de distribución. El trabajo presenta un estudio de las publicaciones más pertinentes en relación con el desarrollo y utilización de la tecnología Smart Grid.\n"}
{"prompt":"Desarrollo de un prototipo de parqueadero inteligente para la automatización del sistema de aparcamiento Simert en la ciudad de Loja. ->","completion":" This work presents a proposal for the SIMERT automation. The idea comes from the necessity to optimize resources in Loja City Hall, as well as for a better control in the use of the system. There are three key issues in the development of this project that are the control device, the center control and the display system of available spaces. The SIMERT control device has the following main components: the vehicle detection block (sensor and loop floor), RFID and Zigbee modules, a module, a keyboard, push buttons, LCD display, power supply and a 2560 “Arduino” Mega. The LCD screen and push bottoms and the keyboard allow the SIMERT user to interact with the device, the other elements are in its inside. The central control has been simulated in the Visual Basic program, one of the functions that it performs is receive the messages of the control device warning when a space is full, information of the SIMERT user (name and last name), license plate, time that is going to be parked and the place that the vehicle is parking; another function is seconds messages to the control device, those messages notified if the client has o not credit for parking and so if it could make use or not of the parking service, also it is responsible to give an alarm when the parking time is over and the vehicle has not yet been removed, also there is an alarm when a vehicle occupied a parking place and it skips the registration after an extra time. The display system of available spaces is compound by a LED signboard and a ZigBee module, the function is drive to users to available spaces for parking.En este trabajo se presenta una propuesta para la automatización del Sistema Integrado Municipal de Estacionamiento Rotativo Tarifado (SIMERT). La idea nace de la necesidad de optimizar recursos en el Municipio de Loja, así como para un mejor control en el uso del sistema. Existen tres partes claves en la elaboración de este proyecto de tesis que son el dispositivo de control, el centro de control y el sistema visualizador de plazas disponibles. El dispositivo de control tiene como componentes principales los siguientes: el bloque de detección vehicular (sensor y loop de piso), un módulo RFID, un módulo ZigBee, un teclado, pulsadores, una pantalla LCD, la alimentación y un Arduino Mega 2560. La pantalla LCD, los pulsadores y el teclado permiten al usuario del SIMERT interactuar con dicho dispositivo, el resto de elementos están en el interior del mismo. El centro de control ha sido simulado en el programa Visual Basic, una de las funciones que realiza es recibir los mensajes del dispositivo de control avisando cuando se ha ocupado una plaza, información del usuario del SIMERT (nombre y apellidos), placa de su vehículo, tiempo que estará estacionado y el lugar en que aparco su vehículo; otra función es enviar mensajes al dispositivo de control, estos mensajes avisan si el cliente tiene o no saldo para estacionamiento y por ende si puede hacer o no uso del servicio de estacionamiento, también es el responsable de dar una alarma cuando ha transcurrido el tiempo de estacionamiento y el vehículo aún no se ha retirado, también se produce una alarma cuando un vehículo ha ocupado un lugar de estacionamiento y no realiza el registro del mismo luego de un tiempo de gracia. El sistema de visualización de plazas disponibles está compuesto por un letreo LED y un módulo Zigbee, su función es guiar al conductor hacia espacios disponibles para estacionarse.\n"}
{"prompt":"Propuesta de automatización de Lectura Inteligente del consumo de agua potable, en el Centro Histórico de la Ciudad de Cuenca ->","completion":" En el trabajo de investigación: “Propuesta de una lectura inteligente del consumo de agua potable en el Centro Histórico de Cuenca”; se describe el estudio y tecnología de la Empresa Pública ETAPA EP, en lo que se refiere a toma de datos y la clase de contador utilizado. La propuesta del trabajo nos permitiría realizar una lectura, además de un corte y reconexión del servicio remotamente, utilizando la misma red de fibra óptica que tiene tendida la empresa en el Centro Histórico, esto implicaría la reducción de costos operativos. Se describe un análisis teórico sobre la lectura a nivel general actual de medidores de agua potable, además de las características más importantes de los sistemas de Infraestructura de Medición Avanzada (AMI) y la tecnología de redes de telecomunicaciones para la transmisión de datos; posteriormente se detalla el proceso de medición y lectura en la ciudad de Cuenca, y medidores utilizados; por último presenta el diseño de la red propuesta para la lectura inteligente, además del tipo de medidor recomendado y costos que involucran; así presentar conclusiones y recomendaciones de la lectura inteligente.In the research: “Proposal for an intelligent reading of water consumption in the downtown of Cuenca”; describes the study and technology of the Public Company ETAPA EP, when it refers to data collection and the type of counter used. The proposal would allow us to carry out a reading, in addition to the disconnection and reconnection of the service remotely, using the fiber optic network that the company has installed in the downtown of the city, this would imply reducing operating costs. Describes a theoretical analysis on the current measure reading of water, in addition to the most important features of Advanced Measurement Infrastructure (AMI) systems, technology and telecommunications networks for data transmission; then the detailed measurement process and reading in the city of Cuenca, and the measure devices used; finally the proposed network design for an intelligent reading, in addition to the recommended type of measuring devices and the costs involved; and then the conclusions and recommendations of the intelligent reading.\n"}
{"prompt":"Simulación del control y monitoreo de un hospital inteligente ->","completion":" Tesis que demuestra la ventaja de la automatización del control de los sistemas básicos principales de un edificio utilizado como hospital. Para lo cual se realiza un estudio de los procesos utilizados y con esto determina los factores que permiten mejorar el control de los sistemas. Luego se presenta un diseño automático para mejorar el control de estos procesos basado en controladores lógicos programables (PLC), sensores y actuadores. Además se desarrolla un sistema SCADA que va a permitir monitorear el funcionamiento de los controladores lógicos programables y con esto llevar un control total de los sistemas.GuayaquilIngeniero en Electricidad Especialización Electrónica y Automatización Industrial\n"}
{"prompt":"Diseño e implementación de controladores inteligentes para el Sistema de Levitación Magnética MLS ->","completion":" El proyecto diseño e implementación de controladores inteligentes para el sistema de levitación magnética MLS consiste en el diseño de controladores inteligentes para un sistema de levitación magnética que controla la posición de una esfera metálica las cuales se desarrollarán mediante la aplicación de técnicas de control con lógica difusa y redes neuronales a través del programa de cálculo MATLAB. Este proyecto está abierto en el sentido de acpetar mejoras y servir como base para la realización de un trabajo similar, además de permitir el análisis de diferentes sistemas de control automático...\n"}
{"prompt":"Automatización y control del sistema eléctrico y de agua potable en un departamento nuevo en la ciudad de Quito ->","completion":" This document presents the concepts and technological developments in home automation, functionality and integration of these technologies with systems possessing a home for automation and control for the smart home, generating a greater comfort, security, communication, saving energy and money with the users of the building. For the implementation of this project it was necessary a study of the requirements and needs of the users and the space for the adaptation, replacement and automation system to control the house. First of all, we need the domotic system plans with all smart things that will be integrate into the space, after that, be proceeded to perform a cost analysis unit and total of the work. As a final part of the project was to make a technical comparison focused on saving electricity with another spaces that do not have an intelligent control system.El presente documento expone los conceptos y desarrollos tecnológicos que existen en la Domótica, las funcionalidades e integración de estas tecnologías con los sistemas que posee un domicilio para la automatización y control de los mismos, generando un mayor confort, seguridad, comunicación, ahorro energético y económico con los usuarios del inmueble. Para la implementación de este proyecto fue necesario realizar un estudio previo de los requerimientos y necesidades de los usuarios del departamento para la adaptación, renovación e integración del sistema de automatización y control domótico en la vivienda. Se realizó el diseño del Sistema Domótico que se integró en el departamento y se elaboraron los planos para la respectiva ubicación de cada elemento inteligente instalado. Una vez implementado el sistema de automatización y control en los sistemas eléctrico y de agua potable se procedió a realizar un análisis de costos unitario y total de la obra. Como parte final del proyecto se procedió a realizar una comparación técnica enfocada al ahorro de energía eléctrica con otro departamento de similares características pero que no posee un sistema inteligente de control.\n"}
{"prompt":"Diseño e Implementación de un Asistente Virtual para Control y Monitoreo de una Casa Inteligente ->","completion":" El objetivo de esta tesis es desarrollar un asistente virtual inteligente, dicho asistente provee de un control domótico a través de: aplicaciones en Android, aplicaciones web, reconocimiento de voz e interfaces visuales basadas en HMI. La comunicación entre el servidor y los diferentes nodos instalados usan un protocolo de descubrimiento basado en UDP, con un proceso continuo de lectura de datos que serán almacenados y obtenidos de la base de datos. El acceso remoto al hogar consta de página web y aplicación en Android los cuales leen la información almacenada en la base de datos, mostrándolos en tiempo real.Ingeniero Electrónico\n"}
{"prompt":"Análisis al paradigma de la Industria 4.0 y propuesta de red eléctrica inteligente. ->","completion":" La Industria 4.0 es un paradigma que abarca varias tecnologías y plataformas de comunicación digital, de esta manera el objetivo principal del presente trabajo de titulación abarca el estudio de dicho paradigma para contribuir con criterios reflexivos desde el punto de vista normativo y la convergencia de plataformas tecnológicas. No obstante, las metodologías escogidas para este trabajo de investigación corresponden al método: Descriptivo; consiste en describir y evaluar las características de un fenómeno determinado para después, analizar los datos recogidos para descubrir el objeto de estudio. Es decir, estudiar y analizar minuciosamente el paradigma de la Industria 4.0, la automatización de procesos industriales, la fabricación conectada al Internet de las cosas (IoT) y las redes eléctricas inteligentes (Smart Grid). De este último aspecto se deberá caracterizar el desempeño y la arquitectura. Analítico-Sintético, basado en la combinación de dos maneras de investigar y que son usadas para desarrollar un determinado trabajo de investigación para lograr los objetivos planteados. Es decir, aplicada a valorar componentes y plataformas tecnológicas del contexto de la Industria 4.0. Pues, específicamente el método analítico analiza el objeto de estudio para determinar cómo el paradigma de la Industria 4.0 se manifiesta en el contexto actual. En cambio, el método sintético, se basa en la síntesis del fenómeno a estudiar, es decir, recopilar información aplicada a artículos científicos en bases de datos; para la misma, se revisa estudios de investigadores y expertos en el paradigma Industria 4.0 para finalmente resumir los datos mencionados.Industry 4.0 is a paradigm that encompasses several technologies and platforms for digital communication, so the mIAn objective of the present work covers the study of this paradigm to contribute with reflective criteria from the regulatory point of view and the convergence of technological platforms. However, the methodologies chosen for this research work correspond to the method: Descriptive; it consists of describing and evaluating the characteristics of a given phenomenon and then analyzing the collected data to discover the object of study. That is to say, to study and analyze thoroughly the paradigm of the industry 4.0, the automation of industrial processes, the manufacture connected to the Internet of things (IoT) and smart electric networks (Smart Grid). From this last aspect, performance and architecture should be characterized. Analytical-Synthetic, based on the combination of two ways of research and that are used to develop a specific research work to achieve the objectives. That is, applied to assess components and technological platforms of the context of Industry 4.0. Well, specifically the analytical method analyzes the object of study to determine how the paradigm of industry 4.0 manifests itself in the current context. On the other hand, the synthetic method is based on the synthesis of the phenomenon to be studied, that is, to collect information applied to scientific articles in databases; for it, we review studies of researchers and experts in the industry 4.0 paradigm to finally summarize the aforementioned data.\n"}
{"prompt":"Diseño y construcción de un sistema automático de pesaje y control estadístico mediante básculas electrónicas inteligentes. ->","completion":" In this paper extensive information on weighing systems is collected and statistical control to make it possible to carry out the construction in our midst. the process of developing a sequential manner and the specific devices that can fulfill the roles planteadas.Se perform the design and construction of an electronic card that allows the built system can operate in a unified manner, or presented the entire assembly is connected at a time, and not have to make connections or disconnections preventing repetitive contacts may fail, facilitating the PLC is governing the functions designed on the card, making are met according to the project developed. For the design of the mechanisms and the contribution of electronic devices with the mechanical part it was taken on the experiences made by the authors of different projects where good technical advice was obtained and should take into account such important aspects as the proper assembly the whole structure, as well as protection relays and auxiliary double protection and comprehensive security of all equipment and accurate for sizing machine installation and general recommendations.En el presente trabajo se recoge una amplia información sobre los sistemas del pesaje y control estadístico para hacer posible que se pueda efectuar la construcción en nuestro medio. Se presenta el proceso de elaboración de una manera secuencial así como los dispositivos específicos que puedan cumplir las respectivas funciones planteadas.Se realizo el diseño y construcción de una tarjeta electrónica para que permita que el sistema construido, pueda funcionar de una manera unificada, o sea todo el conjunto este conectado a la vez, y no tener que realizar conexiones o desconexiones repetitivas impidiendo que los contactos puedan averiarse, facilitando además que el P.L.C. se rija a las funciones diseñadas en dicha tarjeta, logrando que se cumplan de acuerdo al proyecto elaborado. Para el diseño de los mecanismos y el aporte de los dispositivos electrónicos con la parte mecánica se tomó como base las experiencias realizadas por los autores de diferentes proyectos, donde se obtuvo buen asesoramiento técnico, debiendo tener en cuenta aspectos tan importantes como el montaje adecuado de toda la estructura, así como relés de protección y auxiliares para doble protección y amplia seguridad de todos los equipos y recomendaciones muy precisas para el dimensionamiento de la máquina y la instalación en general.\n"}
{"prompt":"Repotenciación de tres módulos didácticos con Relé inteligente para realizar aplicaciones con motores asíncronos de baja potencia ->","completion":" La repotenciación se basa en tres módulos didácticos que no eran aprovechados en su totalidad en el laboratorio de Redes Industriales & Scada, por su limitada funcionalidad, con la reingeniería realizada podrán ser utilizados para distintas aplicaciones en arranque de motores trifásicos asincrónicos con la ayuda de componentes de fuerza, control y relé inteligente (Mini PLC LOGO con puerto Ethernet). Cada módulo cuenta con un ruteador TP-LINK el cual permitirá poder realizar una red local inalámbrica entre todos los Mini PLC LOGO laptops y dispositivos móviles y así poder configurar y monitorear estos equipos de control de manera inalámbrica y además permita realizar aplicaciones destinadas a secuencia de motores. También se cuenta con un Micro Máster 440 por cada módulo el cual permitirá realizar arranque de motores variando su frecuencia. Se realizó un banco de diez prácticas las mismas que aportaran al conocimiento teórico del estudiante con la parte práctica.The repowering is based on three didactic modules that were not used in their entirety in the Laboratory de Redes Industrials & Scada, due to their limited functionality, with the reengineering done they will be able to be used for different applications in start up of three-phase asynchronous motors with the help of components of force, control and intelligent relay (Mini PLC LOGO with Ethernet port). Each module has a TP-LINK router which will allow to make a wireless local network between all the Mini PLC LOGO laptops and mobile devices and thus be able to configure and monitor these control devices wirelessly and also allows applications to be made to sequence engines. There is also a Micro Master 440 for each module which will allow motor starting by varying its frequency. A bank of ten practices was carried out, which contributed to the theoretical knowledge of the student with the practical part\n"}
{"prompt":"Diseño e implementación de un sistema inteligente de control por voz para la dosificación automática de la alimentación de mascotas integrando FIREBASE y AWS ->","completion":" PDFEl presente proyecto de titulación tiene como finalidad el desarrollo de un prototipo que propone la automatización en el suministro de alimentos para mascotas por medio de un dispensador utilizando el asistente de voz Alexa, los amantes y dueños de las mascotas tradicionalmente proveen la comida de forma manual lo que ocasiona interrupción durante las actividades cotidianas; Para esto se enfatiza el uso de la tecnología que con lleva de manera equilibrada un control sobre la dosificación hacia el animal y reabastecimiento del dispensador con mensajes de alertas que genera el sistema de Alexa. La metodología seleccionada se logró relacionar con el sistema inteligente de control por voz donde se pudo concluir que permite precautelar el desorden alimenticio y falta de atención hacia las mascotas del mismo modo vaya cumpliendo los objetivos planteados al inicio del proyecto de manera satisfactoria.The purpose of this degree project is to develop a prototype that proposes automation in the supply of pet food through a dispenser using the Alexa voice assistant, pet lovers and owners traditionally provide food manually what causes interruption during daily activities; For this, the use of technology is emphasized, which carries a balanced control over the dosage to the animal and the refilling of the dispenser with alert messages generated by the Alexa system. The selected methodology was related to the intelligent voice control system where it was concluded that it allows to prevent eating disorder and lack of attention towards pets in the same way that it satisfactorily meets the objectives set at the beginning of the project.\n"}
{"prompt":"Sistema domótico basado en controladores lógicos programables (PLC) para la gestión y control de automatización inteligente de la infraestructura de la universidad Uniandes Tulcán ->","completion":" El presente trabajo dedica buena parte de su contenido, a abordar aquello que constituye y concierne al desarrollo y programación de un Sistema Biométrico. El cual contribuirá en el desarrollo de aplicaciones tecnológicas en la carrera de Sistemas en Uniandes Tulcán. La base para esta investigación es el registro, control y electrónica. La presente tarea investigativa fue dividida en 3 capítulos, en el primer capítulo se plantea el problema que es el componente fundamental del proyecto de investigación, pues en torno a él giran todos los demás temas del proyecto. Aquí se determina los objetivos y la justificación. En el segundo capítulo se desarrolla el marco metodológico y el planteamiento del problema, planteando una investigación de campo y explicativa, aplicando métodos Empíricos, Analítico – Sintético, Inductivo – DeductivoCon el paso del tiempo, las tecnologías de control de asistencia a clases se ha ido mejorando tanto asi que en la actualidad se la realiza mediante tarjetas magenticas para asi registrar la hora exacta de ingreso a la intitucion educativa, es el caso de algunas Universidades como es la UTE(universidad Tecnologica Equinoccial) en la cual al momento del ingreso se pone la huella dactilar en el cual se registra la hora de entrada para asi tener un registro exacto de los estudiastes, el cual sirve para la coordinación de la universidad teniendo un registro d entradas d los estudiantes y profesores. La empresa estadounidense Alianza Fast Identifiy Online (FIDO Alliance) promueve un nuevo paquete de tecnología de seguridad que incluye dispositivos, sistemas operativos y herramientas en línea que sustituyen el uso de contraseñas numéricas por las huellas dactilares.\n"}
{"prompt":"Propuesta de un modelo de automatización del sistema de distribución a 22 kV para la óptima colocación de protecciones inteligentes en el alimentador principal ->","completion":" Se presenta un modelo del sistema de distribución para su automatización con la finalidad de elevar su confiabilidad y seguridad, mediante la óptima colocación de equipos de protección inteligente y basados en un análisis de flujos de carga, interconexión y en el esquema FLISR.Presents a model of automation of the distribution system with the aim of improving its reliability and security, through the optimal placement of smart protective equipment and founded on an analysis of charge flow, interconnection and the schema FLISR.\n"}
{"prompt":"Diseño de un prototipo de casilleros inteligentes, utilizando el carnet universitario y clave de seguridad para el control de acceso a través de una red inalámbrica, mediante la administración de página web y base de datos aplicando tecnología de bajo costo (raspberry y arduino), para beneficio de los estudiantes de la Carrera de Ingeniería en Networking y Telecomunicaciones de la Universidad de Guayaquil ->","completion":" PDFHoy en día podemos ver como la tecnología ha avanzado notablemente, brindándonos una mejor forma de realizar actividades típicas de manera más fácil aplicando nuevos métodos de forma automatizada. Actualmente las instituciones educativas públicas y privadas tienen como objetivo ofrecer calidad y comodidad en diferentes ámbitos educativos, entre ellos, se han visto en la necesidad de aligerar la carga en los bolsos de los estudiantes implementando casilleros para que guarden libros y otros objetos personales. La Carrera de Ingeniería en Networking y Telecomunicaciones, pertenecientes a la Facultad de Ciencias Matemáticas y Físicas de la Universidad de Guayaquil, propuso la implementación de casilleros dentro de las instalaciones para cumplir con este objetivo. El propósito de este proyecto de titulación es crear un prototipo para automatizar dichos casilleros logrando mejorar la administración y control utilizando tecnología de bajo costo. La metodología que se usará para el diseño del prototipo de un casillero inteligente será SCRUM, el cual nos permitirá obtener los resultados deseados en corto tiempo.Today we can see how technology has advanced significantly, giving us a better way to perform typical activities in an easier way by applying new methods in an automated way. Currently the public and private educational institutions aim to offer quality and comfort in different educational areas, among them, they have seen the need to lighten the burden on students' bags by implementing lockers to store books and other personal items. The Engineering Career in Networking and Telecommunications, belonging to the Faculty of Mathematical and Physical Sciences of the University of Guayaquil, proposed the implementation of lockers within the facilities to meet this objective. The purpose of this titling project is to create a prototype to automate these lockers, improving management and control using low-cost technology. The methodology that will be used for the design of the prototype of an intelligent locker will be SCRUM, which will allow us to obtain the desired results in a short time.\n"}
{"prompt":"Implementación de un dispositivo de acceso de control inteligente de gestión de visitantes de una urbanización privada mediante una aplicación móvil usando recursos no renovables ->","completion":" PDFEl presente proyecto busca la implementación de un dispositivo microcontrolador programable inteligente de control de acceso de visitantes usando energía fotovoltaica, con la finalidad de automatizar el control de acceso a la Urbanización Toledo perteneciente a Villa España 2 en la ciudad de Guayaquil, permitiendo una gestión correcta de los visitantes mediante una aplicación móvil, que permite tener un registro de los visitantes a través del usuario residente, mientras que los datos de los propietarios se almacenan a través del usuario administrador, mediante el desarrollo de las etapas del proyecto, se crea el prototipo que se implementará cerca de la garita a fin de que obtenga la información de los visitantes que tienen acceso a la urbanización enviando la información a través de una red inalámbrica por internet hasta ser almacenada en la base de datos, las aplicaciones móviles serán las encargadas de hacer el registro para el acceso de los visitantes, aprobación de esta solicitud, indicaciones necesarias para el arribo hacia el destino y el reporte de las visitas realizadas a los propietarios de viviendas en la urbanización, este proyecto es una automatización de los procesos de control de acceso a la urbanización, además de que la información obtenida de las visitas podrá ser aplicada en futuros proyectos para hacer proyecciones de las visitas para tomar las medidas más acercadas con respecto a estas.This project seeks the implementation of an intelligent programmable microcontroller device for visitor access control using photovoltaic energy, in order to automate access control to the Toledo Urbanization belonging to Villa España 2 in the city of Guayaquil, allowing proper management of the visitors through a mobile application, which allows to have a registry of the visitors through the resident user, while the data of the owners is stored through the administrator user, through the development of the project stages, the prototype is created that will be implemented near the sentry box in order to obtain the information of the visitors who have access to the urbanization by sending the information through a wireless internet network until it is stored in the database, the mobile applications will be in charge of make the registration for visitor access, approval of this request, necessary indications for arrival to the destination and the report of visits made to homeowners in the urbanization, this project is an automation of the access control processes to the urbanization, in addition to the information obtained from the visits may be applied in future projects to make projections of visits to take the closest steps regarding them.\n"}
{"prompt":"Implementación de un componente interactivo de visualización de estructuras de conocimiento. ->","completion":" En los últimos años, internet se ha ido poblando con una gran cantidad de datos semánticos los cuales han proporcionado conocimiento a la web. Las estructuras semánticas de conceptos relacionados pueden ser aprovechadas para apoyar diferentes tareas académicas o basadas en conocimiento, permitiendo la exploración entre los conceptos de un dominio para conocer las interrelaciones jerárquicas entre los conceptos. El presente proyecto permite la explotación de fuentes de conocimiento con el objetivo de facilitar al usuario la exploración visual a través de estas estructuras, por medio de la herramienta D3SPARQL, la cual es una librería de JavaScript que puede ser incrustada en cualquier lenguaje de programación y permite acceder a datos basados en modelos SKOS o simplemente que tengan una estructura semántica. El resultado del proyecto es un componente interactivo de visualización de estructuras de conocimiento denominado “CIVEC”. En tiempo de ejecución, la solución construye consultas interactivas sobre fuentes de datos RDF, de forma fácil y transparente para el usuario. Es decir, se evita que el usuario común tenga que dominar las complejas tecnologías subyacentes.In recent years, the internet has been populated with a large amount of semantic data which have provided knowledge to the web. Semantic structures of related concepts can be harnessed to support different academic or knowledge-based tasks, allowing the exploration between the concepts of a domain to know the hierarchical interrelations between concepts. The present project allows the exploitation of knowledge sources in order to facilitate the user's visual exploration through these structures, through the tool D3SPARQL, which is a JavaScript library that can be embedded in any programming language and Allows access to data based on SKOS models or simply having a semantic structure. The result of the project is an interactive component of visualization of knowledge structures called \"CIVEC\". At runtime, the solution builds interactive queries over RDF data sources, easily and transparently for the user. That is, it prevents the common user from having to master the complex underlying technologies.\n"}
{"prompt":"Modelos de recomendación basados en conocimiento mediante el empleo de la computación con palabras ->","completion":" El continuo desarrollo de nuevas tecnologías ha llevado al crecimiento acelerado de la información digital. Es cada vez mayor la necesidad de crear alternativas que permitan la restauración y organización de toda la información que se proporcione a los usuarios de manera eficaz. En el siguiente trabajo se propone un sistema de recomendación basado en conocimiento mediante el empleo de la computación con palabras, con fines de mejora en las habilidades de resolución de problemas de los programadores, Se aplicará el método deductivo y la exploración. Utilizando esta metodología se analizara los diferentes tipos de sistemas recomendación para poder desarrollar un sistema de recomendación a partir de la información examinada, como resultado se da a conocer un modelo de recomendación de productos siguiendo el enfoque basado en conocimiento, la cual facilita la construcción de un perfil de usuario y BD, calculando el vector peso utilizando cuantificadores lingüísticos, de tal manera que se obtiene los resultados de la recomendación cuyos valores se acerquen más al perfil de usuario.The continuous development of new technologies has led to the accelerated growth of digital information. There is a growing need to create alternatives that create the restoration and organization of all the information that is provided to users in an efficient way. In the following work, a recommendation system based on knowledge is proposed through the use of word computing, in order to improve the problem-solving skills of programmers. The deductive method and exploration will be applied. Using this methodology, the different types of recommendation systems will be analyzed in order to develop a recommendation system from the information examined, as a result, a product recommendation model is released following the knowledge-based approach, which facilitates the construction of a user profile and DB, calculating the weight vector using linguistic quantifiers, in such a way that the results of the recommendation are obtained whose values are closer to the user profile.\n"}
{"prompt":"Estudio sobre el aprendizaje organizacional y la administración del conocimiento en las empresas basado en el pensamiento sistémico ->","completion":" La presente tesis tiene el carácter de investigación sobre los tópicos de organización, modelos de negocios, procesos, empresa, conocimiento, inteligencia, pensamiento sistémico, etc. Lo que se alcanzo es contar con un modelo para realizar diagnóstico situacional sistémico el mismo que podrá ser aplicado en cualquier tipo de organización pequeña y mediana bien sea del sector público o privado. Las organizaciones donde se aplique ésta herramienta podrán contar con un diagnóstico sistémico actualizado y a tiempo de tal manera que les permita tomar decisiones en el corto, mediano y largo alcance. Las organizaciones pueden ser territoriales, sociales, políticas, educativas, ambientales, etc., es decir es aplicable a todas las empresas que tengan un cierto grado de organización y que por sobre todo quieran cambiar y ser competitivas. La temática principal está basada sobre el aprendizaje organizacional, el pensamiento sistémico, la teoría general de sistemas; teorías que son aplicables al modelo organizacional y a la toma de decisiones. El pensamiento sistémico en una metodología que nos permite ver al mundo como un todo, donde sus partes interactúan entre sí. De igual manera si hacemos un análisis más a detalle podemos decir que las organizaciones, empresas y asociaciones también son sistemas, cada una de ellas a nivel interno están ligados por interacciones invisibles de actos y acciones, que a menudo tardan años en exhibir plenamente sus efectos. Con el uso de las Tecnologías de Información y Comunicación el problema de aprendizaje se agudiza si no sabemos administrar de manera eficiente y dar soluciones rápidas. Es por ello que se está empezando a utilizar principios, estrategias y la práctica de diálogo, y se procura integrarlos a un contexto contemporáneo.Magíster en Gerencia de Sistemas de InformaciónCuenca\n"}
{"prompt":"Diseño e implementación de un asesor virtual con interfaz web basado en un sistema de gestión de conocimientos y autoaprendizaje ->","completion":" Este trabajo está dirigido a proponer una solución de valor agregado al portal web de una empresa que brinda servicios de asesoría contable y tributaria con el propósito de aumentar sus ventas y capturar clientes con mayor eficacia. Se procederá a describir a la empresa auspiciante, indicando sus valores corporativos, giro de negocio y organización interna. Se presentará el portal web que desea mejorarse y se analizará su estado previo a la implementación de la solución. Se explicará el concepto del asesor virtual y se hará una revisión de temas como evolución de páginas web, comercio electrónico, gestión de conocimientos, inteligencia artificial, asesor virtual y plataformas de programación web.\n"}
{"prompt":"Método alternativo para la detección temprana de los niveles de alzheimer fundamentado en la iridiología con procesamiento digital de imágenes ->","completion":" El Alzheimer esta categorizado como uno de los tipos de demencia prioritarios para la salud pública del Ecuador y el mundo, es una de las causas principales de discapacidad y dependencia familiar, debido al deterioro progresivo de las capacidades intelectuales, provocado por una serie de factores genéticos, ambientales, factores de salud (lesiones en el cerebro, enfermedades degenerativas, etc.) o incluso hasta el mismo estilo de vida. Sin embargo, esta patología podría ser detectada en etapas tempranas mediante la aplicación de técnicas de inteligencia artificial, para la implementación de prototipos de sistemas expertos. El presente trabajo de investigación aborda una revisión sistemática de literatura contrastando trabajos relacionados, que sirvan de soporte para poner en evidencia que la extracción de características de una imagen del iris permite verificar la evolución de una patología, a tal punto de generar un patrón de referencia como resultado del estudio. Este proyecto se orienta en el desarrollo de un prototipo de predicción de niveles de Alzheimer, con el fin de brindar un aporte clínico a los especialistas como el Neurólogo, Psiquiatra o Psicólogo quienes abordan el tema en cuestión. Por otra parte, toda la información correspondiente a la base de datos de imágenes del iris fue obtenida en la fundación “CASA AURORA DEL PERPETUO SOCORRO”, estas imágenes permitieron obtener los resultados que se presentan en el proyecto. Finalmente, la información es analizada mediante el uso de algoritmos de entrenamiento no supervisado y procesamiento de imágenes\n"}
{"prompt":"SISTEMA BASADO EN CONOCIMIENTO PARA EL APOYO EN LA TOMA DE DECISIONES EN LA PLANIFICACI?N DE LA TRANSMISI?N DEL CANAL ULA TV ->","completion":" In the field of Venezuelan television, the decision is what to transmit and at what times to do so. It is the responsibility of the programmer, depending on the vision of the channel and the corresponding legal requirements according to the law on social responsibility in radio and television. Therefore, this is a task demanding because the channel rating depends entirely on its programming; hence the programmer must bear in mind all the available audio\/visual and give them the appropriate rotation. If these items are not in an organized manner, this management can be problematical when it comes to planning the transmission grid. Thus, the present work carries out the design and development of a system based on knowledge as a software tool for programmer support. This system is stored on an automated channel programming database which is able to suggest a weekly schedule updated to comply with the specifications mentioned above. This system has a user friendly interface for the programmer administrating the stored programs when needed to enter or update programs in the database. All of this uses methodology based on knowledge engineering and will allow us to achieve the solution of the problem and tests.En el ?mbito de la televisi?n venezolana la decisi?n de ?qu? transmitir? y ?a qu? horas hacerlo? es responsabilidad del programador, en funci?n de la visi?n del canal y los requisitos legales correspondientes de acuerdo a la ley de responsabi- lidad social en radio y televisi?n; por lo tanto, ?sta es una tarea comprometedora, ya que el rating del canal depende totalmente de su programaci?n y, por ende, el programador debe tener presente todos los audiovisuales disponibles y darles la debida rotaci?n ya que, si estos elementos no se encuentran de manera organi- zada, esta gesti?n puede hacerse complicada a la hora de planificar la parrilla de trasmisi?n. Por ello, el presente trabajo realiza el dise?o y desarrollo de un sistema basado en conocimiento como herramienta de software para el apoyo del programador, que tenga almacenado en una base de datos automatizada toda la programaci?n del canal y sea capaz de sugerir una programaci?n semanal actualizada que cumpla con las especificaciones anteriormente mencionadas. Este sistema posee una interfaz amigable para el programador, logrando hacer la administraci?n de los programas almacenados cuando se requiera ingresar o actualizar programas en la base de datos, todo esto siguiendo una metodolog?a basada en ingenier?a de conocimiento que permita conseguir la soluci?n del pro- blema y la realizaci?n de las pruebas correspondientes.Pontificia Universidad Cat?lica Del Ecuadorhttp:\/\/axioma.pucesi.edu.ec\/index.php\/axioma\/article\/view\/438\n"}
{"prompt":"Procesamiento digital de imágenes (PDI) apoyado en un entrenamiento neuro-difuso, para la inspección de objetos defectuosos. ->","completion":" This research degree work has the objective to apply and to demonstrate that using intelligent control theories, it is possible to control the industrial process, when they are highly nonlinear, when there is not an appropriate mathematical model or there is a complex dynamic. With the purpose of helping and expand the knowledge on students, educators and researchers in terms of intelligent control techniques for processes, it was implemented and applied a control system to inspect and classify flawed items, focus on 375 cc glass bottles, at the Automation and Industrial Control Laboratory located at AEIRNNR, this study was done in a real time, by capturing imagines with a camera. All mentioned above was done and achieved with a previous study on a bottling manufacture company, in this region, where the quality assurance is important in the final product. This degree work is focused on the digital imagine processing to develop a control system using an algorithm that allows the inspection and classification of the faulty items by imagining like the bottles, this is being achieved by a Neuro-fuzzy controller, correctly applied and verified, while the results were monitored in a visual and auditory way. The types of research used in this project are: descriptive and experimental, descriptive because it explains how the characteristics of the imagines are quantified, applying processing techniques. Also, it is experimental because the experimental variables are manipulated below controllable situations to describe particular situations. Besides, it is a documentary study because it was made from available data and bibliography information. Finally, to develop the system it was used the IDEAL and CommonKADS-RT, methodologies which are applied in the field of experienced systems, based on knowledge.El presente Trabajo de Titulación tiene como objeto aplicar y demostrar, que mediante el uso de teorías de control inteligentes, se logran controlar procesos industriales, cuando estos son altamente no lineales o cuando no se dispone de un modelo matemático adecuado por ser demasiado complejo o tienen una dinámica compleja. Para ello, con el ánimo de favorecer y ampliar el entorno del conocimiento en estudiantes, docentes e investigadores en cuanto a técnicas de control inteligentes para procesos, se implementó y ejecutó el sistema control de inspección y clasificación de objetos defectuosos, específicamente en botellas de vidrio transparentes de 375 cm³, en el Laboratorio de Automatización y Control Industrial del AEIRNNR; basado en conocimiento en tiempo real, a partir de imágenes capturadas mediante el uso de una cámara. Todo lo anterior se consiguió previo el estudio de los procesos en una planta embotelladora de la región, en donde interviene el control de calidad del producto final. El Trabajo de Titulación se centra en el área de procesamiento digital de imágenes (PDI) para dar lugar al desarrollo de un sistema de control por medio de la creación de un algoritmo, que permita la inspección y clasificación de objetos en imágenes como las botellas, esto se logró a través de un controlador Neuro-difuso debidamente entrenado y validado, mientras que la monitorización de los resultados se la realiza mediante la interfaz de usuario de forma visual y sonora. Los tipos de investigación son: descriptiva y experimental, descriptiva porque se explica cómo se puede cuantificar características de las imágenes, con la ayuda de técnicas de procesamiento; se habla también que es de tipo experimental, porque se establece la manipulación de variables experimentales, en condiciones controladas, para describir una situación o acontecimiento particular. A su vez, según la fuente, se considera un estudio documental, puesto que se realizó sobre la base de documentos y revisión bibliográfica. Para el desarrollo del sistema se utiliza conjuntamente las metodologías IDEAL y CommonKADS-RT, metodologías que son aplicadas en el campo de sistemas expertos basados en conocimiento.\n"}
{"prompt":"Identificación y diseño de un controlador para un sistema de antenas inteligentes basado en el algoritmo adaptativo rls ->","completion":" La identificación de sistemas trata de la estimación de modelos de sistemas dinámicos a partir de los datos observados mediante mediciones y experimentos de cualquier planta, a pesar que este proceso es poco utilizado en nuestro medio, es una teoría que ha tomado mucha fuerza durante los últimos años. En el Primer Capítulo, se encuentra una breve reseña historia de la importancia de la identificación de sistemas, el cual toma diversas áreas del conocimiento (ingenierías, economía, biotecnología, etc.). Así como la introducción al conocimiento de las Antenas Inteligentes o Smart Antennas. En el Segundo Capitulo, se muestran los recursos que se necesitan para proponer una solución viable con bases teóricas, partiendo de los conocimientos adquiridos durante el proceso de aprendizaje. En el Tercer Capítulo, se presenta la parte práctica y el diseño de la solución, en la cual, para realizar la identificación del sistemas se trabaja en una planta virtual de antenas inteligentes, donde se diseñan diferentes tipos de entrada escogiendo la más adecuada para continuar con la identificación paramétrica de la planta. En el Cuarto Capítulo, se muestra la implementación o identificación paramétrica utilizando la herramienta Ident de Matlab donde la mejor señal de entrada es ingresada para ser estudiada por los diferentes tipos de métodos, escogiendo así en base a varios criterios, el más adecuado o el que mejor se adapta a la planta. Por último, en el Quinto Capítulo, se implementa el compensador de la planta utilizando la herramienta SISOTOOL de Matlab, realizando las pruebas necesarias para demostrar la validez del porqué la elección de este tipo de controlador.\n"}
{"prompt":"Diseño de aplicaciones de sistemas embebidos basados en tecnología Raspberry y Odroid-U3. ->","completion":" El objetivo principal que persigue este trabajo es proporcionar herramientas para el desarrollo de prácticas de laboratorio en materias como electrónica, instrumentación, automatismos, control, telecomunicaciones, domótica, etc. utilizando nuevas tecnologías orientadas a la programación. El diseño de las aplicaciones se basa en la necesidad de disponer de un conjunto de elementos fácilmente compatibles y modulares en los cuales se pueda configurar bajo programación estructurada las funciones de control a ejecutar. Los beneficiarios de este trabajo, alumnos de Ingeniería Electrónica, afianzan sus conocimientos en programación bajo software de distribución libre de licencias y profundizan sus conocimientos sobre nuevas tecnologías para el desarrollo de proyectos.The next work: \"Applications Design Of Embedded Systems Based On Raspberry-Pi And Odroid-U3 Technology” discusses the implementation of development kits and laboratory practice using embedded systems in various subjects relating to electronic engineering. The focus of this work is embedded computers Raspberry-Pi and ODROID-U3 modern embedded systems that are programmed under various languages free distribution. The main objective of this work is to provide tools for the development of laboratory practices in areas such as electronics, instrumentation, automation, control, telecommunications, domotic, etc. using new technology oriented programming. The application design was based on the need for a set of modular elements easily compatible and in which structured programming could be set under the control functions to be executed. The beneficiaries of this work, Electronic Engineering students, entrench their knowledge in programming under free software licenses and deepen their knowledge of new technologies for the development of projects.\n"}
{"prompt":"Producci?n de recursos educativos abiertos con componentes sociales y sem?nticos basados con t?cnicas de Ingenier?a del Conocimiento ->","completion":" Los Recursos Educativos Abiertos (REA) y los Cursos Educativos Abiertos (OCW) son utilizados como apoyo para los procesos de ense?anza aprendizaje; el car?cter de abierto de estos recursos contribuye a la difusi?n de conocimiento y facilita el acceso a la informaci?n. Existe una gran cantidad de universidades e instituciones de educaci?n superior que se han unido al movimiento abierto, poniendo a disposici?n los OCW que sus docentes realizan para los estudiantes formales, sin embargo se ha detectado que no existe un proceso est?ndar en la producci?n de OCW ya que cada universidad lo realiza con modelos propios de acuerdo a las normativas institucionales. Por lo cual en este trabajo de tesis doctoral se propone un modelo de producci?n de REA y OCW, denominado REACS que contempla el uso de un modelo de dise?o instruccional que permite realizar un proceso sistem?tico de actividades que contribuyen al aprendizaje; adem?s de la utilizaci?n de herramientas sociales y herramientas sem?nticas que aportan al trabajo colaborativo e identificaci?n de los recursos por su significado, lo cual aporta a la inteligencia colectiva. REACS fue comparado con procesos de producci?n similares de las universidades relevantes del movimiento OCW, adem?s de ser implementado en un caso de estudio con tres fases en la creaci?n de OCW para una instituci?n de educaci?n superior. Con esta validaci?n se pudo comprobar que REACS aportaba a incrementar el n?mero de estudiantes que aprueban un curso y disminuye el tiempo de producci?n y publicaci?n de un OCW.\n"}
{"prompt":"Sistema inteligente basado en ontologías, procesamiento del lenguaje natural y técnicas de minería de datos para recomendar contenidos científico-metodológicos del ámbito de terapia del lenguaje ->","completion":" Este proyecto consta de un sistema de búsqueda y recomendación de artículos científicos en el ámbito de terapia de lenguaje, con el propósito de mejorar la investigación en los procesos de aprendizaje del terapista de lenguaje y cualquier persona interesada en el dominio. El sistema hace uso de varias tecnologías para presentar una recomendación acertada en base a la búsqueda del usuario.This project consists of a system for searching and recommending scientific articles in the field of speech therapy, with the aim of improving research in the learning processes of the speech therapist and anyone interested in the field. The system makes use of several technologies to present an accurate recommendation based on the user's search.\n"}
{"prompt":"Sistema basado en redes neuronales artificiales usando microfotografías para el diagnóstico micológico en plantas de maíz ->","completion":" El gran desarrollo que han tenido las Redes Neuronales Artificiales (RNA) en los últimos años ha causado un enorme impacto en las diversas áreas del conocimiento, incluyendo la Biología. Las RNA pueden ser entrenadas para aprender a clasificar patrones en imágenes, con distintos propósitos. El presente proyecto de titulación tiene como objetivo desarrollar un sistema capaz de reconocer 3 tipos de hongos presentes en plantas de maíz, mediante el uso de microfotografías. El sistema está basado en Morfometría y en el uso de algoritmos de Redes Neuronales Profundas (Deep Neural Networks) con lo que se ha logrado el aprendizaje de patrones a partir de un conjunto de imágenes. Las imágenes utilizadas para el entrenamiento de la red neuronal fueron obtenidas del laboratorio de Fitopatología de la Agencia de Regulación y Control Fito y Zoosanitario - AGROCALIDAD, institución pública adscrita al Ministerio de Agricultura y Ganadería. Dichas imágenes pertenecen a 3 plagas que afectan al maíz: Curvularia lunata, Ustilago maydis, y Helminthosporium maydis. El módulo de Morfometría implementado permite procesar la imagen y realizar las mediciones de las plagas en cada muestra. Las mediciones se alojan en la base de conocimiento y las imágenes tratadas se guardan dentro del corpus de imágenes para su aprendizaje. Fueron implementados 4 tipos de algoritmos, 2 de Clasificación y 2 tipos de RNA, de los cuales para el módulo de Morfometría se obtuvieron mejores resultados con el algoritmo Random Forest, ya que obtuvo un margen de confiabilidad de 99 % y para el módulo de Diagnostico se obtuvo un mejor aprendizaje con la Red Neuronal Convolucional, ya que los resultados logrados tuvieron un margen de confiabilidad del 98 %.\n"}
{"prompt":"“control de un robot usando un sistema embebido basado en el procesador nios ii” ->","completion":" En este artículo, presentamos que el desarrollo de la robótica, es una de las expresiones de ingeniería mas desafiantes de los últimos tiempos. Este requiere establecer los parámetros de integración de muchas disciplinas que aporten al desarrollo de prototipos cada vez más inteligentes, autónomos y útiles. Desapegándonos de los estándares, aportando a la educación e investigación, hemos pretendido aportar con nuestro conocimiento en el desarrollo de lo que pretende ser una plataforma que impulse el inventivo de los estudiantes de la ESPOL, para aportar como ha sido costumbre desde siempre con herramientas de desarrollo para el País El presente trabajo es una herramienta para desarrollo e investigación de la robótica en la ESPOL. Pretende hacer uso de tecnologías aprendidas e investigadas para promover en la Universidad la implementación a la medida de soluciones robóticas y no pensando en el actual comportamiento de consumo, que nos dice lo que tenemos que comprar y no lo que tenemos que diseñar. Es un impulso y motivación al desarrollo de soluciones ingenieriles, con tecnología de punta como son los FPGA, sistemas embebidos, comunicaciones inalámbricas de bajo coste pero de eficiencia máxima, trata de romper el paradigma de que lo hecho es lo que hago e idealizar a la población Politécnica a usar los conocimientos adquiridos para crear soluciones y no solo consumir.\n"}
{"prompt":"Sistema basado en lógica difusa para el análisis de preferencias y satisfacción de clientes ->","completion":" El sistema desarrollado se basa en técnicas de Lógica Difusa, permite analizar indicadores relacionados con la perspectiva que tienen los clientes del servicio que presta una empresa a operadoras móviles. Además,permite manejar la incertidumbre en la expresión de las preferencias subjetivas de los clientes, tales como: opiniones, gustos, satisfacción y preferencias del cliente. Los datos fueron proporcionados por la empresa y se creó una base de datos para proveer al sistema difuso de información relevante para su análisis. Esta información fue analizada junto a expertos en el dominio del tema para determinar las reglas difusas. Fue creado un motor de inferencia y una base de conocimiento. El sistema posee una interfaz gráfica que permite la interacción con el usuario. También se han diseñado reportes que permiten visualizar la información resultante del análisis. Con dicha herramienta la empresa da un paso adelante frente a la competencia, ofrecerá un servicio innovador que propicie el desarrollo de una estrategia de fidelización efectiva de la cartera de clientes. Los resultados permiten detectar y comprender las necesidades del cliente, ofrecer mejoras y novedades para responder a sus requerimientos en distintos aspectos y sobre todo mantener la cartera de clientes antiguos y nuevos, así como atraer clientes potenciales.\n"}
{"prompt":"Modelo didáctico para incorporar sistemas de E-Learning basados en software libre en el aprendizaje de la Física en el bachillerato. Caso de estudio: La cinemática. ->","completion":" El desarrollo del trabajo permitió recordar los fundamentos psicopedagógicos del trabajo en línea, y fundamentar teóricamente la construcción de un modelo didáctico para utilizar pedagógicamente Aulas Virtuales. Los resultados obtenidos hacen pensar que esta metodología de refuerzo de los conocimientos que se imparten de forma presencial puede lograr aprendizajes significativos, pero es necesario propiciar una Culturización Informática no solamente a los docentes sino también a los estudiantes. Se caracterizó el modelo didáctico para la enseñanza de la Cinemática dando orientaciones de lo que se debe tomar en cuenta para la planificación de un curso virtual, se determinó que la persona que se interese en esta propuesta debe tener una capacitación específica para aprovechar de mejor manera estas herramientas que fomentan el aprendizaje colaborativo. Se utilizó Moodle para validar la aplicación del modelo por su facilidad de interacción. La comprobación de la hipótesis se lo hizo mediante el estadístico de t-student por ser el -más recomendado para evaluar si dos grupos difieren de sí de manera significativa respecto a sus medias, verificándose la hipótesis de investigación. Finalmente se establecen las conclusiones y recomendaciones de la investigación, la utilización de un modelo didáctico es fundamental para un curso virtual pues selecciona las herramientas disponibles en el Entorno Virtual de aprendizaje y actividades que deben realizar para mejorar la enseñanza de la Física, para ello se recomienda que las instituciones educativas establezcan una política de utilización de Sistemas de E-learning que deba ser socializada a toda la comunidad educativa y la creación de un departamento de Apoyo Técnico y pedagógico, para que la utilización del modelo didáctico se vaya incluyendo paulatinamente en el entorno educativo.This work development helped to remember on line work psychoeducational basics and theoretically substantiate a teaching model construction to use virtual classrooms pedagogically. The results suggest that this knowledge strengthening methodology can achieve significant learning, but it is necessary to create a computer acculturation not only for teachers but also students. The didactic model was characterized by kinematics teaching by considering an online course management main aspects. It was determined that the person who is interested in this proposal should have specific training to better exploit these tools which promote collaborative learning. Moodle was used to validate the model application for its ease of interaction. The hypothesis testing was made through t-student statistical test because it was the most recommended to assess whether two groups differ significantly regarding their actions, verifying the research hypothesis. Research conclusions and recommendations are finally established, a didactic model use is critical for a virtual course because it selects the available tools in the virtual learning environment and the activities to be developed to improve Physics teaching, so it is recommended that schools establish a policy for the E-learning systems use which should be socialized to all the educational community and the creation of a Technical and Pedagogical Support department, so that the didactical model could be gradually included in the educational environment.\n"}
{"prompt":"Control de un Robot usando un sistema Embebido basado en el procesador NIOS II ->","completion":" El presente trabajo es una herramienta para desarrollo e investigación de la robótica en la espol. pretende hacer uso de tecnologías aprendidas e investigadas para promover en la universidad la implementación a la medida de soluciones robóticas y no pensando en el actual comportamiento de consumo, que nos dice lo que tenemos que comprar y no lo que tenemos que diseñar. es un impulso y motivación al desarrollo de soluciones ingenieriles, con tecnología de punta como son los fpga, sistemas embebidos, comunicaciones inalámbricas de bajo coste pero de eficiencia máxima, trata de romper el paradigma de que lo hecho es lo que hago e idealizar a la población politécnica a usar los conocimientos adquiridos para crear soluciones y no solo consumir.GuayaquilIngeniero en Electricidad Especialización Electrónica \/ Ingeniero en Electrónica y Automatización Industrial\n"}
{"prompt":"Sistema de información para la Gestión de los Procesos, Manuales de políticas y procedimientos en el Banco del Litoral S.A. basado en la metodología gestión por procesos de la Norma ISO 9001-Gestión de Calidad ->","completion":" El presente proyecto de tesis consiste en desarrollar e implementar una aplicación web para el Banco del Litoral S.A, la principal característica de esta aplicación web es la facilidad para administrar el inventario de procesos de acuerdo a los lineamientos de la norma ISO 9001 y la administración de los manuales de políticas y procedimientos.This thesis project consists of developing and implementing a web application for Banco del Litoral SA, the main characteristic of this web application is the ease of managing the inventory of processes according to the guidelines of the ISO 9001 standard and the administration of policies and procedures manuals\n"}
{"prompt":"Diseño de un sistema de souvenirs basados en la identidad cultural del Ecuador ->","completion":" Ecuador un país multiétnico y pluricultural que gracias a su variedad y abundancia es un destino turístico elegido por gran cantidad de personas alrededor del mundo, sin embargo, es evidente la necesidad de conocimiento cultural de los grupos étnicos representativos del país, ya que estos grupos no han sido representados correctamente en nuestro contexto. Por esta razón se propone tomar como referencia el Art Toy y el diseño emocional para generar una línea de souvenirs que ayuden a difundir la riqueza cultural que tiene el Ecuador e innovar a manera de causar un impacto en el turismo nacional e internacional.Diseñador de Objetos\n"}
{"prompt":"Diseño de prácticas para el aprendizaje de sistemas embebidos basados en el procesador Nios® II utilizando herramientas de Quartus II y la tarjeta DE0-Nano ->","completion":" El presente proyecto pretende ofrecer una guía para el aprendizaje de sistemas embebidos basándose en el procesador nios II con el que cuenta la FPGA de la DE0-Nano mediante el uso de los chips integrados en esta tarjeta de desarrollo y más aún, establecer una base sobre la cual los estudiantes de pregrado puedan elaborar proyectos en esta temática de alcances similares a los que se lleva acabo en universidades de todo el mundo. La metodología de aprendizaje de la presente propuesta esta basada en el desarrollo de seis prácticas, mediante las cuales se adquieren los conocimientos de los principios básicos del desarrollo de sistemas embebidos sobre el procesador Nios II, se aprende el acceso a registros de memoria que se les asigna a los componentes en la etapa de creación de hardware y al uso de periféricos propios de la tarjeta o externos.GuayaquilIngeniero en Electricidad Especialización Electrónica y Automatización Industrial\n"}
{"prompt":"Revisión sistemática del estado del arte de la Inteligencia de Negocios en el periodo 2016-2020 ->","completion":" Este artículo tiene por objetivo realizar una revisión sistemática sobre la inteligencia de negocios entre los años 2016-2020, para lo cual se analiza un conjunto de artículos científicos referentes a los avances que se han producido en dicho período, se discute el impacto que ha tenido la adopción de la inteligencia de negocios en su estrategia corporativa como clave del éxito y el logro de ventajas competitivas considerables a lo largo de los cuatro años. Para este trabajo se emplea un método de mapeo sistemático basado en un modelo de tres bloques: Definiciones de Protocolo, Ejecución de Búsqueda, Discusión de Resultados. Finalmente se presenta los resultados, hallazgos y se describe la relevancia que ha tenido la inteligencia de negocios en el período 2016-2020.This article aims to conduct a systematic review on business intelligence between 2016-2020, for which a set of scientific articles concerning the advances that have occurred in that period is analyzed, the impact that has had the adoption of business intelligence in its corporate strategy as a key to success, achieving considerable competitive advantages over the four years will be discussed. For this work, a systematic mapping method based on the three-block model is used: Protocol Definitions, Search Execution, Results Discussion. Finally, the results and findings are presented describing the relevance of business intelligence in the period 2016- 2020.\n"}
{"prompt":"Sistemas expertos aplicados a las finanzas ->","completion":" Para el desarrollo de la parte inteligente del sistema de razonamiento basados en reglas se utilizo el lenguaje Prolog con encadenamiento hacía atras y para el desarrollo de la parte inteligencte del sistema de razonamiento basado en casos se utilizo el lenguaje de programación Java. El sistema soporte arquitectura Cliente-Servidor para el lado del cliente se utilizaron applets usando la herramienta Visual Age. El sistema recomendará los instrumentos financieros para cada tipo de inversor de acuerdo a sus datos personales de experiencia en inversiones, horizontes de inversión, entre otros.GuayaquilIngeniero en Computación\n"}
{"prompt":"Aplicación de sistemas expertos al análisis de sistemas ->","completion":" La realización de este trabajo tiene como principal objetivo desarrollar una aplicación web que servirá para simular la interacción existente entre los seres vivos de un mismo ecosistema. Otro objetivo a mencionar es utilizar la aplicación como herramienta educativa la cual conseguirá una mayor inmersión de lo que se lograría con los métodos de enseñanzas tradicionales. Para el desarrollo y utilización de nuestro sistema como herramienta de aprendizaje se pondrán énfasis no solo en captar la atención de los usuarios a través de un juego dinámico y entretenido sino de mantenerla, para esto se debe ser empático y ponerse en el lugar del jugador, para que le resulte interesante la aplicación. nuestro trabajo permite emular por medio de una aplicación la habilidad de toma de decisiones mediante relaciones, según las interacciones existentes entre los seres vivos de un ecosistema y las respuestas del usuario durante la ejecución del sistema.GuayaquilIngeniero en Ciencias Computacionales Especialización Sistemas Multimedia \/ Ingeniero en Ciencias Computacionales Especialización Sistemas de Información\n"}
{"prompt":"Aplicación de sistemas expertos al análisis de sistemas ->","completion":" La realización de este trabajo tuvo como principal objetivo desarrollar una herramienta de aprendizaje que simule la interacción de organismos de distintas especies que conviven y compiten por su supervivencia en un ecosistema acuático. Esta herramienta fue diseñada para permitir al usuario a través de un juego, simular las interacciones que ocurren entre organismos vivos y su medio. La aplicación Guerra de los Mundos “Aldea pez” emplea la técnica de árboles de decisión para realizar la toma de decisiones del usuario bajo diferentes escenarios, y su impacto en el ecosistema a lo largo del tiempo. La base de conocimiento del sistema se desarrolló y validó con la participación de un experto en ecología marina. Una vez implementada, la aplicación fue sometida a un set de pruebas con treinta usuarios de diferentes edades, obteniendo un puntaje superior a cuatro en una escala de cinco niveles para el 80% de la muestra, en cuanto a la facilidad de uso de la aplicación.\n"}
{"prompt":"Utilización de Sistemas Expertos Mediante una Interface Web ->","completion":" El proyecto consiste en diagnosticar las posibles enfermedades que podrán ser tratadas por los productos naturales previamente almacenados en la base de datos, dependiendo de los síntomas ingresados y viceversa. Además se podrá acceder a información, consejos, informes de salud y a la realización de test que ayudaran a mejorar el estilo de vida. Los lenguajes utilizados para la realización de la Interface Web fueron PHP, JavaScript y como Gestor de datos MySql. El resultado muestra una Interface Web de fácil manejo, la misma que ha sido clasificada en Módulos de: Administrador y Usuario.\n"}
{"prompt":"Sistema experto para evaluación de procesadores ->","completion":" Los microprocesadores, esos pequeños cerebros electrónicos de silicio que protagonizan la revolución digital que estamos viviendo, constituyen uno de los logros más sobresalientes del siglo que terminó, pues han comenzado a cambiar la forma en que percibimos el mundo. En la larga línea de innovaciones tecnológicas derivadas del microprocesador, nuestro planeta ha logrado avances científicos, tecnológicos y económicos impensables en décadas anteriores, y la humanidad ha conseguido mejor comunicación, mayor desarrollo y un merecido bienestar. Desempeñan un papel vital, pues permiten la elaboración de productos de enorme utilidad y la prestación de servicios vitales, en todos los campos imaginables de la actividad humana. Por ello nuestro interés en presentar esta investigación sobre el tema, porque a partir de 1947 en que se inventó el primer transistor, nuestro planeta inició una nueva era, pues en la actualidad, 20 millones de esos microscópicos transistores insertados en un microprocesador moderno, permiten al hombre simplificar su vida, o por lo menos, disfrutarla mejor.\n"}
{"prompt":"Sistemas expertos aplicados a las finanzas: análisis, diseño e implementación del sistema experto para la obtención de tarjetas de crédito ->","completion":" El presente documento presenta la implementación de un sistema para la obtención de tarjetas de crédito en instituciones financieras basados en técnicas de sistemas expertos. Se presenta una descripción del problemas, se indican además los alcances, limitaciones, justificaciones y objetivos del mismo. Se describe la solución del problema, las especificaciones y requisitos para utilizar el programa. Incluye el diseño tanto arquitectónico como detallado del sistema. Se realizan las pruebas del sistema y finalmente se presenta la instrumentación de sistemas; tanto de software como de hardware.GuayaquilIngeniero en Computación\n"}
{"prompt":"Sistema experto para la identificación de mamíferos en extinción ->","completion":" La tesis mostrada a continuación ha nacido como parte del agradecimiento que tengo por la vida al haberme permitido estudiar una carrera tan bonita en la Universidad a quien tanto quiero por ser mi segundo hogar durante mis años de estudio. El sistema experto permite identificar las categorías de extinción que tienen los mamíferos de nuestro país. Esperando que esta información sirva como un llamado de atención para que se tomen ciertas medidas que impidan su destrucción. Un sistema experto es aquel que permite realizar cierto tipo de tareas que a menudo son realizadas por expertos humanos. En el desarrollo de esta tesis el experto del que se ha necesitado apoyo es un Biólogo y del Libro Rojo de Mamíferos del Ecuador publicado por Diego Tirira en el año 2001, que es un aporte científico de la Unión Mundial para la naturaleza y que contiene Sistema Experto para Mamíferos en Extinción Pontificia Universidad Católica del Ecuador listados básicos de las especies amenazadas en extinción, organizadas de acuerdo al grado de amenaza.\n"}
{"prompt":"Sistema experto para evaluar solicitudes de crédito en instituciones financieras ->","completion":" Trabajo en el que se desarrolla una aplicación capaz de evaluar solicitudes de credito en instituciones bancarias, al cual se ha denominado sistema experto de crédito o SEC. Se inicia tratando la metodología que sigue actualmente las instituciones bancarias para evaluar a un cliente. Se hace una descripción entendible del sistema experto de crédito. Seguidamente realiza una descripción de la ingeniería de software que por lo general se sigue para desarrollar este tipo de sistemas. Finalmente presenta 2 casos de prueba que se consideran mas representativos de situaciones que se pueden dar en una institución bancaria cuando se evalua al cliente.GuayaquilIngeniero en Computación\n"}
{"prompt":"Diseño e implementación de un sistema experto para seleccionar personal ->","completion":" Desarrolla un prototipo de sistema experto. Trata en forma mas específica sobre lenguajes tradicionales, lenguajes de inteligencia artificial y conchas para sistemas expertos. Estudia el análisis y diseño del sistema experto para seleccionar personal.GuayaquilIngeniero en Computación\n"}
{"prompt":"Sistema experto para asistir la decisión de promoción de ventas ->","completion":" En este artículo se detalla el desarrollo del sistema experto SEGED para asistir la toma de decisiones en las promociones de ventas. SEGED fue diseñado como una aplicación de escritorio que permitirá al Departamento de Compras de una tienda por departamentos gestionar de mejor manera el inventario de la compañía evitando que los productos de baja rotación se acumulen en las bodegas. SEGED fue desarrollado como un sistema experto basado en reglas de inferencia para simular el comportamiento de un experto humano ante diferentes escenarios en el cambiante mundo retail. SEGED evalúa la edad del inventario, la utilidad obtenida de la venta a una fecha determinada y el compromiso de pago que se tiene con el proveedor para determinar el momento en el que el inventario debe ser puesto en descuento y cuál es el porcentaje de descuento óptimo para recuperar la mayor utilidad de la compra. Cada uno de los resultados de SEGED fue validado satisfactoriamente por el usuario experto quien agregó que esta herramienta puede ser ampliamente explotada en el medio.\n"}
{"prompt":"Sistema experto para asistir la decisión de promoción de ventas ->","completion":" El presente trabajo contempla la evaluación de un tipo de mercadería y la estructuración de las reglas básicas del negocio para determinar la decisión de descuento a tomar. Puntualmente por tipo de mercadería nos referimos a aquellos productos de moda que se compran por primera vez debido a las tendencias del mercado.SISTEMA EXPERTO PARA ASISTIR LA DECISIÓN DE PROMOCION DE VENTAS\n"}
{"prompt":"Sistema experto para decisiones de riego en cultivos de cacao” ->","completion":" EXPCAC provee al usuario de una interfaz gráfica de fácil acceso, y sirve como herramienta educativa y de concienciación.El objetivo de este proyecto consiste en el desarrollo de una aplicación web que brinde soporte a los agricultores para llevar a cabo una administración adecuada del riego en plantaciones de cacao, con el propósito de identificar un manejo costo-efectivo.La aplicación EXPCAC, hace uso de métodos de inteligencia artificial, como son los sistemas expertos para la construcción de un modelo experto que simula el impacto del riego en la producción de cacao utilizando reglas de inferencia.\n"}
{"prompt":"Diseño e implementación de un sistema experto para seleccionar personal ->","completion":" Desarrolla un prototipo de Sistema Experto. Trata en forma mas especifica sobre lenguajes tradicionales lenguajes de inteligencia artificial y conchas (shell) para sistemas expertos. Estudia el analisis y diseño del sistema Experto para seleccionar personal\n"}
{"prompt":"Elaboración de un Sistema Experto de Orientación Vocacional ->","completion":" La presente monografía pretende entregar al estudiante una herramienta, que le permita conocer sus aptitudes y destrezas para así poder elegir una carrera idónea a su vocación como futuro profesional. Mediante una parte teórica, se explicará las metodologías que se aplican en la orientación vocacional. Subsiguientemente dentro de este estudio a través de la interfase Web del sistema experto de orientación vocacional, el usuario que este utilizando el sistema seleccionará los datos sobre su personalidad y aptitudes que tiene, consecuentemente proporcionará el sistema las posibles carreras a las que puede optar para su ingreso a la universidad.\n"}
{"prompt":"Sistema experto para determinar el tipo de diabetes ->","completion":" Diagnóstico y clasificación de la diabetes mellitus. Sistemas basados en el conocimiento. Desarrollo del sistema experto. Conclusiones. Recomendaciones. Bibliografía. Direcciones de Internet. Anexos. Apéndices.\n"}
{"prompt":"Sistema experto orientado a medicina pediátrica mediante lógica difusa ->","completion":" Actualmente en un mundo plenamente globalizado en todo aspecto, principalmente en la ciencia y tecnología, nuestro país se ha mantenido al límite de esta evolución. Sin embargo a partir de este nuevo siglo y parte de las últimas décadas del pasado, hemos logrado hechos que a pesar de no tener gran trascendencia por falta de apoyo económico del estado para el desarrollo científico-técnico, las universidades han aportado en cada una de sus carreras profesionales con proyectos realmente interesantes, novedosos, plausibles en diversos campos. Este trabajo de investigación reúne en una aplicación, “Criterios Médicos de Pediatría” y conceptos de “Inteligencia Artificial”. Para facilitar la interpretación de la información, se diseña un programa prototipo de “Sistema Experto” mediante el uso de “Lógica Difusa”. Su orientación va dirigida al área de la medicina pediátrica, específicamente a los departamentos médicos de los establecimientos educativos. Para esto se ha tenido como referencia datos reales y estadísticos proporcionados por la Unidad Educativa Salesiana “Don Bosco” de la Tola. La finalidad está en proveer al Experto Médico, un software con la capacidad de discernir conocimiento e interpretar este en una receta médica . La información adquirida permite determinar cuáles son las enfermedades más usuales que los alumnos comprendidos entre los seis hasta los doce años tienen, cuando estos se encuentran en su establecimiento educativo. De aquí nace la necesidad de proveer a la rama de Pediatría una herramienta inteligente que ayude al experto a evaluar las enfermedades más comunes con razonamiento lógico y de lenguaje natural, necesarios en todo proceso de adquisición del conocimiento. Es ahí cuando este prototipo se ejecuta, extendiendo la prescripción médica adecuada a los alumnos.\n"}
{"prompt":"Sistema experto para decisiones de riego en cultivos de cacao CCN51 ->","completion":" Este trabajo presenta el desarrollo de una aplicación multimedia de acceso web para el control del riego en los cultivos de cacao CCN51. Esta aplicación hace uso de un modelo experto, como fuente de conocimiento, construido con base al conocimiento de un experto en el área. El objetivo del proyecto es el de desarrollar una aplicación que instruya a los agricultores de cacao, haciendo énfasis en la variedad CCN51, sobre lo que representa una buena cultura del riego para prevenir posibles problemas en el crecimiento de sus cultivos debido a estrés hídrico.GuayaquilIngeniero en Ciencias Computacionales Especialización Sistemas de Información \/ Sistemas Multimedia \/ Sistemas Tecnológicos\n"}
{"prompt":"Sistema experto para la evaluación y prevención de la problemática de contaminación de un río ->","completion":" El propósito del proyecto es implementar un sistema experto que permita dar apoyo al diseño de estrategias para reducir el nivel de concentración de un contaminante específico (en este caso será nitrógeno) en un tramo de un río y a la vez simular la manera en cómo afectan las fuentes de contaminación al mencionado tramo del río. Dada la problemática de la contaminación del río, generada por diversas fuentes contaminantes que serán de dos tipos basadas en actividades humanas o también llamadas usos de suelo que son: actividades agrícolas y población, se plantea que, llegado a un punto conocido como zona protegida el nivel de concentración de nitrógeno en el río no exceda un máximo permitido.GuayaquilIngeniero en Ciencias Computacionales Especialización Sistemas Multimedia \/ Ingeniero en Ciencias Computacionales Especialización Sistemas de Información\n"}
{"prompt":"Sistema experto para la detección de cancer a la glandula tiroides - siecat ->","completion":" El objetivo del presente trabajo es el de desarrollar un Sistema Experto para el diagnóstico médico de cáncer de la glándula Tiroides (SIECAT) basado en la técnica de redes bayesianas que establezca la probabilidad de un paciente de obtener un diagnóstico positivo a partir de la valoración de su sintomatología. En la construcción del modelo bayesiano se incorporó el conocimiento de un experto oncólogo. Para la consecución del objetivo se desarrolló una interfaz de usuario que permite el acceso en línea de doctores en medicina -especialistas y no especialistas- a la información y conocimiento contenidos en el Sistema Experto, de tal forma que el SIECAT pueda ser utilizado como una herramienta de consulta.\n"}
{"prompt":"Sistema experto para la evaluación y prevención de la problemática de contaminación de un río ->","completion":" El presente artículo documenta la implementación de un sistema experto que soporta el diseño de estrategias para reducir el nivel de concentración de un contaminante en un río -en este caso nitrógeno- a través de la aplicación de modelos analíticos y expertos que simulan el efecto de diferentes fuentes contaminantes y de la implementación de medidas de manejo ambiental específicas, sobre la calidad del agua del río. Las fuentes contaminantes consideradas, también llamadas “Usos de suelo”, son de dos tipos: actividades agrícolas y asentamientos urbanos, los cuales se distribuyen a lo largo del tramo de río. El diseño del ambiente riparino considera la existencia de una “Zona Protegida” en su parte más baja, donde la concentración de nitrógeno en el río no debe exceder la concentración máxima permitida de 2,44 mg\/l. El sistema experto, desarrollado como una aplicación web, permite a un usuario no experto, simular el ambiente riparino a través de la selección de diferentes distribuciones de uso de suelo a lo largo del río y la aplicación de diferentes medidas de manejo ambiental para el control de los niveles de contaminación por nitrógeno, utilizando una interfaz gráfica interactiva. El sistema incluye información del costo generado por las medidas de manejo de la contaminación aplicadas en el ambiente riparino.This article reports the implementation of an expert system that supports the design of strategies for reducing the level of concentration of a contaminant in a river, in this case nitrogen, through the application of expert analytical models and simulating the effect of different pollution sources and the implementation of specific environmental management measures on water quality of the river. The sources considered pollutants, also called \"Uses of soil\" are of two types: agricultural and urban settlements, which are distributed along the stretch of river. The design of the environment on the banks of a river considers the existence of a \"Protected Area\" in its lower part, where the concentration of nitrogen in the river should not exceed the maximum allowable concentration of 2.44 mg\/l. The expert system, developed as a web application, allows a novice user to simulate the environment on the bank of a river through the selection of different distributions of land use along the river and the application of different measures environmental management to control the levels of nitrogen pollution, using a graphical user interface. El system includes cost information generated management measures of pollution applied in the environment on the bank of a river.\n"}
{"prompt":"Generación de inferencias elaborativas en la comprensión de textos narrativos ficcionales en niños de 11 - 13 años ->","completion":" La comprensión lectora es un proceso cognitivo complejo, que supone representaciones mentales del texto en diferentes niveles interrelacionados. Desde la psicología del discurso, se han planteado diversos modelos descriptivos y explicativos de la comprensión y se ha destacado el rol fundamental del conocimiento previo y del control cognitivo que el lector desarrolle sobre los mecanismos operantes en la lectura (Kintsch, 1996; Meilán & Vieiro, 2001; Molinari Marotto & Duarte, 2007; Zwaan & Singer, 2003). Uno de los mecanismos más relevantes es la generación de inferencias: operaciones cognitivas de agregado, sustitución, omisión o integración de información, que intervienen en la construcción de las representaciones mentales cuando se intenta comprender lo leído (León, 2003). Si consideramos que leer textos es parte de la rutina diaria de un sujeto desde temprana edad (Zwaan & Singer, 2003), el estudio de la generación de inferencias adquiere una importancia capital en la investigación del proceso de comprensión lectora. Asimismo, debemos contemplar que los niños leen una gran cantidad de textos narrativos ficcionales durante sus años de escolaridad primaria y, en los últimos cursos, en sexto y séptimo grado, es donde los mecanismos de lectura básicos se automatizan y pueden dar lugar a un mayor control sobre operaciones tales como la generación de inferencias. Considerando estos aspectos, nuestro principal propósito fue comprobar la incidencia que un grupo de inferencias, las elaborativas, tiene sobre la comprensión de textos narrativos ficcionales en niños de 11-13 años. Para ello realizamos un experimento en el que 56 niños (28 de sexto grado y 28 de séptimo) de un colegio de la Ciudad Autónoma de Buenos Aires leyeron dos cuentos: uno fantástico y otro realista. Luego de la lectura de cada cuento, respondieron un cuestionario de cinco preguntas, que implicaban la generación de inferencias. Antes de la lectura de los cuentos, se administró un primer cuestionario que tuvo la intención de evaluar la experiencia de lectura general y por géneros. Vistos los resultados, se pudo comprobar que las inferencias elaborativas cumplen un rol fundamental en la construcción de representaciones mentales en la comprensión de textos fantásticos y que su generación está ligada a la experiencia de lectura, al conocimiento previo del género y al control que puedan desarrollar los sujetos sobre dichas operaciones. Dados estos factores y como perspectivas futuras de investigación y aportes a la enseñanza de las Prácticas del Lenguaje, esbozamos ciertas propuestas didácticas propiciadoras de la generación de inferencias en la lectura.\n"}
{"prompt":"El impacto de la industrialización en el proceso de fabricación de productos intermedios de hierro o acero sin alear como mecanismo de sustitución de importaciones en el contexto de cambio de la matriz productiva de la industria siderúrgica del Ecuador ->","completion":" Esta tesis de Maestría tiene la intención de evaluar las implicaciones en la industrialización del proceso de fabricación de productos intermedios de hierro o acero sin alear, como mecanismo de sustitución de importaciones en el contexto de cambio de la Matriz Productiva en uno de los Sectores considerados como estratégicos en el desarrollo del país y base fundamental del proyecto de cambio como es la Metal Mecánica. El resultado de este trabajo de investigación es una serie de conclusiones relevantes sobre los antecedentes del proceso de industrialización y sus repercusiones en los volúmenes de importación tanto en unidades comerciales como unidades monetarias durante el período de análisis, así como una serie de inferencias generadas y valoradas en el corto y mediano plazo, con la finalidad de establecer oportunidades y nuevos desafíos en el fomento al cambio de modelo productivo sin enfrentarse a especulaciones o variaciones de mercado. La parte final de este trabajo propone algunas conclusiones y recomendaciones obtenidas en base a la información estudiada y generada durante la investigación.This master's thesis aims to assess the implications of the industrialization of the process of manufacture of steel billets products like mechanism of replacement from imports in the context of changing the Productive Matrix in one of the industrial segments considered like strategic in the development of the country and extremely important in the project of this change as the Metal Mechanics is. The results of this research work are some important conclusions about the antecedents of the process of industrialization and its impact on import volumes both in commercial units as units of currency during the analysis period, as well as a number of inferences generated and valued in the short and medium term, with the purpose of establishing opportunities and new challenges in the promotion to the change of productive model without confronting to speculations or market variations. The final part of this paper proposes some conclusions and recommendations obtained on the basis of the information analyzed and generated during the research.\n"}
{"prompt":"Estudio del comportamiento del DBO en humedal artificial para tratar agua residual proveniente de baños, lavadoras y fregaderos ->","completion":" The present research project related to the topic \"Study of the DBO treatment in Artificial Wetland to treat wastewater coming from bathrooms, washing machines and sinks\", has the fundamental objective of evaluating the removal of the BOD indicator parameter in an artificial wetland. To fulfill the objective of starting the session with the open part, taking into account the concepts issued by various authors on the treatment of wastewater from bathrooms, washing machines and scrubbers and artificial wetlands, types of elements, advantages, parameters, explaining types of wetlands, components, removal mechanisms, and design. Later, please describe the existing treatment system, the existence of the improvements, the implementation of improvements, the realization of the change of the bed, the painted structure, among others, making laboratory tests for the determination of BOD, the type of samples, range of work, methods, quality manual (PG-01), in safety techniques, equipment, materials, reagents, previous operations, procedure, application of formulas, report of results, precision, and records……….El presente proyecto de investigación relacionado con el tema “Estudio del Comportamiento del DBO en Humedal Artificial para tratar Agua Residual proveniente de baños, lavadoras y fregaderos”, tiene como objetivo fundamental de evaluar la remoción del parámetro indicador DBO en un humedal artificial. Para cumplir con el objetivo se inicia con la parte teórica, tomando en cuenta los conceptos emitidos por varios autores sobre el tratamiento de aguas residuales provenientes de baños, lavadoras, fregaderos y humedales artificiales, detallando los tipos, elementos, ventajas, parámetros, explicando sobre tipos de humedales, componentes, mecanismos de remoción, y diseño. Posteriormente, se describe el sistema de tratamiento existente previo a mejoras, en la implementación de mejoras se realiza el cambio del lecho, adecentamiento, entre otros, haciendo pruebas de laboratorio para la determinar DBO, detallando el tipo de muestras, rango de trabajo, métodos, manual de calidad (PG-01), inferencias (sustancias tóxicas), principios (cinco días), medidas de seguridad, equipos, materiales, reactivos, operaciones previas, procedimiento, aplicación de fórmulas, reporte de resultados, precisión, y registros………..\n"}
{"prompt":"Factores que determinan el acceso de los beneficios tributarios por parte de los adultos mayores en la ciudad de Guayaquil. ->","completion":" La presente investigación surge por la necesidad de identificar los factores que inciden en la accesibilidad de los beneficios tributarios por parte de los adultos mayores tomando en cuenta que forman parte de un grupo prioritario donde el Estado ha establecido ciertos incentivos, con la finalidad de mejorar su calidad de vida. De modo que, se selecciona una combinación de diseños metodológicos a fin de, abordar la problemática existente, entre las cuales, se destaca el observacional, prospectivo y transversal definiendo un enfoque mixto para aplicar una encuesta direccionada a los adultos mayores y profundizar los resultados a través de entrevistas a expertos en el área tributaria, lo que permitió tener una mayor amplitud de los resultados y establecer las siguientes inferencias donde se pudo determinar que dentro de los factores que inciden en la accesibilidad se centra el desconocimiento, seguido del nivel de instrucción, los ingresos, las pérdidas de las facultades físicas y el descuido por la falta de cultura tributaria. Por consiguiente, se recomienda que la Administración Tributaria continúe realizando estudios que le permitan establecer un mecanismo que pueda instruir a los adultos mayores a fin de que tenga un conocimiento completo en cuanto a sus beneficios para la mejora de su calidad de vida.\n"}
{"prompt":"Generación de un modelo espacial de riesgo de enfermedades respiratorias crónicas a partir de datos de calidad de aire en la ciudad de Quito entre los años 2013 a 2017. ->","completion":" La contaminación del aire y los efectos nocivos en la salud pública han recibido una atención considerable en la ciudad de Quito. El estudio del modelo espacial de riesgo (MER) fue diseñado para evaluar la probabilidad de riesgo de adquirir enfermedades respiratorias crónicas (ERC) en la población del Distrito Metropolitano de Quito (DMQ), y cómo estas se encuentran relacionadas con la contaminación ambiental. El modelo de regresión logística binaria (MRLB) y el modelo de regresión logística con inferencia bayesiana (MRLIB) se utilizaron para analizar los efectos de la contaminación ambiental en la salud de la población y evaluar los mecanismos más importantes a través de los cuales los factores como calidad del aire, datos meteorológicos e imágenes satelitales, contribuyen al aumento de ERC en los habitantes del DMQ cada año. Se tomaron en cuenta 21 variables para las regresiones logísticas, de las cuales, mediante correlaciones y pruebas de diagnóstico, se escogieron 11 variables independientes que mejor evalúan el comportamiento de la variable dependiente (número de enfermos). El modelo final trata de predecir el riesgo de presentar ERC en las parroquias del DMQ y observar el estado de salud de la población, a través de mapas de probabilidad de riesgo (MPR). El modelo con mayor predicción de ajuste fue el MRLIB, ya que la inferencia bayesiana permite obtener predicciones más exactas en base a los métodos MCMC.Air pollution and adverse effects on public health have received considerable attention in the city of Quito. The study of the spatial risk model (MER) was designed to evaluate the probability of acquiring chronic respiratory diseases (CKD) in the population of the metropolitan district of Quito (DMQ), and how these responses are related to environmental pollution. The binary logistic regression model (MRLB) and the Bayesian logistic regression model (MRLIB) are used to treat the effects of the population's attention and the evaluation of the most important factors through which the factors Air quality, weather data and satellite images. 21 variables were taken into account for the logistic regressions, from which, using correlations and diagnostic tests, 11 variables were selected to evaluate the behavior of the dependent variable (number of patients). The final model tries to predict the risk of presenting CKD in the DMQ plots and observe the health status of the population, through the risk probability maps (MPR). The model with the highest prediction of adjustment was the MRLIB, since the Bayesian inference allows obtaining more accurate predictions based on the MCMC methods.\n"}
{"prompt":"Innovación en el diseño de políticas públicas: formalización bayesiana de process tracing aplicada a la política de regalías en Colombia. ->","completion":" La investigación profundiza en el análisis de innovaciones de política pública; deduce de la teoría neoinstitucional un mecanismo causal que propone que el cambio institucional puede ser detonante de innovaciones, y explora así, una alternativa teórica a las explicaciones del cambio de política que tratan a las innovaciones como sucesos contingentes. El diseño metodológico de la investigación sigue una orientación deductiva basada en la selección de un caso de estudio, analizado mediante la modalidad de comprobación teórica de process tracing. Además, se hace uso de la formalización bayesiana como complemento a la etapa argumentativa de la inferencia. Los instrumentos de política pública son el principal insumo para la caracterización de la política y la definición de evidencias del proceso inferencial.\n"}
{"prompt":"Un marco de trabajo para el desarrollo de aplicaciones web con comportamiento autónomo inteligente ->","completion":" Este trabajo presenta un mecanismo para construir aplicaciones Web sensitivas a la información existente en el contexto. Es decir, sistemas capaces de reconfigurar su comportamiento en función del escenario en que se encuentren. Esto se logra a través del uso de mapas cognitivos para representar las reglas de comportamiento del sistema, en combinación con patrones de diseño que dividen el software en pequeños componentes. Tal esquema permite configurar las reglas del negocio a través de un modelo gráfico que enlaza los datos del contexto, los conceptos del negocio y las acciones realizadas por los componentes. De esta forma el comportamiento del sistema es el resultado de un proceso de inferencia realizado sobre el mapa cognitivo. Este trabajo sienta las bases teóricas para el desarrollo de este tipo de sistemas y detalla su implementación, utilizando tecnologías de licenciamiento abierto y de amplio uso.\n"}
{"prompt":"Estrategias comunicacionales para el comercio popular caso Mercado Central de Ambato ->","completion":" Estudia el tratamiento dado a la comunicación interna y externa del Mercado Central del cantón Ambato a través de estrategias comunicacionales que mejoren el comercio popular dentro de este centro de acopio, promoviendo e incentivando valores de comprensión de estatutos y normativas internas así como la cooperación y el trabajo en equipo, los cuales aparecen inexistentes entre los comerciantes; así como estimulando la comunicación externa a través de la promoción de productos y servicios ofrecidos al interior del mismo. Determina temáticas basadas en la comunicación organizacional y la economía popular solidaria a través de herramientas de difusión en medios virtuales y tradicionales. Contiene el análisis del problema desde el enfoque cualitativo, pues mediante evaluación y monitoreo mediante encuestas basadas en la ley de inferencia. Se concluye que el anhelo de los expendedores es el de encontrar mecanismos que le permitan comercializar sus productos de una mejor manera y obteniendo mejores réditos económicos. Se podría decir que el expendedor o expendedora hace de su puesto un templo al comercio.Study the treatment given to the internal and external communication of the Central Market of the Ambato canton through communication strategies that improve the popular trade within this collection center, promoting and encouraging values of understanding of internal statutes and regulations as well as cooperation and Teamwork, which appear non-existent among merchants; as well as stimulating external communication through the promotion of products and services offered within it. Determines themes based on organizational communication and solidarity popular economy through tools of diffusion in virtual and traditional media. It contains the analysis of the problem from the qualitative approach, by means of evaluation and monitoring through surveys based on the law of inference. It is concluded that the desire of the retailers is to find mechanisms that allow them to market their products in a better way and obtaining better economic returns. It could be said that the vending machine or vending machine makes its place a temple to commerce.\n"}
{"prompt":"Un marco de trabajo para el desarrollo de aplicaciones web con comportamiento autónomo inteligente ->","completion":" Presenta un mecanismo para construir aplicaciones web sensitivas a la información existente en el contexto. Se empieza analizando las características actuales del software basado en el web y se remarca la importancia del comportamiento autónomo. El diseño de la plataforma se basa en la combinación de patrones de diseño de software con mapas cognitivos difusos, una herramienta para representar el conocimiento y realizar inferencias. Se presenta un análisis de las tecnologías web actuales basadas en patrones y se selecciona una para la implementación de la plataforma. Se detalla el diseño y la implementación del marco de trabajo y se analiza su eficiencia.GuayaquilIngeniero en Computación Especialización Sistemas de Información\n"}
{"prompt":"Analisis de la aplicación de barreras arancelarias a las importaciones ecuatorianas: caso textil y calzado ->","completion":" El presente documento elabora un análisis económico-tributario sobre el efecto que han tenido los cambios en las políticas comerciales externas en las decisiones de los agentes de la economía ecuatoriana, para verificar en qué medida se ha promovido la industria local, y si se observan beneficios o pérdidas desde el punto de vista económico y tributario. Con fines de poder estimar los efectos específicos, el análisis se centra en las medidas adoptadas sobre las importaciones de textiles, artículos de cuero y calzado, teniendo como periodo de estudio: 1996 – 2010. Como se mencionó, los diferentes aumentos y disminuciones de impuestos externos, y en específico las que se han decretado a partir del 2007, mantienen la finalidad de proteger la industria nacional por medio de la promoción del desarrollo de las actividades productivas del país y de la limitación de las importaciones de bienes de consumo. El mecanismo para establecer estas restricciones es mediante la publicación de decretos ejecutivos emitidos por la Presidencia de la República, tras previo dictamen favorable del Consejo de Comercio Exterior e Inversiones (COMEXI) quien determina el impacto sobre las decisiones de los agentes frente a la disyuntiva de elegir entre consumo interno y consumo externo. De esta manera, es necesario evaluar si estas políticas han cumplido su cometido, y si es adecuado mantenerlas, en vista de que algunas de ellas (como es el caso de las salvaguardas) tienen el carácter de temporal y deben ser ratificadas si se confirma su beneficio. El trabajo se enfoca en la industria textil y de calzado, en virtud de los cuales se busca determinar si las medidas tomadas de carácter transitorio refiriéndose a las restricciones a sus importaciones han cumplido con los jetivos permanentes de la economía nacional, estos son: incremento y diversificación de la producción nacional encaminados a la oferta de bienes y servicios de calidad que satisfagan las necesidades del mercado interno, así como la competitividad de la producción nacional a través de la reducción de los costos de materia prima, insumos y bienes de capital al momento de importar1. Para analizar el impacto económico en cambios de política comercial y verificar si cumple o no con los objetivos del programa económico del gobierno se procede a trabajar con el cálculo de Elasticidades de Sustitución de Importaciones de Armington. Estas elasticidades se computan considerando la demanda de productos extranjeros en comparación con la producción nacional, en donde estos se distinguen no sólo por su tipo sino también por su lugar de origen. Finalmente se incorpora en el análisis los efectos en la recaudación de tributos para evaluar los impactos en el pago de los mismos. Los resultados observados indican que las elasticidades de sustitución entre bienes domésticos e importaciones estimadas, a nivel de clasificación de la tabla Oferta – Utilización determinaron que la sustitución entre estos dos tipos de bienes es baja. Una vez realizada estas estimaciones, se espera proporcionar sugerencias de políticas sobre la continuidad de las analizadas medidas arancelarias, y de ser el caso, identificar posibles alternativas que conlleven a la consecución de los mismos objetivos iniciales. 1 Capitulo 1 (Principios Generales), artículo 243 de la Constitución Política de la República Este documento está dividido en cuatro capítulos, cada uno de ellos con varias secciones. A continuación se da una introducción a la evolución de las políticas arancelarias del Ecuador. Posteriormente se desarrolla, en el primer capítulo, el marco teórico y conceptual las importaciones y sus principales tributos al comercio exterior; se presentan las definiciones de los principales términos utilizados durante todo el trabajo y se discuten los aspectos principales del Modelo de Sustitución de Importaciones. El segundo capítulo muestra los principales hechos estilizados de las importaciones del Ecuador haciendo énfasis en el caso de la industria textil y el calzado. Se exponen cifras y gráficos explicativos sobre la evolución de las importaciones y otras variables que podrían afectarla. En el tercer capítulo se realiza una revisión de la aplicación de barreras arancelarias enfocadas a desarrollar la industria local en otros países. Se citan los casos del Modelo de Sustitución de Importaciones en Colombia, Costa Rica y México. En el cuarto capítulo se presenta la evidencia empírica para el caso ecuatoriano. Se plantea la metodología con que se trabaja para luego mostrar los resultados de la modelación. Posteriormente, se hace la interpretación de los coeficientes obtenidos y se realizan las inferencias requeridas. Finalmente se redactan las conclusiones y recomendaciones de política.\n"}
{"prompt":"Periodismo digital: Tipos de entrevistas en las transmisiones en vivo del medio El Vocero. ->","completion":" Tras la irrupción de la web 2.0, el ejercicio periodístico ha optado por implementar a sus rutinas periodísticas, las bondades de entornos digitales. Las redes sociales brindan herramientas que potencian el proceso comunicativo entre los profesionales de información y las audiencias. En ese sentido, Facebook Live, es la herramienta de streaming más utilizada en el contexto periodístico local de la Provincia de Santa Elena. De modo que, dentro de este proceso de construcción de la información, existe la implementación de la entrevista como técnica periodística para recopilar datos que corrobore o invaliden las opiniones u otros datos. Por lo tanto, este estudio centra su interés en diagnosticar las transmisiones en vivo del medio El Vocero, con la finalidad de desarrollar inferencias respecto a su técnica de entrevista empleada en sus rutinas periodísticas Tras una observación realizada, se evidencia que dentro de las rutinas que ejecuta El Vocero, destacan los temas como: la seguridad ciudadana, economía y espectáculo, del mismo modo que prima el mecanismo de entrevista, pregunta-respuesta, así como cuenta con un tiempo estimado entre 10 a 15 minutos, en consideración a los datos que el periodista quiera obtener.\n"}
{"prompt":"EDUCACIÓN A DISTANCIA Y CALIDAD ÉTICA ->","completion":" Este artículo parte de la conceptualización de la ética en la educación para realizar observaciones sobre el compromiso de la educación del estudiante y la sociedad. ¿Moral y ética, ética y moral conducen a un mismo fin? ¿La libertad de elegir es el camino de la ética? ¿Dónde radica la verdadera ética, en el individuo que creció con una educación en valores y procede por convicción o en el que, en base de controles, recompensas y castigos logra un proceder apegado a la ética? Se establece además el compromiso de la educación a distancia con los principios y postulados de las Constituciones de los países Latinoamericanos, relacionados con la educación de calidad y con los costos que implica acceder a los programas de quienes ofertan esta modalidad de estudios. Un acápite importante es lo referente con la corresponsabilidad ética del tutor-estudiante, toda vez que son los actores directos del proceso pedagógico. ¿Están preparados los estudiantes para acceder a lo que implica ser parte de este tipo de educación que se fortalece en el uso de los medios tecnológicos modernos de comunicación, dando lugar a los estudiantes virtuales? ¿Tienen las destrezas en comunicación oral y escrita que el modelo implica? ¿Los maestros están dispuestos a realizar el proceso de seguimiento, motivación, orientación, acompañamiento, la universidad o centro de estudio remunera a sus profesionales a fin de exigirles un rendimiento de calidad? En base a estas reflexiones, es pertinente a realizar ciertas sugerencias en pro de la educación a distancia, que cada vez se fortalece más en el Ecuador\n"}
{"prompt":"Diagnóstico situacional de la carrera educación inicial modalidad a distancia ->","completion":" Introducción. El problema de la investigacón. Marco referencial teórico legal y conceptual. Marco metodológico. Análisis e interpretación de los resultados. Conclusiones y recomendaciones\n"}
{"prompt":"Educación a distancia en el nuevo entorno tecnocultural ->","completion":" El sistema de \"servicios globales de comunicación multimedial\"\" capaz de transformar el significado de la educación particularmente a distancia. En este artículo se señalan las características e implicaciones de este sistema en lo atinente a la educación a distancia\"\n"}
{"prompt":"La tecnologia dvb-ip orientada hacia la educación a distancia ->","completion":" El presente trabajo trata sobre “La tecnología DVB-IP orientada hacia la educación a distancia”, enfocada a definir un esquema de teleeducación útil y sostenible en el país, con el fin de mejorar la calidad de enseñanza en el sistema público educativo, favoreciendo a los sectores urbanos públicos y además a las zonas rurales tan abandonadas en los últimos años, sabiendo que las herramientas tecnologías son aún deficientes o carentes en muchos centros educativos a lo largo y ancho del territorio nacional. Con los avances tecnológicos en el campo de las telecomunicaciones ha surgido la opción de cambiar la educación a distancia tradicional a través de correspondencia hacia la teleeducación, que consiste básicamente en valerse de un computador para presentar a través de él, todo el contenido necesario para impartir una clase. Y es así que en este estudio se analiza el caso de implementar una red de educación a distancia utilizando la tecnología DVB-IP en su versión satelital, considerando para esto, puntos como número de centro educativos públicos, alumnos, profesores para establecer la cantidad de establecimientos que debe abarcar el sistema, ubicación de los mismos, costos de adquisición de equipos y de operación. Esta opción resulta trascendente debido a que ayudaría a solucionar muchos problemas que arrastra el sistema de enseñanza en el Ecuador, desde una pésima calidad del contenido impartido pasando por falta de docentes, material didáctico, insuficiente control de los padres, y por supuesto serias carencias de herramientas tecnológicas. Y en lo referente a los problemas descritos en el párrafo anterior, la implementación de una red teleeducativa, no sería exclusivamente una alternativa para recibir clases, sino que ayudaría a corregir estas deficiencias gracias a la interactividad que ofrece el uso de este recurso tecnológico. Para lograr los beneficios de esta opción tecnológica, es necesario analizar el marco legal ecuatoriano para definir que opciones de implementación se pueden presentar, y luego formar un esquema factible de ponerlo en marcha en nuestra nación, que sea sustentable.\n"}
{"prompt":"Mitos y mentiras de la educación a distancia ->","completion":" Escribo este artículo motivado por la misma hipótesis que me llevó a publicar \"El Striptease de la Escuela\" (Editorial Pec, San José, Costa Rica) y \"Educación como Praxis Politica\" (Siglo XXI, México) es decir, la hipótesis de que la educación formal está sumida en un atolladero, del que no podrá salir mientras no se comprenda y valore la dimensión socio-política de la educación. En modo alguno la enseñanza a distancia puede ser vista como un proyecto alternativo de educación, por más que muchos autores se esfuercen en proclamarlo a los cuatro vientos. Uno de los libros más recientes sobre el tema: \"Universidad sin clases\" de Casas Armengol es una clara manifestación de ese afán de ver en la \"Educación a Distancia\" una respuesta capaz de atender \"con la rapidez y eficiencia necesarias a las nuevas funciones, roles y alcances\" (Miguel Casas Armengol, \"Universidad sin clases:Educación a Distancia en América Latina\", OEAUNA- Capeluz, Venezuela, 1987) que demandan las urgencias educativas de los pueblos latinoamericanos.\n"}
{"prompt":"Educación a distancia en el nuevo entorno tecnocultural ->","completion":" En 1913, Thomas Edison: consideró que, debido a la invención del cine, en los siguientes diez años el sistema escolar estadounidense se transformaría por completo. Este cambio no ocurrió en forma tan dramática, pero la introducción de la tecnología audiovisual en la educación, desde comienzos del siglo XX, marcó un divisor extraordinario en los sistemas de extensión y educación a distancia, originados en el estudio por correspondencia (Jeffries, 1995). Se trata, pues, de un nuevo entorno tecnocultural que, con el paso de lo analógico a lo digital, convierte a la computadora en el último eslabón de una máquina, porque ya no transforma ni produce objetos, sino trabaja exclusivamente con informaciones: una materia abstracta y simbólica constituida por datos. Y puesto que buena parte del contenido del aprendizaje es información, hoy es preciso concebir el mayor desafío del aprendizaje a distancia como el desarrollo de herramientas multimediales para proveer acceso a dicha información y, a la vez, de aptitudes permanentes de aprendizaje (Gómez Mont, 1995; Voakam, 1996).\n"}
{"prompt":"Mitos y mentiras de la educación a distancia ->","completion":" La educación es un proceso complejo y global que en modo alguno puede ser visto aislado de los procesos económico y político que viven nuestros pueblos. El hombre que pretendemos educar necesariamente está condicionado política, social y económicamente por una sociedad llena de contradicciones. La educación tradicional, por más que se remoce y acicale, es un imposible pedagógico, un despilfarro económico y un engaño y frustración para un alto porcentaje de la población.\n"}
{"prompt":"Estudio sobre los autores e instrumentos de la modalidad a distancia en la Universidad Tecnológica Equinoccial en la carrera de ciencias de la educación a distancia con mención en educación inicial ->","completion":" Introducción. El problema. Fundamentación científica. Marco metodológico. Conclusiones y recomendaciones.\n"}
{"prompt":"Condiciones ergonómicas adecuadas en aulas y oficinas del Colegio Particular a Distancia Stephen Hawking ->","completion":" El Colegio a Distancia Stephen Hawking es una entidad particular, creada con la finalidad de prestar un Servicio Educativo con perspectiva social. Este colegio se fundó el 09 de abril del 2001 y tiene por objeto generar, estudiar, preservar y extender el conocimiento universal y estar al servicio de la sociedad, a fin de contribuir al logro de nuevas y mejores formas de existencia y convivencia humana, y para promover una conciencia universal, humanista, libre, justa y democrática. El Colegio tiene una buena acogida y actualmente cuenta con 2.200 estudiantes, tanto en el ciclo básico como en el diversificado, lo cuales solo asisten una sola vez a la semana. La actividad académica está a cargo de 45 tutores especializados en sus respectivas áreas y 25 personas en el área Administrativa. En lo que respecta a la infraestructura tecnológica, la Institución posee oficinas para su planta administrativa y docente, aulas y laboratorios para la impartición de conocimientos y el desarrollo práctico de las clases, adema cuenta con una biblioteca general, servicio médico odontológico, escuela de danza y deportes. Las oficinas centrales del colegio está ubicado en la Montalvo 0511 y Sucre Esquina, presididas por su máxima autoridad Lic. Mario Morales como rector. Al igual que varias instituciones dedicadas a la educación a distancia el Colegio a Stephen Hawking están en un proceso de mejoramiento constante de su infraestructura y metodologías de enseñanza para brindar la mejor educación a sus estudiantes, y comodidades a sus docentes y personal administrativo. Un mal común y que acoge a todas entidades públicas y privadas de cualquier índole es la forma de trabajo, que da origen a riesgos psicosociales y ergonómicos en todas aquellas personas involucradas de una u otra forma a la institución, principalmente por la desorganización, el inmobiliario nada ergonómico, ruido ambiental derivado principalmente a la circulación de vehículos, circulación y renovación de aire pobre. En el colegio a distancia Stephen Hawking, los docentes y estudiantes asisten una sola vez por semana, pero dichas jornadas son largas y en lugares muy poco ergonómicas por ejemplo: mala iluminación, posturas inadecuadas derivadas del dimensionamiento del inmueble (pupitres, sillas, mesas de trabajo). Los espacios de trabajo son inadecuados en las oficinas puesto que existe muchos elementos colocados en el escritorio y de forma desorganizada lo que provoca situación de angustia y malestar por la incomodidad del sitio, las dimensiones del escritorio no son los apropiados, el espacio para movilizar las piernas es muy pequeño e insuficiente para el oficinista, no existe apoyo para las muñecas y para los antebrazos. Los bordes del escritorio son rectos lo que es contraproducente ya que deben ser redondeados, la altura de la mesa es inadecuada y su profundidad de la misma forma, los colores no son los adecuados según criterios ergonómicos. El ambiente visual de los entornos de trabajo es incorrecto, puesto que no existen contrastes adecuados, la reflexión de la luz es incorrecta, el color del entorno no es el propicio para desempeñar actividades de aprendizaje y tareas de oficina. La iluminación es deficiente y además existe deslumbramientos o brillos que no permiten visualizar bien las pizarras. Todo lo mencionado trae como consecuencia directa la fatiga ocular que hace que el estudiante no rinda y el oficinista presente síntomas de cansancio. Con respecto a la renovación de aire las aulas y oficinas carecen de una apropiada circulación debidas principalmente a una construcción inadecuada el edificio provocando varios síntomas en los estudiantes, docentes y administrativos como lo es cansancio, somnolencia, dolores de cabeza entre otros. A la problemática mencionada se suma además, el ruido y la temperatura que afectan también a las instalaciones por su ubicación y su inapropiada distribución ya que se encuentra junto a zonas transitadas por vehículos.\n"}
{"prompt":"Modelo de educación a distancia para la carrera de relaciones públicas ->","completion":" INTRODUCCION. MARCO TEORICO. INV4ESTIGACION DE CAMPO. ANALISIS SITUACIONAL DE LA CARRERA DE RELACIONES PUBLICAS. PROPUESTA DE EDUCACION A DISTANCIA. CONCLUSIONES Y RECOMENDACIONES.\n"}
{"prompt":"El desarrollo individual y social a partir de la educación popular a distancia Susudel ->","completion":" Estudia los aspectos fundamentales del sistema educativo del Instituto Radiofónico Fe y Alegría IRFEYAL, su historia, estructura, actividades docente y administrativa y su organización personal, centrándose el análisis en el centro educativo José María Velaz Susudel. Finalidad, métodos y técnicas de trabajo en la educación popular; analiza la influencia que tiene en los educados, en sus familias y comunidad; las alternativas económicas de los egresados y establece conclusiones y recomendaciones para el desarrollo de la educación popular a distancia ofrecida por el IRFEYAL.Licenciado en Ciencias Políticas y SocialesCuenca\n"}
{"prompt":"Perfil de un profesor del área de matemáticas para la modalidad de educación a distancia en la Unidad Educativa Fiscomisional a distancia de Loja Hermano Ángel Pastrana Corral ->","completion":" CAPITULO I. El problema de investigación. CAPITULO II. Marco teórico. CAPITULO III. Metodología de la investigación. CAPITULO IV. Presentación de resultados. CAPITULO V. Conclusiones y recomendaciones. CAPITULO VI. La propuesta. BIBLIOGRAFIA.\n"}
{"prompt":"Propuesta del diseño curricular de la carrera de ciencias de la educación con mención en educación parvularia modalidad a distancia ->","completion":" Introducción. El problema de la investigación. Marco referencial teórico y conceptual. Marco metodológico. Análisis e interpretación de resultados. Conclusiones y recomendaciones.\n"}
{"prompt":"Estudio de factibilidad para la creación de un Colegio a distancia en la ciudad de Quito ->","completion":" El presente trabajo de investigación denominado “Proyecto de Factibilidad para la Creación de un Colegio a Distancia en la Ciudad de Quito” responde a contenidos técnico – administrativos, que son analizados mediante una problemática de orden social, en la que se encuentra afectado de manera general nuestro País, sin duda se habla de uno de los sectores más importantes, como lo es el educacional, para lo cuál se busca alternativas efectivas que permitan la democratización de la educación y que solventen las necesidades de un gran grupo humano que se encuentra marginado de este servicio por falta de tiempo, recursos económicos, etc., a través de la impartición de una enseñanza que esté encaminada hacia las nuevas exigencias del nuevo milenio, y considerando que la educación a distancia o autoeducación, es el comienzo de la nueva formación del futuro. Sobre la base de tal problemática y ante la búsqueda de alternativas que se conviertan en problemas solucionables, se ha planteado la siguiente interrogativa: ¿Cómo se puede ofrecer una Educación a Distancia, a la población que ha desertado en las aulas, para crear la oportunidad de mejorar su calidad de vida y resolver los problemas socio – económicos que afectan a la comunidad educativa? Por lo que para la satisfacción de dicha incógnita se hace necesario realizar un estudio de factibilidad profundo, tomando en cuenta como primer punto a la base principal que es la sociedad inmiscuida en tal situación, y en segunda instancia al contexto administrativo, a través del planteamiento de objetivos realizables, que demuestren y permitan la ejecución de dicho proyecto y así poder dar respuesta a las necesidades reales de la sociedad.\n"}
{"prompt":"Educación a distancia a través de la utilización de las nuevas tecnologías en telecomunicaciones ->","completion":" Se realiza el análisis técnico, diseño y evaluación económica de un sistema de telecomunicaciones necesario para un sistema de teleeducación dentro del cantón Cuenca. Se realiza un análisis de los diferentes tipos de aulas virtuales que se pueden construir dependiendo del equipamiento que a estas se las dé. Se evalúan alternativas para el sistema de telecomunicaciones, se realiza el diseño y valoración económica total de estas opciones. Se analizan 3 opciones: La de utilizar sistemas existentes en nuestro medio (ETAPA), la segunda es la de contar con un sistema a través de enlaces a microonda y la tercera mediante radio enlaces satelitales. Como conclusión, se observa que la alternativa más adecuada para implementar este proyecto es la de utilizar enlaces de radio microonda, pues este cubre el mayor número de poblaciones y además con inversiones adicionales pequeñas puede ser ampliado. Se muestra que este proyecto cubre su costo en 20 años debido al ahorro generado al disminuir el número de profesores necesarios en cada escuelaIngeniero EléctricoCuenca\n"}
{"prompt":"Diplomado a distancia, un entorno virtual para la educación ambiental en la carrera de medicina. ->","completion":" Se realiza una investigación cualitativa en la Facultad de Ciencias Médicas ‘’10 de Octubre’’, para caracterizar el proceso de trabajo para la educación a distancia en entorno virtual para la educación ambiental en la carrera de Medicina. Se emplearon métodos del nivel teórico, empíricos y estadísticos. Entre los métodos del nivel teórico se utilizaron el análisis documental, como eje de la investigación, para profundizar los conceptos esenciales, desde enfoques y contextos diferentes, el método histórico – lógico, el de análisis-síntesis, el hipotético–deductivo, así como el empleo de técnicas cualitativas como la revisión documental y la encuesta. Se partió de materiales concebidos de forma impresa que luego se adaptaron a materiales hipertextuales; se respetó la división de temas como partes independientes, a partir de establecer relaciones entre ellos. Se crearon temas didácticos que facilitan el aprendizaje, así como espacios donde ubicar todos los materiales complementarios y para el trabajo colaborativo. El seguimiento de la participación de los estudiantes se llevó por el registro de ingresos al entorno virtual empleado como bibliografía básica en los temas de educación ambiental. La calidad de la información que brinda la enseñanza a distancia de la educación ambiental contribuye al desarrollo de la independencia cognoscitiva de los estudiantes de la carrera de Medicina, la selección y empleo de materiales, el control y la evaluación del aprendizaje.\n"}
{"prompt":"Tecnología informática aplicada a la educación a distancia. Aplicativo: prototipo de aula virtual ->","completion":" El desarrollo de las redes telemáticas (informática + telecomunicaciones) y el crecimiento de la \"red de redes\" que representa INTERNET están incidiendo en todos los campos de la sociedad y demandando de ella el replanteamiento de las actividades y sus relaciones .La evolución de la educación en el Ecuador.- Multimedia aplicada a la educación virtual, multimedia, hipermedia.- Soluciones al problema de la última milla, estudio de la tecnología XDSL, funcionamiento.- Recursos de las redes multimedia y que seguridades aplicar, funcionamiento, interoperabilidad, compatibilidad y confiabilidad.- La videoconferencia, elementos básicos de un sistema de videoconferencia.- Base de datos y lenguaje de programación, análisis de los lenguajes de programación para la web, estudio de motores de base de datos.- Desarrollo de prototipo.- Integración de la información.- Desarrollo de los módulos del sistema prototipo VirEdu.\n"}
{"prompt":"Desarrollo local y formación de actores locales caso de la Fundación Educativa Monseñor Cándido Rada (FUNDER-GS FEPP) ->","completion":" El Área de Formación Tutorial (o a distancia3) de FUNDER, ofrece cursos en temáticas relacionadas con el Desarrollo Local. En la actualidad cuenta con cinco cursos a distancia de los cuales están abiertos tres (Economía Solidaria, Gestión para el Desarrollo Local I, y Gestión para el Desarrollo Local II), los mismos que engloban aproximadamente 150 estudiantes alrededor del país. Hasta el momento no ha habido una propuesta de formación construida en base a las opiniones de los estudiantes y facilitadores, por lo cual se considera importante conocer las opiniones, necesidades, intereses y expectativas de los estudiantes y ex estudiantes, así como las opiniones y propuestas de los facilitadores (o responsables de sedes), de manera que se pueda realizar una nueva propuesta de formación en desarrollo local que sea integral, participativa y sostenible, y que mejore los procesos de formación a distancia actuales. Por lo tanto, el propósito de esta investigación es conocer las opiniones, necesidades, intereses, expectativas de los estudiantes y ex estudiantes de los cursos de formación a distancia de FUNDER, así como las opiniones y propuestas de los facilitadores de dichos procesos de formación. Esto permitirá aportar a la construcción de una propuesta de formación a distancia que sea integral, participativa y cuyos resultados sean sostenibles.\n"}
{"prompt":"Modalidad de educación a distancia para el bachillerato en la especialidad de agroindustrias en el colegio fiscal mixto \"Dr. José María Velasco Ibarra\" del cantón Buena Fe ->","completion":" El presente proyecto de tesis aquí descrito es de nuestra autoría, no ha sido previamente presentado para ningún grado o calificación profesional, y hemos consultado las referencias bibliográficas que se incluyen en este documento. La Universidad Regional Autónoma de los Andes, UNIANDES, puede hacer uso de los derechos correspondientes a este trabajo, según lo establecido por la Ley de Propiedad intelectual, por su reglamento y por la normativa institucional vigente. El Colegio Particular ―Dr. José María Velasco Ibarra‖ empieza con el Acuerdo Ministerial 1387 a partir del año 1969 – 1970, iniciándose con el Primer Curso, de acuerdo a su rol protagónico que desempeña dentro de su área de influencia, con las opciones prácticas de: Agropecuaria, Comercio y Administración y Manualidades Femeninas. Dentro de los rasgos históricos del colegio ―Dr. José María Velasco Ibarra‖, al paso de tres años de servicio a la juventud estudiosa como colegio particular, se necesitó revitalizarlo a fin de que su proyección tuviera un mayor radio de alcance, entonces una alternativa fue consolidar la unidad de los alumnos, maestros y padres de familia, para solicitar al Estado la nacionalización del colegio, aspiración que se cristalizó mediante Decreto Supremo el 29 de Mayo de 1972. Con la nacionalización del plantel se inició una nueva etapa de vida institucional, dándose ahí las condiciones para su desarrollo en todos los aspectos del quehacer educativo, se dio apertura al ciclo básico. Mediante acuerdo No. 1306 del 25 de Abril de 1974, se autoriza el funcionamiento del primer curso diversificado de Comercio y Administración, por dos años lectivos: (1974 – 1975 y 1975 – 1976). El proyecto tiene la virtud de ser elaborado de acuerdo a la realidad del medio, y los docentes serán los mismos profesores que dictan sus clases en la modalidad de educación regular en el colegio. Se ha tomado en cuenta el aspecto teórico como el práctico. Las habilidades y competencias que los estudiantes adquieran serán suficientes para desenvolverse en el campo productivo.Hoy la educación en nuestro país asiste a un nuevo reto con la sociedad, con la ciencia, con la humanidad. Está consciente de que si no hay avance científico no habrá producción, no habrá generación de alimentos, de energía, de trabajo, no habrá desarrollo económico, de cultura, en fin no habrá prosperidad. El colegio fiscal mixto ―Dr. José María Velasco Ibarra‖ del cantón Buena Fe, no cuenta con el bachillerato en Agroindustrias en la Modalidad a Distancia, limitando por cierto la formación académica de jóvenes y adultos que laboran en el sector agropecuario y desean continuar con sus estudios. Por tal motivo se plantea, ¿Cómo proporcionar una nueva oportunidad de estudio a jóvenes y adultos de la comunidad del cantón Buena Fe que se hayan desvinculados del sistema regular de educación? El resultado de esta investigación, sin dudarlo, beneficiará en forma directa a todos los jóvenes y adultos que requieren formación profesional en el bachillerato de Agroindustrias en la Modalidad a Distancia, los cuales podrán ser profesionales eficientes y eficaces en sus actividades que les tocará desempeñar. Para la ejecución del bachillerato en Agroindustrias en la modalidad a Distancia el colegio fiscal mixto ―Dr. José María Velasco Ibarra‖ del cantón Buena Fe‖ cuenta con el personal docente capacitado y una buena infraestructura física.\n"}
{"prompt":"Los entornos virtuales y su implicación en la deserción de los sistemas a distancia ->","completion":" Al no existir cambios, evidencia de necesidades y limitaciones en el sistema educativo de un país, como el incremento de los índices de deserción que se presentan en los entornos virtuales a distancia, aunque no se trata de establecer un ranking de aspectos causantes en la deserción que se registra en un entorno virtual, no cabe duda que los sistemas de educación a distancia virtual han experimentado cambios en las últimas décadas, hacia la heterogeneidad, multiculturidad, diversidad de contextos familiares; aspectos asociados con la ciudadanía, experiencias vitales, que marcan cognitiva, conductual y emocionalmente a los educandos.Los Sistemas de Educación a Distancia tuvo como objetivo analizar las causas y factores de la deserción estudiantil en la educación a distancia durante el 2016 del semestre B de Ingeniería en Administración Turística y Hotelera. El documento corresponde a una investigación científica descriptiva, cuyo proceso sistemático parte desde la selección del tema y análisis de los resultados. La población estuvo constituida por directivos (4,9%), tutores\/asesores (6,8%) y estudiantes (88,3%) de la carrera, aplicándose encuestas tipo cuestionario, para determinar las causas que generan la deserción estudiantil. Concluyéndose que esta se debe a: lo académico, socioeconómico, procesos de evaluación, estrategias andrológicas y compromiso de los participantes, estos últimos asumen con disciplina y técnicas que permite organizar tiempo, espacio y otras actividades, recomendándose a las autoridades de la institución, que estén prestos a reorientar la praxis académica, apoyándose mediante políticas que permitan al estudiantado continuar con los estudios a distancia y evitar la deserción, que es un problema social.As there are no changes, evidence of needs and limitations in the educational system of a country, such as the increase in dropout rates that occur in remote virtual environments, although it is not a matter of establishing a ranking of aspects causing dropout Since it is recorded in a virtual environment, there is no doubt that virtual distance education systems have undergone changes in recent decades, towards heterogeneity, multiculturalism, diversity of family contexts; Aspects associated with citizenship, life experiences, that cognitively, behaviorally and emotionally mark students. The Distance Education Systems aimed to analyze the causes and factors of student dropout in distance education during the 2016 semester B of Engineering in Tourism and Hotel Administration. The document corresponds to a descriptive scientific investigation, whose systematic process starts from the selection of the topic and analysis of the results. The population was made up of managers (4.9%), tutors \/ advisers (6.8%) and students (88.3%) of the career, applying questionnaire-type surveys to determine the causes that generate student dropout. Concluding that this is due to: academic, socioeconomic, evaluation processes, andrological strategies and commitment of the participants, the latter assume with discipline and techniques that allow organizing time, space and other activities, recommending to the authorities of the institution, that be ready to reorient academic practice, supported by policies that allow students to continue their studies at a distance and avoid dropping out, which is a social problem. Palabras\n"}
{"prompt":"Diseño de un algoritmo predictivo para el análisis de disponibilidad de canales y el uso eficiente de sistemas con acceso oportunista al espectro basado en el modelo k-vecinos más cercanos ->","completion":" Este estudio se basó en un análisis en la banda wifi de 2.4GHz con datos reales tomados en un transcurso de 10 días, dentro de un edificio en tres diferentes pisos, 1, 9 y 16 respectivamente, ubicado en una zona urbana. Se convirtieron los datos de potencia a datos binarios, obteniendo los canales disponibles y no disponibles para así realizar la agrupación de n canales conjuntos. El método K-vecinos más cercanos, considerado un método de aprendizaje que clasifica los datos recordando los datos anteriores llamados entrenamiento, cada vez que un nuevo dato se presenta al sistema, este lo clasifica de acuerdo al comportamiento del dato más cercano. La cercanía de los vecinos se define en base a los atributos del dato y de los de entrenamiento, el algoritmo calcula la distancia entre los atributos.GuayaquilIngeniero en Electrónica y Telecomunicaciones\n"}
{"prompt":"Estudio de la percepción del umbral de olor mediante relaciones cuantitativas estructura -propiedad ->","completion":" Este trabajo desarrolló un modelo predictivo in silico para el umbral de olor de 176 compuestos orgánicos volátiles (VOCs) basado en una relación cuantitativa estructura-propiedad (QSPR). Las moléculas se optimizaron mediante el método semiempírico PM3 para calcular 5440 descriptores moleculares en el programa alvaDesc. Inicialmente, se usó el método V-WSP para la reducción de descriptores. Posteriormente, el conjunto de datos se dividió en grupos de calibración (70%) y predicción (30%). Los compuestos se dividieron en moléculas de alto y bajo poder odorante para modelarlos mediante el método de clasificación kNN (k-vecinos más cercanos) acoplado con los algoritmos genéticos (GAs). Se obtuvo un modelo con 2 descriptores y 5 vecinos cercanos, utilizando tasa de aciertos en calibración (NERcal = 0.75), validación cruzada (NERcv = 0.75) y predicción (NERpred = 0.78). El modelo se desarrolló con los principios de la Organización para la Cooperación y el Desarrollo Económico (OCDE) para hacerlo aplicable.Ingeniero en Alimentos\n"}
{"prompt":"Clasificación vía aprendizaje automático de conformaciones moleculares en estructuras teloméricas ->","completion":" Un gran número de estudios han sido publicados en el área de pequeñas moléculas unidas a secuencias teloméricas que se pliegan en estructura no convencionales de AD denominadas estructuras G- Cuádruple. El estudio de estas estructuras ha sido motivado por su potencial utilidad como blancos para desarrollo de fármacos. Además, las estructuras G- Cuádruples han sido identificadas en otras secuencias de importancia a lo largo de todo el genoma. Dentro de los diversos estudios se han utilizado dos modelos: la secuencia telomérica humana y las secuencia telomérica el Oxytricha, Tetrahymena. Ambos han sido empleados como modelos para estudios computacionales y ensayos in vitro. Aquí estudiamos la trayectoria generada a partir de las simulaciones de dinámica molecular atomística para obtener la cantidad de flexibilidad y movilidad de estas estructuras modelos. Utilizamos herramientas de clasificación (es decir, método del vecino cercano k) y minería de datos. Encontramos las conformaciones más pobladas y discutimos los hallazgos estructurales.A great number of studies have been published on the area of small molecules bound to telomeric sequences that fold on a non-cannonical DNA structure known as G-quadruplex structure. The study of these structures has been driven for its potential as targets for drug development. Furthermore, G-quadruplex structures have been identified in other sequences of importance through all the genome. Within the different studies two main models have been used: the human telomeric sequence and the oxytricha, tetrahymena telomeric sequence. Both cases are used as models for computational studies and in vitro essays. Here we study the trajectory generated from an atomistic molecular dynamic simulation to obtain the amount of flexibility and mobility of these model structures. We used data mining and classification tools (i.e. k nearest neighbor method) to identify automatically subpopulations of structures within the simulation. We found the most populated conformations and we discuss the structural findings.Cuencanúmero especial\n"}
{"prompt":"Comparación química de suelos en distintas coberturas vegetales del PNC mediante métodos de clúster análisis ->","completion":" La vegetación y el suelo son indicadores importantes de la salud del páramo. La capa vegetal del páramo es importante para la protección del suelo y como hábitat para la fauna nativa (Hofstede et al., 2003). La evaluación de las características del suelo requiere medir sus propiedades físicas y químicas. El Parque Nacional Cajas (PNC) es uno de los principales suministros de agua para la ciudad de Cuenca, puesto que sus suelos retienen grandes cantidades de líquido vital, especialmente el páramo de almohadillas; los suelos del pajonal resultan importantes en el secuestro de carbono atmosférico, mientras que los suelos de los bosques de Polylepis y bosques alto-andinos originan ecosistemas únicos evidenciado en un alto endemismo presente en el PNC; razón por lo cual el estudio de las características físico químicas del suelo resulta importante en la investigación de las interacciones sustrato-vegetal. El análisis de conglomerados o clúster es una técnica de análisis exploratorio de datos que permite descubrir asociaciones y estructuras en los datos que no son evidentes a priori,ordenando objetos en grupos de asociación\/similitud de forma que los objetos de un mismo grupo sean muy similares entre sí,y los objetos de clústeres diferentes sean distintos (Figueras, 2001). El método KNN o k-Nearest Neighbors, basado en el reconocimiento de patrones de criterios de vecindad. Parte de la idea de que una nueva muestra será clasificada a la clase a la cual pertenezca la mayor cantidad de vecinos más cercanos del (reconocimiento de patrones patrón) del conjunto de entrenamiento más cercano a esta (Figueras, 2001). El objetivo general de este estudio es investigar las relaciones entre las características químicas del suelo (Ca, Mg, Fe, K, Na, pH, conductividad, nitrógeno total, fósforo, y materia orgánica) y el tipo de coberturas vegetales presentes en el PNC (páramo de pajonal,páramo de almohadilla, bosque de Polylepis y bosque altoandino), mediante métodos de análisis clúster y clasificación KNN.\n"}
{"prompt":"Diseño del plan de distribución y almacenaje de inventario por métodos heurísticos en la empresa Giant Ibarra ->","completion":" Diseñar el plan de distribución y almacenaje de inventarios por métodos heurísticos en la empresa GIANT IBARRA con el fin de reducir los costos logísticos.La empresa GIANT IBARRA al no aplicar una organización sistemática, sino más bien una organización empírica, afectan tanto en su funcionamiento como en su economía encontrando como su principal problema algunos de los costos logísticos elevados. Por lo tanto, se analizó la distribución del inventario dentro de la empresa incluyendo la rotación que ha tenido cada producto dentro de un año, también se analizó el control de inventarios con sus respectivos costos de compra, costos de mantenimiento, costos de ordenar e incluso el costo de oportunidad. Una vez resuelta la distribución con una clasificación ABC de inventarios apoyándose con el índice de rotación, se realizó el pronóstico de los productos más importantes para la empresa que son los productos de clasificación A y B. El pronóstico se realizó con un historial de tres años mediante redes neuronales y vecinos más cercanos, con el fin de comparar sus raíces de errores medios cuadrados y elegir el pronóstico con menor error. Luego, se calculó el coeficiente de varianza para decidir el método de manejo de inventarios, en este estudio se los realiza por métodos heurísticos como: Silver Meal (SM) y el algoritmo de Wagner Whitin (WW), con el objetivo de recudir costos de inventarios. Donde la mejor opción fue el algoritmo de Wagner Whitin con un ahorro del 53,14%, es decir, $31 269.67 mil dólares ahorrados al año.Ingeniería\n"}
{"prompt":"Descripción de las secuelas emocionales en familiares de las víctimas de femicidio en Manabí ->","completion":" El Femicidio es la consecuencia más extrema de la violencia contra la mujer. Estudios de diferentes autores y testimonios de allegados a las víctimas permiten establecer que los efectos de este tipo de sucesos repercuten en el entorno más cercano. La no existencia de una caracterización de las secuelas emocionales en los allegados de las víctimas de Femicidio en Manabí agudiza el panorama de este problema social en esta provincia. Se describen las principales secuelas emocionales que afrontan familiares de las víctimas de Femicidio en Manabí. Se recopilaron testimonios de familiares y vecinos de las víctimas de Femicidio en Manabí, así como de autoridades que conocen del tema, se utilizó la revisión bibliográfica de artículos científicos relacionados con el tema. Se aplicaron métodos y técnicas de investigación cualitativos como análisis de la violencia de género y las secuelas que ésta ocasiona en el seno familiar. Las consecuencias de la violencia de género afectan no sólo a la pareja, sino también a su círculo más cercano ocasionando secuelas que repercuten de distintas maneras en madres, padres, hijos, hermanos, tíos, primos, vecinos y sociedad que ha sido testigo o conocido del delito. Los afectados presentan problemas emocionales, dificultad para adaptarse a los cambios, sentimientos de culpa, baja autoestima, depresión, signos de agresión y actitudes de aislamiento.  Se hace necesario que el Estado ecuatoriano intervenga con políticas no sólo de investigación, sino también de apoyo a familiares de las víctimas.\n"}
{"prompt":"Desarrollo de un sistema de información dss para el ruteo de vehículos ->","completion":" Las organizaciones cada vez más están tomando conciencia de la importancia de una buena gestión de su logística, y el enrutamiento de vehículos es una parte importante dentro de esta gran tarea. Con esa motivación, el objetivo principal de esta tesis es desarrollar un sistema de información DSS para el ruteo de vehículos, que además tenga la ventaja de operar en el web, y de ofrecer una interfaz gráfica de usuario muy amigable y fácil de usar. Actualmente se conoce muchísimo respecto del enrutamiento de vehículos. Existen métodos exactos y métodos inexactos. El inconveniente de los primeros es que a pesar de que proporcionan la solución óptima del problema, cuando el número de puntos a visitar es del orden de las decenas o peor aún, de las centenas o más, la tecnología de los computadores actuales NO permite encontrar la ruta óptima en un tiempo razonable. Por el contrario, los métodos inexactos nos permiten obtener en un tiempo adecuado y viable, sino la solución óptima, una “buena” solución, pero son más complicados de implementar. Existen muchos tipos de problemas relacionados con el ruteo de vehículos. El problema que se escogió para esta tesis es el CVRP simétrico. Se tienen n puntos distribuidos sobre un plano (por ejemplo ubicaciones en una ciudad). El problema a resolver consiste en determinar el orden en que se deben ir visitando cada uno de los n puntos de forma tal que se pueda minimizar, por ejemplo, la distancia recorrida o el tiempo de viaje. El objetivo es que el tomador de decisiones de la empresa, por ejemplo un gerente de transporte, pueda administrar de manera óptima el enrutamiento de sus vehículos. Se desea resolver el problema haciendo uso de heurísticas (algoritmos glotones) y metaheurísticas (algoritmos evolutivos). Una heurística importante a usar será la del “vecino más cercano”. Para las metaheurísticas se desea considerar algoritmos evolutivos, más precisamente, el algoritmo de búsqueda dispersa (scatter search). La única fuente de datos a la que se va a recurrir es la que proporciona GOOGLE EARTH en cuanto a las coordenadas geográficas de un punto terrestre, es decir, longitud y latitud de un punto cualquiera sobre el planeta tierra. Para medir la distancia entre puntos se usará la “métrica euclidiana” y la conocida “métrica del taxi”, pero previamente se deben transformar las coordenadas geográficas a coordenadas UTM, antes de proceder a calcular la distancia entre dos puntos. Existen muchas metaheurísticas, entre ellas: el algoritmo genético, la búsqueda tabú, el recocido simulado, GRASP, que pueden utilizarse, junto con heurísticas, para resolver problemas de optimización. “Búsqueda dispersa” es también un método metaheurístico que se puede emplear para resolver problemas de optimización y forma parte de los algoritmos evolutivos. Tiene sus orígenes en los años setenta, pero es en la última década cuando ha sido rediseñado y probado en muchos problemas con un alto grado de dificultad y con excelentes resultados. Esta es la principal razón por la cual se escogió el método de búsqueda dispersa para resolver el problema de transporte antes explicado. Otro objetivo de esta tesis es hacer un estudio profundo de cada una de las etapas de la metaheurística de búsqueda dispersa. En el primer capítulo se presentan conceptos y definiciones que serán importantes para las cuestiones que se analizan y se discuten en los capítulos posteriores. Luego, en el segundo capítulo, se muestra en primer lugar cómo trabaja en general la metaheurística de búsqueda dispersa cuando intenta resolver un problema de optimización, para posteriormente explicar con todo detalle cómo se ha utilizado la búsqueda dispersa para resolver puntualmente el problema del CVRP simétrico. Se discuten asuntos de diseño e implementación. El tercer capítulo muestra el software, las opciones que presenta al usuario, y experimentos computacionales con datos reales tomados de la ciudad de Guayaquil. Se concluye este documento de tesis con las correspondientes conclusiones y recomendaciones sobre todo el trabajo realizado.\n"}
{"prompt":"Diseño de un modelo de distribución para una empresa courier localizada en guayaquil mediante la aplicación de un modelo cvrptw ->","completion":" La empresa, objeto de estudio, se dedica a ofrecer el servicio de mensajería o Courier en la ciudad de Guayaquil. Al notar que la demanda crece, al igual que las exigencias de sus clientes, han decidido ser más competitivo en el mercado, otro motivo es la disminución en la cantidad de clientes en los últimos tres años, motivo por el cual desea implementar entregas con ventanas de tiempo y un indicador de desempeño para evaluar su desempeño. Actualmente, su modelo de entrega consiste en la distribución de los sobres o valijas corporativas de forma diaria, presentándose problemas al momento de llegar a su destino, debido a que el cliente no se encuentra en el sitio, o no pueden recibir el producto en ese momento. Actualmente organizan la bitácora de entrega utilizando el método del vecino más cercano en forma empírica.GuayaquilINGENIERO EN LOGÍSTICA Y TRANSPORTE\n"}
{"prompt":"Dinámica caótica de series temporales hidrometeorológicas del sistema hidrográfico del río Tutanangosa para el diseño del sistema de agua potable para las comunidades Bellavista y La Florida, parroquia Huambi ->","completion":" Las comunidades Bellavista y La Florida se encuentran ubicadas en la zona rural de la parroquia de Huambi, provincia de Morona Santiago. A pesar de que el río Arapicos se ubica en las inmediaciones de ambas comunidades, estas no se abastecen del agua disponible en su cuenca, por lo que se cree conveniente proponer un sistema de dotación complementario. Los proyectos relacionados al recurso hídrico parten del estudio de las variables hidrometeorológicas que influyen en la cuenca y tradicionalmente le metodología utilizada para su estudio es de naturaleza lineal, lo cual deja de lado el comportamiento dinámico de las variablespor lo que es necesario ampliar su estudio mediante la incorporación de técnicas no lineales. En este proyecto de titulación se estudiaron las variables hidrometeorológicas, precipitación, caudal, temperatura y humedad, cuyos registros se recopilan a través de estaciones pertenecientes al INAMHI y la Dirección de Protección Ambiental de Morona Santiago. Las series de datos fueron rellenadas mediante el método de refresión lineal y el método del promedio diario; y validadas utilizando la prueba de rachas, curva de doble masa y t de Student. Con el fin de buscar algún indicio de caos en las series temporales y estudiar su comportamiento dinámico, se aplicó técnicas de medida del caos sobre las variables antes mencionadas utilizando el software R. Las técnicas que se utilizaron fueron: distribución de probabilidades e histogramas, función de autocorrelación, falsos vecinos más cercanos y mapas recurrentes. Finalmente mediante el análisis de recurrencia cuantitativa se distinguió que las series utilizadas no presentan un largo período de ocurrencia, es decir, no son series deterministas. Por otro lado, se determinó la calidad y cantidad de agua y se propuso el diseño del sistema de agua potable, el mismo que cuenta con un sistema de captación tipo Coanda, conducción y almacenamiento; para así garantizar el abastecimiento de agua potable a las comunidades Bellavista y La Florida para un período de vida útil de 20 años.\n"}
{"prompt":"Evaluación de la exactitud posicional horizontal e inferencia de la escala sobre datos libres OSM en administraciones zonales del DMQ ->","completion":" OpenStreetMap es probablemente el proyecto de Información Geográfica Voluntaria más importante; sin embargo, su naturaleza colaborativa pone en duda aspectos de su calidad. Este problema se ha abordado en otras regiones, mas no en Ecuador; el presente trabajo pretende motivar tales investigaciones, iniciando con el aspecto posicional. La zona de estudio fueron varias Administraciones Zonales del Distrito Metropolitano de Quito. Dos métodos para calcular la exactitud posicional horizontal fueron implementados: el primero relaciona intersecciones viales en OpenStreetMap con sus equivalentes oficiales a través de los nombres; el segundo, a través de la búsqueda del vecino más cercano. Mientras que el primer método produjo escasos resultados y valores atípicos, el segundo se desempeñó mejor pero impuso un límite al error calculado. A continuación se calcularon las versiones local y global del estadístico Getis-Ord, con el propósito de evaluar la autocorrelación espacial. Fueron halladas escasas agrupaciones de errores pequeños, pero abundantes de errores grandes; las vecindades con tales errores fueron homogeneizadas con el propósito de incrementar su importancia. Después de esta corrección fue inferida la escala a la cual pertenecería cada intersección, generando polígonos de Voronoi. Finalmente, se discutieron las oportunidades y limitaciones de la vialidad OpenStreetMap en las zonas estudiadas.\n"}
{"prompt":"“optimización del sistema de ruteo vehicular en la distribución de los productos y creación de un sistema de información para el área de ventas de una empresa farmacéutica en la ciudad de Milagro” ->","completion":" Este trabajo estudia el sistema de gestión para la atención de los requerimientos formulados en los pedidos de los clientes y la distribución de los medicamentos que realiza una empresa farmacéutica en la ciudad de Milagro. Del análisis de la información obtenida, se puede afirmar que tiene un sistema deficitario de registro y gestión en la distribución de los pedidos de los clientes. Por lo indicado, el presente proyecto busca solucionar estos problemas, con la utilización de dos métodos que procuran una optimización en los sistemas de información y de ruteo vehicular. Respecto a la recopilación de datos, se plantea un sistema eficaz y eficiente de registros, debidamente organizado, que garantiza el mantenimiento y actualización de toda la información de los clientes, como datos personales, cambios de dirección, y los pedidos. Además, sirve para que el personal del área de Ventas pueda realizar consultas, así como para optimizar el recorrido de la distribución de productos a partir de la aplicación del modelo VRPTW (Vehicle Routing Problem with Time Windows) que permite obtener primero el ruteo inicial con la aplicación de la heurística del vecino más cercano y después de la metaheurística del Recocido Simulado.\n"}
{"prompt":"Análisis de la variación de las ventas de un bar-restaurant mediante un estudio cuasi-experimental de modificación del signo de dólar en el precio, tomando en cuenta la situación de compra, la situación de uso, tipo de cliente y variables demográficas. Aplicado en el bar-restaurante Balcón Quiteño ubicado en la Ordoñez Laso de agosto del 2014 a septiembre del 2014 ->","completion":" Esta investigación busca comprobar si la modificación del signo de dólar en el menú de un restaurante provoca cambios en las ventas. El método para este estudio fue cuantitativo y por medio de encuestas se levantó la información, se realizó un total de 459 encuestas y así con el programa STATA realizar el análisis PSM (Propensity Score Matching) y el análisis descriptivo de cada variable. El método Matching realiza un análisis del PSM el cual trata que coincida cada participante con un no participante similares y luego medir la diferencia media en la variable resultado entre los dos grupos, luego se comprueba si el PSM es válido, calculando un peso para cada conjunto de participantes y no participantes y ver que estén igualados, se usó las pruebas del vecino más cercano, coincidencia de radio, Kernel y robustez, para observar si los resultados son consistentes y conocer si hubo cambios significativos en las ventas del grupo de control vs el de tratamiento. Los resultados arrojaron que estarían dispuestos a pagar hasta $1,27 más en promedio por persona cuando no existe el signo de dólar, es decir se presume que al eliminar el signo de dólar del menú hace que las personas a nivel cognitivo perciban que el producto no es tan costoso y así éstos estén dispuestos a consumir más por cualquier producto que esté por encima de su limen de percepción.This research seeks to verify if the modification of the dollar sign on the menu of a restaurant provokes changes in sales. The method for this study was quantitative and all the information was collected through surveys, a total of 459 surveys were held and thus, with the assistance of the STATA program, the PSM analysis (Propensity Score Matching) and descriptive analysis of each variable were carried out. The Matching method performs an analysis of the PSM, which tries to match each participant with a similar non-participant and then measure the average difference in the variable obtained as a result between the two groups, then the method checks if the PSM is valid, calculating a weight for each set of participants and non-participants to check if they’re leveled. The nearest neighbor test was performed, as well as the matching radius, Kernel and sturdiness estimators, to see if the results are consistent and if significant changes in the sales of the control group vs. those of the treatment group were obtained. The results showed that they are willing to pay up to $1.27 more on average per person when there is no dollar sign on the menu. It is thought that by eliminating the dollar sign from the menu, on a cognitive level, people start believing that the product is not so costly and so, they are willing to spend more on any product that is above their limen for perception.Ingeniero en MarketingCuenca\n"}
{"prompt":"Modelos de alerta temprana para pronosticar crisis bancarias en Ecuador ->","completion":" PDFEn el Ecuador no se han publicado trabajos de EWS para el sistema bancario, a junio del 2017. Por lo que se propuso encontrar el mejor método de clasificación de bancos en riesgo de quiebre en el sistema bancario ecuatoriano. Se usó el algoritmo Vecino Más Cercano “K-NN” para los datos faltantes y para la clasificación: Mínimos Cuadrados Parciales Discriminantes “PLSD”, Support Vector Machine “SVM” y Árbol de Clasificación (CART). El método PLSD alcanzó una clasificación global del 94.99% y una clasificación de bancos quebrados (18 meses antes de su cierre) del 18.89%. Los bancos que no quiebran tienen altos ratios en eficiencia financiera, margen de intermediación, resultados de ejercicios y cobertura de 100 mayores depositantes. Mientras los bancos que quiebran, tienen altos niveles de morosidad, vulnerabilidad del patrimonio, cartera improductiva y gastos operacionales. El Árbol de clasificación CART arrojó un buen modelo de clasificación, dando un 99.72% de clasificación global y 92.59% de bancos quebrados. Además, nos da información de las variables que mejor discriminan, bajo qué condiciones y nos indica el porcentaje de la población que se encuentra en dicho nodo. Con el SVM se obtuvo la mejor clasificación, un 99.14% de clasificación global. Clasificando el 100% de bancos quebrados y el 99.12% de bancos no quebrados. Esta investigación ayuda a difundir herramientas no tradicionales en el área financiera de América Latina y que sirve de base para impulsar dichas herramientas a otras problemáticas de clasificaciónIn Ecuador, no EWS work has been published for the banking system, in June 2017. Therefore, it was proposed to find the best method for classifying banks at risk of bankruptcy in the Ecuadorian banking system. The nearest neighbor algorithm \"K-NN\" was used for the missing data and for the classification: Discriminant Partial Least Squares \"PLSD\", Support Vector Machine \"SVM\" and Classification Tree (CART). The PLSD method achieved a global rating of 94.99% and a classification of bankruptcy (18 months before closing) of 18.89%. Banks that do not break down have high ratios in financial efficiency, net interest income, exercise results and coverage of 100 largest depositors. While banks that fail, have high levels of delinquency, vulnerability of assets, unproductive portfolio and operating expenses. The CART Classification Tree gave a good classification model, giving a 99.72% overall rating and 92.59% of broken banks. In addition, it gives us information about the variables that best discriminate, under what conditions and indicates the percentage of the population that is in that node. With the SVM the best classification was obtained, a 99.14% overall rating. Classifying 100% of broken banks and 99.12% of banks not broken. This research helps to disseminate nontraditional tools in the financial area of ​​Latin America and serves as a basis to promote these tools to other issues of classification\n"}
{"prompt":"Diagnóstico de gastritis basado en iridología mediante el procesamiento digital de imágenes ->","completion":" El procesamiento digital de imágenes (PDI) ha adquirido un papel importante en el desarrollo tecnológico actual, debido a la posibilidad de automatizar procesos cuando se trabaja conjuntamente con el aprendizaje de máquina. Una aplicación importante del PDI son los sistemas CAD (Computer Aided Diagnosis), los cuales se encargan de facilitar el diagnóstico de patologías en función a una mejora en la imagen donde se resalta cierta área de interés para el especialista. Los sistemas CAD se encuentran generalmente aplicados a la medicina tradicional, aunque en estudios recientes han sido aplicados a medicina alternativa como, por ejemplo, la iridología; la cual se encarga de localizar posibles alteraciones en la salud en base a características mostradas en el iris. Por la distribución del mapa del iris, se optó por detectar anomalías gástricas, concretamente la gastritis, ya que gran parte de la población presenta esta patología en algún momento de su vida. Basado en esto, el presente trabajo tiene como objetivo diseñar e implementar un prototipo para generar un diagnóstico preventivo de la gastritis de forma automática; utilizando el procesamiento digital de imágenes, plantillas iridológicas y aprendizaje de máquina. El sistema implementado trabaja con 100 imágenes en una base de datos de donde se extraen 12 características de color por imagen, las cuales ayudan al sistema a detectar la presencia de gastritis. El prototipo debe realizar un diagnóstico preventivo automático por lo que debe aprender a discernir entre la información obtenida; en otras palabras, debe clasificar los pacientes. Por esta razón, se emplea métodos de aprendizaje supervisado como son: árbol de decisión, vecinos más cercanos, máquinas de soporte y redes neuronales. Los resultados de la evaluación del mejor clasificador son 94% y 92% los cuales representan los valores de exactitud y capacidad predictiva del sistema respectivamente.\n"}
{"prompt":"Evaluación del impacto de la educación tributaria en el cumplimiento tributario de la declaración de impuesto a la renta de las personas naturales capacitadas por el SRI. Estudio para la Ciudad de Guayaquil en el año 2013 ->","completion":" Inside the strategic plan, the IRS as public institution has as one of its main objectives to incentive tax law trough citizens training for it citizens. This study analyze the tax behavior of people who have received training on tax issues by the Internal Revenue Service. The work is based on three main stages, the first conceptualizing the meaning of the tax education as a service provided to citizens. As a second part to identify the group of people currently receiving the training and what the variables and \/ or characteristics that influence their tax compliance are. And the third, to investigate methodologically which is the appropriate method to identify the probability that all people have in receiving training program on tax issues, and also to identify the impact that represents the fact of receiving this training in their tax compliance obligations. From the methodological point of view, the research identifies an inferential analysis with a mixed qualitative and quantitative approach. Among the research techniques used are: collection of database information through the IRS, probabilistic model Logit or Probit regression, propensity score matching tool. Among the main results it can be mentioned that only 1% of the trainees are required to keep accounts, 62% of the trainees are women, the majority. A man its more likely to be trained, if is older and possesses a higher level of income. The use of propensity score matching tool estimates that the impact on the training represent tax compliance is 15.1% to 16.7%, the most representative is the nearest neighbor method.Dentro del Plan Estratégico, el SRI como institución pública tiene como uno de sus objetivos principales incentivar la cultura tributaria mediante capacitaciones a la ciudadanía. El presente estudio analiza el comportamiento tributario de las personas que han recibido capacitaciones de normativa tributaria por parte del Servicio de Rentas Internas. El trabajo se basa en tres etapas fundamentales, la primera parte conceptualizar el significado de la educación tributaria como servicio brindado a la ciudadanía. Como segunda parte identificar el grupo de personas que actualmente reciben las capacitaciones y cuáles son las variables y\/o características que influyen en su cumplimiento tributario. Y la tercera, investigar metodológicamente cual es el método adecuado que permita identificar la probabilidad que tienen todas las personas de recibir un programa de capacitación tributaria, y además identificar el impacto que representa el hecho de recibir estas capacitaciones en el cumplimiento tributario de sus obligaciones. Desde el punto de vista metodológico, la investigación identifica un análisis inferencial con un enfoque mixto, tanto cualitativo como cuantitativo. Entre las técnicas de investigación empleadas son: recopilación de información mediante base de datos de la institución, modelo de regresión probabilística Logit o Probit., herramienta de Propensity Score Matching. Entre los principales resultados obtenidos se puede mencionar, que solo el 1% de los capacitados son obligados a llevar contabilidad, el 62% de los capacitados son mujeres, es decir la mayoría. Existe una mayor probabilidad de ser capacitado si es hombre, si tiene más edad y si posee un mayor nivel de ingresos. El uso de la herramienta Propensity Score Matching estima que el impacto que las capacitaciones representan sobre el cumplimiento tributario es de 15,1% a 16,7%, siendo el método del Vecino más cercano la más representativa.\n"}
{"prompt":"Clasificación vía aprendizaje automático de conformaciones moleculares en estructuras teloméricas ->","completion":" ABSTRACTA great number of studies have been published on the area of small molecules bound to telomeric sequences that fold on a non-cannonical DNA structure known as G-quadruplex structure. The study of these structures has been driven for its potential as targets for drug development. Furthermore, G-quadruplex structures have been identified in other sequences of importance through all the genome. Within the different studies two main models have been used: the human telomeric sequence and the oxytricha, tetrahymena telomeric sequence. Both cases are used as models for computational studies and in vitro essays. Here we study the trajectory generated from an atomistic molecular dynamic simulation to obtain the amount of flexibility and mobility of these model structures. We used data mining and classification tools (i.e. k nearest neighbor method) to identify automatically subpopulations of structures within the simulation. We found the most populated conformations and we discuss the structural findings.Keywords: DNA, molecular dynamic, G- Quadruplex, classification, data mining, k nearest neighbor.RESUMENUn gran número de estudios han sido publicados en el área de pequeñas moléculas unidas a secuencias teloméricas que se pliegan en estructura no convencionales de AD denominadas estructuras G- Cuádruple. El estudio de estas estructuras ha sido motivado por su potencial utilidad como blancos para desarrollo de fármacos. Además, las estructuras G- Cuádruples han sido identificadas en otras secuencias de importancia a lo largo de todo el genoma. Dentro de los diversos estudios se han utilizado dos modelos: la secuencia telomérica humana y las secuencia telomérica el Oxytricha, Tetrahymena. Ambos han sido empleados como modelos para estudios computacionales y ensayos in vitro. Aquí estudiamos la trayectoria generada a partir de las simulaciones de dinámica molecular atomística para obtener la cantidad de flexibilidad y movilidad de estas estructuras modelos. Utilizamos herramientas de clasificación (es decir, método del vecino cercano k) y minería de datos. Encontramos las conformaciones más pobladas y discutimos los hallazgos estructurales.Palabras clave: ADN, simulación molecular, G cuádruple, clasificación, minería de datos, vecino cercano k.\n"}
{"prompt":"Sistema de reconocimiento de microterremotos en tiempo real del volcán Cotopaxi aplicando aprendizaje supervisado ->","completion":" Vivimos en un mundo continuamente cambiante, donde se genera una variedad de fenómenos físicos naturales. Muchos de estos fenómenos físicos han sido monitorizados constantemente por el peligro latente que generan. Los volcanes son un claro ejemplo de un fenómeno natural que puede traer consecuencias catastróficas si entra en etapa eruptiva. En este contexto, el Ecuador posee uno de los volcanes más activos del mundo, lo que genera la necesidad de monitorizar y recopilar información por expertos en geofísica, los cuales están interesados en entender el comportamiento de dicho fenómeno, por estas razones generan la necesidad de estudiar métodos que permitan identificar posibles erupciones mediante la monitorización y detección de la actividad microsísmica de un volcán, con el fin de salvaguardar vidas y pérdidas materiales. En este proyecto se desarrolló un sistema de reconocimiento automático de microterremotos en tiempo real del volcán Cotopaxi al aplicar técnicas de aprendizaje supervisado. El modelo de reconocimiento es obtenido aplicando modelos de aprendizaje supervisado k-Vecinos Cercanos (kNN), Máquina de Vectores Soporte (SVM) y Árboles de Decisión (DT) a características de tiempo, frecuencia y escala, aplicados a los datos proporcionados por el Instituto Geofísico de la Escuela Politécnica Nacional con la actividad sísmica presentada del volcán Cotopaxi en los años 2012, 2013 y 2014. El sistema de reconocimiento está constituido por una etapa de detección y clasificación, para lo cual se realizan procesos de segmentación de la señal en ventanas, etiquetamiento, extracción de características, selección de características y obtención de modelos unificados en un sistema de votación. Para las etapas de detección y clasificación de microterremotos presentaron resultados en términos de exactitud, precisión, sensibilidad, especificidad y tasa de error de balanceo (BER, del inglés Balanced Error Rate), para la detección el algoritmo kNN alcanzó porcentajes del 98.15 %, 95.20 % y 0.017 para la exactitud, precisión y BER, respectivamente, mientras que en la clasificación el algoritmo SVM alcanzó porcentajes del 94.49 %, 60.42 % y 0.16 para la exactitud, precisión y BER respectivamente.\n"}
{"prompt":"Relación estructura-actividad como estrategia para la selección de moléculas candidatas para el desarrollo de inhibidores de tirosinasas ->","completion":" En este trabajo se ha desarrollado un modelo basado en las Relaciones Cuantitativas Estructura-Actividad (QSAR) para predecir la concentración inhibitoria media máxima (IC50) de 581 moléculas sobre la enzima tirosinasa. Cada estructura molecular fue optimizada en el programa HyperChem mediante la mecánica molecular (MM+) y el método semiempírico PM3. Posteriormente, se calcularon 5274 descriptores moleculares y 166 huellas dactilares moleculares MACCS en el programa alvaDesc, los cuales fueron reducidos mediante el método no supervisado V-WSP. Así, 1692 descriptores se sometieron a un proceso de selección supervisada de variables mediante Algoritmos Genéticos (GAs) acoplados con el método de clasificación de los k-vecinos más cercanos (kNN). En esta etapa se aplicó el método simplex para optimizar el umbral para la separación entre las clases de alta y baja actividad. Se obtuvo un modelo óptimo con ocho descriptores moleculares y cuatro vecinos (NERcal = 0.82). Este modelo se validó mediante validación cruzada de ventanas venecianas (NERcv = 0.82) y un grupo externo de predicción constituido por 174 moléculas (NERpred = 0.86). Adicionalmente, se definió el dominio de aplicabilidad del modelo y se brindó la interpretación mecánica de los descriptores moleculares. El modelo QSAR propuesto fue desarrollado usando los cinco principios definidos por la Organización para la Cooperación y el Desarrollo Económico (OECD) para garantizar su aplicabilidad.The purpose of this work was to calibrate a Quantitative Structure-Activity Relationship (QSAR) model to predict the half maximal inhibitory concentration (IC50) of the tyrosinase activity of 581 molecules. For geometry optimization, the molecular mechanic force field (MM+) was used, followed by the PM3 semi-empirical method to refine the structures. Then, compounds were described by 5274 alvaDesc molecular descriptors and 166 MACCS structural keys, which were merged into a single dataset and subsequently reduced by the V-WSP unsupervised variable reduction. Thus, 1692 descriptors were submitted to the Genetic Algorithms (GAs) supervised variable selection process coupled with the k-nearest neighbors classifier. In this step, the simplex method was applied in order to optimize the threshold for the separation between the high and low activity classes. A model composed of eight molecular descriptors and four neighbors classifiers was retained as the optimal one (NERtrain = 0.82). This model was validated by a cross-validation protocol based on venetian blind (NERcv = 0.82) and an external test set of 174 molecules (NERtest = 0.86). In addition, the applicability domain of the model was defined, and the mechanistic interpretation of molecular descriptors was provided. The proposed QSAR model was developed using the five principles defined by the Organization for Economic Co-operation and Development (OECD) in order to guarantee its applicability.Bioquímico FarmacéuticoCuenca\n"}
{"prompt":"Sistemas detector de actitudes negativas en entornos virtuales de aprendizaje. ->","completion":" PDFEn el ámbito académico la presente investigación propone por una parte, analizar y determinar las actitudes negativas que se generan al iniciar una nueva clase y calificar el grado de aceptación de los estudiantes como también las distintas herramientas que ofrecen los modelos educativos, es decir que las actitudes negativas de aprendizaje de los estudiantes sean detectadas a tiempo y reciban observaciones oportunas sobre su funcionamiento y su progreso hacia la realización de los objetivos del curso, para lograr este propósito se ha desarrollado un sistema detector de actitudes negativas en entornos virtuales de aprendizaje el cual analiza los comentarios emitidos de los estudiantes en referencia a cada clase y los almacena en una base de datos recibiendo así un mejor enfoque para el mejoramiento académico del estudiante, es importante. Acorde a los objetivos expuestos anteriormente se puede concluir que se elaboró una revisión bibliográfica sobre los sistemas detectores de actitudes negativas y algoritmos de procesamiento de lenguaje natural para definir los límites y atributos del proyecto, como también la importancia que el sistemas detector de actitudes negativas en entornos virtuales de aprendizaje sea acoplado a la base de datos de la universidad de Guayaquil para poder nutrir más el algoritmo y por ende el resultado sea preciso.In the academic field, this research proposes, on the one hand, to analyze and determine the negative attitudes that are generated when starting a new class and qualify the degree of acceptance of the students as well as the different tools offered by educational models, that is, the Negative learning attitudes of students are detected in time and receive timely observations about their operation and their progress towards achieving the objectives of the course, to achieve this purpose a system has been developed for detecting negative attitudes in virtual learning environments which analyzes the comments issued by the students in reference to each class and stores them in a database thus receiving a better approach for the academic improvement of the student, it is important. In accordance with the objectives set out above, it can be concluded that a bibliographic review was made on negative attitude detection systems and natural language processing algorithms to define the limits and attributes of the project, as well as the importance of negative attitude detection systems in virtual learning environments is coupled to the database of the University of Guayaquil to further nurture the algorithm and therefore the result is accurate.\n"}
{"prompt":"Sistemas de aprendizaje colaborativo m?vil en realidad aumentada ->","completion":" La realidad aumentada educativa es una tecnolog?a que actualmente est? mejorando la calidad de ense?anza, la utilizaci?n de dispositivos m?viles permite que el estudiante sea protagonista de su aprendizaje sin estar confinado a un espacio o tiempo espec?fico para aprender. Aplicaciones colaborativas con realidad aumentada est?n siendo empleadas cada vez m?s en la educaci?n, de tal forma que fomentan el trabajo en grupo donde los estudiantes comparten conocimiento, dudas, opiniones logrando un mejor nivel cognitivo que trabajando individualmente. En este trabajo se presenta el estado de la cuesti?n de Aplicaciones Educativas con Realidad Aumentada en dispositivos m?viles, y Aplicaciones Educativas colaborativas con Realidad Aumentada, desarrolladas desde el 2002 e implementadas en instituciones educativas. As? mismo se realiza un estudio sobre la Realidad Aumentada, Realidad Aumentada m?vil y Aprendizaje M?vil. Adem?s, a partir de las caracter?sticas del estudio de las aplicaciones con Realidad Aumenta, se realiza un an?lisis y dise?o de una Aplicaci?n M?vil para el proyecto de inicio de los alumnos de nuevo ingreso de la UPM. As? como tambi?n una herramienta de autor?a para las gestiones de las actividades propuestas por los docentes de la UPM. Finalmente se presenta un caso de prueba en el que se implementa parte de la propuesta de este trabajo, logrando construir un parte funcional para el proyecto inicial denominado PIANI ? UPM.\n"}
{"prompt":"Sistemas virtuales informáticos en los procesos de enseñanza aprendizaje ->","completion":" PDFEl propósito de esta investigación es evaluar los procesos pedagógicos en las que se encuentran los aprendizajes en la asignatura de computación, en los estudiantes de noveno año de educación básica y diseñar un entorno virtual que contenga técnicas y herramientas tecnológicas. En los antecedentes de estudio la investigación no guarda semejanza con otros trabajos planteados sin embargo existe una amplia bibliografía de temas similares. El contenido del marco teórico está centrado al uso de los sistemas virtuales, los cuales posibilitan el acceso remoto tanto a estudiantes como a profesores desde cualquier lugar y en cualquier momento, mediante una conexión de TCP\/IP (Internet),La filosofía planteada por Moodle incluye una aproximación constructiva basada en el constructivismo social de la educación, enfatizando que los educandos puedan contribuir a la experiencia educativa mediante el uso de las herramientas tecnológicas. Se lo considera como un proyecto factible: entre sus fases abarca una investigación descriptiva y explicativa, además incluye una investigación documental y de campo. Como instrumento de investigación se utilizó la observación “in situ”, a través de entrevistas, encuestas, aplicadas mediante muestreo aleatorio, especialmente en los segmentos docentes y estudiantes de la población en estudio correspondiente a 557 discentes y 60 docentes. De los cuales se tomó como muestra a 58 educandos y 38 maestros, Los recursos que se han utilizado en el presente estudio son: Humanos, técnicos y financieros, El aporte de la tesis es lograr el mejoramiento de la gestión del estudiante con el objetivo de preparar y enviar a la sociedad educandos capaces de enfrentarse a cualquier circunstancia en la vida diaria. La propuesta planteada, es una de esas herramientas, que apoya al docente en su labor educativa y al discente para que aprenda de una manera significativa, y a la vez pedagógica, práctica y dinámica, porque es un sistema virtual interactivo que contiene: textos, sonidos y animaciones, características trascendentales en el aprendizaje actual, Los beneficiarios de este proyecto son, los estudiantes, maestros de la Unidad Educativa el “El Ateneo”. Y la comunidad en general.The purpose of this investigation is to evaluate the computing pedagogical processes of the ninth grade students of basic education and design a virtual environment containing technical and technological tools. In the study antecedents, the investigation is not related to their works mention edbut there is extensive literature of similar topics. It is considered as a feasible project, between its phases covers a descriptive and explanatory research, also includes a documentary and field research. As a research instrument was used observation \"in situ\", through interviews, surveys, applied by random sampling, especially teachers and students segments of the population under study. The sample will be stratified and includes 85 students and 38 teachers, the resources that have been used in this study are: human, technical and financial, the contribution of the thesis is to improve the management of the students in the society , in order to prepare and send them to society and students will be able to face any situation in daily life. The proposal presented, is one of those tools, which supports teachers in their educational work and the learner to learn in a significant way, while teaching, practical and dynamic, because it is an interactive virtual system containing: text, sound and animations, learning transcendental features current beneficiaries of this project are students, teachers of the Education Unit \"El Ateneo\". And the community in general\n"}
{"prompt":"Métricas de colaboración para trabajo autónomo de sistemas de gestión de aprendizaje ->","completion":" Trabajo que propone un modelo para la medición de la colaboración individual en trabajos colaborativos, utilizando un variante de non-negative matriz factorization (NMF) para el cálculo de la contribución de cada participante. El modelo se divide en tres secciones: obtención de revisiones(data access), algoritmo de medición de colaboración (collaboration measurement logic) y visualizador web (web visualization). Para el análisis se utiliza archivos de google drive enviados mediante el sistema de gestión de aprendizaje utilizado en espol (sidweb), los cuales son integrados al modelo propuesto mediante el visualizador web. El modelo se puede adaptar para mostrar la colaboración de wikipedia, one drive.GuayaquilMagíster en Ciencias de la Computación\n"}
{"prompt":"Implementación de un servidor de video streaming basado en los sistemas de gestión de aprendizaje LMS. ->","completion":" The present thesis research consists in the study of the implementation of a video streaming server for its deployment into a learning management system for the Electronic and Telecommunications Engineering career of the Energy Faculty of the National University of Loja to improve the learning process to ease the development of the activities for both teachers and students. It has been researched the study of the video codecs, their main characteristics, advantages and disadvantages, as well as their storage capacity and the most viable option to provide a good video quality, reducing the energy consumption in the devices. In addition, the necessary requirements for the implementation of an educational environment platform were also established. With all the above, we want to provide a video solution to improve learning within the higher education environment. For the development of the present work has divided the investigation in stages, the first one of study, followed by another one of comparison and the last is the selection of the codec and server of video streaming aligned to the needs of the career.El presente trabajo de tesis consiste en el estudio de la implementación de un servidor de video streaming para su despliegue en un sistema de gestión de aprendizaje para la carrera de Ingeniería de Electrónica y Telecomunicaciones de la Facultad de la Energía de la Universidad Nacional de Loja, esto con el propósito de mejorar el proceso de aprendizaje de modo que facilite las actividades tanto a los docentes como a los estudiantes. Se realizó el estudio de los códecs de video, sus principales características, ventajas y desventajas, así como también su capacidad de almacenamiento y la opción más viable para proveer una buena calidad de video reduciendo el consumo de energía en los dispositivos. Además también se establecieron los requerimientos necesarios para la implementación de una plataforma de entorno educativo. Con todo lo mencionado con anterioridad se quiere dar una solución de video que permita mejorar el aprendizaje dentro del entorno de la educación superior. Para el desarrollo del presente trabajo se ha divido la investigación en etapas, la primera de estudio, seguido de otra de comparación y por último la selección del códec y servidor de video streaming alineados a las necesidades de la carrera.\n"}
{"prompt":"El aprendizaje significativo en la resolución de problemas de sistemas lineales con dos incógnitas. ->","completion":" En este proyecto se resalta la importancia que tiene el aprendizaje significativo para resolver sistemas de ecuaciones lineales con dos incógnitas y cómo influyen estas en el desarrollo de problemas de razonamiento lógico numérico. Se identificó a través de los instrumentos de investigación aplicados que la gran mayoría de los estudiantes presentan dificultad para interpretar el lenguaje algebraico y plantear ecuaciones que les ayuden a resolver problemas, por lo cual surgió la necesidad de elaborar una Guía didáctica con estrategias en donde se detallan el proceso de resolución de problemas.\n"}
{"prompt":"Sistema de administración de aprendizaje UCSG E-Learning UCSG ->","completion":" El siguiente proyecto de grado va dirigido hacia la Universidad Católica Santiago de Guayaquil para analizar e implementar un mejorado sistema de administración de aprendizaje, el mismo que ofrecerá varias opciones de enseñanza para que exista interactividad entre el profesor y el estudiante, buscando resultados importantes en el proyecto final, que todos los usuarios queden satisfechos con sistema a implementar. Para lograr esta propuesta, se requiere de una forma de trabajo específica, que permita el diseño, desarrollo y ejecución del sistema a implementar, de una manera coherente para el cumplimiento de los objetivos diseñados. La implementación del sistema ayudará de gran manera a la enseñanza universitaria, ya que agilitará procesos que antes eran más tediosos llevarlos en la clase. El sistema de administración de aprendizaje UCSG será un paso más para que la enseñanza en dicha universidad sea actualizada y mejorada con la ayuda de la tecnología.\n"}
{"prompt":"Aprendizaje significativo para el análisis y resolución de sistemas de inecuaciones lineales. ->","completion":" El presente trabajo investigativo surge de la necesidad de implementar recursos tecnológicos en la enseñanza de las Matemáticas, particularmente para el análisis y resolución de sistemas de inecuaciones lineales, por lo cual se implementó el Software educativo GeoGebra como una herramienta que permite fomentar el Aprendizaje Significativo , ya que permite llevar a la práctica directa todos aquellos conceptos matemáticos relacionados con las inecuaciones, por lo cual se pudo concluir que el uso de este software permitió que los educandos sean un ente activo del proceso de enseñanza aprendizaje mejorando así considerablemente su rendimiento académico. The present research work arises from the need to implement technological resources in the teaching of Mathematics, particularly for the analysis and resolution of systems of linear inequalities, so the GeoGebra Educational Software was implemented as a tool that allows to promote Significant Learning, since it allows all those mathematical concepts related to inequalities to be put into direct practice, so it could be concluded that the use of this software allowed students to be an active entity in the teaching- learning process, thus considerably improving their academic performance.\n"}
{"prompt":"Generación de procesos industriales virtuales orientados al aprendizaje de sistemas automáticos basados en PLCs ->","completion":" Esta tesis de ingeniería se ocupa de la utilización de herramientas de simulación en la automatización industrial. La tarea principal era crear modelos de simulación, incluidas sus aplicaciones de control, para ocho lugares de trabajo en la industria. Todos los modelos de simulación se realizaron utilizando la herramienta de simulación SIMIT 10.0.3. Las aplicaciones de control se crearon en el entorno de programación TIA Portal V15.This engineering thesis deals with the use of simulation tools in industrial automation. The main task was to create simulation models, including their control applications, for eight workplaces in the industry. All simulation models were performed using the SIMIT 10.0.3 simulation tool. The control applications were created in the TIA Portal V15 programming environment.\n"}
{"prompt":"Diseño de un modelo ontológico para los contenidos de aprendizaje de la teoría general de sistemas. ->","completion":" El presente proyecto describe el desarrollo de un modelo ontológico, la ontología es una especificación formal que estructura el contenido de un dominio específico, el dominio elegido fue la teoría general de sistemas, cuyo contenido para su construcción se tomó del libro Introducción a la teoría general de sistemas, del autor Oscar Johansen Bertoglio. La necesidad de crear una ontología nace de la evolución de la web, que ésta pase a ser de sintáctica a semántica con el objetivo de que sea el ordenadorel que interprete lo que el usuario está buscando.Para el desarrollo de la ontología se utilizó la metodología Methontology, ésta metodología está dividida en 5 etapas. La primera etapa llamada Especificación comprendió en establecer la razón de la ontología y para qué va a ser construida, la segunda etapa Conceptualización en conjunto con la tercera etapa Formalización definió la transformación del dominio de informal a formal, mediante glosarios de términos, relaciones binarias, etc. La cuarta etapa llamada Implementación se codificó la información usando Protégé y la quinta etapa de Evaluación, se verifica la razonabilidad de la ontología para su posterior uso. Al final se probó la ontología en una biblioteca de ontologías llamada ONKI. Este documento está dividido en cuatro capítulos, empezando con Capítulo 1 el marco referencial, el Capítulo 2 marco teórico, el Capítulo 3 diseño del modelo ontológico usando Protégé y el Capítulo 4 conclusiones y recomendaciones.\n"}
{"prompt":"Análisis de los algoritmos heurísticos aplicado en el aprendizaje y guía de sistemas autónomos ->","completion":" La investigación sobre el análisis de los algoritmos heurísticos orientado a la guía y aprendizaje de mecanismos autónomos, permite la selección de una base adecuada para el desarrollo de un sistema que provea de inteligencia y autonomía en robots autónomos, simulaciones y experimentos llevados a cabo en la Facultad de Electrónica de la Escuela Superior Politécnica de Chimborazo. La presente investigación de análisis se sustenta en el método científico, con técnicas de observación directa y experimentación mediante softwares de simulación desarrollados en Visual Studio.net (C#) e implementaciones en mecanismos autónomos NXT 2.0, Robot C. El análisis de algoritmos principal tópico en la investigación, que fue integrado en Robot C y su respectiva simulación en Visual Studio .net, para generar un software con base en un algoritmo heurístico, permitiendo que el mecanismo aprenda de una forma rápida fiable y óptima, dando como resultado cuantitativo, obtenido de la simulación de escenarios, con un 45% de efectividad de los algoritmos no heurísticos frente al 95% de los algoritmos heurísticos. Los resultados obtenidos en la simulación, permiten concluir que el desarrollo de sistemas inteligentes usando un algoritmo heurístico es ideal para la automatización del aprendizaje en sistemas autónomos obteniendo un 45% de efectividad con respecto a los algoritmos no heurísticos, al fin de desarrollar un software inteligente que permita ser instalados en los mecanismos autónomos desarrollados en la Escuela de ingeniería Electrónica en la Escuela Superior Politécnica de Chimborazo. En conclusión, el uso de un algoritmo heurístico ofrece una base sólida para generar sistemas software que permitan a los mecanismos autónomos obtener inteligencia y guiarse de una manera efectiva en cualquier tipo de escenario. Se recomienda a los estudiantes y docentes en la catedra de Inteligencia Artificial en la Facultad de Informática y Electrónica, el uso de algoritmos heurísticos.\n"}
{"prompt":"Sistema informático para la gestión de objetos de aprendizaje ->","completion":" Desarrollar una aplicación informática para la creación y gestión de un repositorio de objetos de aprendizaje institucional que se integre a Moodle, y que permita compartir los recursos educativos digitales entre los docentes, dentro de un entorno de enseñanza virtual.El presente trabajo pretende aportar al modelo educativo actual una herramienta que permita almacenar, compartir y evaluar en un entorno de aprendizaje Recursos y Objetos de Aprendizaje a través del desarrollo de una aplicación informática web “Sistema informático para la gestión de Objetos de Aprendizaje”. Para el desarrollo de éste trabajo los Objetos y Recursos de Aprendizaje son catalogados, organizados y evaluados de acuerdo al seguimiento y referencia de normas y estudios realizados; del mismo modo el aplicativo se implementa con la aplicación de una de las metodologías considerada como ágil en el desarrollo de software; en cuanto al modelo se utiliza como referencia una arquitectura divida en capas y finalmente para el entorno de trabajo se utiliza software libre. La implementación del aplicativo y su utilización promueve en la comunidad académica la reutilización de recursos estructurados en su formación, así también la estimulación en la creación de nuevos recursos y el desarrollo de software enfocado al ámbito educativo y su integración a plataformas existentes.Ingeniería\n"}
{"prompt":"Diseño y construcción de un prototipo móvil con capacidad de aprendizaje para la navegación en laberintos ->","completion":" El presente proyecto tiene como finalidad diseñar y construir una Plataforma Móvil con capacidad de aprendizaje para navegación por laberintos desconocidos. El Prototipo esta impulsado por dos servomotores que le permiten, mediante una lógica de control, el desplazamiento frontal y los giros tanto hacia la derecha, izquierda y de 180 grados. El sistema de percepción se lo realiza mediante el uso de sensores de proximidad ubicados de manera estratégica dentro de la Plataforma; con esto se tiene un mejor entendimiento del entorno en el que se desenvuelve. Para el procesamiento y acondicionamiento de las señales, se optó por el uso de un Microcontrolador, en el que se encuentra programada la lógica de control de navegación y aprendizaje. El método utilizado para la resolución de laberinto es el denominado mano en la pared, con el cual se garantiza que el Prototipo pueda encontrar la salida del laberinto en su Etapa de Entrenamiento (Navegación). Finalmente, la lógica de Aprendizaje se basa en el reconocimiento de Eventos (cuando la Plataforma realiza un giro a la derecha, izquierda o un avance frontal) que se guardan en un registro de Estados. Este registro puede ser alterado ante la presencia de una ruta sin salida\n"}
{"prompt":"Estrategia adaptativa en el proceso de enseñanza aprendizaje, aplicado en equipos y sistemas microinformáticos ->","completion":" La presente investigación denominada: estrategia adaptativa en el proceso de enseñanza aprendizaje, aplicado en equipos y sistemas microinformáticos, un tema que en la actualidad es una realidad y una necesidad por las diversidades individuales existentes de los estudiantes puesto que permite utilizarlas para una intervención educativa y lograr un mejor desempeño académico en los estudiantes, el objetivo de la presente investigación fue: Diseñar una estrategia adaptativa aplicable en el proceso de enseñanza aprendizaje en el módulo de equipos y sistemas microinformáticos de segundo y tercer año bachillerato técnico de la especialidad electrónica en la Unidad Educativa “10 de Enero” del Cantón San Miguel, provincia Bolívar, en cuanto a la metodología utilizada esta tiene un enfoque cualitativo, descriptivo y exploratorio con una población de 14 estudiantes del segundo bachillerato y 20 estudiantes del tercero de bachillerato al ser una población manejable no fue necesario obtener muestra alguna, la propuesta planteada fue la implementación de un Entorno Virtual de Aprendizaje denominado EVA en donde se encuentran incluidas las diferentes estrategias metodológicas para la enseñanza aprendizaje de Equipos y Sistemas Microinformáticos estructurado este entorno virtual etiquetas informativas, lecturas recomendadas, videos recomendados, sección retorno, actividad clase, ejercicios prácticos, sección comprobación, foros mismos que permitió reflejar los principales resultados como la de aplicar el juego para enseñar y aprender es muy útil, mismos que facilitan el aprendizaje mediante la construcción del conocimiento por parte del estudiante.Pontificia Universidad Católica del Ecuador, Dirección de Investigación y PosgradosMagister en Pedagogía, Mención Educación Técnica y Tecnológica\n"}
{"prompt":"Modelo de aprendizaje y sistema de remediación académica ->","completion":" PDFEl Presente trabajo propone creer un departamento de ayudantías pedagógicas en la especialización de mercadotecnia y publicidad para de esta manera ayudar a los estudiantes de bajo rendimiento académico de la jornada nocturna con la finalidad de dar solución a los problemas de bajo rendimiento académico existentes en nuestras Universidades, sabiendo que en la actualidad nuestra sociedad exige profesionales con calidad de conocimientos académicos pedagógicos, competitivos y de éxito. Definir la educación es comprometerse con una concepción del hombre y de la sociedad, en sus aspectos psicológicos, sociales, antropológicos y filosóficos en un sentido menos abstracto, la finalidad ataña a la reflexión entorno a los propósitos que determinan la acción educativa. Este trabajo se ha realizado mediante la investigación cualitativa y cuantitativa en función del problema, los objetivos que se persiguen y los datos obtenidos, es decir en una investigación de tipo factible que se apoya en una investigación de campo; las técnicas utilizadas en esta investigación son: la observación directa, consulta a expertos, encuestas, etc. La muestra se tomara en la Facultad de Filosofía en la carrera de Mercadotecnia y Publicidad, con los alumnos de primer curso de la jornada nocturna y para obtener respuestas que contribuyen a la realidad de la investigación y por ende a la respuesta. Espero aportar con esta investigación al gran problema que se suscita en nuestro medio con el alto índice de bajo rendimiento académico y pedagógico en los estudiantes de la jornada nocturna, así contribuir al desarrollo del país. Por esta razón propongo la creación de un departamento de ayudantías pedagógicas en la carrera de Mercadotecnia y Publicidad contribuir el desarrollo de nuestro país.This paper proposes believe a department teaching assistantships in the specialization of marketing and advertising for this way to help students with low academic performance of the night shift in order to solve the problems of low academic performance exist in our universities , knowing that today our society requires professionals with quality teaching academic skills, competitive and success. Defining education is committed to a conception of man and society, in their psychological, social, anthropological and philosophical in a less abstract, the purpose is relevant to the reflection on the purposes that determine the educational activity. This work was carried out using qualitative and quantitative research by the problem, the objectives pursued and the data obtained, that is mean a feasible type of research that relies on field research, the techniques used in this research are : direct observation, consultation with experts, surveys, etc. The sample was taken at the Faculty of Philosophy in the career of marketing and advertising, with the freshmen of the day and night to get answers that contribute to the reality of research and therefore the response. I hope to bring this investigation to the major problem arises in our environment with the high rate of poor academic performance and student teaching in night shift, thus contributing to national development. For this reason I propose the creation of a department teaching assistantships in the career of marketing and advertising help the development of our country.\n"}
{"prompt":"Sistema de evaluación de aprendizaje en rendimiento académico. ->","completion":" La presente investigación realizada en la Unidad Educativa Vicente Rocafuerte tiene como objetivo examinar el sistema de evaluación de aprendizaje y el rendimiento académico en los estudiantes del 9no año de educación general básica en la asignatura de ciencias naturales, mediante una investigación bibliográfica y de campo para la elaboración de un instructivo de pruebas objetivas con base estructurada; el sistema de evaluación de aprendizaje es una temática que merece ser estudiada, puesto que a partir de este es que se pueden gestionar recursos y herramientas capaces de integrar nuevas formas de evaluar, en este sentido, se realiza encuesta a estudiantes y docentes, además entrevista a la autoridad pertinente, ante la necesidad existente surge como propuesta un instructivo de pruebas objetivas con base estructurada el cual detalla en su contenido las bases para diseñar un instrumento evaluativo que se adapte a los requerimientos expuestos por los educandos y los docentes.\n"}
{"prompt":"Desarrollo y evaluación de un sistema de aprendizaje interactivo para niños con discapacidad intelectual y problemas de aprendizaje ->","completion":" Actualmente una gran parte de la población a nivel mundial sufre algún tipo de discapacidad; generalmente estas personas ven violentados sus derechos, en especial la educación. Como una respuesta a esta problemática nace el concepto de educación inclusiva. En Ecuador, en el año 2011, entró en vigencia la nueva Ley Orgánica de Educación Intercultural, la cual establece estatutos que protegen el derecho a la educación de este grupo de personas. Pero la inclusión implica nuevos retos, como el uso de recursos didácticos que faciliten la inclusión de estos niños y fomenten el desarrollo de sus conocimientos. Por ello la importancia de este proyecto, mediante el cual se pretende mejorar el aprendizaje en las áreas de Matemáticas y Lengua y Literatura de los niños con discapacidad intelectual y problemas de aprendizaje que cursan el tercer año de educación básica, además de medir su grado de aceptación hacia el sistema desarrollado mediante un software de reconocimiento de gestos. Para conseguir estos resultados se desarrolló un sistema interactivo, que conjuntamente con el dispositivo Kinect, permite a los niños interactuar con él mediante movimientos corporales. Finalmente se probó el sistema con un grupo de niños, quienes luego de trabajar con el mismo mostraron una considerable mejora en los conocimientos de los temas desarrollados, además de constatarse un alto grado de aceptación de los niños hacia el sistema. Debido a los resultados favorables que se han obtenido con el mismo, el trabajo futuro consistiría en masificar su impacto incluyéndolo en escuelas e incluso en hogares.Nowadays a large part of the population worldwide suffers from some kind of disability and generally their rights are violated, especially in education. As a response to this problem, the concept of inclusive education emerged. In Ecuador, in the year 2011, came into force the new Organic Law of Intercultural Education, which establishes statutes that protect the right to education of this group of people. But this inclusion implies new challenges such as the use of didactic resources that facilitate the inclusion of these children and encourage the development of their knowledge. For this reason this project becomes important because through it is intended to improve the learning in the areas of Mathematics, and Language and Literature of children with intellectual disabilities and learning problems who attend the third year of basic education, in addition to measuring their degree of acceptance of the developed system using gesture recognition software. In order to achieve these results, educational software was developed, which jointly with the Kinect device allows children to interact with it through body movements. Finally, the system was tested with a group of children, who, after working with the system, showed considerable improvement in knowledge of the developed topics, besides of a high degree of acceptance of children toward the system. Due to the favorable results obtained with it, the future work would consist in making the system accessible to schools and even homes in order to spread its impact.Ingeniero en Electrónica y TelecomunicacionesCuenca\n"}
{"prompt":"Desarrollo del sistema de gestión de un repositorio de objetos de aprendizaje en la Escuela de Ingeniería en Sistemas–ESPOCH. ->","completion":" En la Escuela de Ingeniería en Sistemas (EIS) de la Escuela Superior Politécnica de Chimborazo (ESPOCH), la poca cantidad de contenidos educativos utilizados es una de las causas que genera el menor interés en uso de la plataforma E-virtual; por lo que, en el presente trabajo se desarrolló el sistema denominado Repositorio de Objetos de Aprendizaje (ROA), con el fin de publicar los recursos y objetos de aprendizaje de acceso libre. Se utilizó Scrum como metodología de desarrollo de software, herramientas hardware y software adecuados; además, las funcionalidades se fundamentan en las especificaciones del Sistema de Gestión Instruccional (IMS) para garantizar la interoperabilidad del repositorio, por lo que, el sistema basado en la web permite la gestión y publicación de objetos de aprendizaje de forma apropiada. Para demostrar el incremento de objetos de aprendizajes publicados en el repositorio desarrollado se ha definido dos grupos de estudio, además se utilizaron las técnicas de observación y revisión bibliográfica para la recolección de datos. Con 95% de confiabilidad, la cantidad promedio de objetos de aprendizaje que se obtiene es de 1 y 3.4 para el grupo de control y experimental respectivamente, en base a las características de las 5 asignaturas específicas de la EIS, definidas para los grupos de estudio. Apoyándose en la inferencia estadística con la prueba T-Student se determina que existe diferencias significativas de las medias; por lo tanto, se concluye que el sistema ROA incrementa en un 240% la cantidad de objetos de aprendizaje relacionadas a las 5 asignaturas de los grupos de estudio, lo que permite mejorar la colaboración y reutilización de los contenidos educativos en al EIS. Se recomienda definir un plan de conservación de los objetos de aprendizajes gestionados en el sistema ROA, para la administración adecuada sin afectar al propósito del repositorio.In the School of Systems Engineering (SSE) at Escuela Superior Politécnica de Chimborazo (ESPOCH) a small amount of educational content applied becomes one of the causes that generates a poor interest when using the E-virtual platform, therefore, this work developed a system called Repository of Learning Objects (ROA) in order to publish the resources and learning objects of free access. Scrum was used as a software methodology, hardware and software tools, also the functionalities are based upon the specifications of the Instructional Management System (IMS) to ensure interoperability of the repository, so the web-based system allows the management and publication of learning objects in an appropriate way. In order to demonstrate the increase of learning objects published in the repository, two study groups have been defined, besides, observation and bibliographic review techniques were used to collect data. With 95% of reliability, the average number of learning objects obtained is 1 and 3.4 for the control and experimental group respectively, in relation to the characteristics of 5 specific subjects of the SSE defined for the study groups. Based on the statistical inference through the application of the T-student test, it is determined that there are significant differences in the means, therefore, it is concluded that the ROA system increases by 240% the amount of learning objects related to the 5 subjects of the study groups that allows to improve the collaboration and reuse of the educational contents in the SSE. It is recommended to define a conservation plan for learning objects managed in the ROA system for a proper administration without affecting the purpose of the repository.\n"}
{"prompt":"Elaboración de un módulo de guías de práctica para el aprendizaje y entrenamiento en el desarrollo de sistemas SCADA ->","completion":" En el presente trabajo, se produce un manual de guías prácticas para el aprendizaje y la capacitación en el desarrollo de sistemas SCADA, para lo cual procedemos a la investigación de diferentes tipos de herramientas informáticas SCADA en las que cada software debe cumplir con los requisitos de costos de licencia, administración, accesibilidad, etc. Luego se proceder a la selección de 5 programas que cumplen con los requisitos establecidos por los sistemas SCADA, para realizar las pruebas de cada uno de ellos dentro de los laboratorios de la Universidad Politécnica Salesiana específicamente en los laboratorios de PLC y LACTI, y al final para aceptar la credibilidad se verifica a través de la validación de las guías de práctica con los estudiantes de la asignatura Redes de Computadoras III de la carrera de Ingeniería Electrónica y Automatización.In the present work, a manual of practice guides for learning and training in the development of SCADA systems is produced, for which we proceed to the investigation of different types of SCADA computing tools where each software must comply with the requirements for license costs, management accessibility, etc. Then proceed to the selection of 5 programs that meet the requirements established by SCADA systems, perform the tests of each of them within the laboratories of the Universidad Politecnica Salesiana specifically in the laboratories of PLC and LACTI, and in the end his credibility is verified through the validation of the courses of practice with the students of the Computer Networks III subject of the Electronics Engineering and Automation career.\n"}
{"prompt":"Clasificación de aplicaciones móviles para personas con discapacidad mediante modelos de aprendizaje supervisado ->","completion":" Los dispositivos móviles son actualmente la industria de más rápido crecimiento, ha permitido el desarrollo de aplicaciones móviles acordes a las necesidades de los usuarios, aun así, existe un grupo vulnerable que son las personas con discapacidad que no pueden acceder a las mismas aplicaciones por sus limitaciones. Además, no hay evidencia de que haya una calificación inclusiva como se demuestra en la App Store: Android Google Play y para iOS App Store. El objetivo de este proyecto es clasificar aplicaciones móviles mediante el uso de modelos de aprendizaje supervisado para determinar las aplicaciones inclusivas disponibles en Google Play. La metodología aplicada al proyecto es CRISP-DM son las siguientes fases: Fase 1 - Entendimiento del negocio: Comprender el desarrollo de las tecnologías aplicaciones para las personas con discapacidad, definición de palabras claves enfocadas a cada discapacidad existente. Fase 2 - Entendimiento de los datos: fuente de información se tomó la página de Google Play realizando la búsqueda con las palabras claves. Fase 3 - Preparación de los datos: Se lleva a cabo el proceso de minería de texto aplicada a la descripción de las aplicaciones obtenida de la fase 2. Fase 4 - Desarrollo y evaluación de los modelos: proceso de entrenamiento y test, se valida los modelos de acuerdo a los parámetros de medición: precision, recall, f1-score, accuracy, para los modelos : Naive Bayes, Máquina de vector de soporte lineal, Regresión logística, Nearest-neighbor. La evaluación de los modelos permitió obtener los mejores resultados en cuanto a métricas de precision, recall, f1-score al modelo de máquina de vector de soporte lineal. El modelo Máquina de vector de soporte lineal propuesto para la clasificación de aplicaciones móviles para personas con discapacidad obtuvo los mejores resultados clasificando correctamente en un 70%.\n"}
{"prompt":"Detección de la intención de movimiento de extremidades inferiores usando métodos de aprendizaje supervisado ->","completion":" Este trabajo se enmarca dentro el proyecto Prototipo de exoesqueleto usable en las extremidades inferiores, mediante la utilización de algoritmos de control adaptativos. El objetivo fue desarrollar un algoritmo capaz de detectar la intención del movimiento partiendo de electromiogramas (EMG) de sujetos con patologías en los miembros inferiores utilizando redes neuronales artificiales (ANN, por sus siglas en inglés) con reconocimiento de patrones mediante el método Levenberg-Marquardt. Se contempló una etapa de pre-procesamiento del EMG (filtrado, rectificación y normalización) y la anotación de la intención del movimiento. El algoritmo fue entrenado y validado usando una base de datos EMG de sujetos normales. Se obtuvo un desempeño global de 90,96% para una evaluación punto a punto y 94,88% en una evaluación por eventos. Estos resultados fueron publicados en ETCM-IEEE2018. Se registró una base de datos de 6 pacientes (42.83 ± 10.51 años), contentiva de 78 señales EMG, correspondientes a 13 músculos. Con los parámetros de entrenamiento obtenidos en la primera base de datos, se determinó la intención de movimiento en los sujetos con patologías y adicionalmente los valores de relación señal a ruido (SNR) y de frecuencia media (MNF). Se obtuvo un desempeño global de 93,14% punto a punto y 91.19% por eventos, el tiempo de retardo fue de 31,06±18,89 ms, SNR de 17,28±1,67 dB y los valores de MNF hallados son menores a los reportados en la literatura, lo que sugiere menor torque en esta población. Estos resultados permiten contemplar la implementación del algoritmo en tiempo real para un exoesqueleto.This work is part of the project Prototype of usable exoskeleton in the lower extremities, through the use of adaptive control algorithms. The aim of this project was to develop a capable algorithm of detecting the motion intention based on electromyograms (EMG) of subjects with pathologies in the lower limbs using artificial neural networks (ANN) with pattern recognition and the Levenberg-Marquardt method. Contemplated a stage (filtering, rectification and normalization) and the annotation of the motion intention for EMG pre-processing. Trained and validated the algorithm using an EMG database of normal subjects. Obtained an overall performance of 90.96% for a point-to-point evaluation and 94.88% in an evaluation by events. Publishing these results for ETCM-IEEE2018. Recorded a database of six patients (42.83 ± 10.51 years), containing 78 EMG signals, corresponding to 13 muscles. With the training parameters obtained in the first database, determined the motion intention in the subjects with pathologies, additionally, the values of signal-to-noise ratio (SNR) and mean frequency (MNF). Obtained an overall performance of 93.14% point-to-point and 91.19% by events, the delay time was 31.06 ± 18.89 ms, SNR of 17.28 ± 1.67 dB and the MNF values found they are lower than those the literature reported, suggesting lower torque in this population. These results allow contemplating the implementation of the algorithm in real time for an exoskeleton.Ingeniero en Electrónica y TelecomunicacionesCuenca\n"}
{"prompt":"Segmentación geométrica de la ciudad de Quito por medio de un método de aprendizaje no supervisado ->","completion":" This document contains an application of data analysis methods on urbanism and Geographic Information Systems. It aims to find shape and density patterns in the map of Quito, starting from the assumption that there are some similarities between the city blocks in terms of its geometric features and its spatial location. The Hierarchical Agglomerative and DBSCAN algorithms have been considered as analysis tools. Since the result is a new partition of the city, in which the new neighborhoods or sectors are not defined in an arbitrary way, we open the door for rethinking urban planning.El presente documento recoge una aplicación de métodos de análisis de datos en urbanismo y Sistemas de Información Geográfica. Se apunta a encontrar patrones de forma y densidad en el mapa de Quito, partiendo del supuesto de que existen similitudes entre las manzanas de la urbe en términos de sus atributos geométricos y su ubicación espacial. Los algoritmos Jerárquico Aglomerativo y DBSCAN han sido considerados como herramientas de análisis. Siendo el resultado una nueva segmentación de la ciudad, en la cual los nuevos barrios o sectores no están definidos de manera arbitraria, se abre la puerta a un replanteamiento de la planificación urbana.\n"}
{"prompt":"Pronóstico de producción hidroeléctrica del Ecuador usando redes neuronales. ->","completion":" PDFEn el presente trabajo se realiza la predicción de la producción hidroeléctrica del Ecuador del año 2015 utilizando redes neuronales artificiales de tipo perceptrón multicapas y redes neuronales recurrentes Elman y Jordan, desarrollados en R. Para esta predicción se utiliza datos del periodo comprendido entre 2000 y 2015, utilizando el último para el respectivo análisis de predicción, el cual se evalúa con medidas de rendimiento y se compara con el modelo serie de tiempo ARIMA. Para este fin se estudiarán los conceptos de los tipos de redes neuronales para entender sus modelos de predicciones. Además, se utiliza normalización de datos escalando a máximos y mínimos para mejorar el conjunto de entrenamiento y prueba en las neuronas, se utiliza el aprendizaje supervisado para las entradas de las neuronas con la función de activación sigmoide y la regla de aprendizaje de descenso degradado.In this work, the prediction of the hydroelectric production of Ecuador in 2015 is carried out using artificial neural networks of multilayer perceptron type and recurrent neural networks Elman and Jordan, developed in R. For this prediction, data from the period between 2000 and 2015 are used, using the latter for the respective prediction analysis, which is evaluated with performance measures and compared with the ARIMA time series model. For this purpose, the concepts of the types of neural networks will be studied to understand their prediction models. In addition, data normalization is used scaling to maximum and minimum to improve the training and testing set in neurons, supervised learning is used for neuron inputs with the sigmoid activation function and the gradient descent learning rule.\n"}
{"prompt":"Desarrollo de un modelo predictivo basado en algoritmos de aprendizaje de máquina supervisado en pacientes con enfermedades de alto índice de mortalidad y su relación con Covid-19. ->","completion":" PDFCOVID-19 es una enfermedad respiratoria provocada por el coronavirus SARS-CoV-2, los infectados pueden ser asintomáticos o presentar síntomas desde un leve resfriado o hasta padecer del síndrome respiratorio agudo grave. El objetivo de este trabajo de investigación es proponer un modelo predictivo que estime el riesgo de fallecer en pacientes COVID-19. Para realizar el estudio se preparó una base de datos de origen anónimo de pacientes diagnosticados con COVID-19 que fueron atendidos en un Hospital de la ciudad de Guayaquil, con base en la metodología Descubrimiento de Conocimiento en Bases de Datos, además se realizó un análisis estadístico en SPSS, finalmente con el dataset se entrenaron los algoritmos Naive Bayes y Árboles de Decisión para obtener los resultados. El algoritmo Naive Bayes presentó una precisión del 75% mientras el Árbol de Decisión presentó una precisión del 83%. Podemos concluir que el algoritmo Árboles de Decisión obtuvo un mejor rendimiento, lo que indica que esta herramienta basada en Inteligencia Artificial podría ser utilizada por los profesionales de la salud como soporte para ofrecer un diagnóstico oportuno y un tratamiento adecuado. Se recomienda comparar los resultados de diferentes algoritmos para la determinación del que obtenga el mejor rendimiento.COVID-19 is a respiratory disease caused by the SARS-CoV-2 coronavirus, those infected can be asymptomatic or have symptoms ranging from a mild cold or even suffering from severe acute respiratory syndrome. The objective of this research work is to propose a predictive model that estimates the risk of dying in COVID-19 patients. To carry out the study, an anonymous database of patients diagnosed with COVID-19 who were treated at a Hospital in the city of Guayaquil was prepared, based on the Knowledge Discovery in Databases methodology, an analysis was also carried out. Statistical analysis in SPSS, finally with the dataset the Naive Bayes algorithms and Decision Trees were trained to obtain the results. The Naive Bayes algorithm presented a precision of 75% while the Decision Tree presented a precision of 83%. We can conclude that the Decision Trees algorithm obtained a better performance, which indicates that this tool based on Artificial Intelligence could be used by health professionals as a support to offer a timely diagnosis and adequate treatment. It is recommended to compare the results of different algorithms to determine the one with the best performance.\n"}
{"prompt":"Sistema de recomendación de asistencia virtual para farmacias que suministran medicación ante malestares generales por Covid-19 basado en aprendizaje de máquina supervisado por Python. ->","completion":" PDFEl COVID-19, es una enfermedad que ha cobrado muchas vidas, especialmente por personas que se han automedicado, tratando de calmar los malestares ocasionados por el virus, los farmacéuticos, sin tener una herramienta inteligente que pueda predecir un medicamento, recetan lo que ellos ya conocen por experiencia de diversas enfermedades tratadas con anterioridad. El presente proyecto consiste en realizar un sistema de recomendación, basado en aprendizaje de máquina supervisado en Python, utilizando herramientas de Machine Learning mediante algoritmos como Redes neuronales y Árboles de decisiones. Entre los principales objetivos específicos, se encuentran la extracción de un conjunto de base de datos con la información vinculada a los medicamentos que han tomado los pacientes diagnosticados con COVID-19, para después proceder a depurararla y construir un Dataset con las variables relacionadas que sirvan como ayuda. La metodología empleada es “Knowledge Discovery in Databases – K-DD”, el cual se desarrolla en 6 fases: importación y muestreo de datos, calidad de datos, transformación, modelización, evaluación e implementación. Se utilizó la librería sklearn de la herramienta Python para el entrenamiento del algoritmo, la herramienta Stat:Fit para las distribuciones estadísticas, y basándose en la sintomatología del paciente los algoritmos arrojaron un porcentaje de precisión, teniendo el 0.89 de precisión para Redes Neuronales y 0.87% de precisión para Árboles de decisiones. Entre ambos se concluyó que el mejor predictor es el algoritmo de redes neuronales. Se concluyó que existe relación entre los algoritmos de redes neuronales y árboles de decisiones, haciendo que se cumplan las hipótesis planteadas.COVID-19 is a disease that has claimed many lives, especially by people who have self medicated, trying to calm the discomforts caused by the virus, pharmacists, without having an intelligent tool that can predict a drug, prescribe what they already know from experience of various previously treated diseases. This project consists of making a recommendation system, based on supervised Machine Learning in Python, using Machine Learning tools using algorithms such as Neural Networks and Decision Trees. Among the main specific objectives are the extraction of a database set with the information related to the drugs taken by patients diagnosed with COVID-19, and then proceed to refine it and build a Dataset with the related variables that serve as help. The methodology used is “Knowledge Discovery in Databases - K-DD”, which is developed in 6 phases: data import and sampling, data quality, transformation, modeling, evaluation and implementation. The sklearn library of the Python tool was used for the training of the algorithm, the Stat: Fit tool for the statistical distributions, and based on the patient's symptoms, the algorithms yielded a percentage of precision, with 0.89% precision for Neural Networks and 0.87 % precision for Decision Trees. Between the two, it was concluded that the best predictor is the neural network algorithm. It was concluded that there is a relationship between the algorithms of neural networks and decision trees, making the hypotheses raised.\n"}
{"prompt":"Desarrollo de un modelo predictivo basado en algoritmos de aprendizaje automático supervisado en pacientes con diagnóstico de enfermedades de insuficiencia renal en un Centro de Salud Público. ->","completion":" PDFLa enfermedad Insuficiencia Renal (IR) disminuye drásticamente la calidad de vida de quien la padece, este mal está aumentando tanto en los países desarrollados como en los de desarrollo. Por lo que se propone un modelo predictivo de diagnóstico oportuno de la IR mediante el uso de algoritmos supervisados de Machine Learning con la finalidad de que los expertos del área médica puedan tomar mejores decisiones para minimizar el riesgo de la enfermedad en los pacientes. Para lo cual se requirió recopilar información relevante por medios bibliográficos y encuestas a expertos tanto del área de medicina como de sistemas, así como también se necesitó el historial clínico de pacientes de un centro de salud para con estas entrenar el sistema predictivo que utilizan los métodos de Naïve Bayes y árboles de decisiones. Dando todo esto como resultado un sitio web capaz de predecir correctamente si tiene IR a través de sus factores de riesgo a algo más de siete pacientes de cada diez. Se debe tener en consideración que el éxito de predicción aumenta con cada registro de predicción nuevo validado por el médico, ya que este método mantiene un continuo aprendizaje.Renal Insufficiency (RI) drastically decreases the quality of life of those who suffer from it, this disease is increasing in both developed and developing countries. Therefore, a predictive model for the prompt diagnosis of IR is proposed using supervised Machine Learning algorithms in order that experts in the medical area can make better decisions to minimize the risk of the disease in patients. For which it was needed to collect relevant information through bibliographic means and surveys of experts from both the medicine and systems areas, as well as the clinical history of patients from a health center to train the predictive system using the methods Naïve Bayes and Decision Trees. Giving all this as a result, a website capable of correctly predicting if they have IR through their risk factors to just over seven patients out of ten. It should be considered that prediction success increases with each new prediction record confirmed by the doctor, since this method keeps continuous learning.\n"}
{"prompt":"Prototipo de un modelo logístico-inteligente basado en aprendizaje de máquina supervisado, que facilite el acceso oportuno al servicio prehospitalario, en estado de emergencia por Covid-19. ->","completion":" PDFLa llegada del virus COVID-19 al país significó un gran desafío para todas las áreas de trabajo y una de las áreas mayormente afectadas por el virus fue el sistema de salud pública, que debido a la creciente cantidad de llamadas de emergencia relacionadas con COVID-19, los servicios prehospitalarios terminaron por saturarse, a tal punto que hubo un aumento muy significativo en los tiempos de respuesta a las llamadas de auxilio; lo que derivó en resultados fatales, motivo por el cual el presente estudio propone el diseño de un modelo predictivo de servicios prehospitalarios mediante el uso de algoritmos supervisados de aprendizaje de máquina que permita mejorar los tiempos de respuesta en casos de emergencia relacionados con COVID 19, el mismo que por medio del uso de las metodologías de investigación documental y científica se logra obtener las variables relacionadas con los servicios prehospitalarios, permitiendo determinar que los algoritmos a usar en este trabajo serían Random Forest y K NN, teniendo en cuenta que algoritmos aplicar, se realizar la aplicación de las metodologías de desarrollo de prototipo, Knowledge Discovery in Databases (KKD) y Pasos para la Construcción de un Modelo de Machine Learning, las cuales ayudaron al diseño y desarrollo del prototipo, y de esta forma se vuelve posible obtener de manera tangible los resultados del proceso investigativo, llegando a predecir el hospital más cercano al paciente con caso de COVID-19, obteniendo un porcentaje de precisión de 0,996 en el modelo que usa Random Forest y 0.86 en el de K-NN, permitiendo al modelo ser un asistente de apoyo a la toma de decisión del operador automatizando el proceso, por consiguiente, reduciendo el tiempo de respuesta del servicio prehospitalario.The arrival of the COVID-19 virus in the country meant a great challenge for all areas of work and one of the areas most affected by the virus was the public health system, which due to the increasing number of emergency calls related to COVID-19, the pre-hospital services ended up being saturated, to such an extent that there was a significant increase in response times to calls for help; This is the reason why this study proposes the design of a predictive model of pre-hospital services through the use of supervised Machine Learning algorithms to improve response times in emergency cases related to COVID-19, the same that through the use of documentary and scientific research methodologies is achieved to obtain the variables related to pre-hospital services, allowing to determine that the algorithms to be used in this work would be Random Forest and K-NN, Taking into account which algorithms to apply, the application of the prototype development methodologies, Knowledge Discovery in Databases (KKD) and Steps for the Construction of a Machine Learning Model, which helped in the design and development of the prototype, and in this way it becomes possible to obtain in a tangible way the results of the research process, predicting the closest hospital to the patient with COVID 19 case, obtaining an accuracy percentage of 0.996 in the model that uses Random Forest and 0.86 in the K-NN model, obtaining an accuracy percentage of 0.86 in the K-NN model. 86 in the K-NN model, allowing the model to be an assistant to support the operator's decision making, automating the process and consequently reducing the response time of the prehospital service.\n"}
{"prompt":"Algoritmos de aprendizaje no supervisado para la estimación de la resistencia a la insulina y el síndrome metabólico en el adulto mayor de la ciudad de Cuenca ->","completion":" En este trabajo de titulación se explora la Resistencia a la Insulina (RI) y el Síndrome Metabólico (SM) en el Adulto Mayor cuencano desde el punto de vista de métodos de clasificación no supervisada. En el caso de la RI se analizaron cinco métodos de estimación usando una clasificación de K-medias sobre una población de 119 adultos mayores de la ciudad de Cuenca quienes se sometieron a una Prueba Oral de Tolerancia a la Glucosa (POTG) de dos puntos. El algoritmo de K-medias, con K=2 y K=3 fue aplicado en experimentos unidimensionales para los métodos Homa-IR, Quicki, Avignon, Matsuda. Los resultados obtenidos permitieron desarrollar una plataforma de ayuda al diagnóstico de RI y fueron objeto de dos publicaciones (en el IV Congreso de Tecnologías de la Información y Comunicación TIC-EC 2017, y el IEEE ETCM 2017: 2nd IEEE Ecuador Technical Chapters Meeting). Para el estudio del SM usando Self-Organizing Map (SOM) de Kohonen, se analizaron dos tipos de normalización (binaria y por rangos) para las entradas de la red neuronal usando una población de 387 adultos mayores. Los resultados, usando un pre-procesamiento por rangos permiten una mejor clasificación de la población en todos los casos. Este estudio ha permitido seleccionar el tipo de pre-procesamiento para el diagnóstico de SM en la población de adultos mayores de la ciudad de Cuenca usando SOM y fue objeto de una publicación en el V Congreso REDU 2017 y el II Congreso I+D+Ingeniería. Los trabajos futuros están orientados a validar los resultados obtenidos en otras poblaciones de adultos mayores.In this degree work, Insulin Resistance (IR) and Metabolic Syndrome (MS) are explored in the Cuenca‘s elderly population, from the point of view of unsupervised classification methods. In the case of IR, five estimation methods were analyzed using a K-means classification on a population of 119 people older than 65 years old who underwent a two-point Oral Glucose Tolerance Test (OGTT). The K-means algorithm with K = 2 and K = 3 was applied in onedimensional experiments for the Homa-IR, Quicki, Avignon, and Matsuda methods. The results obtained allowed the development of a platform to aid in the diagnosis of IR. These findings were object of two publications (IV Congress of Information and Communication Technologies TIC-EC 2017, and IEEE ETCM 2017: 2nd IEEE Ecuador Technical Chapters Meeting). For the study of MS using Kohonen’s SOM, two types of normalization (binary and by rank) were analyzed for the inputs of the neural network using a population of 387 elderly people. The results, using a pre-processing by ranges allow a better classification of the population in all cases. This study allowed to select the type of pre-processing for the diagnosis of MS in the elderly population of the city of Cuenca using SOM and was the object of a publication in the V Congress REDU 2017 and the II Congress I+D+Ingeniería. The future work is oriented to validate the results obtained in other elderly populations.Ingeniero en Electrónica y TelecomunicacionesCuenca\n"}
{"prompt":"Análisis de validación de un modelo estadístico de regresión logística mediante un algoritmo de aprendizaje de máquina supervisado para predecir la mortalidad en pacientes con fibrilación ventricular. ->","completion":" PDFLa arritmia cardíaca (también llamadas palpitaciones) son problemas en el ritmo cardíaco, que ocurren cuando los impulsos eléctricos que coordinan los latidos cardíacos no funcionan correctamente, lo que hace que el corazón lata de forma rápido, demasiado lento o de una manera irregular. El objetivo del este trabajo es predecir la mortalidad de pacientes por fibrilación ventricular por medio del uso de métodos de inteligencia artificial con el fin de validar la efectividad de un modelo estadístico por lo que se aplicaron algoritmos de machine learning. Para emplear estos modelos inicialmente lo que se ha hecho es descargar una base de datos del repositorio científico kaggle, para lo cual la BD sirvió para el entrenamiento de los algoritmos de machine learning tanto la regresión logística como árboles de decisión para obtener un resultado aproximado. Al comparar los resultados de los algoritmos usados notamos que para nuestra base de datos el Regresión Logística presentó una precisión del 98% mientras que el árbol de decisión presentó una precisión del 100% debido a que se tuvo que emputar casi la mitad de los datos. El algoritmo de árboles de decisión obtuvo un mejor rendimiento, lo que muestra que esta herramienta basada en la inteligencia artificial podría ser usada por profesionales como ayuda para ofrecer diagnósticos oportunos y tratamientos adecuados.Cardiac arrhythmias (also called palpitations) are heart rhythm problems that occur when the electrical impulses that coordinate heartbeats don't work properly, causing the heart to beat too fast, too slow, or in an irregular manner. The objective of this work is to predict the mortality of patients due to ventricular fibrillation through the use of artificial intelligence methods in order to validate the effectiveness of a statistical model for which machine learning algorithms were applied. To initially use these models, what has been done is to download a database from the kaggle scientific repository, for which the database was used to train the machine learning algorithms, both logistic regression and decision trees to obtain an approximate result. When comparing the results of the algorithms used, we noticed that for our database the Logistic Regression presented an accuracy of 98% while the decision tree presented an accuracy of 100% because almost half of the data had to be computed. The decision tree algorithm performed better, showing that this AI-based tool could be used by professionals to help provide timely diagnosis and appropriate treatment.\n"}
{"prompt":"Sistema de reservación de turnos en trabajos mecánicos automotrices con notificación inteligente utilizando la técnica de aprendizaje automático basado en redes neuronales artificiales con datos supervisados ->","completion":" Resumen: Para la realización del trabajo de investigación de un sistema de reservación de turnos en trabajos mecánicos automotrices con notificación inteligente utilizando la técnica de aprendizaje automático basado en redes neuronales artificiales con datos supervisados, se realizó el estudio de varios trabajos que hacen uso de este en la actualidad. La implementación de este se basa en las redes neuronales con datos supervisados haciendo uso del algoritmo de retropropagación (Backpropagation) para dar solución a la problemática planteada en la investigación. Como tecnologías para el desarrollo se utiliza Java como lenguaje de programación, se utiliza PostgreSQL para la gestión de la base de datos de los clientes de la mecánica, como Entorno de Desarrollo Integrado (IDE) NetBeans, por las facilidades que brinda al usarlo con el lenguaje Java. Como metodología que guía el proceso de desarrollo se utiliza XP.\n"}
{"prompt":"Detector de alcoholemia para conductores que analiza variables faciales y ambientales del automóvil mediante el aprendizaje automático supervisado para la reducción de accidentes de tránsito ->","completion":" Desarrollar un detector de alcoholemia para conductores de vehículos que analice el comportamiento facial, cambios de temperatura y la concentración de etanol en el aire del automóvil, mediante el aprendizaje automático supervisado, para disminuir los accidentes de tránsito.En el presente trabajo de titulación se realizará un detector de alcoholemia para conductores que analiza variables faciales y ambientales del automóvil mediante el aprendizaje automático supervisado, con el cual se pretende obtener una herramienta diseñada para la reducción de accidentes de tránsito a causa de conductores que se encuentran en estado etílico, el proyecto se encuentra desarrollado en base a la metodología del modelo en V con el cual se establecen los parámetros y funciones que se deben cumplir en cada una de sus fases que dará como resultado un modelado eficiente del sistema. Dicho modelamiento se encuentra desarrollado en dos etapas, la primera tiene la finalidad recolectar la temperatura facial, diámetro de la pupila y nivel de alcohol en el aliento del conductor para crear un conjunto de datos que serán utilizados para el entrenamiento del algoritmo de aprendizaje automático supervisado basado en la clasificación del árbol de decisión, la segunda etapa del sistema verifica el estado del conductor haciendo uso del algoritmo mencionado cuyo resultado determinará si el vehículo se enciende o no; el sistema es sometido a pruebas de funcionabilidad con diferentes sujetos en diferentes estados etílicos y sobrios cuyos resultados demuestran la factibilidad del sistema y a su vez mediante un análisis de costo beneficio se demuestra la rentabilidad del proyecto.\n"}
{"prompt":"Detectar accesos no autorizados tempranos a través del análisis de pistas de auditoria generadas por la plataforma SIIPNE3W de la Policía Nacional usando aprendizaje automático ->","completion":" Los delitos informáticos cada vez son más frecuentes en la actualidad, uno de dichos delitos constituye el acceso no consentido a un sistema informático el cual ha tenido un crecimiento notable de denuncias en los últimos años. El objetivo del presente proyecto es predecir éste tipo de accesos inusuales a través del análisis de información de las pistas de auditoria de la plataforma SIIPNE3w de la Policía Nacional del Ecuador haciendo uso de herramientas de Aprendizaje Automático. El propósito del estudio es comparar algoritmos de clasificación supervisado y no supervisado, su precisión\/sensibilidad en la detección de anomalías (accesos no autorizados o inusuales) para determinar cuál otorga mejor resultado. Los algoritmos elegidos incluyen: árbol de decisiones y bosque de aislamiento. El etiquetado de datos necesario para el algoritmo supervisado se lo alcanzó utilizando clúster k-means. Para una adecuada gestión se utilizan el estudio de caso como metodología de investigación y CRISP-DM para el desarrollo de los modelos de aprendizaje. Como resultado se obtiene que la etiquetación de datos juega un papel importante al momento de la clasificación para los algoritmos supervisados, además que el algoritmo de bosque de aislamiento nos brinda mejor resultado de clasificación para el caso que se estudia.\n"}
{"prompt":"Diseño de un modelo predictivo-asistencial de pacientes infectados por Covid-19, mediante un modelo supervisado de Machine Learning basado en criterios de derivación hospitalaria o ambulatoria. ->","completion":" PDFUn problema derivado de la pandemia del COVID-19 es la falta de una herramienta digital que pueda predecir la intensidad de la gravedad de un paciente enfermo. El presente proyecto consiste en realizar un modelo predictivo asistencial para pacientes infectados por COVID-19, utilizando herramientas de Machine Learning mediante algoritmos de aprendizaje supervisado como Naive Bayes y Random Forest para obtener un criterio sobre derivación hospitalaria o ambulatoria. Entre los principales objetivos específicos se encuentran la extracción de un conjunto de base de datos con la información vinculada al historial médico de los pacientes diagnosticados con COVID-19, para la depuración y construcción de un dataset con las variables relacionadas, y evaluarlas para mejorar la toma de decisiones a partir de un modelo de algoritmo supervisado. La metodología empleada es “Knowledge Discovery in Databases – KDD”, la cual se desarrolla en 6 fases: importación y muestreo de datos, calidad de datos, transformación, modelización, evaluación e implementación; sin embargo, esta última fase no se llevará a cabo, en su lugar se realizará un prototipo desarrollado a nivel de Python. Se utilizó la librería sklearn de la herramienta Python 3.5 para el entrenamiento del algoritmo, la herramienta STAT:FIT para las distribuciones estadísticas, y basándose en la sintomatología del paciente los algoritmos arrojaron un porcentaje de precisión (93,5% Random Forest y 95% Naive Bayes), concluyendo que el mejor predictor es el algoritmo de Naive Bayes, también se demostró que existe relación entre ambos algoritmos con respecto a la derivación hospitalaria o ambulatoria mediante el análisis de correlación de Pearson, haciendo que se cumplan las hipótesis planteadas. Al ser útil este prototipo para la toma de decisiones para la respectiva derivación del paciente, los beneficiarios directos son los doctores, dado que obtienen una herramienta que les agilitará la exhaustiva acción de decidir.A problem derived from the COVID-19 pandemic is the lack of a digital tool that can predict the severity of a sick patient. The present project consists of carrying out a predictive model of care for patients infected by COVID-19, using Machine Learning tools using supervised learning algorithms such as Naive Bayes and Random Forest to obtain criteria on hospital or outpatient referral. Among the main specific objectives are the extraction of a set of databases with the information related to the medical history of patients diagnosed with COVID-19, for the purification and construction of a dataset with the related variables and evaluate them to improve the decision making based on a supervised algorithm model. The methodology used is \"Knowledge Discovery in Databases - KDD\", which is developed in 6 phases: import and data sampling, data quality, transformation, modeling, evaluation and implementation; however, this last phase will not be carried out, instead a prototype developed at the Python level will be made. The sklearn library of the Python 3.5 tool was used for the training of the algorithm, the STAT::FIT tool for the statistical distributions, and based on the patient's symptoms, the algorithms yielded a percentage of precision (93.5% Random Forest and 95% Naive Bayes), concluding that the best predictor is the Naive Bayes algorithm, it was also shown that there is a relationship between both algorithms with respect to hospital or outpatient referral by means of Pearson's correlation analysis, making the hypotheses raised. As this prototype is useful for decision-making for the respective referral of the patient, the direct beneficiaries are the doctors, since they obtain a tool that will expedite the exhaustive decision making action.\n"}
{"prompt":"Análisis y diseño de un sistema para identificar signos de retinopatía hipertensiva a través de imágenes de retina, aplicando la tecnología de deep learning ->","completion":" PDFEste proyecto plantea un prototipo de inteligencia artificial mediante la creación de un algoritmo para el limitante tecnológico en el área de la oftalmología, que es la detección manual de la retinopatía hipertensiva. Su finalidad es predecir mediante imágenes si una persona tiene o no la enfermedad. Para la creación de este sistema se decidió por la metodología de prototipado ya que tiene etapas funcionales que sirven para la creación del mismo. Se trabajó con la tecnología de aprendizaje supervisado mediante deep Learning y redes neuronales convolucionales. Se utilizó la base de datos de kaggle para la obtención y estudio de imágenes de retinas. Debido a que las imágenes tenían tamaños diferentes y ruidos dentro de ellas, se procedió a realizar un pre-procesamiento en las retinografías. Después de procesadas estas imágenes se pasan a una red neuronal de dos clases donde se estudia las características mínimas, que para una persona puede llevar años de estudios. Se dio solución a varias pruebas de sobre-entrenamiento que se presentaron en las verificaciones. Al final se llegó a obtener un prototipo con una interfaz gráfica y amigable al usuario, que detecta si una persona tiene RHTA. Además de esto, el proyecto guarda las imágenes para llevar un control de los pacientes para una futura prevención de la enfermedad. Los recursos tecnológicos requeridos deben ser de alto rendimiento, se aconseja una máquina con GPU NVIDIA. Este proyecto busca que personas del Ecuador incursionen en el mundo de la inteligencia artificial y Big Data, ya que ahora son predicciones en imágenes de retina pero mañana podrían ser fotografías de pulmones, cerebro o corazones, que ayuda a las personas a prevenir la enfermedad.This project proposes a prototype of artificial intelligence through the creation of an algorithm for the technological limitation in the area of ophthalmology, which is the manual detection of hypertensive retinopathy. Its purpose is to predict by images if a person has the disease or not. For the creation of this system, it was decided by the prototyping methodology since it has functional stages that serve to create it. We worked with the technology of supervised learning through deep Learning and convolutional neural networks. Data bases such as kaggle were used to obtain and study retinal images. Because the images had different sizes and noises within them, we proceeded to pre-process the retinographies. After processing these images are passed to a neural network of two classes where the minimum characteristics are studied, which for a person can take years of studies. A solution was given to several over-training tests that were presented in the verifications. In the end it was possible to obtain a prototype with a user-friendly graphical interface, which detects if a person has RHTA. In addition to this, the project saves the images to keep track of the patients for a future prevention of the disease. The technological resources required must be high performance, we recommend a NVIDIA GPU machine. This project seeks that people from Ecuador venture into the world of artificial intelligence and Big Data, since now they are predictions in retina images but tomorrow could be photographs of lungs, brain or hearts, which helps people to prevent the disease.\n"}
{"prompt":"Modelo para la detección y mitigación de ataques de suplantación de identidad, utilizando aprendizaje automático ->","completion":" El continuo surgimiento de nuevas tecnologías ha ocasionado el incremento en la delincuencia cibernética. Estos ciberataques se han convertido en amenazas graves, dando origen a nuevos malware o programas con código malicioso, en donde utilizan técnicas de Ingeniería Social con el fin de robar o destruir datos importantes. Por tal razón, los ciberdelincuentes aprovechan la ingenuidad de las personas para robar información confidencial, esto ha generado el incremento de fraudes durante los últimos cinco años. Frente a este escenario el presente proyecto se enfoca en el desarrollo de un modelo para la detección y mitigación de ataques de suplantación de identidad utilizando técnicas de Machine Learning. Cabe mencionar que el desarrollo se realizó en un ambiente controlado para garantizar la seguridad del entorno. Para la generación de correos infectados se extrajeron enlaces maliciosos de PhishTank. De modo que se realizó la extracción de las características de los correos para la fase de entrenamiento utilizando el algoritmo Naive Bayes. Luego se detectaron los correos infectados mediante el algoritmo de Árboles de Decisión con la finalidad de enviar a cuarentena los correos ilegítimos. Por último, se validó con los algoritmos de ML Random Forest, Regresión Logística y Clasificador Ficticio, con la finalidad de conocer el porcentaje de precisión en la detección de phishing de la solución propuesta en comparación con otros algoritmos de aprendizaje supervisado.\n"}
{"prompt":"Modelo basado en aprendizaje de máquina supervisado, para el análisis de datos cardiovasculares y su aplicación en el diagnóstico y pronóstico médico mediante el uso de una página Web dinámica. ->","completion":" PDFLas enfermedades cardiovasculares son un problema de la salud pública en el Ecuador y todo el mundo, por lo que este trabajo investigativo propone el diseño de un modelo computacional de clasificación a través del uso de técnicas de machine learning, hemos optado por trabajar con el aprendizaje automático apoyado en un modelo probabilístico que permita evaluar los factores de riesgo de las enfermedades cardiovasculares. Este modelo está basado en Redes Bayesianas, que, en base a los factores de riesgo de la enfermedad, mostrará como resultado el porcentaje que tiene el paciente de contraer la misma. Se aplicó la metodología de investigación documental que aporte con el conocimiento necesario para la realización de este proyecto en el cual se realizaron pruebas para verificar el comportamiento de cada una de las variables utilizadas en el modelo probabilístico, el cual brindará resultados eficientes y en un corto periodo de tiempo siendo así una herramienta de apoyo en la toma de decisiones a los expertos y aportando con el diagnóstico oportuno para prevenir la enfermedad.Cardiovascular diseases are a public health problem in Ecuador and around the world, so this research project proposes the design of a computational classification model through the use of machine learning techniques, we have chosen to work with learning automatic based on a probabilistic model that allows to evaluate the risk factors of cardiovascular diseases. This model is based on Bayesian Networks, which, based on the risk factors of the disease, determined as a result the percentage that the patient has of contracting it. The documentary research methodology that provides the necessary knowledge to carry out this project was applied in which tests were carried out to verify the behavior of each of the variables used in the probabilistic model, which will provide efficient results and in a short period of time being thus a support tool in the decision making of the experts and contributing with the opportune diagnosis to prevent the disease\n"}
{"prompt":"Desarrollo de aplicativo web basado en máquinas de vectores de soporte(svm) de aprendizaje supervisado para la predicción en la recomendación de cultivos mediante datos ambientales para fincas agroecológicas del cantón La Maná, provincia de Cotopaxi. ->","completion":" At present, artificial intelligence applied in the agricultural field follows a very successful trend in several areas within precision agriculture, including the detection of plant diseases and the prediction of plantations, to achieve these goals high-precision data and information and effective methods for an assessment of soil states are required. There are elements that must be taken into account, such as environmental variables, soil elements and PH; thus, becoming of great importance since there are large quantities of crops such as fruits and vegetables, which can reproduce with greater intensity depending on the description and characteristics of the soil for that planting. The present research project aims to make predictions of crop planting on agro ecological farms using supervised learning machine learning techniques and artificial intelligence models such as vector support machines (SVM), which will allow through an API to process the entry of environmental data to predict if the soil where the planting will take place is suitable for a certain crop through a web application which contains SVM models. Thanks to the development of this web application, technology is provided to the farmer to correctly execute the planting of his production that he requires in the future.En la actualidad, la inteligencia artificial aplicada en el campo agrícola sigue una tendencia de gran éxito en varias áreas dentro de la agricultura por precisión lo cual incluyen como la detección de enfermedades de las plantas y predicción de siembras, para lograr estos objetivos se debe contar con datos e información de alta precisión y se requiere métodos eficaces para una evaluación de los estados de suelo. Existe elementos que se deben tener en cuenta, como las variables ambientales, elementos del suelo y PH; convirtiéndose así de gran importancia que existe grandes cantidades de cultivos para como son los frutos y vegetales, lo cual pueden reproducirse con mayor intensidad en base a la descripción y características del suelo para esa siembra. El presente proyecto de investigación tiene como objetivo realizar predicciones de siembra de cultivos en fincas agroecológicas mediante técnicas machine learning de aprendizaje supervisado y modelos de inteligencia artificial como las máquinas de vectores de soporte (SVM) , lo que permitirá mediante una API procesar el ingreso de datos ambientales para predecir si el suelo donde se va realizar la siembra es el indicado para un determinado cultivo mediante una aplicación web que contiene modelos de inteligencia artificial de tipo SVM. Gracias al desarrollo de esta aplicación web se contribuye con tecnología al agricultor para que ejecute de manera correcta la siembra de su producción que requiera a futuro.\n"}
{"prompt":"Una revisión del aprendizaje profundo aplicado a la ciberseguridad ->","completion":" Este estudio presenta una descripción general sobre la ciberseguridad desde la perspectiva de las redes neuronales y técnicas de aprendizaje profundo de acuerdo con las diversas necesidades actuales en ambientes de seguridad informática. Se discute la aplicabilidad de estas técnicas en diversos trabajos de ciberseguridad, como detección de intrusos, identificación de malware o botnets, phishing, predicción de ciberataques, denegación de servicio, ciberanomalías, entre otros. Para este estudio se aplicó el método analítico-sintético que sirvió para identificar soluciones óptimas en el campo de la ciberseguridad. Los resultados destacan y recomiendan algoritmos aplicables a la seguridad cibernética como base de conocimiento y facilidad para investigaciones futuras dentro del alcance de este estudio en el campo. Esta investigación sirve como punto de referencia y guía para la academia y los profesionales de las industrias de la seguridad cibernética desde el punto de vista del aprendizaje profundo.\n"}
{"prompt":"Clasificación de sílabos académicos en base a redes neuronales de aprendizaje profundo ->","completion":" A fin de facilitar la homologación de créditos entre las universidades del país, se requiere automatizar la clasificación de sílabos en áreas y subáreas. Esta investigación tiene como objetivo clasificar los sílabos mediante la técnica de redes neuronales conectadas de aprendizaje profundo, a través de una combinación de número de capas, funciones de activación, tamaños y épocas de entrenamiento. Este modelo fue comparado con respecto a algoritmos basados en Support Vector Machine (SVM), Naive Bayes y Árboles de decisión. Los resultados demostraron que el modelo de aprendizaje profundo propuesto fue superior en 1.4% con respecto a Naive Bayes, 6.2% con respecto a SVM y 7.2% con respecto a Árboles de decisiónIngeniero en Sistemas y Telemática\n"}
{"prompt":"Desarrollo de controladores con redes neuronales de aprendizaje profundo aplicando tensorflow ->","completion":" En el presente proyecto se desarrollaron algoritmos de redes neuronales usando la librería TensorFlow, para la solución de aplicaciones básicas como el problema XOR, el cual no es separable linealmente, la identificación de una función sencilla (z=x^2+y^2). Por medio de las redes neuronales que se pueden entrenar usando esta herramienta también se realiza la identificación, control neuronal inverso y control neuronal con modelo de referencia lineal de sistemas dinámicos (Antena con péndulo invertido, Tanques Acoplados, Viga y Bola). Las redes neuronales fueron diseñadas y entrenadas en el lenguaje de Python y luego exportados a MATLAB R2017b. Las redes se han entrenado usando aprendizaje supervisado e implementando varias funciones de activación en cada una de sus capas, principalmente “ReLU”. Para el desarrollo y para la trasferencia entre Python y MATLAB del modelo entrenado, se usa una API (Application Programming Interface) la cual es Keras, y Deep Learning Toolbox Importer for Tensorflow-Keras Models. Para la simulación de los modelos entrenados se usa Simulink de MATLAB.\n"}
{"prompt":"Un enfoque de aprendizaje profundo para estimar la frecuencia respiratoria del fotopletismograma ->","completion":" Este trabajo presenta una metodología para entrenar y probar una red neuronal profunda (Deep Neural Network – DNN) con datos de fotopletismografías (Photoplethysmography – PPG), con la finalidad de llevar a cabo una tarea de regresión para estimar la frecuencia respiratoria (Respiratory Rate – RR). La arquitectura de la DNN está basada en un modelo utilizado para inferir la frecuencia cardíaca (FC) a partir de señales PPG ruidosas. Dicho modelo se ha optimizado a través de algoritmos genéticos. En las pruebas realizadas se usaron BIDMC y CapnoBase, dos conjuntos de datos de acceso abierto. Con CapnoBase, la DNN logró un error de la mediana de 1,16 respiraciones\/min, que es comparable con los métodos analíticos reportados en la literatura, donde el mejor error es 1,1 respiraciones\/min (excluyendo el 8 % de datos más ruidosos). Por otro lado, el conjunto de datos BIDMC aparenta ser más desafiante, ya que el error mínimo de la mediana de los métodos reportados en la literatura es de 2,3 respiraciones\/min (excluyendo el 6 % de datos más ruidosos). Para este conjunto de datos la DNN logra un error de mediana de 1,52 respiraciones\/min.\/\/This article describes the methodology used to train and test a Deep Neural Network (DNN) with Photoplethysmography (PPG) data performing a regression task to estimate the Respiratory Rate (RR). The DNN architecture is based on a model used to infer the heart rate (HR) from noisy PPG signals, which is optimized to the RR problem using genetic optimization. Two open-access datasets were used in the tests, the BIDMC and the CapnoBase. With the CapnoBase dataset, the DNN achieved a median error of 1.16 breaths\/min, which is comparable with analytical methods in the literature, in which the best error found is 1.1 breaths\/min (excluding the 8 % noisiest data). The BIDMC dataset seems to be more challenging, as the minimum median error of the literature’s methods is 2.3 breaths\/min (excluding 6 % of the noisiest data), and the DNN based approach achieved a median error of 1.52 breaths\/min with the whole dataset.\n"}
{"prompt":"Análisis de imágenes de Rayos-X de COVID-19 usando aprendizaje profundo. ->","completion":" PDFExisten diversas formas de detectar el covid-19, de manera estándar con la prueba PCR, obtenida habitualmente de secreciones nasales, o a través de imágenes, siendo usadas para apoyar los resultados obtenidos por la prueba estándar. Las afecciones por covid-19 deja evidencias radiológicas de neumonía visibles bajo los rayos-x, ya que, produce sombras en los pulmones, por lo cual, el objetivo de la investigación es analizar las imágenes de radiografías torácicas usando técnicas de aprendizaje profundo para el diagnóstico de pacientes con covid-19. La modalidad del trabajo es 30% campo y 70% investigativa. Se realizaron 2 modelos de redes neuronales convolucionales pre-entrenados con las arquitecturas vgg-16 e Inception v3, los cuales fueron desarrollados en Google Colab, estos fueron entrenados con dos conjuntos de datos, el primero fue la unión de dos dataset obtenidos de la plataforma Kaggle y el segundo conjunto de datos fue referenciado de otra tesis con el fin de realizar comparaciones entre el modelo propuesto en dicha tesis, con los modelos planteados en el presente trabajo de investigación, se observó el comportamiento de los modelos siendo entrenados con grandes y pequeñas cantidades de datos, dando los siguientes resultados: para el primer dataset el modelo que obtuvo mayor precisión y exhaustividad fue el modelo Inception v3, y para el segundo conjunto de datos el modelo que obtuvo mejores resultados fue el que usó la arquitectura vgg-16.There are several ways to detect covid-19, as standard with the PCR test, usually obtained from nasal secretions, or through imaging, being used to support the results obtained by the standard test. Covid-19 conditions leave radiological evidence of pneumonia visible under x-rays, as it produces shadows in the lungs, therefore, the objective of the research is to analyze the images of chest x-rays using deep learning techniques for the diagnosis of patients with covid-19. The modality of the work is 30% field and 70% investigative. 2 models of pre-trained convolutional neural networks were performed with the vgg-16 and Inception v3 architectures, which were developed in Google Colab, these were trained with two data sets, the first was the union of two datasets obtained from the Kaggle platform and the second set of data was referenced from another thesis in order to make comparisons between the model proposed in this thesis, with the models proposed in this research work, the behavior of the models was observed being trained with large and small amounts of data, giving the following results: for the first dataset the model that obtained greater accuracy and completeness it was the Inception v3 model, and for the second dataset the model that obtained the best results was the one that used the vgg-16 architecture.\n"}
{"prompt":"Desarrollo de un sistema de control de acceso de personal empleando reconocimiento facial respaldado con técnicas de aprendizaje profundo ->","completion":" El presente proyecto de investigación consiste en el desarrollo de un sistema de detección y reconocimiento facial automatizado por medio de técnicas de aprendizaje profundo, mejorado como una aplicación para el registro de personal al ingresar a la zona o área de trabajo, a través de la visión por computadora, un sub-campo de aplicación de la Inteligencia artificial. Para detectar y alinear el rostro se utilizó algoritmos de aprendizaje profundo como MTCNN y un modelo desarrollado por el marco de trabajo MXNET, denominado RetinaFace pero al ser multiplataforma se lo usará en PyTorch, estos modelos nos permiten ajustar a los usuarios al sistema para realizar el control de identificación por medio de reconocimiento facial. Una vez detectado el rostro mediante los modelos antes mencionados, se obtiene las coincidencias más cercanas a los rostros ajustados al sistema realizando el reconocimiento y obteniendo su registro de ingreso\/ salida de su área de trabajo, este proceso lo realiza Facenet, el cual es un modelo pre entrenado que permite identificar al usuario registrado en el sistema. Se agregó un algoritmo de anti-plagio, denominado algoritmo de la vida, el cual cumple la función de detectar la imitación de rostros y evitar la vulnerabilidad al momento de reconocer a una persona ajustada al sistema mediante una foto o un video. Se desarrolla una interfaz web con un servidor local denominado Flask, Cabe mencionar que todo el sistema de reconocimiento facial se lo realiza en tiempo real y con un par de fotos por cada usuario registrado, siendo esta característica fundamental ya que no se necesita un set grande de fotos por cada usuario que se registre al sistema.\n"}
{"prompt":"Implementación de un prototipo para contar personas en video capturado en tiempo real utilizando técnicas de aprendizaje profundo ->","completion":" El desarrollo de dispositivos de visión artificial para la detección y seguimiento de objetos en video requiere la utilización de algoritmos complejos implementados en sistemas computacionales de alto rendimiento. Aunque existen un sinnúmero de técnicas holísticas y de machine learning utilizadas para la detección de objetos, hoy en día, la tendencia es utilizar nuevas técnicas de procesamiento de imágenes y video basadas en redes neuronales convolucionales, con las cuales se han logrado mejores resultados en cuanto a la confiabilidad de la detección y el tiempo de procesamiento. En este trabajo se implementó un prototipo para realizar el conteo de personas entrelazando un algoritmo de detección de objetos pre entrenado Single Shot Detection (SSD) de MobilNet con un algoritmo de seguimiento de objetos basado en la estimación del centroide, operando en un hardware dedicado de Nvidia Jetson Tx1. La programación del prototipo se realiza utilizando librerías de Python y OpenCV bajo el entorno del sistema operativo linux Ubuntu instalados en la tarjeta Nvidia. En la evaluación del contador de personas se evidencia el equilibrio logrado entre la rapidez, la precisión y el costo computacional del prototipo funcionando en tiempo real bajo un escenario con ambiente de luz natural y luz artificial con resultados muy aceptables.\n"}
{"prompt":"Diseño y desarrollo de un sistema prototipo para reconocimiento automático del hablante empleando técnicas de aprendizaje profundo ->","completion":" Este proyecto pretende sentar las bases de un sistema con un potencial a desarrollar, utilizado para un nivel más alto de seguridad basándonos en características de la voz humana como frecuencia fundamental, Coeficiente de frecuencias ceptrales de Mel, entre otros parámetros que pueden ser extraído con el análisis de una espectro de frecuencia.This project aims to lay the foundations for a system with a potential to develop, used for a higher level of security based on characteristics of the human voice such as fundamental frequency, Mel's Coefficient of ceptral frequencies, among other parameters that can be extracted with the analysis of a frequency spectrum.\n"}
{"prompt":"Aplicación de ‘aprendizaje profundo’ para el pronóstico de precipitación a partir de datos de reflectividad de radar meteorológico ->","completion":" Los estudios publicados sobre el pronóstico de lluvia utilizando técnicas de Aprendizaje Profundo en la región de América del Sur son muy escasos. Las redes de monitoreo hidrometeorológicas disponibles, por lo general redes de pluviómetros, no han proporcionado datos suficientes para lograr resultados satisfactorios en la predicción de estos patrones (Bendix et al., 2017). En este trabajo se aplican técnicas de Aprendizaje Profundo para enfrentar la problemática. Existiendo en Ecuador una red de radares meteorológicos, RadarNet-Sur, se encontró la posibilidad de aplicar dichas técnicas para el análisis de la información recogida por la red y proponer una metodología para el pronóstico de lluvia. La metodología presentada consta de tres pasos, predicción de imágenes de radar con técnicas de Aprendizaje Profundo, transformación de la salida del primer paso a términos de precipitación, e, interpretación de los resultados obtenidos. Los resultados se prestan a discusión de cómo mejorar la calidad de la predicción obtenida. Esto, a pesar de trabajar con un conjunto de datos limitado, permite la discusión de la factibilidad de usar Aprendizaje Profundo para reproducir la dinámica de movimiento de nubes y pronóstico inmediato de lluvia aunque existe amplia posibilidad de mejorar el modelo en caso de trabajar con un conjunto de datos más grande. Sin embargo, el modelo no es aplicable inmediatamente debido a que el mismo no aprende la totalidad de relaciones y patrones existentes para el conjunto de prueba. Por esto se discuten algunas soluciones a realizar en trabajos futuros que podrían mejorar notablemente el rendimiento del modelo.The studies published on rain forecasting in the South American region using Deep Learning techniques are very scarce. The available hydrometeorological monitoring networks, usually rain gauge networks, have not provided sufficient data to achieve satisfactory results in the prediction of these patterns (Bendix et al., 2017). In this work, Deep Learning techniques are applied to face this problem. Using information collected from a network of meteorological radars that exist in Ecuador, RadarNet-Sur, this work applies deep learning techniques to the mentioned information and proposes a methodology for rain forecasting. The methodology presented consists of three steps, radar image prediction with Deep Learning techniques, a transformation of the former’s output to precipitation terms, and, interpretation of the results obtained. The results lend themselves to a discussion of how to improve the quality of the prediction obtained. This, despite working with a limited data set, so that there is a possibility of improving the model if working with a representative set. However, the model is not immediately applicable because it does not learn all the existing relationships and patterns for the test set. This is why some solutions to be carried out in future works are discussed that could significantly improve the performance of the model.Ingeniero de SistemasCuenca\n"}
{"prompt":"Rendimiento de RaspberryPi con Intel_NCS ejecutando métodos de aprendizaje profundo neuronal en clasificación de tipo de vehículos en tiempo continuo ->","completion":" La clasificación de tipo de vehículos y su conteo en las calles de una ciudad, ayuda a tomar decisiones respecto a la construcción y ampliación de vías, cuantificación del tráfico y necesidades de ciclo vías. Sin embargo, se requiere de un sistema automático que realice esta clasificación de forma continua en un flujo de video. El objetivo de esta investigación es reportar el rendimiento de dos métodos de detección y clasificación de actores de movilidad basados en Deep Neural Networks (DNN) ejecutándose en un Raspberry Pi 3B+, permitiendo identificar el modelo que brinda mayor precisión con menor consumo de recursos. Se comparó You Only Look Once v3 (YOLO v3) y Single Shot MultiBox Detector (SSD). Los resultados demuestran que SSD es la mejor alternativa siendo hasta trece veces más veloz que YOLO v3. Durante la ejecución del sistema utilizando el Intel Neural Compute Stick 2 con SSD se tiene un consumo promedio del CPU del Raspberry Pi 3B+ del 10% y 15% de memoria RAM. El valor de referencia de mAP para SSD es del 72.7%.Ingeniero en Sistemas y Telemática\n"}
{"prompt":"Diseño e implementación de un sistema virtual de detección de la pose 3D de un objeto mediante técnicas de aprendizaje profundo para aplicaciones robóticas. ->","completion":" El presente proyecto realiza el diseño de un sistema virtual detector de la pose 3D de objetos mediante técnicas de aprendizaje profundo para aplicaciones robóticas, esto con el fin de proveer una herramienta académica-práctica a los estudiantes en su educación virtual. Se plantea una arquitectura del sistema virtual manejada en cuatro etapas, desde la generación de un conjunto de datos mediante el enfoque de imágenes sintéticas fotorrealistas y de aleatorización de dominio. La siguiente etapa hace referencia al método de aprendizaje profundo para el entrenamiento de redes neuronales convolucionales sobre el marco de aprendizaje Pytorch previa la selección de hiperparámetros que permiten a la red realizar una abstracción de las características del objeto. La tercera etapa integra el detector de pose 3D para conseguir los valores de posición y orientación del objeto en tiempo real, la inferencia del detector trabaja sobre imágenes publicadas por el entorno virtual o en tiempo real desde la cámara web del ordenador. Finalmente, se realiza la comunicación de estas etapas mediante sistemas operativos de robots para el envío de los resultados obtenido por el detector hacia el brazo robótico Mitsubishi RV-2SDB previo el cálculo de su configuración de cinemática inversa para la ejecución de la aplicación de recoger y colocar objetos en el entorno virtual. Los resultados obtenidos en la detección de pose indican buenos resultados en imágenes del mundo exterior con datos sintéticos como en el agarre de objetos sobre el entorno virtual, con un buen grado de satisfacción e interés por los usuarios de destino.ESPEL\n"}
{"prompt":"Implementación de un prototipo de sistema autónomo de visión artificial para la detección de objetos en video utilizando técnicas de aprendizaje profundo ->","completion":" Hoy en día la visión por computador o visión artificial es un campo con diversas aplicaciones en areas tales como la seguridad ciudadana, instrumentación médica, líneas de procesos industriales, actividades militares, etc. El uso de algoritmos y técnicas de visión artificial basadas en machine learning y deep learning están haciéndose cada vez más populares por cuanto ya existen a la mano computadores pequeños con gran capacidad de procesamiento tales como los arduinos, raspherry, nvidia y otros. El objetivo de este proyecto es implementar un pequeño prototipo de sistema autónomo de visión artificial capaz de detectar autos y personas en video capturado en tiempo real cuyo detector se basa en el algoritmo YOLOv3 en la versión AlexeyAB-Darknet corriendo sobre una placa de hardware de alto rendimiento NVIDIA Jetson TX2 y un framework basado en Linux-Python-OpencvTensor-Cuda. YOLOv3 es un algoritmo pre-entrenado para detectar ochenta objetos, sin embargo, para propósito de este trabajo, el detector ha sido configurado para mostrar personas y autos livianos. En las pruebas realizadas en el prototipo, se alcanzó una tasa de acierto superior al noventa por ciento con YOLOv3 en la versión completa, aunque la velocidad de procesamiento del detector resultó inferior comparada con la versión liviana del mismo algoritmo al probarse con videos pregrabados y también en videos capturados en tiempo real a través de una webcam conectada en el prototipo\n"}
{"prompt":"Modelo predictivo de fallas en alimentadores primarios de concesión de la Empresa Eléctrica Regional Centro Sur usando aprendizaje profundo de máquina ->","completion":" Este trabajo de titulación propone la predicción de interrupciones no programadas en alimentadores primarios de concesión de la Empresa Regional Centro Sur C.A. (CENTROSUR) usando Aprendizaje Profundo de Máquina. El modelo, basado en redes neuronales, ha sido poco explorado en la industria de la distribución de energía eléctrica, tanto en el ámbito local como internacional. Para la elaboración del modelo, se recopilaron y analizaron datos históricos de la empresa de los últimos cinco años con información de las interrupciones no programadas. La validación del modelo computacional de predicción se realizó usando información del alimentador #521 de la Subestación (S\/E) 5 de la CENTROSUR, que es donde se evidencia la mayor incidencia de fallas.This work proposes the forecasting of failures in primary feeders of Empresa Eléctrica Regional Centro Sur C.A. (CENTROSUR) using Deep Learning. The model, based on neural networks, has not been wide explored in the electricity distribution industry, both locally and internationally. For the development of the model, the company’s historical data from the last five years about failures was collected and analyzed. The validation of the forecasting model was performed using data from the #521 primary feeder of the Substation (S\/E) 5 of CENTROSUR, where the highest incidence of faults is evidenced.Ingeniero EléctricoCuenca\n"}
{"prompt":"Comparativas de métricas de modelos de aprendizaje profundo para el pronóstico de consumo energético del edificio de la Facultad de Ciencias Matemáticas y Físicas considerando series de tiempo. ->","completion":" PDFActualmente Ecuador está experimentando un aumento en el uso de energía en áreas residenciales como resultado del crecimiento de la población, que va acompañado de un aumento en los costos de energía. Los sistemas de control predictivo son uno de los enfoques que se han considerado cuando se requieren predicciones de consumo de alta precisión. El objetivo del proyecto de títulación es utilizar técnicas de aprendizaje profundo para predecir el comportamiento de uso de energía de la Facultad de Ciencias Matemáticas y Físicas, así como utilizar métricas de regresión para evaluar cada modelo. El método a utilizar es experimental y hace uso de un conjunto de datos de marzo a octubre 2021 que contiene variables de energía, temperatura y humedad para el edificio FCMF-UG, con estos dos últimos agrupados por niveles FCMF. Se probará con tres arquitecturas de redes neuronales: LSTM, GRU y MLP, y se considerarán situaciones con diversos horizontes pronósticos. Como resultado, el modelo MLP ocupa el primer lugar según la comparativa de métricas analizadas y los tiempos de ejecucion computacional.Currently, Ecuador is experimenting an increase in energy use in residential areas as a result of population growth, which is accompanied by an increase in energy costs. Predictive control systems are one of the approaches that have been considered when high-precision consumption predictions are required. The aim of the current degree project is to use deep learning techniques to predict the behaviour of energy use from the Faculty of Mathematical and Physical Sciences, as well as to use regression metrics to evaluate each model. The method to be used is experimental, and it makes use of a dataset from March to October 2021, which contains energy, temperature, and humidity variables for the FCMF-UG building, with the latter two grouped by FCMF levels. It will be tested with three neural network architectures: LSTM, GRU, and MLP, and situations with various prognostic horizons will be considered. As a result, the MLP model ranks first according to the comparison of analyzed metrics and computational execution times.\n"}
{"prompt":"Reconocimiento de expresiones faciales a través de un análisis de patrones de movimientos musculares faciales por medio de técnicas de aprendizaje profundo ->","completion":" Desarrollar un sistema electrónico de reconocimiento de expresiones faciales basado en técnicas de aprendizaje profundo que permita determinar seis emociones básicas en personas con limitada movilidad por medio de una aplicación en tiempo real que valide el funcionamiento.El presente proyecto consiste en el desarrollo de SIREF, el cual es un sistema electrónico para el reconocimiento de expresiones faciales a través de un análisis de patrones de movimientos musculares por medio de técnicas de aprendizaje profundo (DL), el objetivo principal es reconocer seis emociones básicas en personas con limitada movilidad, por medio de una aplicación en tiempo real que valide el funcionamiento. El sistema está conformado por tres sensores musculares MyoWare de electromiografía (EMG) que miden la actividad eléctrica filtrada y rectificada de un músculo. En tal sentido, SIREF consta de una interfaz hombre máquina (HMI), a través de la cual se muestra el tipo de expresión facial detectada y los valores en porcentaje de contracción musculares que reciben el rostro. En cuanto al diseño del dispositivo se emplea hardware y software libre, así como para el correcto ciclo de vida de desarrollo de SIREF basado en el “Modelo en Cascada”, donde, se divide cada uno de los procesos en sucesivas fases del proyecto, como el análisis, diseño e implementación del sistema. Para finalizar, el funcionamiento y validación del sistema está enfocado en el capítulo IV del documento a través de diferentes pruebas realizadas al sistema, a fin de lograr que la calidad y efectividad de SIREF sea lo mejor posible.Ingeniería\n"}
{"prompt":"Detección de técnicas de aprendizaje profundo aplicadas en las diferentes áreas del conocimiento, empleando el método de revisión sistemática de literatura ->","completion":" Deep Learning is a field of research that has become very popular in recent years for data learning, as it reaches high-level abstractions through the modeling of several layers of processing. Deep Learning has inspired a large number of researchers who use deep algorithms to detect patterns and extract data characteristics, in order to obtain more accurate results than commonly used models. That is why, thanks to the growing application of Deep Learning, the present Degree Work aims to determine the techniques and \/ or deep learning models that are currently applied in the areas of knowledge of engineering, medicine, research, industry and finance. For this, a Systematic Literature Review was developed based on the protocol of Barbara Kitchenham, resulting in the selection of 64 primary studies from which the research problem and the applied Deep Learning model were extracted. In the Systematic Literature Review it was obtained that, the Deep Learning LSTM model is ideal for problems of sales prediction, to validate this result the sales data of ILE (Lojana's Industry of Especerías) were used in developing a prediction model of sales using the LSTM network, which was compared with the models of Machine Learning simple neural network and the ARIMA model, using as an evaluation metric the mean square error, the experiments showed that despite the small size of the data the LSTM model gets less error than the other models. Finally, the DL has a wide range of applications, among them the sales prediction, where it was found that the LSTM model has a lower error than the Machine Learning models, although the data is limited. Therefore, the LSTM model is more efficient than Machine Learning models, although to validate the effectiveness of DL in future work, it is recommended to compare the results with other DL models.Deep Learning es un campo de investigación que se ha vuelto muy popular en los últimos años para el aprendizaje de datos, ya que alcanza abstracciones de alto nivel a través del modelado de varias capas de procesamiento. Deep Learning ha inspirado a un gran número de investigadores que emplean algoritmos profundos para detectar patrones y extraer características de los datos, con el propósito de obtener resultados más precisos que los modelos comúnmente usados. Es por ello que, gracias a la creciente aplicación del Deep Learning, el presente Trabajo de Titulación tiene como objetivo determinar las técnicas y\/o modelos de aprendizaje profundo que se aplican actualmente en las áreas de conocimiento de ingeniería, medicina, investigación, industria y finanzas. Para ello se desarrolló una Revisión Sistemática de Literatura en base al protocolo de Bárbara Kitchenham resultando en la selección de 64 estudios primarios de los cuales se extrajo el problema de investigación y el modelo Deep Learning aplicado. En la Revisión Sistemática de Literatura se obtuvo como resultado que, el modelo Deep Learning LSTM es ideal para problemas de predicción de ventas, para validar este resultado se emplearon los datos de ventas de ILE (Industria Lojana de Especerías) en desarrollar un modelo de predicción de ventas empleando la red LSTM, la cual se comparó con los modelos de Machine Learning red neuronal simple y el modelo ARIMA, empleando como métrica de evaluación el error cuadrático medio, los experimentos demostraron que a pesar del pequeño tamaño de los datos el modelo LSTM obtiene menor error que los otros modelos. Finalmente, el DL tiene una amplia gama de aplicación, entre ellas la predicción de ventas, donde se encontró que el modelo LSTM tiene un menor error que los modelos Machine Learning, a pesar de que los datos son limitados. Por tanto, el modelo LSTM es más eficaz que los modelos Machine Learning, aunque para validar la eficacia de DL en trabajos futuros se recomienda comparar los resultados con otros modelos DL.\n"}
{"prompt":"Detección de nivel de cansancio de un conductor mediante DEEP LEARNING para reducir los índices de accidentes de tránsito. ->","completion":" In this article we present the detection of fatigue level of a vehicle driver and according to this level the autonomous driving assistance is implemented, the detection of fatigue level is based on facial recognition using deep learning (Deep Learning) developed in the Matlab software, applying neural networks previously trained and designed, this detection sends us a metric that comprises four levels, according to the metric the position and velocity control of a simulated Car-Like vehicle in the Unity3D software is performed which presents a user friendly environment with the use of haptic devices, the development of the control algorithm is based on path correction which calculates the shortest distance to reenter the desired path.ESPEL\n"}
{"prompt":"Desarrollo de un algoritmo de reconocimiento de emociones utilizando Deep Learning mediante el análisis de la señal de la voz ->","completion":" En los últimos años, la tecnología ha sido una clave esencial para que la sociedad obtenga un mejor estilo de vida, con este avance tecnológico existe el método de aprendizaje profundo. Este trabajo de titulación investiga un algoritmo de reconocimiento de emociones mediante el aprendizaje profundo (Deep Learning), utilizando también un modelo de entrenamiento llamado redes neuronales convolucionales. Este proyecto realizó un clasificador para el reconocimiento de cuatro emociones fundamentales tales como la felicidad, el enojo, el miedo y la tristeza. Para la detección de estas emociones se utilizó una base de datos que contienen 640 audios que se reparte equitativamente entre hombre y mujer. Para el entrenamiento de la red neuronal se utilizó 2 modelos de capas convolucionales uno mediante el uso de 10 capas y otro con el uso de 5 capas, también se utiliza un optimizador de Adam de 32 y de 128, para el desarrollo del proyecto se utilizó el software Matlab®. Los resultados obtenidos se analizaron mediante cuatro parámetros fundamentales, los cuales son exactitud, precisión, sensibilidad y especificidad, se utilizó el cálculo del Ber para verificar el mejor resultado entre los 5 experimentos que se realizó en cada género.\n"}
{"prompt":"Análisis del rendimiento de detectar, clasificar vehículos y pedestres en tiempo continuo con smartphone Android y TensorFlow Lite ->","completion":" Generalmente, se utilizan personas para conteo manual de vehículos y actores de la movilidad, lo cual resulta costoso. Actualmente, el avance de la tecnología permite utilizar métodos basados en redes neuronales convolucionales a la visión por computadora. El objetivo de este trabajo es conocer el rendimiento de las técnicas actuales en un dispositivo smartphone Android, estas medidas son conocidas en la literatura como precisión y recall. Consecuentemente se analiza la creación de un sistema automático a bajo costo que permita clasificar y contar estos actores del espacio público, usando TensorFlow Lite. Adicionalmente, se reentrena un modelo basado en Single Shot Detector para comparar 2 modelos: el primero por efecto y el segundo re-entrenado. Los resultados reportan un incremento significativo en rendimiento mAP para el modelo, como también mejoran las medidas de precision y recall.Ingeniero en Sistemas y Telemática\n"}
{"prompt":"Comparación de métodos de reducción de dimensionalidad enfocados a algoritmos de clasificación supervisados aplicado a datos de redes de sensores ->","completion":" Desarrollar una comparación entre los diferentes métodos de RD enfocados a algoritmos de clasificación supervisados, aplicados a datos de redes de sensores con el fin de determinar el más adecuado.El presente proyecto muestra la aplicación de métodos de reducción de dimensionalidad y algoritmos de clasificación con datos obtenidos de cinco distintos sistemas embebidos que hacen uso de redes de sensores inalámbricos con el objetivo de realizar una representación gráfica de los resultados y conjuntamente determinar el más adecuado mediante el cálculo de su eficiencia. Para su desarrollo se realiza el análisis de características de los sets de datos y la preparación de estos, que implica su limpieza y acondicionamiento. Además, un breve estudio para determinar la plataforma correcta que permita trabajar con los datos analizados previamente. Se implementa cada método de reducción de dimensionalidad seleccionado para este trabajo a cada set de datos y consecutivamente se aplica los algoritmos de clasificación a los datos adquiridos. En la parte final como resultados relevantes, se observan los métodos de RD de forma gráfica al ser aplicados a las bases de datos especificadas con anterioridad. Con ello, se realiza una comparación de los datos obtenidos del cálculo de la matriz de confusión para determinar la eficiencia lograda por cada algoritmo dentro de cada método de reducción de dimensionalidad.Ingeniería\n"}
{"prompt":"Extracción de características para la clasificación de imágenes a través de la reducción de dimensionalidad aplicando Análisis de Componentes Independientes (ICA) ->","completion":" En la investigación presentada mediante la tesis \"Extracción de características para la clasificación de imágenes a través de la reducción de dimensionalidad aplicando análisis de componentes independientes (ICA)\" se ha incluido un interesante estudio de lo relacionado con el manejo de los componentes independientes en el área de la visión por computador. Se realizaran varios experimentos con el afán de buscar la mejor técnica para encontrar similitudes entre componentes independientes de distintas imágenes, a fin de comparar una imagen que pertenezca a un grupo de imágenes de pruebas con cada imagen de un grupo de datos de entrenamiento y determinar cuáles imágenes se parecen más entre sí, formando pares de imágenes en base de los cuales calcularemos porcentajes de precisión de los distintos experimentos.This research presented by thesis \"Extraction feature´s for images classifications via dimensionality reduction using independent components analysis (ICA)\" has included a very interesting study of the management of independent components on computer vision area. Several experiments were done to search the best technique to find similarities between independent components of distinct images, what is sought is to compare an image that belongs a group of test images with each image´s data training group and determine which are more similar each other, doing images pairs in basis of which we calculate accuracy percentages of the distinct experiments.\n"}
{"prompt":"Diseño y desarrollo de un sistema de recomendación basado en filtrado colaborativo utilizando datos secuenciales mediante redes neuronales recurrentes ->","completion":" Actualmente los sistemas de recomendación buscan adaptarse a los gustos actuales de los usuarios, siendo las redes neuronales una solución a este problema. En este punto, nuestro trabajo consiste en diseñar y desarrollar un sistema de recomendación basado en filtrado colaborativo utilizando datos secuenciales mediante redes neuronales recurrentes.Currently, recommendation systems seek to adapt to the current tastes of users, with neural networks being a solution to this problem. At this point, our work consists of designing and developing a recommendation system based on collaborative filtering using sequential data through recurrent neural networks.\n"}
{"prompt":"Reconocimiento de lengua de señas ecuatoriano mediante SVM usando características de profundidad y color ->","completion":" En el presente trabajo de titulación se propone un algoritmo de reconocimiento de señas del lenguaje dactilológicas ecuatoriano (LSEC) de una base de datos realizada previamente en el Instituto Nacional de Audición y Lenguaje, se aplicará un modelo basado en histogramas de gradientes orientados (HOG) para la extracción de características de los datos, y como entrenador se empleará al clasificador de máquinas de vectores de soporte (SVM). El modelo de reconocimiento se implementa utilizando los elementos de videos RGB y de profundidad, estos pasan por una etapa de preprocesamiento que consta en la alineación de los elementos y segmentación de la imagen, de esta manera, se extraerá la figura de la persona ejecutor de señas. Además, se lleva a cabo una reducción de dimensionalidad del vector HOG, correspondiente a la extracción de características de los datos, por medio de un modelo estadístico de análisis de componentes principales (PCA).\n"}
{"prompt":"Enfoque de la teoría de juegos en detección de cáncer de mama, asistido por un algoritmo clasificador ->","completion":" La ciencia del último siglo ha centrado su atención sobre la teoría de juegos algorítmica en investigaciones sobre inteligencia artificial, ensayos médicos, economía, telecomunicaciones, etc., en general es un área de inminente crecimiento. Los algoritmos basados en la teoría de juegos son estudios actuales que tienen como objetivo analizar la dinámica de toma de decisiones en entornos donde existen partes que compiten entre sí y que requieren construcción de estrategias. Una parte importante de estos estudios se dirigen a aplicaciones médicas como el diseño de sistemas computacionales de apoyo al profesional para la detección de patologías. En la presente investigación se propone el desarrollo de un algoritmo clasificador modelado en base a la teoría de juegos para detectar la presencia de cáncer de mama, utilizando el software Matlab; se emplea una base de datos que contiene las características celulares de una muestra de tejido obtenida de pacientes con sospecha, y diagnóstico confirmado de cáncer de mama. Con el objetivo de validar la confiabilidad del algoritmo propuesto se desarrollaron modelos con Machine Learning, Máquina de Vectores de Soporte y Redes Neuronales Artificiales. A partir de las técnicas de optimización: reducción de dimensionalidad y selección de características, se definieron modelos eficientes y mayor capacidad predictiva. La comparación de los resultados obtenidos entre los parámetros de rendimiento del algoritmo de teoría de juegos y los de Machine Learning, demuestran que es apto para aplicaciones de clasificación.\n"}
{"prompt":"Implementación de técnicas de Machine Learning para la detección de anomalías basados en NIDS. ->","completion":" Los delitos informáticos y ataques a redes de datos se han incrementado de manera significativa, por lo que, se ha hecho necesario la implementación de técnicas que detecten estas amenazas y salvaguarden la información de las organizaciones. Los Sistemas de Detección de Intrusos en la Red (NIDS) permiten detectar anomalías y ataques en tiempo real, al analizar el tráfico local y saliente de la red. En la actualidad, para mejorar su rendimiento se ha optado por utilizar técnicas de Machine Learning (ML) que automaticen estos procesos y mejoren la detección de una anomalía informática. Este documento implementa técnicas de ML mediante el uso de conjuntos de datos, en el contexto de un NIDS, para la detección y predicción de anomalías en la red. Se realizaron pruebas con algoritmos de aprendizaje No Supervisado y Supervisado sobre los conjuntos de datos NSL-KDD y UNSW-NB15. Un análisis exploratorio de los datasets junto con técnicas de reducción de dimensionalidad permitió comprender la naturaleza de los datos, previo al modelamiento. El mejor resultado obtenido arrojó un nivel de predicción de anomalías en la red del 96.06%, mostrando que la metodología Knowledge Discovery in Databases (KDD) combinada con técnicas de reducción de dimensionalidad es robusta y extrapolable para escenarios reales con diferentes configuraciones de red.Computer crimes and attacks on data networks have increased significantly, so it has become necessary to implement techniques that detect these threats and safeguard the information of organizations. Network Intrusion Detection Systems (NIDS) allow to detect anomalies and attacks in real time, by analyzing the local and outgoing traffic of the network. At present, to improve its performance, it has been chosen to use Machine Learning (ML) techniques that automate these processes and improve the detection of a computer anomaly. This paper implements ML techniques through the use of datasets, in the context of a NIDS, for the detection and prediction of anomalies on networks. Tests were performed with Non-Supervised and Supervised learning algorithms on NSL-KDD and UNSW-NB15 datasets. An exploratory analysis of the data together with dimensionality reduction techniques allowed us to understand the nature of the data, prior to the modeling. The best result showed a prediction level of anomalies on the network of 96.06%, showing that the Knowledge Discovery in Databases KDD) methodology combined with dimensionality reduction techniques is robust and extrapolated for real scenarios with different network configurations.\n"}
{"prompt":"Algunos problemas y oportunidades de los sistemas bovinos de producción de leche en el trópico húmedo de baja altitud ->","completion":" Existen más de 3,000,000 de productores de leche en América Latina y del Caribe, un número importante de ellos se desenvuelve en las condiciones tropicales húmedas en el piso térmico altitudinal más cercano a nivel de mar y si bien comparten muchos de los problemas comunes a todos los sistemas; relaciones inadecuadas entre los productores primarios y directivos, falta de estímulos y éxodo a las ciudades, deterioro creciente del ambiente, alta dimensionalidad, insuficiente preparación de los directivos, visión limitada, indisciplina tecnológica insuficiencias de comunicación, tecnológicas y financieras, también presentan problemas muy particulares. De estos los que más afectan la sostenibilidad son los relacionados con: la combinación de altas temperaturas con humedades relativas superiores al 70%, el bajo nivel proteico de las especies de pastoreo, el bajo uso de las leguminosas arbustivas y arbóreas y la menor disponibilidad de materia seca durante la estación menos lluviosa. Contrapuestos a estos problemas se dispone actualmente de una amplia información, experiencias, metodologías y tecnologías probadas por años, que con una perspectiva de sistema, pueden minimizar las amenazas y afectaciones. La mejora pasa por la capacitación, apoyo de toda la sociedad e información para trazar los objetivos convenientes a cada sistema y aprovechar sosteniblemente los recursos del suelo, el agua, la vegetación y las razas. Se presentan y se discuten tecnologías para el pastoreo, para la suplementación, la optimización y aprovechamiento multifuncional de la arborización, reproductivas y genéticas, el manejo holístico y un monitoreo constante y analítico de la competitividad, intensidad y eficiencia económica. Palabras clave: Ganadería tropical, dificultades, solucione.ABSTRACTThere are more than 3,000,000 milk producers in Latin America and the Caribbean. An important number of them unfolds in the humid tropical conditions on the thermal floor close to sea level altitude and share many of the problems common to all systems, such as: inappropriate relationships between managers and primary producers, lack of stimuli and exodus to the cities, increasing deterioration of the environment, high dimensionality, inadequate preparation of managers, limited view, technological indiscipline communication, technological and financial shortages, among other particular problems. The characteristics of the cattle breeders mostly affected by unsustainability are high ambiental temperatures combined with relative humidities above 70%, low level of protein in pasture vegetation, low use of leguminous shrubs and trees and a reduced availability of dry matter during the less rainy season. Currently a wealth of information on experiences, methodologies and technologies are available to combat effectively these problems. The best way to protect themselve is by training, support from the cattle society, access to adequate information on how to exploit in an effective and sustainable way resources such as races, vegetation, water, soil resources, etc. Additionally, farmers should apply the most suitable grazing method, foresee in the most appropriate food supplements, include the multifunctional use of tree planting, be knowledgeable about cattle breeding and genetics, try to apply a holistic management of the farm, and foresees in analytical monitoring, as to strengthen and secure competitiveness and economic rentability. Keywords: Tropical livestock, difficulties, solution.\n"}
{"prompt":"Aplicación de métodos estadísticos para el análisis y predicción de perfiles de consumo de energía eléctrica ->","completion":" El objeto del proyecto investigativo está enfocado en predecir y analizar los perfiles de consumo de energía eléctrica mediante la aplicación de métodos estadísticos, para ello se dispone de información referente al consumo de energía como también de mediciones para variables climáticas.The object of the research project is focused on predicting and analizing the consumption profiles of electric energy through statistical methods. For this, information is provided about energy consumption as well as measures for weather variables.\n"}
{"prompt":"Pronòstico de venta: comparaciòn de la precicion de la predicciòn con diferentes mètodos ->","completion":" Se presentan antecedentes historicos del desarrollo de las redes neuronales, asi tambien como sus primeras aplicaciones. se presenta la teoria matematica que da forma a las redes neuronales. se describe la teoria convencional utilizada para la predicciòn de los valores de una serie de tiempo. se utilizan tres series de tiempo distintas de ventas para realizar la comparacion practica, delos mètodos convencionales y las redes neuronales.GuayaquilIngeniería en Estadística Informática\n"}
{"prompt":"Evaluación de los métodos de predicción de la vía aérea difícil en pacientes con politraumatismo ->","completion":" PDFLa vía aérea puede estar involucrada desde el primer instante de un politraumatismo, por lo que su afectación suele ser en forma primaria y\/o secundaria, o directa o indirectamente. La evaluación de la vía aérea y su manejo es un común denominador de vital importancia para los profesionales de la salud, identificar anticipadamente si la vía aérea será de difícil manejo, es un paso importante para asegurar el manejo de la situación, para así aumentar la seguridad del paciente que requiere manejo básico o especializado. Siendo el objetivo evaluar los métodos predictores para valorar la vía aérea difícil en pacientes con politraumatismo. Para nuestra muestra se recopilará la información en los casos de los pacientes politraumatizados del área de emergencia del Hospital Luis Vernaza, quienes a través de una técnica cuantitativa lograr establecer en cifras cuál de las evaluaciones es el más usado para poder llegar a predecir la vía aérea difícil. Se incluye a todos los pacientes politraumatizados. Se excluirán pacientes pediátricos, aquellos que incluyan patología diversa al politrauma y que se haya usado otro método distinto a la intubación endotraqueal. En este estudio se incluyó un total de 50 pacientes, de los cuales un 10% tuvieron vía aérea difícil y el 90% vía aérea fácil. Los test que fueron de mayor ayuda son el de Mallampati, una distancia corta de inter-incisivos, y aquellos pacientes con vía aérea comprometida por el trauma. Se encontró una incidencia del 10% de vías aéreas difíciles. Incluir el mayor número o combinar las distintas valoraciones, harán que la detección oportuna de una vía aérea difícil sea la más adecuada, para así evitar poner en peligro la vida del paciente.The airway may be involved from the first moment of a multiple trauma, so their involvement is usually in primary and \/ or secondary, or directly or indirectly. The evaluation of the airway and management is a common denominator of vital importance for health professionals, early identification if the airway is difficult to manage, is an important step to ensure the handling of the situation, in order to increase the patient safety requires basic or specialized handling. The objective being to assess the predictive methods to assess the difficult airway in patients with multiple injuries. For our sample data be collected in cases of multiple trauma patients in the emergency area of Luis Vernaza Hospital, who through a quantitative technique able to establish figures which of the assessments is the most used to get to predict airway difficult. All trauma patients are included, pediatric patients are excluded, those who include diverse pathology at polytrauma and who has used a different method to endotracheal intubation. In this study a total of 50 patients, of whom 10% had difficult airway and 90% air easily included. The tests that were most helpful are Mallampati, a short distance inter-incisor, and patients with airway compromised by the trauma. an incidence of 10% was found difficult airways. Include as many or combine the different assessments, make early detection of a difficult airway is the most appropriate in order to avoid endangering the patient's life.Universidad de Guayaquil. Facultad de Ciencias Médicas. Escuela de Graduados\n"}
{"prompt":"Aplicación de métodos simplificados para la predicción de daño sísmico en estructuras de baja altura ->","completion":" El trabajo de investigación se orientó a determinar la capacidad de la mampostería de las estructuras de baja altura de la ciudad de Cuenca, Ecuador frente a solicitaciones sísmicas. A través de un análisis de macroelementos que se basa en una curva de empuje adaptativo que estudia el grado de desplazamiento de un nodo de control debido a un progresivo aumento de carga sísmica.The current research project was oriented to determine the masonry capacity of the low height structures of the city of Cuenca, Ecuador considering seismic strains. This was carried out through a macroelement analysis which is based through an adaptive pressurve curvature which studies the displacement degree of a control node due to a progressive increase of seismic weight.\n"}
{"prompt":"Metodos de prediccion y prevencion de hipertension Inducida por el embarazo ->","completion":" Se revisan los métodos de predicción en hipertensión inducida por el embarazo, siendo lá historia clínica, el roll over test y la presión arterial media los más rápidos, inocuos y que están al alcance de todo facultativo. Además se analizan los métodos de predicción en relación a procedimientos de prevención en hipertensión inducida por el embarazo, como, son la suplementación dietética con calcio, la administración de bajas dosis de aspirina y el reposo. (Revista de la Facultad de Ciencias Médicas (Quito), 12: 27 , 1987).\n"}
{"prompt":"Predicción del crecimiento mediante el uso del Método de Hagg y Taranger ->","completion":" pdfEn esta investigación se describen los estadios de maduración esquelética mediante el uso del Método de Hagg y Taranger a niños de 8-10 años que fueron atendidos en la clínica de Odontopediatría de la Universidad de Guayaquil en el periodo 2015-2016 por los alumnos del paralelo 5\/3. Se estudiaron 6 pacientes (1 niño y 5 niñas), se procedió a tomar una radiografía periapical de la falange media del dedo medio de la mano que no utilizan (si usan la mano derecha, se tomó la radiografía de la mano izquierda o viceversa). La investigación da como resultados que el niño se encuentra en un periodo de poco crecimiento y las niñas de las 5 que están en estudio, 2 niñas no han indicado el periodo de crecimiento y 3 niñas están iniciando el pico de crecimiento. Según estos resultados obtenidos se llega a la conclusión que el 50% de los pacientes están iniciando el pico de crecimiento y en estos pacientes coinciden su edad cronológica con la maduración esquelética; mientras que el 50% restante de los pacientes presentan un retardo en su maduración ósea por lo que no coincide con su edad cronológica.In this research the skeletal maturation stages are described using the method of Hagg and Taranger children 8-10 years who were treated at the clinic of Pediatric Dentistry at the University of Guayaquil in the period 2015-2016 by students of parallel 5\/3. 6 patients (1 child and 5 girls) were studied, we proceeded to take a periapical radiograph of the middle phalanx of the middle finger that do not use (if you use the right hand, the ray of the left hand or vice versa was taken) . Research results given as the child is in a period of low growth and 5 girls being studied, 2 girls have not indicated the growth period and 3 girls are starting peak growth. According to these results it is concluded that 50% of patients are starting peak growth in these patients and their chronological age coincide with the skeletal maturation; while the remaining 50% of patients have a delay in their bone maturation so that does not match their chronological age.\n"}
{"prompt":"Predicción de la muerte súbita cardíaca usando alternancia de la onda T modificado mediante le método espectral adaptativo ->","completion":" La muerte súbita cardíaca (MSC) es una de las principales causas de muerte a nivel mundial. En el Ecuador no existen registros oficiales relacionados con la MSC, sin embargo, se tienen datos asociados con muertes de origen cardíaco. Las enfermedades cardiovasculares constituyen una de las principales causas de muertes en el país, junto con el cáncer, la diabetes y las enfermedades respiratorias. El análisis de la alternancia de la onda T (TWA) del ECG es una de las principales herramientas que permiten determinar si un individuo presenta un alto riesgo de sufrir MSC. En este trabajo se desarrolla un método de detección de TWA, denominado SM-Adaptativo. Este método consiste en el análisis en el dominio temporal y frecuencial conjunto de las ondas T del ECG, con el fin de obtener la magnitud de TWA que permita determinar si la señal analizada presenta o no alternancias. Se utiliza el método Matching Pursuit (MP) junto con la distribución de Wigner-Ville (WVD) para el análisis en el dominio tiempo-frecuencia. Posteriormente se aplica el método de factorización de matrices no negativas (NMF) para separar los componentes relacionados con el ruido de los componentes representativos TWA. El método SM-Adaptativo pretende aprovechar las ventajas del método espectral SM, desarrollado en el dominio frecuencial, y del método de la media móvil MMA, método de análisis temporal, generando mejores resultados frente a ruido y a datos no estacionarios. Los resultados obtenidos demuestran que el algoritmo presenta un comportamiento equilibrado cuando se analizan señales con y sin TWA con un porcentaje de exactitud de 94.44% en señales sintéticas y un porcentaje de 80.56% en señales reales.\n"}
{"prompt":"Evaluación de la recuperación secundaria por la inyección de agua en el Campo Oso Arena T utilizando diferentes métodos de predicción. ->","completion":" La inyección de agua ha sido utilizada desde el siglo XIX como un método de recuperación secundaria, en los años 50 se desarrollaron teorías analíticas para predecir el impacto en la producción de petróleo, hoy en día es el principal y el método más conocido de los métodos convencionales de recuperación secundaria de petróleo que tienen los procesos de inyección de agua. En el siguiente proyecto presenta las generalidades del Campo Oso, su geología, un marco teórico para la comprensión del área de estudio y la teoría base para la aplicación de los métodos de predicción que son Buckley and Leverett, Stiles y Dykstra Parson que permite evaluar la influencia de producción de petróleo de pozos cercanos a un pozo inyector de agua en el yacimiento, Arenisca T del campo Oso. En el análisis de los métodos de predicción da como resultado que el pozo X-3 es el que mejor se ajusta a las predicciones tanto en yacimientos homogéneos como heterogéneos obteniendo al tiempo de estudio de 272 días un acumulado de petróleo predicho de 18500 BPPD para Buckley and Leverett, 22000 BPPD para Stiles y 22000 BPPD para Dysktra Parson similares a la producción real de 19126 BPPDWater injection has been used since the nineteenth century as a method of secondary recovery, in the 50s analytical theories were developed to predict the impact on oil production, nowadays it is the main and best known method of methods conventional secondary recovery of oil that have the processes of water injection, In the following project presents the generalities of the Bear Field, its geology, a theoretical framework for the understanding of the study area and the base theory for the application of the methods of Prediction that are Buckley and Leverett, Stiles and Dykstra Parson that allows to evaluate the influence of oil production from wells near a water injector well in the reservoir, Sandstone T of the Bear field. In the analysis of the prediction methods, it results that the well X-3 is the one that best fits the predictions in both homogeneous and heterogeneous reservoirs obtaining at the time of study of 272 days a cumulative of predicted oil of 18500 BPPD for Buckley and Leverett, 22000 BPPD for Stiles and 22000 BPPD for Dysktra Parson similar to the actual production of 19126 BPPDValencia Tapia, Raúl Armando, director\n"}
{"prompt":"Explicación y metodo de predicción de la inflación en una economia dolarizada pequeña y abierta al mundo ->","completion":" TRABAJO QUE PRUEBA QUE A TRAVES DE LA PREDICCION DEL INDICE DE PRECIOS AL CONSUMIDOR POR MEDIO DE UNA CAMINATA ALEATORIA, SE PUEDE PREDECIR LA INFLACION CON UN ALTO NIVEL DE AJUSTE. INICIALMENTE ESTA ORIENTADO A DAR UN ENTENDIMIENTO TOTAL ACERCA DE LA INFLACION, LUEGO TRATA LOS METODOS DE PREDICCION DE LA INFLACION. POSTERIORMENTE PRESENTA UNA CAMINATA ALEATORIA CON LA QUE SE INTENTA ESTIMAR EL IPC PARA EL POSTERIOR CALCULO DE LA INFLACION PARA EL ECUADOR. ADEMAS REALIZA UN ANALISIS DESCRIPTIVO DEL IPC Y SUS COMPONENTES Y JUNTO CON EL ANALISIS ECONOMETRICO SE HACE EL CONTRASTE DE LA TEORIA CON LA REALIDAD.\n"}
{"prompt":"Diseño de un sistema inteligente de predicción y simulación para la escritura en niños con espasticidad ->","completion":" Este proyecto de investigación y desarrollo presenta los resultados de la investigación en base a la implementación práctica de modelamiento matemático aplicado en el estudio del grafismo y la terapia de lenguaje en el aprendizaje de niños regulares y con discapacidad motriz.This research and development project presents the results of the research based on the practical implementation of mathematical modeling applied in the study of graphics and language therapy in the learning of regular and disabled children.\n"}
{"prompt":"Métodos de correlación estructura-actividad aplicados a efectos adversos de antibióticos, Cuenca, 2019 ->","completion":" En el siguiente estudio se utilizó el método QSAR para desarrollar un modelo matemático que relacione parámetros estructurales de los antimicrobianos con sus efectos adversos, permitiendo la predicción respectiva en el caso de nuevos fármacos con similares composiciones moleculares. Para elaborar dicho modelo matemático usamos el método QSAR, el cual agrupa un conjunto de técnicas computacionales relacionadas con diseño y visualización espacial virtual de moléculas, descriptores, bioinformática y estadística. Para el cálculo de los descriptores moleculares está el software Dragon 7, y para el análisis estadístico, el programa Matlab. Logramos elaborar un modelo satisfactorio con el 67% de precisión en la predicción, el 80% de sensibilidad y el 88% de especificidad. La importancia de este trabajo yace en la posibilidad de ahorrar tiempo y recursos en el desarrollo de nuevos fármacos y de incrementar la seguridad de estos medicamentos por una preselección molecular acertada.Médico\n"}
{"prompt":"Planificación y predicción de la fragmentación en las voladuras a cielo abierto ->","completion":" In this seminar graduation thesis the prediction of the fragmentation of the open pit mines, We have taken Calcareos Huayco quarry like a example , the lack of application of different methods of predicting the fragmentation of material flown in different quarries of Ecuador specifically from quarries near the city of Guayaquil and the great benefits of control of fragmentation in the blasting has prompted us to develop a simple procedure to control fragmentation. For this work we require the following data, geology and physical properties of solid mechanics to study, method of calculation for the development of grid blasting method of Cunningham to get the rock factor A, Development of equations of the method KUZ RAM selected for this case of study.\n"}
{"prompt":"Comparación de resultados de la estimación estadística de sismos entre los métodos del algoritmo M8 y lógica difusa, en el Ecuador Continental ->","completion":" La estimación o predicción de ocurrencia de eventos sísmicos, ha sido una de las ramas de investigación que ha tenido un auge considerable en décadas recientes. En Latinoamérica y, especialmente, Ecuador, los estudios técnico-científicos son escasos y su aplicación ha sido considerablemente baja, por tanto, el presente proyecto propone la comparación de la estimación de ocurrencia de eventos sísmicos de gran magnitud (7Mw+) a mediano plazo (5 años), por el Algoritmo M8 (metodología usada a nivel mundial con resultados concluyentes) o también por Lógica Difusa, con ello, probar la eficiencia de éste último en la predicción sísmica por su mayor utilidad y compatibilidad con los SIG. Se realizó una recopilación de diversas fuentes de información sísmica y se ha construido un catálogo sísmico para el territorio ecuatoriano con 57 años de completitud, con ello se han realizado análisis retrospectivos y prospectivos con el Algoritmo M8, mostrando que en la zona Sierra centro y Oriente existe una alta probabilidad de ocurrencia sísmica, dada la amplia zona de alerta, se han considerado 2 optimizaciones a través de Densidad Sísmica y Función Binomial. Para la aplicación de Lógica Difusa se describieron 4 variables fundamentes, las cuales, mostraron coincidencias con el Algoritmo M8, pero su área de alerta es mucho menor y detallada. Se concluye que, ambas metodologías pueden ser usadas como complementarias, es decir, la Lógica Difusa puede ser una optimización para el Algoritmo M8, considerando este proyecto como una base para estudios de mayor profundidad y de mayor alcance en Sismología.\n"}
{"prompt":"Utilidad del método de Johnson y Toshach para predicción de peso neonatal en embarazos a término Hospital Enrique C. Sotomayor 2010 - 2011 ->","completion":" PDFLa contextura neonatal constituye uno de los elementos importantes que condicionan el proceso de trabajo de parto. La macrosomía fetal representa un riesgo obstétrico materno-fetal, por lo que justifica evaluar herramientas clínicas de bajo costo para estimar este factor, las complicaciones potenciales al nacimiento incluyen distocia de hombros, lesión del plexo braquial, lesión ósea, y asfixia intraparto, entre otros. El riesgo materno asociado al parto incluye lesiones del canal y piso pélvico, estimar el peso permite evaluar desproporción céfalo-pélvica y preveer complicaciones. El método de Johnson y Toshach consiste en la aplicación de una fórmula que utiliza la medición de altura de fondo Uterino, el índice de masa corporal, altura de presentación del polo fetal para estimar el peso fetal. El presente estudio establece la relación existente entre el índice de masa corporal materno con el peso del producto al nacer, identifica la semana gestacional en la que el método tiene mayor sensibilidad en embarazos a término, valora las complicaciones del parto en función del peso neonatal y elabora tablas de referencia para predicción del peso neonatal acordes a los parámetros antropométricos del Ecuador. Mediante un estudio tipo descriptivo, correlacional y de diseño no experimental, longitudinal y prospectivo a pacientes embarazadas, en trabajo de parto en el área Toco quirúrgica del Hospital GinecoObstetrico “Enrique C. Sotomayor” en el período comprendido entre Septiembre del 2009 al 30 de Septiembre del 2011. Los resultados destacan que no existe diferencia significativa entre la media de los pesos calculados con la formula y la de los pesos reales, pues son 3,100 y 3,118 g respectivamente. La eficacia de la formula con respecto a la edad gestacional es útil en los 5 grupos, con confiabilidad del 95%, destacándose su eficacia entre la semana 38 y 39 reportándose una diferencia entre el peso calculado y el peso neonatal de 10 gramos.The neonatal texture is one of the important elements that influence the process of labor. Fetal macrosomía is a maternal-fetal risk obstetrics, thus warranting clinical assessment tools to estimate this cost factor, the potential complications at birth include shoulder dystocia, brachial plexus injury, bone injury, and perinatal asphyxia, among other . The maternal risk associated with birth injuries include pelvic floor channel and estimate the weight evaluates cephalopelvic disproportion and anticipate complications. The method of Johnson and Toshach involves the application of a formula that uses the measurement of fundal height, body mass index, height presentation of the fetal pole to estimate fetal weight. This study establishes the relationship between maternal body mass index with birth weight of the product, identifies the gestational week in which the method is more sensitive in term pregnancies, delivery complications assessed according to weight and neonatal made reference tables for birth weight prediction in line with anthropometric parameters of Ecuador. Through a descriptive study, correlational and nonexperimental design, longitudinal and prospective patients who are pregnant, in labor in the Toco area Surgical Gynecology Obstetric Hospital \"Enrique C. Sotomayor \"in the period from September 2009 to September 30, 2011. The results highlight that there is no significant difference between the mean weights calculated with the formula and the actual weights, they are 3.100 and 3.118 g respectively. The effectiveness of the formula with respect to gestational age is useful in 5 groups, with 95% reliability, particularly their effectiveness between weeks 38 and 39 being reported is a difference between the calculated weight and birth weight of 10 grams. KEYWORDSUniversidad de Guayaquil. Facultad de Ciencias Médicas. Escuela de Graduados\n"}
{"prompt":"Generación de un modelo de predicción de la variable ondulación geoidal, para la zona rural del cantón Guayaquil, mediante el uso del método Cokriging ->","completion":" La ondulación geoidal es la separación entre el Elipsoide y Geoide, sin embargo, este último es complicado de establecer debido al desconocimiento de la gravedad media. Para fines prácticos y del estudio, se considera al nivel medio del mar como una aproximación cercana al Geoide, es decir que la ondulación geoidal está definida por la diferencia entre alturas elipsoidales y niveladas. En Ecuador, se trabaja con alturas niveladas geométricamente, pero su obtención es muy costosa, lo que lleva a buscar métodos para optimizar su realización. Cokriging es una técnica de interpolación no tradicional que mejora la eficiencia de las estimaciones, gracias a que utiliza tanto la correlación espacial de las muestras y la relación entre fenómenos para predecir el valor de la variable de interés. El objetivo fue generar un modelo predictivo de ondulación geoidal mediante Cokriging para la zona rural del cantón Guayaquil. Se partió de un total de 332 puntos que fueron divididos en 16, 33, 49, 66 muestras y se aplicó Cokriging (y Kriging) ordinario, residual y universal con la ondulación geoidal derivada del EGM08 como variable auxiliar. Los modelos generados fueron validados con puntos excluidos del modelamiento y se calcularon indicadores estadísticos para facilitar la toma de decisión. El modelo de Cokriging universal con 66 puntos fue el mejor, con un RMSE final de 8cm. y RSR de 2cm. A través de Cokriging se alcanzó mayores precisiones que con Kriging, lo que reduce presupuestos y potencia el uso de datos GNSS\/nivelación para obtener la ondulación geoidal.\n"}
{"prompt":"Implementación y evaluación de un dashboard para el análisis del comportamiento de los estudiantes y predicción en Moodle ->","completion":" El desarrollo tecnológico ha hecho que en las últimas dos décadas las Tecnologías de Información y Comunicación se involucren cada vez más en el proceso de enseñanza y traten de cambiar los modelos tradicionales de aprendizaje. Con el soporte de la tecnología moderna, se han desarrollado y perfeccionado plataformas que fomentan la adopción de un nuevo paradigma de aprendizaje virtual. Estas plataformas almacenan las interacciones de los estudiantes y los docentes con los recursos del curso en motores bases de datos, información que puede llegar a ser muy relevante, pero en muchos casos no ha sido procesada de forma que resulte útil para el uso de los docentes y estudiantes. Por ello, este estudio pretende implementar y evaluar un dashboard de análisis de comportamiento de los estudiantes y predicción de abandono en Moodle. La herramienta ayudará a los docentes a conocer lo que hacen los estudiantes antes, durante y después de una clase mediada por plataformas virtuales. Además, también ayudará a los estudiantes a gestionar su proceso de aprendizaje y monitorear de manera sencilla y eficaz su avance en el curso. Dada la naturaleza analítica de la investigación, se ha hecho uso de análisis exploratorios del modelo de datos de Moodle, evaluación de visualizaciones existentes y diseño de la herramienta basado en la arquitectura de Moodle para el desarrollo de un dashboard de visualizaciones y predicción de abandono. Como resultado se implementó FlipMyLearning, un plugin para la plataforma Moodle que permite al docente monitorear el proceso de aprendizaje de los estudiantes para la toma de decisiones informadas. El plugin desarrollado contiene visualizaciones tanto para el docente como para el estudiante, divididas en diferentes secciones, cada una orientada a monitorear diferentes aspectos del curso. La investigación realizada demuestra que las visualizaciones generadas resultaron útiles para los docentes y los estudiantes que participaron en el proceso de evaluación. Además, variables como el tiempo invertido, la cantidad de sesiones e indicadores relacionados a la profundidad cognitiva y la amplitud social son variables útiles para identificar grupos de estudiantes en riesgo de deserciónThe development of technology has meant that in the last two decades Information and Communication Technologies have become more and more involved in the teaching process and have tried to change traditional learning models. With the support of modern technology, platforms have been developed and perfected that encourage the adoption of a new virtual learning paradigm. These platforms store student and teacher interactions with course resources in database engines, information that can be very relevant, but in many cases has not been processed in a way that is useful for use by teachers and students. Therefore, this study aims to implement and evaluate a dashboard for student behavior analysis and dropout prediction in Moodle. The tool will help teachers to know what students do before, during and after a class mediated by virtual platforms. In addition, it will also help students manage their learning process and easily and effectively monitor their progress in the course. Given the analytical nature of the research, exploratory analysis of the Moodle data model, evaluation of existing visualizations and design of the tool based on Moodle architecture were used to develop a dashboard of visualizations and dropout prediction. As a result, FlipMyLearning was implemented, a plugin for the Moodle platform that allows the teacher to monitor the learning process of students for informed decision making. The developed plugin contains visualizations for both the teacher and the student, divided into different sections, each oriented to monitor different aspects of the course. The research conducted shows that the visualizations generated were useful for both teachers and students who participated in the evaluation process. In addition, variables such as time spent, number of sessions and indicators related to cognitive depth and social breadth are useful variables to identify groups of students at risk of dropping outIngeniero de SistemasCuenca\n"}
{"prompt":"Línea base de funcionamiento del software de simulación EMLAB para el cálculo y predicción de coberturas de servicios de telecomunicaciones en el Ecuador ->","completion":" The present work is in essence a useful tool for the user of the EMLAB software at the University of the Americas, a source of consultation and a baseline for teachers and students who plan the realization of class work, end-of-course projects, development of research lines, among others; since it details extensively each and every one of the functionalities and forms of operation in a work environment in a general and specific way. In its first part, the document presents in detail, all the theoretical framework that includes the operation and structure of software development used in EMLAB, emphasizing the propagation models for the different telecommunications services and their practical application, the simulation of wireless networks and functional description of the EMLAB software for its application in point-to-point systems work environments, supported by the theory and recommendations of the ITU-R. After understanding the conceptual and theoretical framework, an in-depth analysis of all the elements that constitute the work environment of the EMLAB software is carried out, the operation of the menus, sub-menus, buttons in each of the working windows is described in detail , database management, registration and data entry in the systems of transmission, analysis and registration of the sites on the digital map of Ecuador, description of tables, where for obvious reasons the possibility of building a system of customized transmission for a specific telecommunications service. With the previous information, what is done is to build two broadcast television systems that operate in the VHF band, for a television channel that operates in the cities of Quito and Guayaquil. It is explained in detail and with real operating parameters, design of the radiant arrays, configuration of the transmission sites, review of the radiation solids, simulation process and calculation of coverage prediction, among the main aspects.El presente trabajo constituye en esencia una herramienta útil para el usuario del software EMLAB en la Universidad de Las Américas, una fuente de consulta y una línea base para docentes y estudiantes que proyecten la realización de trabajos en clase, proyectos de fin de curso, desarrollo de líneas de investigación, entre otros; puesto que detalla extensamente todas y cada una de las funcionalidades y formas de operación en un ambiente de trabajo de forma general y específica. En su primera parte, el documento presenta de forma detallada, todo el marco teórico que engloba el funcionamiento y estructura de desarrollo de software utilizado en EMLAB, haciendo hincapié en los modelos de propagación para los diferentes servicios de telecomunicaciones y su aplicación práctica, la simulación EMLAB para su aplicación en ambientes de trabajo de sistemas punto a punto, soportados por la teoría y recomendaciones de la UIT-R. Luego de entender el marco conceptual y teórico, se realiza un profundo análisis de todos y los elementos que constituyen el ambiente del trabajo del software EMLAB, se describe a detalle el funcionamiento de menús, submenús, botones en cada una de las ventanas de trabajo, manejo de las bases de datos, registro e ingreso de datos en los sistemas de transmisión, análisis y registro de los sitios sobre el mapa digital del Ecuador, descripción de tablas, de donde tenemos la posibilidad de construir un sistema de transmisión personalizado para un servicio de telecomunicaciones específico. Con la información previa lo que se hace es construir dos sistemas de transmisión de televisión abierta que operan en la banda VHF, para un canal de televisión que opera en las ciudades de Quito y Guayaquil. Se explica en forma detallada y con parámetros de operación reales, diseño de los arreglos radiantes, configuración de los sitios de transmisión, revisión de los sólidos de radiación, proceso de simulación y cálculo de predicción de cobertura, entre los aspectos principales.\n"}
{"prompt":"Valor de la Medición Sérica de PCR Cuantitativo para predicción de mortalidad en pacientes con Pancreatitis Aguda Grave Hospital \"Luis Vernaza\". Periodo 2010 ->","completion":" INTRODUCCIÓN La predicción temprana de la severidad de la pancreatitis siempre ha sido una meta buscada por los médicos (del Cid, 2009) logrando disminuir los períodos de hospitalización prolongado y mejorando la sobrevida de los pacientes. (Gutiérrez, 2002). Por lo tanto la determinación del pronóstico en pacientes críticos puede ser fundamental para la adecuada implementación de recursos terapéuticos de manera oportuna y proporcional al riesgo (Prieto, 2003). Esto es de gran importancia porque hoy en día se sabe que la pancreatitis aguda es una de las enfermedades en las cuales existe evidencia de que una intervención temprana puede disminuir la morbilidad y mortalidad asociadas a ella cuando se interrumpe su progresión a PAG. (Nathens, 2004; Papachristou 2005)\n"}
{"prompt":"Análisis de la robustez de un modelo de redes neuronales para la predicción de caudales en la cuenca del río Paute ->","completion":" En esta tesis se analiza la robustez del método de las redes neuronales para la predicción de caudales aplicado a la cuenca alta del Río Paute. El método de las redes neuronales es un modelo basado en los datos o data-driven model. El análisis de la robustez del modelo nos sirve para evaluar las variaciones en la respuesta del modelo debido a variaciones en los datos de entrada y a la capacidad de predicción del modelo. Por esta razón se realiza un análisis de sensibilidad y un análisis de incertidumbre del modelo para estudiar la robustez del mismo. Del análisis de sensibilidad se busca obtener información sobre la importancia de cada variable en el modelo. Con esta información podemos tomar decisiones orientadas más específicamente. Del análisis de incertidumbre se busca obtener información sobre el nivel de incertidumbre del modelo, específicamente para el problema de predicción de caudales. Como fuentes de incertidumbre se han estudiado la incertidumbre estructural del modelo y la propagación de incertidumbre debido a la incertidumbre en los datos de entrada. El método de las redes neuronales será utilizado para la predicción de caudales, dados los datos de precipitación e historia del caudal como variables de entrada. Es importante recalcar que los datos se han obtenido por mediación del Grupo de la Tierra y del Ambiente, ante diversas entidades que han monitoreado la cuenca del Río Paute…\n"}
{"prompt":"Modelo predictivo del proceso de deshidratación de banano ->","completion":" El presente trabajo consiste en representar lo que sucede en un deshidratador destinado para banano en un modelo matemático y físico, explica y considera fenómenos físicos importantes como son los modos de transferencia de calor que se den en estado transiente y la transferencia de masa en el mismo estado. Se empieza el modelo manteniendo la misma relación del porcentaje de volumen de espacio vacío, para que aplicando uno de los métodos de estado transiente que relacione íntimamente la transferencia de masa y calor, con la finalidad de proceder mediante una corrida computacional aplicándolo primero en sentido de desplazamiento del flujo de aire para que posteriormente se lo haga considerando al tiempo. El análisis y aplicación del modelo se lo realiza poco a poco, empezando con un modelo sencillo que posteriormente al considerar más variables involucradas se llegue al modelo óptimo que represente fielmente lo que sucede en el deshidratador, una vez obtenido dicho modelo, se hace una verificación del mismo aplicando datos experimentales para realizar una comparación y análisis del modelo.\n"}
{"prompt":"Caracterización acústica de los auditorios de la UDLA, mediante modelos predictivos y mediciones in situ ->","completion":" The acoustic characterization of the enclosures of massive concentration has turned into a priority in order to determine the behavior of the sound to give auditory quality, In case of this work of thesis there was realized an acoustic analysis the University of the Americas´ auditoriums, with measurements in-situ and with simulations predictive with the software E.A.S.E. Electro Acoustics Simulation for Engineers, comparing the results obtained in each of them in the following parameters: C50, C80, vivacity RTmid, warmth BR, brightness Br, STI, STIPA, In order to determine a good characterization and the different types of analysis. After having obtained the results of the different evaluated parameters, so much of it forms in situ like across simulation, is achieved to conclude that the values obtained of the time of reverberation differ between if, verified that there could not decide with exacted the coefficient of absorption and the form of installation of material in every audience.La caracterización acústica de los recintos de concentración masiva se ha convertido en una prioridad con el fin de determinar el comportamiento del sonido para dar calidad auditiva, en el caso de este trabajo de titulación se realizó un análisis acústico de los Auditorios de la Universidad de las Américas, con mediciones in situ y con simulaciones predictivas con el software E.A.S.E. Electro Acoustics Simulation for Engineers, comparando los resultados obtenidos en cada uno de ellos en los siguientes parámetros: C50, C80, Vivacidad TRmid, Calor BR, Brillo Br, STI, STIPA, con el fin de determinar una buena caracterización acústica y los distintos tipos de análisis. Después de haber obtenido los resultados de los diferentes parámetros evaluados, tanto de forma in situ como a través de simulación, se logra concluir que los valores obtenidos del tiempo de reverberación difieren entre sí, comprobado que no se pudo determinar con exactitud el coeficiente de absorción y la forma de instalación del material en cada auditorio.\n"}
{"prompt":"Rediseño de gestión de crédito y cobranza de importadora de repuestos basado en modelos predictivos. ->","completion":" El objetivo principal fue rediseñar la gestión de crédito y cobranza con el fin de disminuir en un 50% los costos anuales asociados a estas actividades. Para el rediseño de la gestión de crédito, se creó modelos predictivos para los días de crédito con regresiones lineales múltiples. El rediseño de la gestión de crédito consiste en la elaboración de una herramienta práctica realizada en Excel, con el fin de estimar los días en los que pagará el cliente. De acuerdo a esta estimación, se indica el descuento apropiado. El rediseño de la gestión de cobranza consiste en la creación de un procedimiento estandarizado, en el que se eliminó o se redujo las actividades que no agregan valor. Se cambió los formatos de los reportes de Cuentas vencidas y de Gestión de cobro para tener mayor agilidad y confiabilidad de la información. Finalmente, se analizó la contratación de un servicio de cobranza externo para cuentas críticas.GuayaquilIngenieras Industriales.\n"}
{"prompt":"Modelo de análisis predictivo para el mejoramiento presupuestario de la planificación logística del Consejo Nacional Electoral del Ecuador, basado en el uso de técnicas de minería de datos ->","completion":" El Consejo Nacional Electoral (CNE) es el máximo organismo de sufragio del Ecuador, sus funciones son organizar, controlar las elecciones, sancionar a partidos y candidatos que infrinjan las normas electorales; además inscriben y fiscalizan a los partidos y movimientos políticos. Actualmente, esta institución específicamente la Dirección Nacional de Logística presenta una inadecuada proyección del presupuesto del material electoral, realizando este proceso mediante la experiencia de la dirección mencionada sin ninguna técnica que sustente dicho valor, el proceso lo realizan mediante cálculos y consolidaciones de datos en hojas Excel, por lo que el trabajo toma mucho tiempo, tanto de procesamiento y tratamiento de datos. El presente proyecto tiene como propósito mejorar la planificación del proceso electoral, a través del diseño de un modelo analítico para la predicción del presupuesto de papeletas electorales definido de acuerdo a un estudio de técnicas, herramientas y algoritmos analíticos más utilizados en el mercado. Se utilizaron los tipos de investigación exploratoria y descriptiva para recopilar los datos del negocio; estas técnicas fueron aplicadas siguiendo los lineamientos de la metodología de desarrollo CRISP –DM específica para minería de datos. Los resultados muestran que se obtiene una precisión del 89,58 %, a diferencia del 25% obtenido antes de aplicar la solución propuesta. En consecuencia, podemos avizorar la efectividad del modelo, por lo que su aplicación permitirá un análisis eficiente en la toma de decisiones, y de esta forma mejorar la proyección presupuestaria y la optimización del recurso económico para las demás direcciones de la institución.\n"}
{"prompt":"Realización de un modelo matemático predictivo para ruido urbano de la ciudad de Quito y comparación con el modelo CORTN ->","completion":" Las ciudades están sujetas a un paulatino crecimiento demográfico, lo que implica una mayor implantación de industrias y actividades humanas en general, las mismas que ocasionan mayores problemas medioambientales. Uno de estos problemas es el ruido provocado por los automotores, específicamente de la Ciudad de Quito, el mismo que provoca el 84% de la contaminación acústica. En el presente trabajo de fin de carrera se busca establecer la primera ecuación que estime un valor de nivel de presión sonora equivalente a una hora Leq (1hora) en dBA, producido por el rodaje de automotores, a partir de la velocidad y del número de vehículos que circulan por un determinado lugar de la Ciudad de Quito, para lo cual se utilizaron datos monitoreados de ruido, velocidad y número de vehículos de la campaña 2010 - 2011 realizada por la Universidad Internacional SEK. Este estudio tiene como objetivo general realizar un modelo estadístico-matemático predictivo de ruido urbano en base al tráfico vehicular para la ciudad de Quito. Además, como objetivos específicos están los siguientes: elaborar una base de datos con los datos ya obtenidos; probar adaptabilidad del modelo matemático de ruido ambiental CoRTN a los datos experimentales; establecer una metodología para determinar una ecuación predictiva de ruido para Quito; determinar los valores de las constantes A y B de la ecuación predictiva de ruido de tráfico para la Ciudad de QuitoIng. Katty Coral\n"}
{"prompt":"Aplicación de modelos predictivos de regresión no lineal para el encolado alcalino de papel corrugado medio y “test liner” ->","completion":" cel papel usado para la elaboración de cajas de cartón en el ecuador en su mayoría es proveniente de fibras recicladas, es decir, fibras que ya han sufrido un proceso de fabricación (pulpa no virgen). una de las características del papel reciclado es absorber rápidamente las sustancias acuosas que entran en contacto con él, lo que provoca que pierda muchas de sus características físicas de resistencia, por ejemplo, la compresión corta. por esta razón las industrias papeleras se ven en la necesidad de encolar sus papeles.GuayaquilMAGÍSTER EN ESTADÍSTICAS CON MENCIÓN EN GESTIÓN DE LA CALIDAD Y LA PRODUCTIVIDAD\n"}
{"prompt":"Automatización de rutas de patrullaje basados en modelos dinámicos y predictivos apoyados en el análisis de información delictual ->","completion":" La inseguridad durante los últimos años es uno de los principales problemas en el Ecuador, esto ha sido puesto en evidencia por prestigiosas instituciones y empresas dedicadas a llevar a cabo análisis y estudios de este tema, como en el caso de la encuesta de victimización y percepción de la inseguridad del 2011, realizada por la única institución gubernamental encargada de este tipo de estudios como el del Instituto Nacional de Estadísticas y Censos, publica en su sitio web (INEC, 2011) donde se da a conocer las incidencias de delitos cometidos por cada 100.000 habitantes, dentro del territorio Nacional. Es necesario contribuir de forma tecnológica con la entidad encargada de realizar este trabajo, la cual es la Policía Nacional del Ecuador, esta institución proporciona la información que ayuda a identificar delitos y concentración de los mismos, por esta causa el propósito de este proyecto se enfoca principalmente en analizar la información, pre procesar los datos y finalmente desarrollar modelos predictivos delictuales de las rutas de patrullaje. Se propone el desarrollo de modelos dinámicos predictivos mediante la realización de Estudio de Caso (Simons & Filella, n.d.) como metodología de investigación, y apoyados de KDD, SEMMA y CRISP-DM; siendo esta ultima la escogida por tener un 43% más de precisión que sus contrapartes; a su vez, el algoritmo utilizado fue SimpleKMeans con la metodología de codo. Como resultado final del proyecto se determinó que los clusters analizados después del proceso de filtro de la data set original se incorporó de modo satisfactorio a las rutas de patrullaje, promoviendo una disminución significativa del 31.20% de los casos delictuales.\n"}
{"prompt":"Control predictivo basado en modelo de un campo de colectores solares tipo acurex ->","completion":" El presente trabajo, presenta los resultados del control de un sistema de colectores solares tipo ACUREX, aplicando control predictivo basado en modelo como una t?cnica que aporta criterios para su estudio y mejoramiento. Se ha empleado el simulador creado para entorno Simulink, trabajo de (Camacho, et al., 1997).\n"}
{"prompt":"Modelo predictivo del proceso de combustión de la cascarilla de arroz ->","completion":" Modelo físico-matem tico predictivo del proceso de combustión de la cascarilla de arroz, el cual analiza teóricamente los fenómenos que ocurren en el proceso de combustión de la cáscara de arroz considerando la transferencia de calor y de masa y procesos químicoGuayaquilIngeniero Mecánico\n"}
{"prompt":"Ensayo de termofluencia del acero aisi-sae 1018 y construcción del modelo predictivo de vida ->","completion":" Este trabajo presenta el estudio del comportamiento y vida residual del acero de transmisión AISI-SAE 1018 afectado por el fenómeno de termofluencia, este acero es un material muy común en el medio local, y en cual fue posible evidenciar y documentar la gran afectación que causa la condición de trabajo en alta temperatura. Para la realización de los ensayos se hizo necesaria la construcción de un banco experimental siguiendo la norma E-139, y utilizando probetas dimensionadas según la norma E-8. Previo a los ensayos se realizó la caracterización del material, con el fin de corroborar los valores proporcionados por el proveedor del acero, y a así asegurar la veracidad de estudio. Se ensayaron probetas en el banco experimental, variando la temperatura y el esfuerzo axial, y registrando durante el ensayo los valores de tiempo de ruptura y deformación de las probetas mediante un sistema de adquisición y registro de datos implementado para la realización de este estudio. Finalmente, se utilizó la base de datos obtenida para graficar y analizar la deformación del material a lo largo de su vida útil, y para obtener una herramienta de determinación de vida residual mediante el modelo predictivo Larson-Miller.\n"}
{"prompt":"Ensayo de termofluencia del acero aisi-sae 1018 y construcción del modelo predictivo de vida ->","completion":" Este trabajo incursiona en uno de los retos al que se enfrenta la Ingeniería de Materiales, el cual es el estudio de las fallas de los componentes que se encuentran trabajando bajo condiciones adversas, teniendo como objetivo la construcción de un banco de pruebas experimentales para el estudio del comportamiento de aceros comunes frente al fenómeno de termofluencia.\n"}
{"prompt":"Ensayo de termofluencia del acero AISI-SAE 1018 y construcción del modelo predictivo de vida. ->","completion":" El objetivo es la construcción de un banco de pruebas experimentales para el estudio del comportamiento de aceros comunes frente al fenómeno de termofluencia. Se estudió el comportamiento del acero de transmisión AISI-SAE 1018, en el cual se evidenció la gran afectación que causa la condición de alta temperatura. Siguiendo la metodología indicada en la norma ASTM E139, se logró una herramienta de predicción de vida útil para el material ensayado. El banco experimental que se construyó a partir del diseño básico de un sistema de brazo palanca, el análisis y dimensionamiento mediante computadora de sus partes, y del diseño del sistema de control y supervisión, servirá para que los estudiantes de la carrera de Ingeniería Mecánica mediantes prácticas de laboratorio puedan ampliar su conocimiento en el área de la mecánica de falla.GuayaquilIngenieros Mecánicos.\n"}
{"prompt":"Modelo predictivo de deserción de clientes de un banco usando librería mahout del framework hadoop ->","completion":" Tesina sobre el diseño de un modelo predictivo de deserción de clientes de un banco usando librería Mahout del framework HADOOP\n"}
{"prompt":"Diseño de un modelo predictivo de temperatura a través del espectro infrarrojo usando visión por computadora. ->","completion":" PDFEn la actualidad conocer la temperatura a futuro se ha vuelto importante para realizar actividades cotidianas, tomando debidas precauciones ante variaciones de temperatura, por lo que el proyecto presente tiene la necesidad de predecir la temperatura del cuerpo humano, esto se debe a una de las principales pandemias que es el COVID-19. La investigación presente del diseño de un modelo predictivo de temperatura a través del espectro infrarrojo usando visión por computadora, tiene como finalidad obtener un predicción de la temperatura por medio de imágenes infrarrojas que son adquiridas mediante una cámara FLIR, la cual se realizó a través de redes neuronales, utilizando RESNET-50, debido a que esta red neuronal se encuentra en el top 5 de error de clasificación, además de que es la más utilizada para trabajar con grandes cantidades de imágenes. En este caso usaremos 1000 imágenes térmicas para realizar el modelo predictivo 900 se emplearán en el entrenamiento y 100 se utilizarán para el testing. Los resultados que nos brinda esta investigación es reducir el tiempo de espera para determinar la temperatura de las personas, esto debido a que en la actualidad existen largas filas al momento de ingresar a cualquier lugar cerrado o abierto, como lo son: centros comerciales, oficinas, terminales, entre otros.At present, knowing the temperature in the future has become important to carry out daily activities, taking due precautions against temperature variations, so the present project has the need to predict the temperature of the human body, this is due to one of the main pandemics that is COVID-19. The present investigation of the design of a predictive model of temperature through the infrared spectrum using computer vision, aims to obtain a prediction of the temperature by means of infrared images that are acquired by means of a FLIR camera, which was carried out through neural networks, using RESNET-50, because this neural network is in the top 5 for classification error, in addition to being the most used to work with large amounts of images. In this case we will use 1000 thermal images to perform the predictive model 900 will be used in training and 100 will be used for testing. The results that this research gives us is to reduce the waiting time to determine the temperature of the people, this because at present there are long lines when entering any closed or open place, such as: shopping centers, offices, terminals, among others.\n"}
{"prompt":"MODELO PREDICTIVO EN LOS ACCIDENTES DE TRANSITO CON BASE EN DATA SCIENCE. ->","completion":" La raz?n de accidentes en las v?as se ha convertido en una de las principales causas que mayor n?mero de v?ctimas anualmente. Este problema se concentra especialmente en pa?ses de ingresos medios y bajos donde no se cuenta con un plan de movilidad segura ni medidas de prevenci?n efectivas referentes a accidentes de tr?nsito para evitar muertes y lesiones en la sociedad. En el Ecuador y en el cant?n Guayaquil espec?ficamente, no es ajeno este problema de accidentalidad vial, por lo que en este estudio se realiz? un an?lisis estad?stico de los principales sectores de la ciudad, tomando en cuenta factores como la hora y el d?a de la semana de estos incidentes en la ciudad, tomando como referencia la base de accidentes de la ciudad, y con base en los resultados, se pueda identificar propuestas y soluciones con el fin de reducir las cifras negativas de esta problem?tica social, con la informaci?n proporcionada por las entidades que controlan el tr?nsito en el cant?n, con ayuda de software estad?sticos.Se conceptualiza t?rminos utilizados en el estudio te?rico del tema analizado y los m?todos estad?sticos que se utilizan para este proyecto, posteriormente, mediante la base de datos de accidentes de tr?nsito 2016-2018, se realiz? un an?lisis estad?stico para conocer el estado actual de la proporcionalidad y ocurrencia de accidentes en el cant?n, luego se desarroll? el an?lisis de la probabilidad de accidentes mediante el modelo de regresi?n log?stica binaria para obtener una estimaci?n sobre que si existe o no un accidente de tr?nsito para el a?o 2019 en la ciudad.The reason for road accidents has become one of the main causes of the greatest number of victims existing annually; This problem is especially concentrated in middle and low-income countries where there is no safe mobility plan or effective prevention measures related to traffic accidents to prevent deaths and injuries in society. In Ecuador and in the canton of Guayaquil specifically, this road accident problem is no stranger, so in this study a statistical analysis was carried out where the main sectors of the city were analyzed, taking into account factors such as time and day of the week of these incidents in the city, taking as a reference the base of accidents of the city, and based on the results, proposals and solutions can be identified in order to reduce the negative figures of this social problem, with the information provided by the entities that control the traffic in the canton, with the help of statistical software. Terms used in the theoretical study of the analyzed topic and the statistical methods used for this project are conceptualized, subsequently, through the 2016-2018 traffic accident database, a statistical analysis was carried out to know the current status of proportionality and occurrence of accidents in the canton, then the analysis of the probability of accidents was developed using the binary logistic regression model to obtain an estimate of whether or not there is a traffic accident for the year 2019 in the city.\n"}
{"prompt":"Modelo predictivo del comportamiento de la cartera crediticia para cooperativas de ahorro y crédito ->","completion":" Las cooperativas de ahorro y crédito son organizaciones jurídicas que realizan actividades de intermediación financiera, aceptan depósitos, otorgan créditos y ofrecen una amplia variedad de otros servicios financieros. El producto central de una cooperativa son los microcréditos que se otorgan a quienes no puede justificar fácilmente sus ingresos. Cuando una persona ingresa a la cooperativa a solicitar un crédito, un asesor de crédito analiza su buró, luego se analiza los documentos que respaldan los ingresos y garantías en función a la actividad, el perfil de los socios y el destino al cual se va a dar uso el crédito; al final de acuerdo a su experiencia resuelve otorgar o negar el crédito. En este contexto, se creó un modelo predictivo para una cooperativa del comportamiento de la cartera crediticia, mediante un modelo de minería de datos, que determinó factores que influyen en el otorgamiento de créditos, ejemplo: tipo de crédito, plazo, frecuencia, estado civil, entre otros. La metodología se definió en 4 fases: Evaluación de herramientas y metodologías, Diseño del modelo, Implementación del modelo y Validación del modelo. Como resultado el modelo predictivo de la cartera crediticia se obtuvo una confianza del 99.9 % y se conocieron los patrones que cumplen un buen pagador\n"}
{"prompt":"Implementación de un controlador predictivo basado en modelo con restricciones sobre un microcontrolador de gama alta ->","completion":" Éste proyecto de investigación y desarrollo muestra los resultados de la implementación de un algoritmo de control predictivo basado en modelo, corriendo en un microcontrolador de gama alta, el cual fue aplicado a un \"helicóptero\" estático para probar su desempeño. En la implementación se utilizó funciones BLAS de la librería de código abierto GSL.This research and development project presents the results of a model predictive control algorithm implementation, running on a high-end microcontroller. The controller was applied to a static \"helicopter\" to test its performance. Basic linear algebra subprograms of GSL (GNU Scientific Library) open source library were used in this implementation.\n"}
{"prompt":"Modelo predictivo de mortalidad en neonatos de alto riesgo del Hospital Gineco-Obstétrico “Isidro Ayora” ->","completion":" Neonatal mortality is one of the health problems that has decreased less in recent years, the early identification of risk factors in critical infants allows adapting a comprehensive and effective therapy that modifies the result...La mortalidad neonatal es uno de los problemas de salud que menos ha disminuido en los últimos años, la identificación precoz de factores de riesgo en neonatos críticos permite adaptar una terapéutica integral y eficaz que modifique el desenlace...\n"}
{"prompt":"Modelo predictivo para la calificación de riesgo de la COAC Jardín Azuayo mediante lógica difusa ->","completion":" Magíster en Administración de Empresas\n"}
{"prompt":"Detección del Orden de Lectura de un documento en base a Inteligencia Computacional ->","completion":" En la actualidad, los documentos digitales se han vuelto una parte esencial de nuestra vida cotidiana. Actualmente podemos encontrar un documento digital para casi cualquier libro o documento que necesitemos, pero una gran problemática es que muchos de estos documentos digitales son imágenes guardadas en formato PDF, lo que hace muy difícil la extracción de la información de manera digital. Debido a estas y otras problemáticas se han generado sistemas de procesamiento de imágenes que busca recuperar la información almacenada mediante el Reconocimiento Óptico de Caracteres (OCR) pero una gran limitante de este tipo de sistemas es que no puede definir un Orden de Lectura lógico. El Orden de Lectura no es más que la secuencia lógica de interpretación de la información contenida en un documento. Mediante el procesamiento de documentos en formato PDF y procesamiento digital de imágenes, en este proyecto se busca desarrollar un algoritmo capaz de identificar el Orden de Lectura de un documento que permita extraer su información de forma ordenada. Esto se lo realizará en base a Lógica Difusa, la cual se basa el Razonamiento Aproximado y en el uso de Reglas Lingüísticas. Este proyecto puede ser usado para la recuperación de información y así crear bibliotecas virtuales o aplicaciones que sirvan de ayuda a personas con discapacidad visual.\n"}
{"prompt":"Optimización de parámetros mixtos de arreglos de antenas, utilizando técnicas de computación inteligente ->","completion":" Del desempeño de las antenas depende el nivel de potencia recibido en el equipo receptor, el nivel de la potencia de interferencia en el receptor, etc., en sistemas inalámbricos de telecomunicaciones. En ese particular, es de especial interés el diseño y fabricación de antenas, que contemplen en el proceso de diseño de las mismas, parámetros que estén en concordancia con las especificaciones requeridas según el uso destinado para la antena en estudio.GuayaquilMagíster en Telecomunicaciones\n"}
{"prompt":"Herramienta de reconocimiento facial con técnica de visión computacional 2D ->","completion":" In this thesis an image recognition system has been designed by artificial vision, centered on people's faces. Here, we have studied the complexity of two algorithms that have demonstrated their efficiency and robustness in face recognition applications using computer vision. In addition, a system has been implemented for such purpose based on said algorithms and the proposal of improvements in them. The algorithms mentioned above are: 1) The method Autorostros (Eigenfaces) and 2) The method of Linear Discriminant Analysis (Fisherfaces). Both methods are able to detect faces by comparison with images stored in databases, and among the fundamental characteristics of these methods we can highlight the following: the method of Autorostros is responsible for comparing with a single image of the person who serves as a reference and that is stored in the database; while the Linear Discriminant Analysis method performs the comparison against an average of reference images stored in the database. In this thesis it has been possible to demonstrate experimentally that the first method needs less processing time, but is less robust; while the second method requires a longer processing time, but is more robust. Therefore, the latter is appropriate for working in environments affected by pollution and unwanted signals. With the above background, in order to improve the robustness of the method Autorostros, it is proposed to create a database with a set of reference photos of each of the faces to identify, find a measure of the central tendency of these photos to each face and take this measure as the new reference. However, even doing this, the results are still inferior to the Linear Discriminant Analysis method. Therefore, if a rapid identification system is desired and a certain margin of error is tolerated, the recommended method is the Autorostros. On the other hand, if you want to implement a robust processing system, the appropriate method is Linear Discriminant Analysis.En esta tesis se ha diseñado un sistema de reconocimiento de imágenes por visión artificial, centrado en rostros de personas. Aquí, se ha estudiado la complejidad de dos algoritmos que han demostrado su eficiencia y robustez en aplicaciones de reconocimiento de rostros usando visión por computador. Además, se ha implementado un sistema con tal propósito basado en dichos algoritmos y la propuesta de mejoras en los mismos. Los algoritmos mencionados anteriormente son: 1) El método Autorostros (Eigenfaces) y 2) El método Análisis Discriminante Lineal (Fisherfaces). Ambos métodos son capaces de detectar rostros por comparación con imágenes guardadas en bases de datos, y entre las características fundamentales de dichos métodos podemos destacar lo siguiente: el método de Autorostros se encarga de comparar con una única imagen de la persona que sirve de referencia y que se encuentra guardados en la base de datos; mientras que el método Análisis Discriminante Lineal realiza la comparación contra un promedio de imágenes de referencia guardadas en la base de datos. En esta tesis se ha podido demostrar experimentalmente que el primer método necesita menos tiempo de procesamiento, pero es menos robusto; mientras que el segundo método requiere un tiempo de procesamiento más alto, pero es más robusto. Por lo que, este último es el apropiado para trabajar en entornos afectados por la contaminación y señales no deseadas. Con los antecedentes expuestos, con el objeto de mejorar la robustez del método Autorostros, se propone crear una base de datos con un conjunto de fotos de referencia de cada uno de los rostros a identificar, buscar una medida de la tendencia central de dichas fotos para cada rostro y tomar esta medida como la nueva referencia. Sin embargo, incluso haciendo esto, los resultados siguen siendo inferiores al método Análisis Discriminante Lineal. Por lo tanto, si se desea un sistema de identificación rápido y se tolera un determinado margen de error, el método recomendado es el Autorostros. Por otra parte, si se desea implementar un sistema de procesamiento robusto, el método apropiado es el Análisis Discriminante Lineal.\n"}
{"prompt":"Sistema de simulación 3D utilizando motores de física computacional e inteligencia artificial para la visualización de lahares del Volcán Cotopaxi ->","completion":" En la mayoría de ingenierías y áreas científicas, se realizan investigaciones donde su enfoque es ayudar a la sociedad, esta investigación es acerca de la visualización de lahares del volcán Cotopaxi localizado en el país Ecuador de Sudamérica y cuyo principal propósito es simular la generación de lahares por el deshielo del glaciar, así como visualizar el caudal de los lahares en un barrio del Sector del Valle de los Chillos, que circulan por los ríos Santa Clara y Pita cuyo volumen representan el 20% del total del lahar generado por la erupción del volcán. Para esta meta, se ha aplicado una metodología ágil para ser capaces de producir un sistema de simulación en 3D de los lahares del volcán Cotopaxi como parte de un sistema complejo. Con el propósito de la visualización del volcán se utilizó motores de Física de Fluidos y generadores de terrenos incorporados sobre el motor de juegos Unity 3D. La validación de la solución ha sido ejecutada en base a los datos y estudios previos realizados por Instituto Geofísico de la Escuela Politécnica Nacional (IG-EPN) que es la entidad responsable del monitoreo diario del volcán Cotopaxi. Los resultados demostraron que este sistema permite recrear la experiencia de la formación de lahares altamente destructivos en el Sector del Valle de los Chillos en ambientes distribuidos.\n"}
{"prompt":"Aprendizaje computacional y morfolog?a matem?tica aplicados al procesamiento de im?genes biom?dicas ->","completion":" El Procesamiento Digital de Im?genes (PDI) es una subdisciplina aplicada del procesamiento digital de se?ales. La morfolog?a matem?tica es una t?cnica no lineal de PDI que sirve para el procesamiento y an?lisis de im?genes. Esta t?cnica se compone de dos operaciones fundamentales que son la erosi?n y la dilataci?n. En base a secuencias de estas operaciones se pueden dise?ar algoritmos morfol?gicos de manera heur?stica. El principal problema del dise?o heur?stico es que los resultados est?n altamente condicionados a la experiencia del dise?ador de naturaleza subjetiva. En esta tesis se propone un nuevo paradigma para el dise?o autom?tico de operadores morfol?gicos invariantes ante traslaciones y localmente definidos por medio de una ventana, llamados W-operadores. El paradigma propuesto consiste en definir y representar a un W-operador para clasificaci?n y segmentaci?n mediante un sistema de reconocimiento de patrones. Esta tesis est? compuesta por siete cap?tulos. En el cap?tulo I se presentan las definiciones necesarias y se formula a nivel te?rico el problema del dise?o autom?tico de W-operadores. En el cap?tulo II se realiza una revisi?n bibliogr?fica exhaustiva y un an?lisis te?rico de los m?todos propuestos en la literatura cient?fica para el dise?o de W-operadores. En el cap?tulo III se propone y analiza el nuevo paradigma para el dise?o de W-operadores basado en el uso de teor?a de reconocimiento de patrones. En el cap?tulo IV se propone y testea un nuevo m?todo para el procesamiento de im?genes binarias basado en redes neuronales tipo feed-forward. Luego, en el cap?tulo V se extiende el m?todo propuesto para im?genes binarias al caso donde las im?genes a procesar son im?genes en escala de grises. En este cap?tulo se aplica, eval?a, y realizan comparaciones del m?todo propuesto en la segmentaci?n de im?genes m?dicas. En el cap?tulo VI se extienden el m?todo propuesto al caso donde las im?genes a procesar son im?genes color RGB. En este cap?tulo tambi?n se aplica el m?todo propuesto a un problema de segmentaci?n de im?genes m?dicas. Finalmente, en el cap?tulo VII se presenta una discusi?n, conclusiones, y trabajo futuro.\n"}
{"prompt":"Reconocimiento de firmas usando redes neuronales artificiales (RNA) ->","completion":" Antecedentes. Reconocimiento de patrones. Redes neuronales. Desarrollo del sistema aplicacional. Implementación y prueba del sistema. Conclusiones y recomendaciones. Anexos.\n"}
{"prompt":"Sistema de reconocimiento de partituras musicales ->","completion":" Introducción. Partitura. Procesamiento de imágenes. Redes neuronales artificiales. Reconocimiento de patrones. Extracción de características. Metodología de desarrollo. Conclusiones y recomendaciones. Bibliografía. Anexos.\n"}
{"prompt":"Diseño e implementación de controladores de temperatura aplicando los algoritmos de optimización bio-inspirados colonia de abejas artificiales y enjambre de partículas ->","completion":" En las últimas décadas, los algoritmos bio-inspirados, desarrollados dentro del campo de la Inteligencia Computacional, se han convertido en un paradigma de la optimización metaheurística, debido a los resultados exitosos presentados tras la aplicación de los mismos. Sin embargo, la mayoría de los estudios investigativos realizados, se han enfocado en el desarrollo de más algoritmos bio-inspirados; ya sea, en la creación de un algoritmo basado en un nuevo modelo, la generación de una versión mejorada o la hibridación de dos o más algoritmos. Es por eso que, en el presente trabajo investigativo se propone el diseño de controladores tipo proporcional, integral, derivativo, a través del uso de los algoritmos de optimización Enjambre de Partículas y Colonia de Abejas Artificiales, y su implementación en el control de un sistema de flujo de aire caliente del módulo PCT-2 disponible en los laboratorios de Electrónica de la Universidad de las Fuerzas Armadas – ESPE. Posteriormente, se complementa la investigación, con un análisis de los resultados obtenidos de la salida del sistema, en comparación del sistema controlado asociado al uso de los algoritmos mencionados y en base al uso del Algoritmo Genético. En este trabajo, primero se detalla un análisis del fundamento teórico, tanto del Algoritmo Genético, como de los algoritmos de optimización Enjambre de Partículas y Colonia de Abejas Artificiales; y el estudio de los trabajos previos que han sido usados como base para el desarrollo del mismo. Luego se muestra el desarrollo de la construcción de los códigos de los algoritmos como métodos de sintonización de los controladores, y finalmente el análisis comparativo de los resultados alcanzados en simulación y en las mediciones reales del sistema controlado.\n"}
{"prompt":"Algoritmos Básicos de la Computación Cognitiva para la Programación de Cerebros Artificiales ->","completion":" El reduccionismo científico crea soluciones casi perfectas, inflexibles y específicas para una gran cantidad de problemas. Por lo general, estas soluciones son modelos de deducción causal que van desde las causas hacia los efectos. En esta tesis se presenta 3 algoritmos inteligentes de inducción causal que van desde los efectos hacia las causas: El reconstructor de imágenes mentales, el caracterizador evolutivo y el ruteador causal jerárquico. Estos algoritmos usan redes de nodos interrelacionados que exploran el espacio de patrones para encontrar las mejores causas o soluciones que explican los efectos o problemas presentados como evidencia. Para cada algoritmo, se presenta una aplicación. Pero estos algoritmos son muy generales y aplicables a muchos problemas. El reconstructor de imágenes mentales resuelve el juego del buscaminas en pocos segundos. El caracterizador evolutivo infiere la tridimensionalidad de fotos bidimensionales mediante un sistema básico de visión artificial. Y el ruteador causal jerárquico se presenta como una solución teórica para el aprendizaje y auto-organización en tiempo real de las geometrías causales de un brazo robótico y de todo tipo de robot. Pero este problema es una frontera de la ciencia. No se lo resuelve pero se sugieren estrategias para resolverlo.Scientific reductionism finds solutions that are almost perfect, inflexible, and specific for a big variety of problems. In general, these solutions are models of causal deduction that go from causes to effects. This thesis presents 3 intelligent algorithms of causal induction that go from effects to causes: The mental image reconstructor, the evolutionary characterizer, and the hierarchical causal router. These algorithms use networks of interrelated nodes that exploit the pattern space to find the best causes or solutions that explain the effects or problems presented as evidence. For each algorithm, an application is presented. But these algorithms are very general and applicable to many problems. The mental image reconstructor solves the minesweeper videogame in few seconds. The evolutionary characterizer infers the tridimensionality of bidimensional photos through a basic system of artificial vision. And the hierarchical causal router is presented as a theoretical solution for learning and self-organizing in real time the causal geometries of a robotic arm and of every type of robot. But this problem is a frontier of science. It is not solved here but some strategies to solve it are suggested.\n"}
{"prompt":"Implementación de una solución de Inteligencia de Negocios en la Mesa de Servicios Tecnológicos IBM - UTPL ->","completion":" This project was developed to solve processes currently carried out manually, in the management of SLAs indicators in each of the Services which manages the department MST - IBM. As a result of this research has been to implement a Business Intelligence solution, it allows management and consolidation of information generated from a storage system called \"Tivoli\". The main purpose is to provide graphic indicators to provide an overview of the state of technological support management within the UTPL, as well as provide information that may help mitigate potential risks that arise according to demand attention to the requirements and incidents of different services. The proposed solution can be implemented in various fields, according to the vision that can guide within a company or organization.El presente proyecto se desarrollado para dar solución a procesos que actualmente se llevan de forma manual, en cuanto a la gestión de indicadores de SLAs en cada uno de los Servicios que maneja el departamento de MST – IBM. Como resultado de la presente investigación se ha podido implementar una solución de Inteligencia de negocios, la misma que permite la gestión y consolidación de información generada desde un sistema de almacenamiento de información llamado “Tivoli”. El propósito fundamental es el de proporcionar indicadores gráficos que permitan brindar una visión general del estado de la gestión del soporte tecnológico dentro de la UTPL, como también proveer de información que permita mitigar posibles riesgos que se presenten de acuerdo a la demanda de atención a los requerimientos e incidentes de los distintos servicios. La propuesta de solución podrá ser implementada en distintos campos, de acuerdo a la visión que se la pueda orientar dentro de una empresa u organización.\n"}
{"prompt":"Sistema de notificación de agenda a través de reconocimiento facial : prototipo para docentes a tiempo completo de la Carrera de Computación de la Universidad Católica de Santiago de Guayaquil. ->","completion":" Este trabajo de titulación fue desarrollado con el propósito de diseñar e implementar un prototipo de plataforma informática basada en visión por computador y para notificaciones de agenda a los docentes de tiempo completo de la Facultad de Ingeniería, Carrera de Computación de la UCSG. La metodología de investigación tuvo un enfoque cualitativo, exploratorio y descriptivo; para recoger la información que sirva de base para el producto diseñado, se aplicó entrevistas a profesores de tiempo completo de la unidad académica beneficiaria de esta investigación. Analizadas las opiniones resultantes de las entrevistas se puede confirmar la importancia del reconocimiento facial como una rama de la ciencia computacional, aplicable al campo de la seguridad y al acceso a sistemas informáticos, dependiendo de los tipos de roles que se le asignen a los usuarios; además de que la teoría basada en visión por computador permite la identificación de un rostro como detector de características biométricas, que tiene su aplicación en la seguridad y la confirmación de una coincidencia facial, con el fin de mejorar el acceso a un sistema, utilizando rasgos faciales como puntos específicos que miden las diferencias entre individuos; luego de la prueba realizada de este aplicativo se pudo constatar la facilidad de uso y ventajas que proporciona su implementación para controlar sus actividades agendadas para el desarrollo de sus clases.\n"}
{"prompt":"Implementación de un sistema de chatbot para la atención de consultas de información a través de las redes sociales de las Carreras de Ingeniería en Sistemas Computacionales y Computación de la Universidad Católica de Santiago de Guayaquil. ->","completion":" Los estudiantes de las carreras de Ingeniería en Sistemas Computacionales y Computación de la Facultad de Ingeniería realizan consultas con relación a los distintos procesos administrativos que se llevan a cabo y lo hacen personalmente en la Facultad o por correo, sin que exista una herramienta que optimice dichos procesos y agilice los trámites y se haga uso apropiado de las nuevas tecnologías. Por tal motivo se desarrolló esta investigación con el propósito de implementar un sistema de chatbot para la atención de consultas de información a través de las redes sociales de las carreras mencionadas, para lo cual se utilizó el enfoque mixto de la investigación, realizando el levantamiento de información a través de entrevistas y encuestas al personal administrativo de las carreras; como resultado se identificó también las vías de comunicación a través de las que se hacen consultas para mantenerse informado sobre admisiones, tramites y modelos de solicitudes. Se concluye que la herramienta de chatbot se convirtió en el instrumento necesario para optimización de procesos a través de los canales de redes sociales, siendo de fácil administración.Systems Engineering and Computer Engineering of Engineering school students ask for questions about the different kinds of administrative processes and they do it by themselves in the school building or by email, without counting on a tool that optimize those processes and speed up those transactions, making good uses of the new technologies. That’s why this investigation was made for, with the porpoise to implement a chatbot system for the attendance of the common questions through the different social networks of the career, this investigation uses mixed approach making the information research with interviews and quizzes to the administrative personal of the mentioned careers; as a result the access ways of communications to be informed about admissions, transactions y request model letters. It concludes that the chatbot tool was converted in a needed instrument for processes optimization through the social networks, being easy to manage.\n"}
{"prompt":"Implementar una solución de inteligencia de negocios para explotar la información académica de los estudiantes aplicando Learning Analytics ->","completion":" En el presente proyecto de investigación se han obtenido y extraído los datos de los diversos sistemas académicos de los estudiantes de la carrera de Sistemas Informáticos y Computación de la Universidad Técnica Particular de Loja con el propósito de poder analizar los rastros académicos, sociales, económicos e institucionales que han dejado los estudiantes en los últimos cinco años. Una vez reconocidos los rastros se han extraído sus características para descubrir los factores y su influencia positiva o negativa en los estudiantes, esto se obtiene al interrelacionar el resultado de cada factor con el estado de aprobación o reprobación obtenido por los estudiantes según sus registros académicos. A cada factor se lo ha agrupado dentro un marco propuesto para Learning Analytics, constituido de seis dimensiones: personal, formativa del docente, económica, familiar, institucional y académica. Una vez detectados los resultados de la interrelación de cada factor y su influencia en los estudiantes, se han creado flujos individuales por cada dimensión para poder calcular los pesos que permitirán predecir el porcentaje de probabilidad de aprobación que tendrá un estudiante al cumplir o no con las variables de cada factor.In this research project have been obtained and extracted the data from the various academic systems Student Career Computer and Computer Systems of the Universidad Técnica Particular de Loja in order to be able to analyze academic, social, economic traces and institutions that have left students in the past five years. Once recognized traces its characteristics are drawn to discover the factors and their positive or negative influence on students, this is obtained by interconnecting the result of each factor to the prior approval or disapproval obtained by students according to their academic records. Each factor is what has grouped within a proposed Learning Analytics framework, consisting of six dimensions: personal, teacher training, economic, familial, institutional and academic. Once detected results from the interplay of each factor and its influence on students, have created individual flows for each dimension to calculate the weights which disclose the percentage chance of approval that a student will have to comply or not with the variables of each factor.\n"}
{"prompt":"Sistema avanzado de asistencia al conductor para la detección de distracción y somnolencia basado en técnicas de inteligencia artificial \/ ->","completion":" Resumen: En esta investigación se presenta el desarrollo de un sistema para detectar la somnolencia y distracción de un conductor en tiempo real y emitir alertas para evitar posibles accidentes de tránsito. La detección se realiza mediante el análisis de los ojos del conductor utilizando el método de visión por computadora conjuntamente con el algoritmo de puntos de referencia faciales y es flexible a las diferentes condiciones físicas de las personas, a las variaciones de iluminación y a las condiciones de la carretera de conducción. La distracción, somnolencia, el cansancio, el exceso de velocidad y la fatiga, son las principales causas de accidentes y, precisamente, los sistemas avanzados de asistencia al conductor contribuyen a reducir estos graves errores humanos. Se realiza un análisis de los métodos desarrollados para la detección de somnolencia y distracción, tomando en cuenta la precisión, el tiempo de respuesta y la intromisión con el conductor, entre los que destaca el método de visión por computadora y se realiza las pruebas y análisis de dos algoritmos basados en este método.\n"}
{"prompt":"Realidad Aumentada en la asignatura Desarrollo de la Inteligencia de la Modalidad Abierta y a Distancia ->","completion":" En la actualidad, donde las técnicas convencionales para impartir los conocimientos a los estudiantes de educación a distancia, a través de libros y guías de estudio con contenidos estáticos no están logrando el objetivo de motivar el aprendizaje de los estudiantes. Es en este punto, donde las nuevas tecnologías enfocadas a la educación, ayudan a fomentar el interés y principalmente motivar el aprendizaje a través de herramientas tecnológicas mediante contenidos interactivos, donde el estudiante pasa de ser un mero espectador, a ser el actor principal de su propio aprendizaje. En el presente trabajo se ha desarrollado una aplicación móvil de realidad aumentada para la asignatura de Desarrollo de la Inteligencia, a través de la cual los estudiantes pueden interactuar con contenidos u objetos 3D interactivos afines a dicha asignatura. Mediante la aplicación móvil el estudiante simplemente debe enfocar la tarjeta RA con su cámara para generar el escenario de realidad aumentada, pudiendo interactuar con el mismo a través de gestos táctiles u botones en pantalla dispuestos para este fin.Currently, where conventional techniques to impart knowledge to students of distance education through books and study guides with static content they are not achieving the desired motivate student learning goal. It is at this point, where new technologies focused on education, help stimulate interest and mainly motivate learning through technological tools through interactive content, where the student goes from being a mere spectator, to be the main actor of his own learning. In this word we have developed a augmented reality mobile application for the subject of Development of Intelligence, through which students can interact with 3D interactive content or objects related to that subject. Using the mobile application the student must simply focus the RA card with your camera to generate the scenario augmented reality, can interact with\n"}
{"prompt":"Impacto de la elaboración y aplicación del Spftware de Razonamiento Lógico, para el desarrollo de la inteligencia Lógica Matemática, en los estudiantes del Segundo Semestre de la Escuela de Ingeniería en Sistemas y Computación, de la Universidad Nacional de Chimborazo en el período 2013-2014 ->","completion":" Los problemas evidenciados en los jóvenes del segundo semestre de la Carrera de Ingeniería en Sistemas y Computación de la Universidad Nacional de Chimborazo son: que les cuesta resolver ejercicios de razonamiento con agilidad, bajo rendimiento en la materia de matemáticas y poseen un nivel básico de lógica deductiva, es por esto que el objetivo del presente estudio es facilitar un recurso didáctico asistido por computador como es el software educativo Chakana, para desarrollar la inteligencia lógica-matemática en los estudiantes, en base a este objetivo el estudio demuestra cómo la elaboración y aplicación del software de razonamiento lógico tiene un impacto favorable en el desarrollo de la inteligencia lógica-matemática en los estudiantes, mediante el análisis de relaciones lógicas y efectuar analogías, la metodología que se ha empleado para el desarrollo del software educativo ha sido la propuesta Thales, en cambio, la metodología para la aplicación del software se la efectuó realizando un test inicial sobre la inteligencia lógica-matemática, que determinó la línea base, para luego durante 14 semanas consecutivas trabajar con el software educativo Chakana, y posteriormente aplicar el test final al mismo grupo, con estos datos se comprobó la hipótesis fundamentada en la teoría de la significancia estadística, es por esto que se puede concluir que, se facilitó un recurso didáctico asistido por computador como es el software educativo Chakana, que genera un impacto favorable en el desarrollo de la inteligencia lógica-matemática, en los estudiantes y se recomienda realizar una constante innovación educativa a través de recursos didácticos digitales.UNACH, Sede Ecuador.\n"}
{"prompt":"Diseño y construcción de un dispositivo portátil para la identificación de billetes orientado a personas con discapacidad visual mediante el uso de visión artificial. ->","completion":" En el presente trabajo de titulación se desarrolló un dispositivo portátil capaz de detectar billetes y su denominación, orientando su uso a personas con discapacidad visual, emplea visión artificial y aprendizaje computacional. Para la realización de este prototipo se emplearon los métodos: deductivo, heurístico y experimental. Este cuenta con una fase de programación y otra de diseño en cuanto al hardware. La programación se llevó a cabo en Python, en él se desarrolló un clasificador lineal, regresión logística, consiguiendo diferenciar un billete del fondo de una imagen. Esto se logró con la extracción de características de un conjunto de entrenamiento de billetes y fondo, aplicando una variación del descriptor Local Binary Pattern que lo hace invariante a la rotación, luego se entrenó estos resultados usando regresión logística para obtener el modelo con más bajo coste error de todos los elementos del conjunto de entrenamiento. Dicho modelo se multiplica por cada ventana de la imagen aplicada el descriptor para comparar ese valor con cierto umbral y clasificarlas como billete o fondo. Una vez segmentado el billete de 1, 5, 10 o 20 dólares, se aplica la correlación para determinar el mejor emparejamiento entre el billete segmentado y las plantillas informando así la denominación del billete. En cuanto al hardware, se diseñó una carcasa que contiene una Raspberry pi 3, una cámara Raspberry pi, una batería de 3000mAh, un altavoz de 0.25W con su respectivo circuito, un switch y pulsador. El rango de distancia para obtener un buen número de identificaciones correctas está entre 16 y 29cm del billete a analizar al dispositivo, tomando un tiempo de procesamiento de 2,41 minutos aproximadamente. Es recomendable disminuir el tiempo empleado para la identificación de billetes sin afectar su desempeño así como adicionar otras técnicas o mecanismos para mejorar los resultados de la identificación.In the current degree, work was developed in a portable device capable to detect bills and its denomination, guiding its use to people with visual impairment, employs artificial vision and computational learning. For the implementation of this prototype, the deductive, heuristic and experimental methods were applied. The same counts with a programming stage and other of design related to the hardware. The programming was carried out in Python, into it was developed a lineal classificator, logistic regression, obtaining to differentiate a bill from the bottom of an image. This was achieved with the extraction of characteristics of a set of training of bills and bottom, applying a variation of the descriptor Local Binary Pattern that do it invariant to the rotation, then these results were trained using logistic regression for obtaining the model with lower error cost of all the elements of training set. This model is multiplied by each window of applied image the descriptor in order to compare this value with certain threshold and classify them like bill or bottom. Once segmented the bill of 1,5,10 or 20 dollars, is applied the correlation for determining the better matching between the segmented bill and the templates informing in this way the bill denomination. Regarding to the hardware, a casing that contains a Raspberry pi 3 was designed, a Raspberry pi camera, a battery of 3000mAh, a loudspeaker of 0,25W with its respective circuit, a switch and button. The range of distance to get a good number of correct identifications is between 16 and 29 cm from the bill to analyse the device, taking a processing time of 2,41 minutes approximately. Is recommendable to reduce the employed time for the bills identification without affect its management such as to add other techniques or mechanisms to improve the identification results.\n"}
{"prompt":"Sistema de medición del tamaño de la pupila con visión artificial para investigación en psicología e inteligencia artificial del Grupo IDEIAGEOCA. ->","completion":" El presente trabajo tiene como objetivo desarrollar un sistema de medición del tamaño de la pupila con visión artificial, para investigación en psicología del Grupo IDEIAGEOCA. El sistema consta de dos etapas que son: preprocesamiento de imágenes y segmentación; en la primera etapa utiliza obtención de imágenes, redimensionamiento de imágenes y en la segunda utiliza detección de iris, detección de pupila y medición del diámetro de la pupila. Las imágenes de ojos utilizadas para la experimentación se tomaron de dos fuentes, de una cámara y del Internet. Como resultado de unificar los módulos del sistema de visión por computador (svc), se obtuvo un 80\\% de fiabilidad al medir el tamaño de la pupila. Para la evaluación del sistema se utilizó dos métricas, la precisión y el error entre la medida real y la medida automática de la pupila, por lo tanto, el sistema está optimizado manteniendo un nivel aceptable de eficiencia.The objective of this work is to develop a system for measuring pupil size with artificial vision, for research in psychology of the IDEIAGEOCA Group. The system consists of two stages: image preprocessing and segmentation; in the first stage it uses image acquisition, image resizing and in the second stage it uses iris detection, pupil detection and pupil diameter measurement. The eye images used for experimentation were taken from two sources, from a camera and from the Internet. As a result of unifying the modules of the computer vision system (svc), 80 % reliability was obtained when measuring pupil size. Two metrics were used to evaluate the system, the accuracy and the error between the actual measurement and the automatic pupil measurement, therefore, the system is optimized while maintaining an acceptable level of efficiency.\n"}
{"prompt":"Buscador interno Web con procesamiento del lenguaje natural y métricas de similitud de inteligencia artificial tomando como caso de estudio un E-commerce ->","completion":" En los últimos años, el Procesamiento Natural del Lenguaje ha contribuido al avance de diferentes áreas y aplicaciones como reconocimiento de voz, motores de búsqueda web, minería social, etc. Este artículo aplica técnicas de Procesamiento Natural del Lenguaje para el desarrollo de un buscador interno web y sistema recomendador en un e-commerce. El sistema está desplegado en una PaaS y cuenta con una base de datos NoSQL en la que se almacenó un dataset con 100 documentos con información sobre obras literarias. Cada documento está estructurado por 15 campos y para la implementación del sistema se consideraron solo seis campos de los documentos almacenados. El funcionamiento del buscador compara una consulta con el corpus de los documentos mediante el coeficiente de Jaccard, el coeficiente de Sorensen-Dice, y el coseno de Salton. Además, el sistema recomendador aplica métricas de similitud para encontrar libros similares a los últimos visualizados por el usuario. Las herramientas fueron validadas mediante pruebas funcionales y no funcionales. Las pruebas funcionales usaron validación humana, por medio de una encuesta de satisfacción a un grupo etario de 25 personas entre 23 y 25 años con educación universitaria. Los resultados mostraron que al menos un 65% de los usuarios calificaron a las herramientas con el nivel máximo de satisfacción. Para las pruebas no funcionales se realizaron pruebas de estrés y carga, obteniendo una latencia elevada en ciertos casos, debido a que se utilizaron servicios gratuitos.Nowadays, Natural Language Processing con- tributes to the advancement of different areas and applications such as voice recognition, web search engines, social mining, etc. This scientific article applies Natural Language Processing techniques for the development of an internal web search engine and recommender system in an e-commerce. The system is deployed in a PaaS with a NoSQL database, and a dataset with 100 documents about literary works. Each document is structured by 15 fields, and for the implementation of the system, only six document fields’ were considered. The behavior of the search engine compares a query with the corpus of documents using the Jaccard coefficient, the Sorensen- Dice coefficient, and the Salton cosine. Also, the recommender system applies similarity metrics to find books similar to the last ones viewed by the user. The tools were validated through functional and non-functional tests. The functional tests used human validation through a satisfaction survey in a group of 25 people between 23 and 25 years old with a university education. The results showed that at least 65% of users rated the tools with the highest level of satisfaction. For the non-functional tests, stress and load tests were carried out, obtaining a high latency in some cases, due to the fact that free services were used.\n"}
{"prompt":"Diseño de un algoritmo computacional de identificación de Macroinvertebrados basados en parámetros de taxonomía ->","completion":" El objetivo del presente trabajo fue diseñar un algoritmo computacional de identificación de macroinvertebrados que utilice parámetros morfométricos extraídos de las imágenes basado en la inteligencia artificial. Por la problemática que presenta la identificación y extracción de las características morfométricas mediante el método de inspección visual, se aplicó el método automatizado del Histograma de Gradientes Orientados (HOG) para la extracción de las características. Se probaron varios algoritmos de Machine Learning y técnicas de Deep Learning con dos sets de datos, el primero contenía 504 observaciones, siendo una cantidad pequeña ya que para la aplicación de estos algoritmos es necesario una base de datos extensa, entre más datos se tenga mejor es el entrenamiento y el rendimiento de los algoritmos, el segundo, para lograr los resultados esperados se incrementó artificialmente la base de datos mediante el método de Image Data Generator en Keras a 2242 observaciones. Como resultado de esta experimentación se determinó que el modelo de clasificación más adecuado para el caso es el clasificador Random Forest con la aplicación del método automatizado de extracción de características HOG por su Accuracy\/precisión del 100%.Tesis\n"}
{"prompt":"Del pensamiento complejo al pensamiento computacional: retos para la educación contemporánea ->","completion":" Una de las problemáticas de la educación hoy en día es que se continúa privilegiando la enseñanza del contenido sobre el desarrollo de destrezas y habilidades cognitivas que permitan un desarrollo del pensamiento de los estudiantes. Frente a una educación tradicional, se considera que una reflexión del pensamiento complejo puede contribuir a una mejor comprensión de una realidad contemporánea. La educación hoy tiene como reto el explicar y el comprender, desde una perspectiva hermenéutica, las nuevas complejidades de la realidad con la aparición y utilización cotidiana del internet, de las TIC, de la web 2.0 y de las redes sociales. Por este motivo, se plantea una relación entre pensamiento complejo y el pensamiento computacional que incide en un mejoramiento de la calidad educativa. En el presente artículo se iniciará con una reflexión en torno a la educación a partir de la concepción de incertidumbre del pensamiento complejo. Luego se plantearán elementos de conexión entre un pensamiento complejo y un pensamiento computacional a partir del conectivismo y los desafíos de una sociedad 3.0 en la que las tecnologías de la información y comunicación se encuentran incorporadas en la vida cotidiana de los seres humanos. A su vez, una definición de pensamiento computacional nos situará sobre esta nueva forma de pensar a partir de problemas reales a través de una nueva lógica computacional para lograr resoluciones. El pensamiento computacional desafía a la educación contemporánea a incorporar este nuevo enfoque para la solución de problemas, construcción de sistemas y comprensión de la relación prospectiva entre la ciencia, la tecnología y una sociedad 3.0. \/\/ One of the problems of education today is that it continues to favoring the teaching of contents instead applying skills and cognitive abilities that allow a development of the thought of the students. Besides a traditional education, it is considered that a reflection of the complex thought can contribute to a better understanding of a contemporary reality. Education today has as a challenge the explanation and understanding, from a hermeneutic perspective, of the new complexities of reality to the occurrence and the everyday use of the internet, ICTS web 2.0 and social networks. For this reason, the proposal of this article is that there is a relationship between complex thinking and computational thinking that affects an improvement of the quality of education. This research focuses on a reflection on education from the conception of uncertainty and complexity. It refer to the relationship between a complex thought and a computational thinking from connectivism and the challenges of a society 3.0 in which ICT is incorporated into the daily life of human beings. In the other hand, a definition of computational thinking will put us on this new way of thinking from real problems through a new computational logic to achieve solutions. The computational thinking challenges the contemporary education to incorporate this new approach to the solution of problems, building systems and prospective understanding of the relationship between science, technology and society 3.0.\n"}
{"prompt":"Iinfluencia del uso de las tecnologías de la información y comunicación (tic´s) en el rendimiento académico de los estudiantes de educación general básica en la asignatura de computación de la unidad educativa “Ciudad de Montalvo” del Cantón Montalvo_ Provincia de los Ríos en el periodo lectivo 2010-2011. ->","completion":" La velocidad y complejidad con las que se produce el conocimiento deben estar orientadas a satisfacer las necesidades del hombre y su mundo. En la actualidad no encontramos ante una sociedad de cambios, ante una explosión de tecnologías de la información y comunicación, ante una sociedad de la información o “red”. Esta condición \"relacional\" constituye el insumo de una nueva economía denominada \"economía de redes\" o \"economía de la información\". Esta nueva economía permite el intercambio de bienes inmateriales; que, en el campo didáctico-pedagógico, se expresa en los procesos de enseñanza y aprendizaje logrando una interacción entre docentes y estudiantes con una retroalimentación inmediata (chats) sin tener en cuenta el limitante del espacio geográfico o esquivando el temporal (correo-plataformas virtuales). La utilización de las tecnologías de la información y comunicación en el contexto educativo en general y en la educación superior en particular, desempeñan un papel preponderante con la educación superior al servicio de la formación y actualización de los intelectuales y profesionales. Permite una mayor interacción entre docentes y estudiantes, un aprendizaje colaborativo entre estudiantes, un auto-aprendizaje y, fundamentalmente un cambio de actitud en los roles que deben cumplir los docentes y estudiantes.\n"}
{"prompt":"Medir el valor estadístico del ancho de banda del canal como parámetro fundamental de la calidad de servicios en la comunicación de datos. ->","completion":" La presente tesis expone los fundamentos teóricos necesarios para comprender la 1QoS en la Transmisión de Información, las técnicas que pueden ser utilizadas para medir el ancho de banda de un acoplamiento entre 2 puntos. Además se estudia y analiza diversas formas, herramientas y lenguajes que permiten la comunicación entre redes Si bien es cierto el ancho de banda disponible es la medida más útil que permite tener un mejor manejo de la red de datos, pero es también muy difícil medir este valor debido a la complejidad que presentan las redes actuales, esto hace presumir valores aproximados en la medida del ancho de banda que permitirá determinar de manera estadística que tan fiable es la comunicación.\n"}
{"prompt":"Análisis e implementación de técnicas y modelos para evaluar arquitecturas de software ->","completion":" Resumen: En el presente trabajo de titulación se hace uso de métodos y técnicas de evaluación arquitectónica que permitan la evaluación de la arquitectura. Se seleccionó 27 métodos de evaluación arquitectónica dónde se eligieron 3 métodos: BOSCH, PROTEUS y LAMSWEERDE para crear un marco de evaluación arquitectónica que permita evaluar la complejidad y la mantenibilidad de la arquitectura de un sistema software a través del uso de modelos matemáticos, métricas, prototipos. El trabajo tiene como finalidad la documentación e implementación de técnicas, métodos herramientas o frameworks de evaluación de la arquitectura software, así como su respectiva comparación, que determinen si una arquitectura software está bien diseñada a través de los atributos de calidad.\n"}
{"prompt":"Integración datos médicos de HUTPL desde el enfoque de Semantic Web ->","completion":" Resumen: La información médica de pacientes es diversa, extensa y de alto valor para el apoyo a la toma de decisiones informadas. Esta información es de alta complejidad, está distribuida entre diferentes sistemas, es heterogénea, se almacena en diferentes formatosy presenta niveles de estructuración variados. La gestión de esta información plantea retos de interoperabilidad en tareas relacionadas con la integración y re-uso de datos. En este trabajo se presenta una alternativa para enfrentar estos retos a través del uso de tecnologías semánticas. Se propone transformar esta información heterogénea, distribuida, y no estructurada enuna forma que asegure alta interoperabilidad, re-uso y procesamiento directo por agentes máquina. El piloto de esta propuesta se desarrolló en el Hospital UTPL.\n"}
{"prompt":"Modelo de gestión de proyectos orientado al desarrollo de software basado en modelos ->","completion":" Resumen: El enfoque de desarrollo de software dirigido por modelos (MDD) permite desarrollar aplicaciones basadas en modelos independientes de la plataforma, de la funcionalidad o el comportamiento del sistema; además, reduce el esfuerzo de programación y la complejidad técnica, ya que a través de la generación automática de código a partir de modelos, permite disminuir los costos de desarrollo, mayor productividad, reutilización, portabilidad, interoperabilidad, facilidad de evolución y mejora de la calidad del software. Con todas estas ventajas y beneficios que se manifiestan al usar MDD, es necesario adoptar estándares, marcos de trabajo o metodologías para la gestión de proyectos desarrollados bajo este enfoque, que permitan definir los procedimientos para la gestión del mismo, teniendo claros los requisitos y pasos a fin de lograr una ruta de trabajo eficiente. Dichos estándares o marcos de trabajo, deben considerar la visión de integración de procesos y de conceptos de las buenas prácticas planteadas por cada una de ellas en correspondencia con las fases del MDD, para de esta forma fortalecer los procesos de la empresa en la consecución de sus objetivos.\n"}
{"prompt":"Interfaz de desarrollo para clases introductorias a programación ->","completion":" Integrated development environments, commonly known as IDEs, are used by students when they are in the initial process of learning to code and program. Such IDEs can have a high level of complexity that in most cases turn out to be a negative contribution to the learning process. This research project has as a main goal to develop a simple, but fully functional, user interface by which students can improve their learning process and motivation. The mentioned interface has been created as a web application, gathering pioneer and trending technologies used in front-end and back-end of applications. This solution is constructed over architecture designed from factor of previous environments used by students and a container system that makes this solution efficient and secure.Los ambientes integrados de desarrollo, comúnmente conocidos como IDEs, son utilizados por los estudiantes de la Universidad San Francisco de Quito cuando se encuentran en el proceso inicial de aprender código y programar. Estos ambientes de desarrollo tienden a tener un alto nivel de complejidad que en la mayoría de los casos contribuyen negativamente con el proceso de aprendizaje. Nuestro proyecto tiene como principal objetivo desarrollar una simple, pero funcional, interfaz de programación para que los estudiantes puedan mejorar su proceso de aprendizaje y motivación. La interfaz mencionada ha sido desarrollada como una aplicación web, haciendo uso de tecnologías pioneras y conocidas en el lado del servidor y el lado del cliente. Esta solución es soportada por una arquitectura diseñada a partir de características de ambientes utilizados previamente por los estudiantes y un sistema de contenedores que vuelven a la solución eficaz y segura.\n"}
{"prompt":"Implementación de una metodología y herramientas de pruebas para el grupo de desarrollo de software ->","completion":" La Universidad Técnica Particular de Loja dentro del Grupo de Desarrollo de Software -. GDS de la Unidad de Proyectos y Sistemas Informáticos - UPSI ha conformado desde hace dos años aproximadamente el Team de SQA (Software Quality Assurance), encargado del aseguramiento de calidad del Software. Este team ha lievado a cabo airededor de unas 3000 pruebas hasta marzo del 2006 a 10 largo del desarrollo del Proyecto PHANTOM (Sistema de Gestiôn Académica - UTPL) y como resultado de dichas pruebas ha detectado más de 2300 defectos. Para poder Ilevar a cabo todo este proceso, los miembros del Team realizan las pruebas de forma manual, lo que origina una pérdida de tiempo debido a la complejidad de la aplicaciôn, los cambios constantes de la misma y la gran cantidad de información que se maneja. Otro de los problemas es que el sistemaha sufrido una evolución a 10 largo de su vida activa y en cada nueva version o bien se corrigen defectos, o se añaden nuevas funciones, o ambas cosas. En cualquier caso, una nueva version exige la realizaciOn de nuevas pruebas lo que les demanda mayor tiempo. Como se ha podido comprobar segün la problemática planteada, es necesario automatizar las pruebas, adoptar una metodologia y utilizar una 0 varias herramientas que nos permitan ejecutar las pruebas de una manera ràpida y eficaz.The Private Technical University of Loja within the Software Development Group. GDS of the Computer Systems and Projects Unit - UPSI has formed for approximately two years the SQA Team (Software Quality Assurance), in charge of quality assurance of the Software. This team has performed around 3000 tests until March 2006 throughout the development of the PHANTOM Project (Academic Management System - UTPL) and as a result of these tests detected more than 2300 defects. In order to carry out this whole process, Team members perform the tests manually, which causes a loss of time due to the complexity of the application, the constant changes of the same and the great amount of information that is handled . Another problem is that the system has undergone an evolution during its active life and in each new version or defects are corrected, new functions are added, or both. In any case, a new version requires the realization of new tests which demands more time. As it has been verified according to the problem raised, it is necessary to automate the tests, adopt a methodology and use one or several tools that allow us to execute the tests in a fast and effective way.\n"}
{"prompt":"Enrutamiento de paquetes en Redes Definidas por Software mediante Aprendizaje Automático ->","completion":" Network complexity has increased over the years and the paradigm of software-defined networks (SDN) is helping overcome limitations and determine new network requirements. For this reason, this study will analyze if, in any way, packet routing can be improved by using machine learning models. In order to demonstrate this, a basic network topology was designed and used to perform all tests...La complejidad de las redes ha ido incrementando durante el transcurso de los años y el paradigma de las redes definidas por software (SDN) está contribuyendo a resolver las limitaciones y determinar nuevos requerimientos de las redes. Por esta razón, en este trabajo, se propone experimentar con un nuevo enfoque para mejorar el enrutamiento de paquetes en una red definida por software mediante la utilización de modelos de aprendizaje automático..\n"}
{"prompt":"Servicios web semánticos y agentes inteligentes para la gestión del conocimiento ->","completion":" Uno de los avances más importantes para el intercambio de la información, es la creación del Internet. Con el nacimiento de la WWW (World Wide Web), en el año de 1989, se dio un paso más hacia la consecución de su objetivo que es el de interconectar remotamente varios sistemas software. En sus orígenes la web fue concebida como un medio para compartir recursos (información). En la actualidad, gracias a los Servicios Web, este ha pasado a ser de un simple repositorio donde se acumula información de cualquier tipo, a una fuente de servicios accesibles desde cualquier lugar del plan eta. El incremento exponencial de la cantidad de datos publicados en la web y el consecuente aumento de la complejidad y el tiempo necesario por parte de usuarios humanos para encontrar la información que precisan en un determinado momento, es lo que dio lugar a lo que se conoce como Web Semántica. La Web Semántica plantea dotar de estructura y semántica a un sinnúmero de recursos y servicios que provee la web, de forma que se facilite su acceso y explotación no sólo por usuarios sino por agentes software. En el mundo de los Servicios Web, y de forma similar a lo ocurrido en la web, la cantidad cada vez mayor de servicios disponibles hace inviab le en tiempo y eficiencia que sea un usuario humano el que determine el servicio o servicios necesarios para satisfacer una necesidad concreta, surgiendo de este modo los Servicios Web Semánticos. El problema a resolver es la inexistencia de información procesable automáticamente por máquinas. Y la solución es equivalente, a saber, in cluir información expresada formalmente y que permita a los sistemas informáticos entender en cierto modo, el contenido de los documentos. Con este propósito se hace uso de la Ingeniería Ontológica, la misma que encamina hacia la mejora del acceso a la información. Cuando la información ha sido descrita por medio de ontologías, los sistemas informáticos quedan habilitados para acceder a esta información de forma automática sin la intervención de usuarios humanos, es allí donde aparecen en escena los agentes inteligentes, los cuales pueden definirse como entidades software encargadas de acceder a la información de los servicios y ejecutarlos en lugar de usuarios humanos.\n"}
{"prompt":"Implementación en Matlab de la técnica de detección por grupos en receptores MIMO para el estándar 4G. ->","completion":" En el presente trabajo se propone el estudio y la implementación de la técnica de detección en grupos (GD) para sistemas multiple input multiple output Single Carrier Frequency Division Multiple Access (MIMO SC-FDMA) utilizados en el estándar Long Term Evolution-Advanced (LTE-A). Se realiza el análisis del modelo de canal y detección de señales para sistemas de comunicación inalámbricas. Los receptores lineales como el minimum mean square error (MMSE), utilizado en uplink (UL) en LTE-A, y zero-forcing (ZF) tienen una baja complejidad computacional, y paupérrimo rendimiento, a diferencia de los receptores no lineales que tienen alto rendimiento a costa de una alta complejidad computacional, imposible de implementar para su comercialización. Los resultados de experimentos realizados en Matlab muestran que los receptores con GD incrementan el rendimiento proporcional al tamaño del grupo, además de mantener un aceptable compromiso entre rendimiento y complejidad computacional.In this research, we propose the survey and implementation of group detection (GD) technique for multiple input multiple output Single Carrier Frequency Division Multiple Access (MIMO SC-FDMA) systems used in the Long Term Evolution-Advanced (LTE-A) standard. The analysis of the channel model and detection of signals for wireless communication systems is carried out. The linear receivers such as the minimum mean square error (MMSE), used in the uplink (UL) in LTE-A, and zero-forcing (ZF) have a low computational complexity, and a poor performance, there being a difference with non-linear receivers which have high performance at the expense of a high computational complexity, impossible to implement for its commercialization. The results of experiments carried out in Matlab show that the receivers with GD increase the proportional performance to the size of the group, in addition to get an acceptable compromise between performance and computational complexity.\n"}
{"prompt":"Comparación de técnicas de detección para sistemas MIMO masivo ->","completion":" Los sistemas MIMO masivos son una tecnología que ayuda a 5G en brindar mayor velocidad y eficacia de transferencia de datos en redes celulares por la gran cantidad de antenas en las estaciones base. Este incremento trae un inconveniente a la hora de detección de las señales en la estación base ya que aumenta el ruido y las interferencias. Las investigaciones han evaluado muchos detectores buscando aquellos con mejor rendimiento y baja complejidad computacional, uno de los detectores son los de cancelación de sucesiva de ruido, se detecta la señal más fuerte, y luego se le resta su interferencia a la señal recibida para luego detectar las siguientes señales. En esta investigación se compara la eficiencia y la complejidad computacional de los detectores SIC (cancelación de interferencia sucesiva) y OSIC (cancelación ordenada de interferencia sucesiva), basados en los detectores MMSE (error cuadrático medio mínimo) y ZF (forzado cero) para detectar la señal, y luego cancelar su interferencia de la señal recibida. El detector OSIC ordena la señal en base a SNR (relación señalruido) o SINR (relación señal-interferencia más ruido), detectando la señal con mayor SNR o SINR y luego proceder a la cancelación de interferencia sucesiva. Para esto se simula en Matlab algunos escenarios de un sistema MIMO masivo, con 16 antenas de transmisión (dispositivo móvil) y 64, 100 y 200 antenas de recepción (estación base) mediante modulación 16, 64 y 128 QAM para evaluar la eficiencia y complejidad computacional de cada detector propuesto. Finalmente, se presentan los resultados mediante gráficas de SNR en función de BER (tasa de error por bit) para evaluar la eficiencia de los detectores ZF-SIC, MMSE-SIC, OSIC-SINR y OSIC-SNR en cada modulación QAM para cada dimensión del sistema MIMO masivo simulado, y una gráfica evaluando el tiempo de convergencia de cada detector para evaluar su complejidad computacional.Massive MIMO systems are a technology that helps 5G to provide greater speed and efficiency of data transfer in cellular networks due to the large number of antennas that use in base stations. This increase brings a disadvantage when it comes to detecting signals at the base station because it increases noise and interference. Research has evaluated many detectors looking for those with the best performance and low computational complexity, one of the detectors is the successive noise cancellation detectors, the strongest signal is detected, and then its interference is subtracted from the received signal to later detect the following signs. This investigation compares the efficiency and computational complexity of the SIC (successive interference cancellation) and OSIC (ordered successive interference cancellation) detectors, based on the MMSE (minimum mean square error) and ZF (zero forced) detectors to detect the signal, and then cancel its interference from the received signal. The OSIC detector orders the signal based on SNR (signal-to-noise ratio) or SINR (signal-to-interference ratio plus noise), detecting the signal with the highest SNR or SINR and then proceeding to successive interference cancellation. So, some scenarios of a massive MIMO system are simulated in Matlab, with 16 transmitting antennas (mobile device) and 64, 100 and 200 receiving antennas (base station) using 16, 64 and 128 QAM modulation to evaluate efficiency and computational complexity of each detector proposed. Finally, the results are presented using graphs of SNR versus BER (bit error rate) to evaluate the efficiency of the ZF-SIC, MMSE-SIC, OSIC-SINR and OSIC-SNR detectors in each QAM modulation for each massive MIMO system dimension simulated, and a graph evaluating the convergence time of each detector to evaluate its computational complexity.\n"}
{"prompt":"Análisis de filtros adaptativos de la familia SM aplicados para el diseño de un cancelador de eco acústico ->","completion":" En el presente proyecto se realizó el estudio del filtraje adaptativo donde se explica en qué consiste el filtro de Wiener y las utilidades del algoritmo Steepest-Descent, se revisaron las diferentes aplicaciones tales como la identificación de sistemas, ecualización del canal y la mejora de la señal, se analizó las características de los filtros LMS, RLS y AP. Posteriormente se comparó su desempeño y respuesta con la implementación de un cancelador de eco donde se verificó que el algoritmo RLS presenta mayor velocidad de convergencia y menor desajuste frente a los algoritmos LMS y AP, sin embargo presenta problemas de estabilidad y el costo computacional es mayor. Realizado este análisis previo se estudiaron los algoritmos SM, se obtuvo la complejidad computacional de cada uno de los filtros pertenecientes a esta familia y para el desarrollo del cancelador de eco que propone este proyecto se partió de las características del filtro adaptativo Simplified Set-Membership Affine Projectionya que el filtro propuesto es una mejora en cuanto a velocidad de convergencia y desajuste. Se realizó la comparación de los filtros SM-NLMS, SIM SM AP, SM AP y SIM SM PUAP analizando sus características y las variaciones que sufren al aumentar el valor del factor de reutilización.Finalmente se realizó el estudio del filtro adaptativo Robust Set-Membership Affine-Projection y el análisis tanto con umbral fijo (RSMAP1), como con umbral variable (RSMAP2), se estudiaron sus características, su desempeño y el costo computacional que representa su implementación. Se diseñó el cancelador de eco aplicando el filtro RSMAP1 y el filtro RSMAP2 y se analizaron los resultados en comparación con el filtro Simplified Set-Membership demostrando que el algoritmo RSMAP conserva sus características de estabilidad y convergencia incluso cuando el canal es variable en el tiempo...\n"}
{"prompt":"Artículo científico - Análisis de filtros adaptativos de la familia SM aplicados para el diseño de un cancelador de eco acústico ->","completion":" En el presente proyecto se realizó el estudio del filtraje adaptativo donde se explica en qué consiste el filtro de Wiener y las utilidades del algoritmo Steepest-Descent, se revisaron las diferentes aplicaciones tales como la identificación de sistemas, ecualización del canal y la mejora de la señal, se analizó las características de los filtros LMS, RLS y AP. Posteriormente se comparó su desempeño y respuesta con la implementación de un cancelador de eco donde se verificó que el algoritmo RLS presenta mayor velocidad de convergencia y menor desajuste frente a los algoritmos LMS y AP, sin embargo presenta problemas de estabilidad y el costo computacional es mayor. Realizado este análisis previo se estudiaron los algoritmos SM, se obtuvo la complejidad computacional de cada uno de los filtros pertenecientes a esta familia y para el desarrollo del cancelador de eco que propone este proyecto se partió de las características del filtro adaptativo Simplified Set-Membership Affine Projectionya que el filtro propuesto es una mejora en cuanto a velocidad de convergencia y desajuste. Se realizó la comparación de los filtros SM-NLMS, SIM SM AP, SM AP y SIM SM PUAP analizando sus características y las variaciones que sufren al aumentar el valor del factor de reutilización. Finalmente se realizó el estudio del filtro adaptativo Robust Set-Membership Affine-Projection y el análisis tanto con umbral fijo (RSMAP1), como con umbral variable (RSMAP2), se estudiaron sus características, su desempeño y el costo computacional que representa su implementación. Se diseñó el cancelador de eco aplicando el filtro RSMAP1 y el filtro RSMAP2 y se analizaron los resultados en comparación con el filtro Simplified Set-Membership demostrando que el algoritmo RSMAP conserva sus características de estabilidad y convergencia incluso cuando el canal es variable en el tiempo.\n"}
{"prompt":"Diseño e implementación de un dispositivo para la adquisición de datos meteorológicos y conectividad IP que se integre con la red de datos de Senagua en la cuenca del río Santa Bárbara ->","completion":" En la cuenca del río Santa Bárbara, SENAGUA tiene en funcionamiento un conjunto de estaciones meteorológicas automáticas para el estudio del clima, que en gran parte cuentan con un sistema de telemetría. Al ser estos equipos importados, da como consecuencia elevados costos en su instalación, dado que se necesita actualizar y buscar la compatibilidad de los sensores con el sistema de adquisición de datos. Por esta razón, el objetivo de este proyecto es diseñar e implementar un sistema de adquisición de datos meteorológicos automático, basado en estándares internacionales tales como OMM, ASTM y otros, que tenga un funcionamiento similar al de las estaciones actuales. Para el desarrollo del prototipo del sistema se ha utilizado ingeniería inversa, la instrumentación de los sensores, así como los criterios de tropicalización para la exposición a ambientes adversos, utilizando tres plataformas diferentes: Microcontrolador PIC, Arduino y Raspberry PI. Las diferentes arquitecturas presentadas se han elegido acorde a tres parámetros de análisis para sistemas embebidos. En primer lugar, el análisis de costos permite comparar los gastos que se realizarían al colocar una estación meteorológica Campbell Scientific, actualmente funcionando en la red de SENAGUA, con respecto a cada una de las plataformas en las que se ha desarrollado el equipo. En segundo lugar, el análisis de consumo energético determina el número de paneles solares necesarios para alimentar el sistema. En tercer lugar el análisis de la complejidad computacional permite establecer cuán difícil (y por lo tanto el consumo de horas hombre) es implementar los algoritmos necesarios en cada una de las plataformas. Como resultado se obtiene la comparativa de las tres diferentes arquitecturas, estableciendo una estación meteorológica de menor costo, bajo consumo energético y mínima complejidad computacional, siendo la plataforma basada en Microcontrolador PIC, aquella que presenta un mejor rendimiento en base a los parámetros de análisis.In the Santa Barbara river basin, SENAGUA has in place a set of automatic weather stations for the climate study, which largely have a telemetry system. These are imported equipments, so installation is expensive, since the need of updates and to search the compatibility of sensors with the data acquisition system. For this reason, the aim of this project is to design and implement a system of automatic meteorological data acquisition, based on international standards such as WMO, ASTM and others, which operates similar to current operating stations. For the development of the prototype system, it has been used reverse engineering, instrumentation of the sensors and tropicalisation criteria for exposure to adverse environments, using three different platforms: PIC microcontroller, Arduino and Raspberry PI. The different architectures already submitted have been chosen according to three parameters of analysis for embedded systems. First, the cost analysis allows you to compare the costs that would be made by placing a Campbell Scientific weather station, currently operating in network SENAGUA with respect to each of the platforms on which the equipment has developed. Secondly, energy consumption analysis determines the number of solar panels required to power the system. In third place, the computational complexity establishes the difficulty (and therefore the manhours quantity) to implement algorithms required of each platform used. As a result the comparison of three different architectures is obtained, establishing a weather station with lower cost, lower energy consumption and lower computational complexity. The PIC microcontroller platform is the one that presents better performance based on the analysis parameters.Ingeniero en Electrónica y TelecomunicacionesCuenca\n"}
{"prompt":"Desarrollo de un marco de referencia para sistemas mimo masivo que permita la optimización de la eficiencia espectral mediante la selección de antenas, para la tecnología 5g. ->","completion":" MIMO Massive is an emerging technology in wireless communication that increases Spectral Efficiency (SE) to a large extent compared to MIMO systems. MIMO Massive considers a base station equipped with a large number of antennas (for example, from tens to hundreds) and that serves many users of a single antenna on the same frequency and time resource. However, these base stations require multiple radiofrequency (RF) chains, which consist of an amplifier, mixer, converters, filter, etc. Therefore, due to the multiple RF chains, the cost and complexity of the system hardware increases. To reduce costs and hardware complexity, antenna selection techniques are used that minimize complexity with almost the same capacity. This work analyzes the optimization of the Spectral Efficiency through antenna selection schemes such as Precoding, Beamforming and Antenna Selection Algorithms and the effect on the performance of the MIMO Massive systems for the future 5G technology (Fifth Generation). With the help of the bibliographic review and analyzing mathematically the different techniques of Antenna Selection, elements of each scheme that allow a variety in the study of optimization were chosen. On the part of the Pre-codings, the minimum squared error estimator (MMSE), Zero-forcing (ZF) and Matched Filter (MF) were chosen. Also in Beamforming a Hybrid scheme was studied according to the Kalman, MMSE and ZF Precodes. Upon arriving at the Antenna Selection Algorithms, we proceeded to choose the Antenna Selection Algorithms: Random, Rapid and Based on Quantification. MATLAB facilitated the task of analyzing Spectral Efficiency, by developing programs that allowed the visualization of the operation of each of the aforementioned techniques based on determining parameters. Once the results are obtained, it is possible to define what scheme and in which scenario they can optimize the Spectral Efficiency. When examining the precoding, MMSE and ZF achieve a high performance, but due to the degree of computational complexity of the first one, ZF has a viable option. In Beamforming, Kalman due to its mathematical structure surpasses MMSE and ZF, compensating its high computational processing with its high rates of Spectral Efficiency. While for the Antenna Selection Algorithms, the Quantification Based Algorithm provides better optimization options, which by means of the inclusion of the quantization error achieves superior results than the Random and Rapid Selection Algorithm.MIMO Masivo, es una tecnología emergente en la comunicación inalámbrica que aumenta la Eficiencia Espectral (Spectral Efficiency, SE) en gran medida en comparación con los sistemas MIMO. MIMO Masivo considera una estación base equipada con un gran número de antenas (por ejemplo, de decenas a cientos) y que sirve a muchos usuarios de una sola antena en el mismo recurso de frecuencia y tiempo. Sin embargo, estas estaciones base requieren múltiples cadenas de radiofrecuencia (Radio-frecuency, RF), que consisten en amplificador, mezclador, conversores, filtro, etc. Por lo tanto, debido a las múltiples cadenas de RF, el costo y la complejidad del hardware del sistema aumentan. Para reducir los costos y la complejidad del hardware, se utilizan técnicas de selección de antenas que minimizan la complejidad con casi la misma capacidad de sistemas MIMO Masivos que utilizan todas sus antenas. Este trabajo analiza la optimización de la Eficiencia Espectral mediante esquemas de selección de antena como Precodificación, Beamforming y Algoritmos de Selección de Antenas y el efecto en el rendimiento de los sistemas MIMO Masivo para la futura tecnología 5G (Fifth Generation, 5G). Con la ayuda de la revisión bibliográfica y analizando matemáticamente las diferentes técnicas de Selección de Antenas, se eligió elementos de cada esquema que permitan una variedad en el estudio de la optimización. Por parte de las Precodificaciones se optó por el Estimador de error cuadrático mínimo (Minimum mean square error, MMSE), Fuerza Cero (Forcing-Zero, ZF) y Filtro Adaptado (Matched Filter, MF). Asimismo en Beamforming se estudió un esquema Híbrido en función de las Precodificaciones Kalman, MMSE y ZF. Al llegar a los Algoritmos de Selección de Antenas se procedió a estudiar los Algoritmos de Selección de Antenas: Aleatoria, Rápida y Basado en Cuantificación. MATLAB facilitó la tarea de análisis de la Eficiencia Espectral, mediante la elaboración de programas que permitieron la visualización del funcionamiento de cada una de las técnicas ya mencionadas en función de parámetros determinantes. Obtenidos los resultados se logra definir que esquema y en qué escenario pueden optimizar la Eficiencia Espectral. Al examinar las Precodificaciones, MMSE y ZF logran un alto rendimiento, pero debido al grado de complejidad computacional de la primera, se tiene como opción viable a ZF. En Beamforming, Kalman debido a su estructura matemática supera a MMSE y ZF, compensando su alto procesamiento computacional con sus altas tazas de Eficiencia Espectral. Mientras que para los Algoritmos de Selección de Antenas, presta mejores opciones de optimización el Algoritmo Basado en Cuantificación, que mediante la inclusión del error de cuantificación logra resultados superiores que el Algoritmo de Selección Aleatoria y Rápida.\n"}
{"prompt":"Optimización del algoritmo de encriptación asimétrica RSA para la mitigación de ataques de seguridad de redes ->","completion":" Ante el desarrollo de las telecomunicaciones, la información que viaja a través de la red se ha visto afectado por enemigos que intentan quebrantar la seguridad. La criptología es la solución para reducir las amenazas en las redes, mediante algoritmos y protocolos, que permiten cifrar y descifrar sin tomar en cuenta los recursos computacionales. Los algoritmos asimétricos proporcionan una comunicación segura a través del Internet, sin embargo las soluciones matemáticas que estas brindan requieren de un mayor costo computacional. El presente proyecto tiene como objetivo optimizar el algoritmo de encriptación asimétrica RSA para mejorar la seguridad de los mensajes y disminuir el consumo de los recursos. Para llevarlo a cabo se diseñó y desarrolló una solución genérica, en la que el algoritmo permite incrementar la velocidad del cálculo, al disminuir la complejidad matemática. Además se combina tanto el cálculo modular como el probabilístico para mejorar el tiempo de cifrado y descifrado.\n"}
{"prompt":"Simulación numérica de la distribución de temperaturas y flujo de aire en el horno de una cocina de uso doméstico ->","completion":" En siguiente trabajo analiza numéricamente el proceso de combustión en un quemador atmosférico del horno de una cocina de uso doméstico, usando un código comercial CFD (Computacional Fluid Dinamics). El combustible utilizado es gas butano parcialmente premezclado con aire. Debido a su complejidad, el problema se dividió en 3 partes, la primera simula el desplazamiento de la mezcla butano-aire dentro del quemador que sirve para obtener el campo de velocidades de la mezcla en la salida del quemador, la segunda simula el proceso de combustión y la tercera el flujo de gases calientes dentro del horno. Para la simulación se empleó el software comercial Ansys CFX V.11. Los modelos utilizados han sido para turbulencia, P1 para radiación y Eddy Dissipation para la combustión, usando el mecanismo de reacción de un paso. Como resultado de simulación se obtuvo la distribución de temperaturas, velocidades, direcciones de flujos en la cámara de combustión. Estos resultados fueron validados mediante comparación con los datos obtenidos experimentalmente, por lo tanto el modelo puede ser utilizado para el estudio de influencia de los cambios geométricos de los elementos del horno y de los parámetros de funcionamiento en la distribución de temperatura.\n"}
{"prompt":"Localización de fallas en sistemas eléctricos de distribución con generación distribuida usando máquinas de soporte vectorial ->","completion":" This paper proposes the Support Vector Machines (SVM) use as tool that allows us to locate the type of fault that can occur in the electrical distribution system, with the presence of Distributed Generation (GD). This approach is based on the measurement of the RMS voltages in both the substation and at the points where the distributed generators are onnected and will be used as descriptors for the SVM, to illustrate the proposed methodology was considered the IEEE 34-bar circuit in which two generators are connected in which the energy penetration will be varied through the short-circuit impedance all types of faults were simulated and the database was constructed using the ATPDraw software. The results show a range of accuracy from 70% to 100% in locating faults, showing that distributed generators increase the accuracy of the vector support machines.En el presente documento se propone el uso de las Máquinas de Soporte Vectorial (SVM) como una herramienta que permita localizar el tipo de falla que se puede presentar en el sistema de distribución eléctrica, con la presencia de Generación Distribuida (GD). Este enfoque se basa en la medición de los voltajes RMS tanto en la subestación como en los puntos donde se conectan los generadores distribuidos y serán utilizados como descriptores para las SVM, para ilustrar la metodología propuesta se consideró el circuito de 34 barras de la IEEE en el cual se conectan dos generadores en el que se ira variando la penetración de energía a través de la impedancia de corto circuito, se simulan todos los tipos de fallas y la base de datos se construye mediante el software ATPDraw. Los resultados muestran un rango de precisión del 70% al 100% en localizar las fallas demostrando que los generadores distribuidos aumentan la precisión de las máquinas de soporte vectorial.\n"}
{"prompt":"Estudio de la autonomía del vehículo eléctrico Kia Soul aplicando máquinas de soporte vectorial en la ciudad de Cuenca ->","completion":" Este Proyecto estudia la autonomía de un vehículo 100% eléctrico, que mediante la aplicación de Máquinas de Soporte Vectorial para regresión, se encuentra un modelo matemático de la autonomía dependiendo de algunas variables tomadas con el vehículo en circulación, con las SVM mejoramos otros métodos de estudio, obteniendo respuestas más precisas.This Project studies the autonomy of a 100% electric vehicle, which through the application of vector support machines for regression, is a mathematical model of autonomy depending on some variables taken with the vehicle in circulation, with the SVM we improve other methods of study, obtaining more precise answers.\n"}
{"prompt":"Desarrollo de un sistema seguidor de tendencia en base a máquina de soporte vectorial optimizado por cúmulo de partículas para pares de divisas ->","completion":" El presente proyecto de investigación desarrolló un sistema para predecir la continuidad y cambio de tendencia de pares de divisas del mercado FOREX. La motivación surge de la necesidad de poner al alcance de los inversores modelos predictivos fundamentados en Inteligencia Artificial que permitan tomar mejores decisiones y generar rentabilidad. El sistema fue elaborado con el software de programación Python en sincronismo con la plataforma Metatrader 5, y adicionalmente se diseñó una interfaz gráfica, para que en conjunto agiliten el análisis de los pares disminuyendo los tiempos para la generación de gráficos, evitando la engorrosa tarea de tener que descargar datos manualmente. El funcionamiento predictorio se efectúa mediante el cruce de dos hiperplanos, los cuales fueron optimizados por algoritmo de enjambre de partículas (PSO). El estudio de los cruces históricos de los hiperplanos permite controlar el riesgo que se asume al efectuar una operación comercial debido a que filtra el ruido en los datos. En caso de querer realizar una operación de compra se considera al menos los dos últimos cruces con proyección alcista y se define el Stop Loss, a partir de promediar la cantidad de pips que movió el par antes de cada cruce. La estrategia que se elaboró a partir de este sistema se evaluó en tres pares de divisas diferentes (EURUSD, USDJPY, NZDUSD) en temporalidades de 1hora, 15 y 5 minutos. De los resultados obtenidos se puede destacar que el indicador de cruce de hiperplanos y la variante de MACD demostró tener mayor acertividad y rentabilidad en temporalidades de 5 y 15 minutos en comparación con la temporalidad de una hora, siendo una estrategia útil para operar con una estrategia de Scalping, la cual se basa en realizar un gran número de operaciones a corto plazo. El documento consta de cuatro capítulos distribuidos de la siguiente manera: introducción, marco referencial, metodología y diseño, resultados y conclusiones.This research project developed a system to predict the continuity and change of trend of currency pairs in the FOREX market. The motivation arises from the need to make predictive models based on Artificial Intelligence available to investors that allow them to make better decisions and generate profitability. The system was developed with Python programming software in synchronism with the Metatrader 5 platform, and in addition a graphical interface was designed, so that together they speed up the analysis of pairs, reducing the times for the generation of graphs, avoiding the cumbersome task of having to download data manually. The predictive operation is carried out by crossing two hyperplanes, which were optimized by the particle swarm algorithm (PSO). The study of the historical crossovers of the hyperplanes allows to control the risk that is assumed when carrying out a commercial operation because it filters the noise in the data. In case of wanting to carry out a buy operation, at least the last two crosses with an upward projection are considered and the Stop Loss is defined, based on averaging the number of pips that the pair moved before each crossing. The strategy that was developed from this system was evaluated in three different currency pairs (EURUSD, USDJPY, NZDUSD) in time frames of 1 hour, 15 and 5 minutes. From the results obtained, it can be noted that the hyperplane crossover indicator and the MACD variant proved to have greater accuracy and profitability in timeframes of 5 and 15 minutes compared to the timeframe of one hour, being a useful strategy to operate with a strategy Scalping, which is based on carrying out a large number of short-term operations. The document consists of four chapters distributed as follows: introduction, frame of reference, methodology and design, results and conclusions.\n"}
{"prompt":"Análisis de algoritmos basados en máquinas de soporte vectorial y redes neuronales artificiales para el diagnóstico de fallas en transformadores de potencia empleando muestras de gases disueltos en el aceite ->","completion":" The main parameter that determines the state of the power transformers in operation, whether normal or deteriorating, is the insulation inside, composed of dielectric components such as oil and paper covering the winding enclosure. Abnormalities in insulation are products of degradation of the mentioned components; Forming chemical by-products that are derived from aging and accumulate in the oil in the form of gases, the main effect is the life of the transformers. The most accepted and used method to detect gases inside a transformer is the Dissolved Gas Analysis (AGD), because it emits more information, allows to diagnose probable failures by means of conventional techniques of interpretation of results (gases in ppm) before Which is present in the machine, this type of fault is commonly known as \"Incipient Failure\". In the present work, samples of the AGD were made to several power transformers submerged in oil (shown in Tables 9, 10, 11 and 12) to form a database (gas concentrations and fault diagnosed), evaluated and performed A diagnosis of the state to several power transformers based on intelligent methods of data interpretation for the prediction of failures, these are: Artificial Neural Networks and Vector Support Machines to compare them with the criteria scientifically accepted as: Criterion of Rogers and Criterion of Dornenburg , In order to determine the most assertive method to detect incipient faults in power transformers.El parámetro principal que determina el estado de los transformadores de potencia en operación ya sea normal o en deterioro, es el aislamiento en su interior, compuesta de los componentes dieléctricos como el aceite y el papel que cubren el recinto del bobinado. Anormalidades en la aislación son productos de la degradación de los componentes mencionados; formándose subproductos químicos que se derivan del envejecimiento y se acumulan en el aceite en forma de gases, como efecto principal se merma la vida útil de los transformadores. El método más aceptado y utilizado para detectar gases en el interior de un transformador es el Análisis de Gases Disueltos (AGD), debido a que emite mayor información, permite diagnosticar probables fallas mediante técnicas convencionales de interpretación de resultados (gases en ppm) antes de que se presente en la máquina, a este tipo de fallas se las conoce comúnmente como “Fallas Incipientes”. En el presente trabajo se tomaron muestras del AGD realizados a varios transformadores de potencia sumergidos en aceite (mostrada en las tablas 9, 10, 11 y 12) para formar una base de datos (concentraciones de gases y falla diagnosticada), con lo que se evaluó y realizó un diagnóstico del estado a varios transformadores de potencia basado en métodos inteligentes de interpretación de datos para la predicción de fallas, estos son: Redes Neuronales Artificiales y Máquinas de Soporte Vectorial para compararlos con los criterios científicamente aceptados como: Criterio de Rogers y Criterio de Dornenburg, con el fin de determinar el método más asertivo en detectar fallas incipientes en transformadores de potencia.\n"}
{"prompt":"Modelamiento basado en datos para la detección de fallos en una bomba hidráulica centrífuga multietapa vertical a partir de señales multimodales en condición normal ->","completion":" El presente trabajo se detalla el proceso de desarrollo de una nueva metodología para la creación de detectores de fallos basados en el uso de modelos generativos obtenidos a partir de señales multimodales de una máquina funcionando en estado normal. Utilizando para este objetivo una GAN, y un clasificador de una sola clase (OC-SVM).This work details the development process of a new methodology for the creation of fault detectors based on the use of generative models obtained from multimodal signals of a machine operating in normal state. Using for this purpose a GAN, and a one-class classifier (OC-SVM).\n"}
{"prompt":"Construcción de un prototipo para el reconocimiento y traducción del lenguaje de señas a texto utilizando el sensor kinect. ->","completion":" On the following research work it is introduced a system the language of Ecuadorian signs specially the alphabet this language is based on automatic learning techniques, to facilitate in a way, the communication of people who suffer from a kind of hearing impairment for those who do not know this language. In order to meet the objective a bunch of ideas and various authors investigations were combined in order to define the procedure of which this prototype is, it consists of four phases: hand detection, obtaining the descriptive characteristics of the same, classification and interpretation of the information obtained in previous stages. The data acquired by Kinect depth were stored in a database so then it can be processed, adapting it to a fixed size, and transforming them into binary images so that the computational cost is as low as possible. The training data is applied for child employee for the Training of Machine Learning called Support Vector Machine (SVM) after feature extraction through descriptor Histograms Oriented Gradients (HOG), once the detector is obtained images may be applied to identify hands and perform the translation accordingly. The translation can be visualized in real time through a guide made in Matlab which shows the sign made by the user, resizing it and finally the translation corresponding to the signal originally issued.En el presente trabajo de investigación se presenta un sistema para la traducción del lenguaje de señas ecuatoriano específicamente del abecedario de este lenguaje basado en técnicas de aprendizaje automático, para facilitar de cierta forma, la comunicación de las personas que padecen de algún tipo de discapacidad auditiva con aquellas que no manejan o conocen este lenguaje. Para cumplir con el objetivo se combinaron ideas e investigaciones de varios autores con el fin de definir el procedimiento del que se constituye este prototipo, mismo que consta de cuatro fases: Detección de la mano, obtención de las características descriptivas de la misma, clasificación e interpretación de la información obtenida en las etapas anteriores. Los datos adquiridos con Kinect mediante el sensor de profundidad se almacenan en una base de datos de entrenamiento para luego ser preprocesadas, adecuando su tamaño a uno fijo, y transformándolas a imágenes binarias de tal forma que el coste computacional sea el menor posible. Los datos de entrenamiento son empleados para el entrenamiento de las máquinas de aprendizaje denominada Maquinas de Soporte Vectorial (SVM) , previa extracción de características a través del descriptor de Histogramas de Gradientes Orientados (HOG), una vez obtenido el detector se podrá aplicar a imágenes para identificar manos en ellas y realizar la traducción correspondiente. La traducción se podrá visualizar en tiempo real a través de una Guide realizada en Matlab que muestra la seña realizada por el usuario, el redimensionamiento de la misma y finalmente la traducción que corresponde a la seña emitida originalmente.\n"}
{"prompt":"Métodos de clasificación aplicados al perfil del estudiante por categorías de rendimiento global en la prueba Ser Bachiller 2019 ->","completion":" El proceso educativo está condicionado por varios factores, sin duda, los más preponderantes están en el ámbito social, económico y familiar del entorno estudiantil; la preocupación de los estudiantes y sus familiares, una vez que terminan la educación media, es el acceso a la educación superior. El presente estudio de investigación, empleó técnicas de Big Data. El mismo que permitió que, a partir del examen de ingreso Ser Bachiller 2019 y de la encuesta de Factores Asociados 2019, del INEVAL, pronosticar el acceso a la educación superior de bachilleres en todo el país. De las datas proporcionadas se construyó una sola matriz, sobre ésta se depuró la información; eliminando así variables similares y otras que no presentan información en por lo menos el 50 % de observaciones. Así mismo, se eliminaron observaciones que no presentaron resultados de las evaluaciones parciales. Posteriormente, se redujo la matriz, seleccionando las variables utilizadas en estudios similares realizados en Colombia, Argentina y Costa Rica. Además, se revisaron las variables que emplean los proyectos Pisa y Terce, y así tomar los indicadores más recurrentes como las variables significativas para este estudio. Se logró una matriz de 265 915 observaciones por 48 variables; de estas 48 variables, 45 correspondieron a factores asociados. Se aplicó el Análisis de Componentes Principales para representar los 45 factores asociados en un conjunto condensado de menor dimensión; sobre esta base se trabajaron los modelos predictivos que determinan el ingreso, o no, a la educación superior de un determinado individuo. Utilizando las técnicas de Regresión Logística, Análisis Discriminante y Máquina de Soporte Vectorial. Se estableció que, de estos modelos, el más adecuado es el de Regresión Logística el mismo que produce sus pronósticos con un 70 % de eficiencia. Adicionalmente, se determinaron los factores asociados que más influyen en forma positiva y en forma negativa, para que el estudiante ingrese a la universidad.\n"}
{"prompt":"Diseño de un algoritmo de visualización para el diagnóstico de fallas en motores de encendido provocado mediante la utilización de la transformada de Wavelet ->","completion":" El estudio tiene el propósito de desarrollar un algoritmo de visualización para diagnosticar fallas mecánicas inducidas a un motor de combustión interna, mediante la aplicación de la Transformada Wavelet. Se determina con Máquinas de Soporte Vectorial, que el modelo \"Cúbico\", es ideal para categorizar las características de las señales temporales adquiridas.This study has the intention to develop an algorithm of visualization in order to diagnose induced-mechanical failures for an internal combustion engine, through the application Wavelet Transformed. It’s determined by Machines of Vectorial Support that \"the Cubical\" model, is ideal for categorizing the characteristics of the acquired temporary signals.\n"}
{"prompt":"Desarrollo de un algoritmo de diagnóstico para la detección de fallas mecánicas en motores de encendido provocado basados en la transformada Wavelet ->","completion":" En este proyecto se desarrolla un algoritmo de diagnóstico para detectar anomalías mecánicas en motores de encendido provocado mediante la técnica de análisis de la Transforma Wavelet. Los resultados determinan que este método, es más certero respecto al análisis de Fourier, debido a su bajo porcentaje de error de clasificación al utilizar SVM's.This project develops a diagnostic algorithm to detect mechanical anomalies in ignition engines by the technique of analysis of the Wavelet Transform. The results determine that this method is more accurate compared to Fourier analysis, due to the low rate of classification error when using SVM's.\n"}
{"prompt":"Estimación de las emisiones contaminantes de vehículos con motor de encendido provocado mediante análisis de ruido a través de herramientas de clasificación de aprendizaje ->","completion":" Este proyecto trata de la vinculación de la señal acústica emitida por un motor de combustión interna de encendido provocado con sus emisiones contaminantes, en el cual se pretende estimar los contaminantes que la NTE INEN 2204 analiza en la RTV a través de ruido mediante herramientas de aprendizaje y clasificación.This Project to treat of the connection of the acoustic signal emitted for an engine of combustion internal of provoked ignition with its polluting emissions, in which it is intended to estimate the polluting that the NTE INEN 2204 analyzes in the RTV through of noise through learning tools and classification.\n"}
{"prompt":"Desarrollo de un algoritmo mediante análisis de aprendizaje automático para la detección de fallos en vehículos M1 con motores de encendido provocado ->","completion":" En el presente trabajo investigativo se propone como objetivo principal el desarrollo de un algoritmo de aprendizaje automático para la detección de fallas en etapa temprana en vehículos M1. Por consiguiente, mediante la herramienta de aprendizaje y clasificación se analizan los datos de comportamiento del sistema con diferentes tipos de Máquinas de Soporte Vectorial (SVM’s) como el clasificador cúbico y el gaussiano, para de esa manera determinar la fiabilidad.This research paper proposes as its main objective to develop an automatic learning algorithm in order to detect early phase M1 vehicles defects. Therefore, by means of such learning-tools and classification, the system performance data is then analyzed with different kinds of Support Vector Machines (SVMs): including the cubic-classifier and the gaussiano, which function in order to determine reliability.\n"}
{"prompt":"Desarrollo de un sistema de automatización y gestión de la información en una línea de producción de banano ->","completion":" El presente trabajo detalla la automatización de un sistema de recolección de datos en una línea de producción de banano por medio de un indicador electrónico, enviando la información hacia una aplicación, generando predicciones utilizando el aprendizaje automático y articulando el reporte de producción.This work details the automation of a data collection system in a banana production line by means of an electronic indicator, sending the information to an application, generating predictions using machine learning and articulating the production report.\n"}
{"prompt":"Aplicación móvil para clasificar regiones en imágenes mamográficas dicom ->","completion":" El cáncer de mama genera millones de muertes alrededor del mundo todos los años lo cual hace indispensable su pronta detección. Mientras la tecnología avanza se ve la necesidad del uso cotidiano de dispositivos cada vez más pequeños. En el presente trabajo se desarrolló un prototipo móvil que permite clasificar regiones de interés presentes en las imágenes mamográficas DICOM. Se utilizó una data set de 211 imágenes mamografías. El proceso se dividió en cuatro fases: preparación de imágenes, preprocesamiento, segmentación y clasificación. En la fase preparación se usó la librería DCMTK para la lectura y manejo de imágenes. En la fase preprocesamiento con algoritmos como Clahe para la mejora del contraste. Además, la técnica HMF para eliminar el ruido de tipo sal y pimienta. La fase segmentación con Canny se utilizó para la detección de bordes y Watershed para la segmentación. Lo que permitió obtener regiones correspondientes a Masas, Microcalcificaciones y tejidos presentes en la mama. Los resultados de HMF en proporción máxima de señal a ruido promedio de todas las imágenes usadas de 77 dB. El algoritmo Canny presento un 21% de uso en CPU y Watershed uso de Memoria en ejecución de 3709,97 Megabytes (MB). Para luego, ser clasificado mediante Máquinas de Soporte Vectorial (SVM) con resultados de accuracy: 82,43% en masas, 83,78% en micros y 75,36% en masas con micros. Donde la clasificación tiende a bajar para imágenes de tipo masas y micros, y solo masas o micros se mantienen en valores similares.Breast cancer causes millions of deaths around the world every year, which makes early detection essential. As technology advances, the need for the daily use of increasingly smaller devices is seen. In the present work, a mobile prototype was developed that allows classifying regions of interest present in DICOM mammographic images. A data set of 211 mammography images was used. The process was divided into four phases: image preparation, preprocessing, segmentation, and classification. In the preparation phase, the DCMTK library was used for reading and managing images. In the preprocessing phase with algorithms such as Clahe for contrast enhancement. In addition, the HMF technique to eliminate salt and pepper type noise. The segmentation phase with Canny was used for edge detection and Watershed for segmentation. What allowed to obtain regions corresponding to Masses, Microcalcifications and tissues present in the breast. The HMF results in a maximum average signal-to-noise ratio of all images used of 77 dB. The Canny algorithm presented a 21% CPU usage and Watershed Memory usage in execution of 3709.97 Megabytes (MB). To then be classified using Support Vector Machines (SVM) with accuracy results: 82.43% in masses, 83.78% in micros and 75.36% in masses with micros. Where the classification tends to go down for images of the masses and micros type, and only masses or micros remain at similar values.\n"}
{"prompt":"Rendimiento de algoritmos de clasificación en el reconocimiento de actividades de personas ->","completion":" Desarrollar una metodolog´ıa para la medici´on de desempe˜no de algoritmos de clasificaci ´on en el contexto del reconocimiento de actividades de personas.El reconocimiento del accionar de personas utilizando técnicas de aprendizaje de máquina y la gran cantidad de información proporcionada por sensores y procesadas por ordenadores, son sintetizados en modelos que permite estimar comportamientos futuros y prevenir posibles acontecimientos o acciones que afecten al ser humano. Un modelo correctamente entrenado y validado, fácilmente puede sustituir al ser humano en la toma de decisiones. Los modelos de reconocimiento surgen de la aplicación de varias metodologías de aprendizaje de máquina para el tratamiento de los datos. Parten con el análisis del problema a solucionar, la organización de la información en variables, la extracción de características que expresan la acción y el entorno, la segmentación de las características para el entrenamiento y evaluación, el entrenamiento de cada algoritmo y finalmente la evaluación. Este trabajo se centra en la solución a un problema de reconocimiento de cuatro actividades caminar, sentarse en una cama, sentarse en una silla y acostarse. Se utiliza la base de datos de un repositorio digital, los mismos que se someten a metodologías para acondicionar los datos de tal forma que sean útiles para el entrenamiento. Los algoritmos considerados en el entrenamiento son el K-vecinos más cercanos, máquina vectorial de soporte y una red neuronal artificial. La evaluación se basa en métricas que permiten cuantificar el rendimiento de los modelos. La matriz de confusión y sus derivaciones como: la tasa de error, especificidad y recall son los principales indicadores. Los resultados obtenidos, independientemente del modelo, son aceptables debido que sus rendimientos están sobre el 80% de eficiencia en el reconocimiento.\n"}
{"prompt":"Control de sistema de distribución eléctrica usando técnica descubrimiento de patrón (Pattern discovery technique) ->","completion":" Distribution systems are a fundamental part of the electricity generation lifecycle, which are responsible for transporting the power supply from the transformation substations to the final consumer or customer, through transformation stages that are performed by power transformers. Voltage control systems are tools in charge of regulating voltage levels in the critical buses of the system, allowing the power supply to reach the final consumer and guaranteeing safety, quality and reliability at the lowest possible cost. For the above, and the importance of being able to optimally control the voltage profiles, so as to guarantee quality within the established standards, the design is proposed through a methodology that allows the redesign of on-line controllers. The control strategy presented in the article allows the reconfiguration action for a PI controller in a D-STATCOM by using Pattern Discovery techniques and the Vector Support Machines S.V.M. (Suport Vector Machine). In addition, the proposed algorithm provides the compensation system with fast, stable action against tolerable disturbances and failures for the Electrical Distribution System.Los sistemas de distribución son parte fundamental del ciclo de vida de la generación eléctrica, estos son los encargados de transportar el suministro eléctrico desde las subestaciones de transformación hasta el consumidor final o cliente, pasando por etapas de transformación que son realizadas por transformadores de potencia. Los sistemas de control de tensión son herramientas encargadas de regular los niveles de tensión en las barras críticas del sistema, permitiendo que el suministro eléctrico llegue al consumidor final y garantizando la seguridad, la calidad, y la confiabilidad, al menor costo posible. Por el antes expuesto, y la importancia de poder controlar de forma óptima los perfiles de tensión, de manera que se garantice de calidad dentro de las normas establecidas, se propone el diseño a través de una metodología que permita el rediseño de controladores on-line. La estrategia de control presentada en el artículo permite la acción de reconfiguración para un controlador PI en un D-STATCOM mediante el uso de técnicas de Descubrimiento de patrones y las Maquinas de Soporte Vectorial S.V.M. (Suport Vector Machine). Además el algoritmo propuesto proporciona al sistema de compensación una acción rápida, y estable ante perturbaciones y fallas tolerables para el Sistema de Distribución Eléctrica.\n"}
{"prompt":"Estimación de posición de la muñeca a través de señales electromiográficas ->","completion":" Estimar la posición de la muñeca en los movimientos flexión-extensión y radial-cubital a través de señales electromiográficas.El presente estudio, expone la estimación de posición de la muñeca a través de señales electromiográficas, para conseguir esto, se efectuó la selección de las posiciones angulares en los movimientos Flexión-Extensión y Abducción-Aducción, siendo la base principal para el desarrollo de esta investigación. Posteriormente, se eligieron los músculos de los que se extrajeron las señales mioeléctricas, de acuerdo con parámetros como el tamaño del músculo, la superficialidad y el aporte al movimiento en ejecución. Una vez definido un músculo de estudio por movimiento, se extrajeron muestras electromiográficas con la ayuda de tarjetas electrónicas y electrodos superficiales de Plata\/Cloruro de Plata (Ag\/AgCl). Posteriormente, se conformó una base de datos de cada movimiento constituido por 34 muestras, mismas que estaban integradas por 3 activaciones musculares. Conformada la base de datos, se realizó el procesamiento, acondicionamiento y digitalización de la señal; más adelante, se llevó a cabo el proceso de caracterización con análisis en el dominio del tiempo y frecuencia, de donde se obtuvo características particulares de la señal, que son de importancia para los clasificadores. Ulteriormente de obtener las características principales, se aplicó técnicas de aprendizaje de máquina, analizando la clasificación con varios algoritmos de tipo supervisados como Redes Neuronales, Maquinas de Soporte Vectorial, Análisis Discriminante, Nearest Neighbor y de tipo no supervisados como Clustering con la técnica Mapas de auto-organización (SOM); esto, con la finalidad de encontrar un clasificador óptimo que permita la identificación acertada del movimiento.Ingeniería\n"}
{"prompt":"Diagnóstico en línea de un motor de encendido provocado Hyundai Accent DOHC 1.5L mediante herramientas de aprendizaje y clasificación a través del análisis de la señal del sensor de oxígeno de banda corta ->","completion":" En este trabajo se realizó un algoritmo de clasificación para un conjunto de fallas de un motor de combustión interna de encendido provocado, interviniendo en los sistemas de encendido y alimentación, esto se logró mediante el pretratamiento de los datos utilizando análisis de componentes principales y máquinas de soporte vectorial para el proceso de entrenamiento. Obteniendo resultados de precisión en la clasificación superiores a 90% en cada una de las clases.In this work, a classification algorithm was developed for a group of failures of an internal combustion engine with ignition provoked, intervening in the ignition and power systems, this was achieved through the pre-treatment of the data using principal component analysis and support vector machines for the training process. Obtaining results of classification accuracy greater than 90% in each of the classes.\n"}
{"prompt":"Identificación de la intención de movimiento de los dedos de la mano ->","completion":" Identificar la intención de movimiento individual de los dedos de la mano.El presente trabajo expone, la identificación de la intención de movimiento de los dedos de la mano, previo a esto, se hizo énfasis en los movimientos de estudio principales, siendo la base para el desarrollo del estudio de reconocimiento y ubicación de los músculos principales a los movimientos de flexión y extensión interfalángica de los dedos de la mano. Para el desarrollo de este estudio se realizó un estudio histórico a los métodos de análisis de señales bioeléctricas, así como las metodologías implementadas para el proceso de adquisición y caracterización de señales mioeléctrica, además del uso de una técnica de reconocimiento de patrones. Tras el desarrollo de un sistema de interfaz de adquisición - caracterización de señales electromiográficas a 8 canales de reconocimiento y el uso del dispositivo MYO, ubicado en el antebrazo a los músculos de acción principal a los movimientos de la mano, luego las señales adquiridas se normalizan y rectifican, haciéndolas óptimas para el proceso de caracterización a los métodos comunes en el dominio del tiempo y frecuencia, logrando de esta manera obtener un total de 100 muestras de cada uno de los movimientos de estudio, mismos que están integrados a 5 intenciones realizadas por muestra. Una vez obtenida la base de datos característicos de cada uno de los movimientos de estudio, se aplicó el proceso de clasificación de las señales, haciendo uso de una base de datos para el entrenamiento de la máquina de soporte vectorial, y otra base de datos para la comprobación.Ingeniería\n"}
{"prompt":"Desarrollo de un prototipo portátil para el reconociemiento de señales dactilológicas mediante visión artificial ->","completion":" The social and work insertion of deaf-mute people is complicated by the lack of knowledge of sign language by the hearing people, so an alternative was proposed for two-way communication between deaf and hearing people with the development of a portable recognition prototype Dactylological signs by artificial vision, which was based on Vector Support Machine (SVM). The hardware consists of a Pi Camera of 5 MP (Mega Pixels), a Raspberry Pi 3 with a processor of 2GHZ that allows the treatment of images and the work with several softwares and thanks to their size makes the prototype is compact, a screen 7 \"HD Touch (High Definition) with native connection to the Raspberry. The software consists of two parts, the same ones that work together to result in the operation of the prototype, the trainer program creates a database that serves as support for the application through the camera in live video capture the fingerprint And thanks to the SVM compare them and predicts forming words as vectors, which are then reproduced through audio. The effectiveness of the prototype was validated through satisfaction surveys conducted at INAL (National Institute of Hearing and Language) and FENASEC (National Federation of Deaf People of Ecuador). Of which the results obtained were 83% of satisfactory acceptance on the use of the prototype.La inserción social y laboral de las personas sordomudas se complica debido al desconocimiento del lenguaje de señas por parte de personas oyentes, por tal motivo se propuso una alternativa para la comunicación bidireccional entre personas sordomudas y oyentes con el desarrollo de un prototipo portátil de reconocimiento de señales dactilológicas por medio de visión artificial, el cual se basó en SVM (Máquina de Soporte Vectorial). El hardware consta de una Pi Camera de 5 MP (Mega Pixeles), una Raspberry Pi 3 con un procesador de 2GHZ que permite el tratamiento de imágenes y el trabajo con varios softwares y gracias a su tamaño hace que el prototipo sea compacto, una pantalla táctil HD (High Definition ) de 7” con conexión nativa hacia la Raspberry. El software consta de dos partes, las mismas que trabajan conjuntamente para dar como resultado el funcionamiento del prototipo, el programa entrenador crea un banco de imagenes que sirve de apoyo para que la aplicación por medio de la cámara en video en vivo capture las señales dactilológicas y gracias al SVM las compare y prediga formando palabras como vectores, mismas que luego se reproducen por medio del audio. Se validó la efectividad del prototipo mediante encuestas de satisfacción realizadas al INAL (Instituto Nacional de Audición y Lenguaje) y FENASEC (Federación Nacional de Personas Sordas del Ecuador). De las cuales los resultados obtenidos fueron un 83% de aceptación satisfactoria sobre el uso del prototipo.\n"}
{"prompt":"Desarrollo de un sistema de visión artificial para la detección de aglomeración de personas en un semáforo. ->","completion":" Presents the development of a system of artificial vision for the measurement of flow pedestrian in the real time in an intersection of traficc light. For the get the same it will development in matlab put to practical toolbox, in which one of detector of object in waterfall pot to practical the algorithm of viola-jones for detector the faces of the people, o part high of body, in what location in the scientist literature a of the important work of the detection in real time is the method based in the learning of adaboost that for your eficience, this method that uses the algorithm has been chosen, beside the object detector of people, that is based in the technique of histograms of oriented gradients and a guide of Support Vector Machine classifier, that is based of a method that offers robust results thanks to invariance to change in the fund or in the positions of the pedestrians. The aportation principal in this work is the integration of these three algorithms: FrontalFaceCART, Upperbody and peopleDetector for the detection of people in real time with the finality of lower the margin of error in the detection of people.Se presenta el desarrollo de un sistema de Visión Artificial para la medición del flujo peatonal en tiempo real en una intersección de semáforo. Está desarrollado en Matlab utilizando su toolbox, en el cual dentro del detector de objetos en cascada utiliza el algoritmo de Viola-Jones para detectar las caras de la gente (FrontalFaceCART) o parte superior del cuerpo (Upperbody), donde en la literatura científica uno de los trabajos importantes de detección en tiempo real es el método basado en el aprendizaje de Adaboost que es el que utiliza dicho algoritmo, donde por su eficiencia ha sido elegido; además del objeto detector de personas (peopleDetector) que se basa en la técnica de histogramas de gradientes orientados (HOG) y un entrenado de las Máquinas de Soporte Vectorial (SVM) clasificador, se trata de un procedimiento que ofrece resultados robustos gracias a su invariancia ante cambios en el fondo o en las posturas de los peatones. La principal aportación en este trabajo, es la integración de estos tres algoritmos: FrontalFaceCART, Upperbody, y peopleDetector, para la detección de personas en tiempo real con la finalidad de bajar el margen de error.\n"}
{"prompt":"Reconocimiento de imágenes mediante redes neuronales ART ->","completion":" Consideramos de gran utilidad investigar acerca de los principios de ART1 dado que es un algorítmo que no goza de la misma difusión de otros como perceptrón, perceptrón multicapa o mapas autoorganizativos de Kohonen. Otra razón importante es el sinnúmero de aplicaciones que posee ART1 que incluyen a parte del reconocimiento automático de blancos, previsiones financieras, monitoreo de máquinas, diseño de circuitos digitales, análisis químico y visión de robots.\n"}
{"prompt":"Estudio de redes neuronales y aplicaciones prácticas ->","completion":" En su descripción monográfica escrita los autores opinan que las Redes de Neuronas Artificiales son un tipo de aprendizaje y de procedimientos automático insi prtadoa en el funcionamiento del sistema nervioso. Estas simulan las propiedades de los sistemas neuronales biológicos a través de modelos matemáticos recreados mediante mecanismos artificiales, tratando de modelar esquemáticamente la estructura hardware del cerebro. Estos sistemas de procesamiento de informacióm, paralelos, distribuídos y adaptivos, son capaces de aparender de la experiencia a partir de datos del entorno y empleando algoritmos numéricos\n"}
{"prompt":"Clasificación de los sonidos cardíacos usando ondículas y redes neuronales ->","completion":" The auscultation of cardiac sounds is a clinical examination that allows to determine if a patient should be referred to a specialist. The phonocardiogram (PCG) corresponds to the recording of these sounds. The objective of this work is the evaluation of the combination of two of the proposed algorithms during PhysioNet 2016 challenge, the first is based on wavelets and the second on a neural convolutional network to evaluate the performance in the classification of cardiac sounds (normal\/abnormal). The results show a better balance between specificity and sensitivity with respect to the wavelet method, although its performance is inferior to the method based on neural networks. The proposed method has a lower computational cost.La auscultación de los sonidos cardíacos es un examen clínico que permite determinar si un paciente debe ser referido a un especialista. El fonocardiograma (PCG), por sus siglas en inglés, corresponde al registro de estos sonidos. El objetivo de este trabajo es la evaluación de un esquema fundamentado en dos algoritmos propuestos durante el desafío PhysioNet 2016, el primero basado en ondículas y el segundo en una red neuronal convolucional (RNC), para evaluar el desempeño en la clasificación de los sonidos cardíacos (normal\/anormal). Los resultados obtenidos muestran un mejor equilibrio entre especificidad y sensibilidad con respecto al método de las ondículas, aunque su desempeño es inferior al método basado en RNC. El método propuesto tiene un menor costo computacional.\n"}
{"prompt":"Reconocimiento de patrones manuscritos (vocales) usando redes neuronales ->","completion":" En muchas aplicaciones informáticas se requiere interpretar información como señales, voz, sonido, etc., para esto existen diversas técnicas. Se presenta aqui una propuesta para el reconocimiento de caracteres vocales basado en matrices como los datos de entrada, luego estas matrices se transformaran como vectores y con la ayuda de las redes neuronales en específico las redes de base radial, se obtendrá un reconocedor que permita identificar vocales mayúsculas y minúsculas, escritas a mano alzada po cualquier usuario.....\n"}
{"prompt":"Locomoción de un robot cuadrúpedo basada en redes neuronales artificiales ->","completion":" Se diseñó y construyó un robot cuadrúpedo con locomoción basada en la red neuronal artificial perceptrón multicapa, para conocer si logra mantener la estabilidad durante la caminata sobre terrenos irregulares. Se utilizó el método inductivo para el desarrollo del diseño estructural, la circuitería interna, el algoritmo de control y la interfaz de monitoreo. La aplicación del método experimental permitió verificar el funcionamiento del robot. Las piezas que componen el cuerpo y las patas del robot fueron construidas mediante la técnica de impresión 3D con plástico PLA. El algoritmo de control para la locomoción del robot y la interfaz de monitoreo de datos de: sensores ultrasónicos, acelerómetro y velocidad, temperatura y voltaje de cada uno de los motores fueron desarrollados en MATLAB R2010a. La comunicación se realiza inalámbricamente entre la placa microcontroladora Arduino del robot y el ordenador mediante dispositivos Xbee y como fuente de alimentación se utilizaron dos baterías Li-Po. Mediante el análisis de los datos se comprobó que el robot cuadrúpedo no muestra una variación significativa de inclinaciones comparadas con las ideales, por lo tanto mantiene la estabilidad a pesar de irregularidades y obstáculos presentes en el terreno sobre el cual se desplaza. El robot cuadrúpedo podría utilizarse en procesos industriales de transporte de materiales o sustancias peligrosas y exploración de ambientes con terrenos irregulares, de difícil acceso o contaminados.A quadruped robot with locomotion was designed and build based on the artificial neural network perceptron multilayer, to find out if it can keep the stability while walking on uneven terrain. The inductive method was used for the structural design, the internal circuitry, the control algorithm and interface monitoring. The experimental method application allowed verifying the operation of the robot. The component parts of the body and legs of the robot were constructed by 3D printing technique with PLA (Poly Lactic Acid) plastic. The control algorithm for the robot locomotion and monitoring interface data of: ultrasonic sensors, accelerometer and speed, temperature and voltage of each one of the servomotors were developed in MATLAB R2010a. Communication in done wirelessly between the Arduino motherboard plaque and the computer through Xbee devices and as a main power supply two batteries Li-Po were used. By analyzing the data it was found that the quadruped robot shows no significant variation compared with the ideal inclinations, therefore maintains stability despite irregularities and obstacles in the terrain over which it travels. The quadruped robot could be used in industrial processes transporting hazardous materials or substances and exploration of irregular terrain, inaccessible or contaminated.\n"}
{"prompt":"Redes Neuronales Artificiales para Predecir el Riesgo de Insolvencia ->","completion":" En las organizaciones la predicci?n del riesgo de insolvencia llega a ser una arista muy importante en el ?rea financiera dado que se requiere informaci?n anticipada para poder enfrentar a tiempo los problemas econ?micos que puedan presentarse. Tener una buena gesti?n del riesgo financiero prepara con antelaci?n las decisiones y estrategias a tomarse para perdurar en el tiempo. El presente art?culo presenta los conceptos claves del riesgo de insolvencia, as? como su importancia y la teor?a aplicada en los diferentes modelos que se han usado para la predicci?n del riesgo de insolvencia. El modelo que destac? es el uso de la red neuronal artificial, se analiz? las diferentes aplicaciones con redes neuronales artificiales que se han desarrollado para el c?lculo del riesgo de insolvencia de manera predictiva, observando las estructuras b?sicas de la red en cada aplicaci?n, analizando las ventajas y desventajas que se pueden presentar al utilizar este modelo.Mag?ster en Administraci?n de Empresas, menci?n Finanzas\n"}
{"prompt":"Sistema de análisis de riesgo financiero utizando redes neuronales ->","completion":" Este trabajo se basa en la implementación de un sistema que permita analizar el riesgo asociado a un proyecto financiero de expansión, mediante el uso estadístico y un método basado en la inteligencia artificial. Objetivos principales: - proveer una medida representativa del riesgo de un proyecto de inversión; - aplicar los principios de las redes neuronales en las proyecciones de los valores posibles de una variable financiera incierta; - ayudar al analista a la toma de decisiones acerca de un proyecto de inversión. Luego se presentan en orden cronológico las partes que conformaron cada una de las etapas de este trabajo.GuayaquilIngeniero en Computación\n"}
{"prompt":"Sistema de análisis de riego financiero utizando redes neuronales ->","completion":" ESTE TRABAJO SE BASA EN LA IMPLEMENTACION DE UN SISTEMA QUE PERMITA ANALIZAR EL RIESGO ASOCIADO A UN PROYECTO FINANCIERO DE EXPANSION, MEDIANTE EL USO ESTADISTICO Y UN METODO BASADO EN LA INTELIGENCIA ARTIFICIAL. OBJETIVOS PRINCIPALES: -PROVEER UNA MEDIDA REPRESENTATIVA DEL RIESGO DE UN PROYECTO DE INVERSION. -APLICAR LOS PRINCIPIOS DE LAS REDES NEURONALES EN LAS PROYECCIONES DE LOS VALORES POSIBLES DE UNA VARIABLE FINANCIERA INCIERTA. - AYUDAR AL ANALISTA A LA TOMA DE DECISIONES ACERCA DE UN PROYECTO DE INVERSION. LUEGO SE PRESENTAN EN ORDEN CRONOLOGICO LAS PARTES QUE CONFORMARON CADA UNA DE LAS ETAPAS DE ESTE TRABAJO.\n"}
{"prompt":"Controlador lógico programable básico con FPGA y redes neuronales ->","completion":" En el presente documento se estructura una RNA (Red Neuronal Artificial) en una tarjeta FPGA (Field Programmable Gate Array) XC3S500E haciendo uso del Lenguaje para Descripción y Modelado de Circuitos VHDL, para diseñar la funcionalidad de un Controlador Lógico Programable que consta de cuatro entradas digitales y una salida digital. La arquitectura de la RNA modelada sobre la tarjeta FPGA está conformada por cuatro neuronas en la capa de entrada, tres neuronas en la capa oculta y una neurona en la capa de salida.\n"}
{"prompt":"Reconocimiento de imágenes en frames de vídeo utilizando redes neuronales ->","completion":" En la actualidad existen varias aplicaciones para realizar el reconocimiento y clasificación de imágenes en los sistemas de videovigilancia y para esto se requiere procesar el vídeo de manera rápida debido a que son vídeos en tiempo real. Uno de los métodos que se utiliza para realizar estas aplicaciones es el uso de redes neuronales. En el presente proyecto de investigación se realizó un clasificador de imágenes utilizando las redes neuronales convolucionales (CNN), que se utilizaron para entrenar al clasificador cuyas imágenes a ser reconocidas son una secuencia de cuadros de vídeo obtenido a través de una cámara de videovigilancia. El aporte del proyecto es la clasificación de imágenes (personas, vehículos) desde los frames de vídeo que generalmente tienen baja calidad en definición, iluminación, distancia de objetos, etc., y la implementación del clasificador con la red neuronal que requiere una buena capacidad computacional para realizar millones de operaciones simultáneas. En ese contexto para realizar el clasificador de imágenes se utilizó el programa MATLAB que cuenta con una Red Neuronal Convolucional (CNN) denominada Alexnet. Esta red tiene un conjunto de más de 1 millón de imágenes para facilitar el reconocimiento de las mismas. A esta red se la entrenó nuevamente para que únicamente clasifique ciertos objetos en el vídeo (personas, autos). Finalmente se obtuvo el clasificador con redes neuronales que permite reconocer y clasificar personas y autos en vídeos.\n"}
{"prompt":"Reconocimiento e interpretación del alfabeto braille mediante redes neuronales ->","completion":" El problema de la investigación. Marco teórico. Desarrollo del sistema. Factibilidad. Presupuesto. Anexos. Manuales de instalación y usuario.\n"}
{"prompt":"Detección de ataques en una intranet utilizando redes neuronales ->","completion":" Introducción. Marco teórico. Desarrollo. Conclusiones y recomendaciones.\n"}
{"prompt":"Interpretación semiautomática del lenguaje de señas mediante redes neuronales ->","completion":" Planteamiento del problema. Marco teórico. Desarrollo del sistema. Conclusiones y recomendaciones\n"}
{"prompt":"Sistema multimedio del funcionamiento de redes neuronales (RNA media) ->","completion":" Capitulo I. Introduccion. Capitulo II. Marco teorico. Capitulo III. Desarrollo de RNA media. Capitulo VI. Conclusiones y recomendaciones. Glosario. Bibliografia. Anexos.\n"}
{"prompt":"Clasificación de frutas basadas en redes neuronales convolucionales ->","completion":" Magíster en Tecnologías de la Información\n"}
{"prompt":"Óptima ubicación de generación distribuida en redes de distribución con el uso de redes neuronales artificiales ->","completion":" En el presente trabajo se desarrolla el entrenamiento de redes neuronales artificiales por medio del software MATLAB simulink, con la finalidad de encontrar la óptima ubicación de unidades de generación distribuida (potencia reactiva) en el sistema de distribución IEEE de 34 barras. Para la creación y entrenamiento de las redes neuronales artificiales de utilizará el sistema de prueba del IEEE de 33 barras. Posteriormente, a este sistema se le añade o añaden una o dos unidades de generación con valores especificados en el planteamiento del problema; se tendrá las variables de interés (voltajes en las barras) las cuales se utilizará como datos para el entrenamiento de la red. Una vez realizado el entrenamiento de la RNA se procede a valorar en el sistema de distribución IEEE de 34 barras, permitiendo identificar cual es la ubicación óptima de UGD para la mejora de perfiles de voltaje. Finalmente se presentan algunos resultados de los casos de estudios propuestos, como el tiempo que tarda en entrenarse la RNA, la mejor validación, la efectividad del entrenamiento de la red entre otros parámetros.In the present work, artificial neural network training is developed by means of the MATLAB simulink software, in order to find the optimal location of distributed reactive power generation units in the IEEE 34-bus distribution system. For the creation and training of artificial neural networks, the IEEE 33-bar test system will be used. Subsequently, to this system one or two generation units are added or added with values specified in the problem statement; we will have the variables of interest (voltages in the bars) which will be used as data for the training of the network. Once the ANN training has been carried out, the IEEE 34-bar distribution system is evaluated, allowing the identification of the optimal location of the UGD for the improvement of voltage profiles. Finally, some results of the proposed case studies are presented, such as the time it takes to train the ANN, the best validation, the effectiveness of the network training, among other parameters.\n"}
{"prompt":"Credit scoring, aplicando técnicas de regresión logística y redes neuronales, para una cartera de microcrédito ->","completion":" Esta investigación pretende contrastar la hipótesis de sí el uso de redes neuronales, para la modelización del credit scoring de una cartera de microcrédito, logra un mejor performance que utilizar una metodología de regresión logística. Para esto se hace uso de la información de una cartera del producto de microcrédito, proporcionada por una institución financiera ecuatoriana de mediano tamaño, desembolsada entre los periodos de enero 2014 a diciembre 2017. La información corresponde al momento del desembolso de los créditos, por lo cual se construye modelos scoring de originación. Los dos modelos por desarrollar son construidos con el programa estadístico R y una vez se cuenta con estos, se procede a comparar su poder predictivo, capacidad para diferenciar entre buenos y malos clientes, adaptación a los datos, etc.; a partir de distintos estadísticos como KS, coeficiente de Gini, matriz de confusión, AUROC, criterio de información de Akaike. Además, se aplica los modelos en un periodo de información distinto al que se usó en su construcción y de esta forma establecer si son generalizables, al ser funcionales con información distinta al de su desarrollo. El modelo de redes neuronales se ajusta de mejor forma a los datos, pues se obtiene un criterio de información Akaike menor al de regresión logística, con una diferencia de 8.029,2 puntos. De igual forma, los estadísticos KS, coeficiente de Gini y curva ROC evidencia que hacer uso de las redes neuronales logra una mejor clasificación de los clientes, con 5,19, 5,84 y 2,92 puntos porcentuales por encima de los estadísticos del modelo de regresión logística, respectivamente. Finalmente, la matriz de confusión muestra un menor error con el modelo de redes neuronales, al compararlos con un mismo punto de corte óptimo. Los resultados obtenidos evidencian que la metodología de redes neuronales proporciona un modelo scoring más robusto que al usar una regresión logística, pudiendo corroborar que la hipótesis planteada es verdadera, bajo el proceso de modelización empleado.\n"}
{"prompt":"Reconocimiento de caracteres del alfabeto dactilológico mediante redes neuronales artificiales: Un enfoque experimental ->","completion":" RESUMENEn este artículo se presenta el desarrollo de un sistema orientado a facilitar la comunicación de aquellas personas con discapacidad auditiva, del habla o ambas; y que se ven obligados a utilizar otras formas de comunicación como el uso del lenguaje de señas. Para solventar el problema de comprensión de este lenguaje, se propone un enfoque experimental de reconocimiento de caracteres del alfabeto dactilológico mediante la adquisición y procesamiento de imágenes digitales, y la aplicación de un clasificador basado Redes Neuronales Artificiales (RNA).Palabras clave: Dactilología, lenguaje de señas, Redes Neuronales Artificiales, clasificador.ABSTRACTThis article presents the development of a system aimed to aid people with speech and\/or communication disabilities, who must use the sign language and the dactilologic alphabet in order to transmit their ideas. To assist others in understanding such language, we present an experimental approach for sign language characters recognition through digital image acquisition and processing techniques and the use of a Neural Network based classifier.Keywords: Dactylology, sign language, Artificial Neural Networks, classifier.\n"}
{"prompt":"Valoración de la molestia percibida por el ruido de tráfico aplicando redes neuronales artificiales ->","completion":" This work covers the configuration and application of an artificial neural network, to make an assessment of perceived verbal annoyance between people towards different descriptors of traffic noises such as A-weighted equivalent sound pressure level (LA), equivalent continuous sound pressure level (LAeq), percentile level (Ln), temporal sound level variance (TSVL), peak factor (CF) and spectral centroid (G). All these values were obtained in a data survey carried out in a previous work, which presents responses of verbal annoyance tabulated through surveys. The configuration of the neural networks was made using MatLab software, where the architecture of the network is specified based on parameters such as number of neurons, layers and the error to be taken into account to verify its operation, which in this work falls into the mean square error. Each parameter of the network architecture was modified several times obtaining different results. These results were compared to each other until finding a configuration that guarantees a minimum mean square error and therefore a correct functioning. Finally, a comparison was made between the final data delivered by the neural network and those presented in the previous work in order to find the efficiency in the neural network.Este trabajo aborda la configuración y aplicación de una red neuronal artificial, para realizar una valoración de la molestia verbal percibida entre las personas hacia diferentes descriptores de ruidos de tráfico tales como nivel de presión sonora ponderado A (LA), nivel de presión sonora continuo equivalente (LAeq), nivel percentil (Ln), varianza temporal de nivel sonoro (TSVL), factor de cresta (CF) y centroide espectral (G). Todos estos valores fueron obtenidos en un levantamiento de datos realizado en un trabajo previo, el cual presenta respuestas de la molestia verbal tabuladas mediante encuestas realizadas. La configuración de las redes neuronales se realizó mediante el software MatLab, donde se especificó la arquitectura de la red en base a parámetros como numero de neuronas, capas y el error a ser tomado en cuenta para comprobar su funcionamiento, que en este trabajo recae en el error cuadrático medio. Cada parámetro de la arquitectura de la red fue modificado varias veces obteniendo diferentes resultados. Estos resultados fueron comparados entre si hasta encontrar una configuración que garantice un error cuadrático medio mínimo y por lo tanto un correcto funcionamiento. Por último, se realizó una comparación entre los datos finales entregados por la red neuronal y los presentados en el trabajo previo con la finalidad de encontrar la eficacia en la red neuronal\n"}
{"prompt":"Proyección de la demanda de energía eléctrica a corto plazo, mediante redes neuronales artificiales ->","completion":" Para llegar con dicha energía a los clientes, se debe expandir y mejorar las instalaciones eléctricas de distribución de energía eléctrica, requiriéndose dinero, que se debe invertir en dichas instalaciones. El conocimiento de la magnitud de energía requerida, trae como consecuencia, el uso de los recursos de manera adecuada, para evitar: - inversiones prematuras, en expandir las instalaciones que no tendrán un aprovechamiento inmediato (sobre equipamiento), - inversiones por debajo de la necesidad del sistema eléctrico a futuro, sobreutilizando las existentes, generando deterioro en ellas y en la calidad del suministro (sub equipamiento). Por tal motivo, es necesario establecer el mejor método de pronóstico de la demanda, que se ajuste al comportamiento de la población dentro de esa área de concesión, donde la CNEL EP Santa Elena presta sus servicios.GuayaquilMagíster en Automatización y Control Industrial\n"}
{"prompt":"Aplicación de redes neuronales artificiales en la estimación del nivel de servicio en un CALLCENTER. ->","completion":" En el presente proyecto se realiza la construcción de una red neuronal artificial para pronosticar el grado o nivel servicio de un centro de llamadas o call center perteneciente a un proveedor de internet. Esta red se elabora con la finalidad de demostrar que a través de este tipo de modelo computacional se puede predecir el grado de calidad en el servicio de un call center, es decir, poder determinar la eficiencia de atención de los operadores en los futuros días en función a una base de datos del nivel de servicio en días previos. Se empieza por dar una descripción concisa de los modelos tradicionales de determinación o pronóstico de una variable, así como también, se detallan la composición y funcionamiento de las redes neuronales artificiales, tanto en sus topologías, algoritmos de aprendizaje, aplicativos en diferentes áreas y su utilidad en la actualidad. Posterior a esto se define el problema a resolver especificando el método a utilizar, los modelos de predicción, métodos de ajuste exponencial y diferentes topologías de redes neuronales artificiales para poder llegar a la solución deseada. Con estos aditamentos se implementa una red neuronal utilizando como interfaz MINITAB y como elemento de aprendizaje SOLVER, con la finalidad de ver en base a análisis comparativos los errores de estimación y las etapas de entrenamiento de los modelos asociados para este estudio.In the present project the construction of an artificial neural network is done to determine the degree or level of service of a Call Center. This network is elaborated with the purpose of demonstrating that through this type of computational model the quality of the service in the Call Center can be predicted, that is, to be able to determine the efficiency of attention of the operators in function of the demand of calls that they enter We start by giving a concise description of the traditional models of determination or prognosis of a variable, as well as detailing the composition and functioning of artificial neural networks, both in their topologies, learning algorithms, applications in different areas and their utility today. After this, the problem to be solved is defined by specifying the method to be used, the prediction models, exponential adjustment methods and different topologies of artificial neural networks in order to reach the desired solution. With these add-ons, a neural network is implemented using MINITAB as an interface and as a learning element SOLVER, with the purpose of seeing the estimation errors and the training stages of the associated models for this study based on comparative analyzes.\n"}
{"prompt":"Análisis De Conductas Sociales Aplicado A Big Data Mediante Técnicas De Redes Neuronales Artificiales. ->","completion":" ADOBELas distintas empresas que manjean un foro donde interactuan diferentes usuarios, sin importar la étnia, localización o lenguaje nativo, realizan diferentes conjuntos de procesos para efectuar una buena comunicación entre usuarios a la hora de compartir ideas, recursos u opiniones. Algunas empresas – instituciones, regulan estos sitios web mediante tecnicas tecnológicas tradicionales, por ende, el tiempo de análisis podría no ser el más optimo. El realizar un análisis y clasificar los comentarios de cientos, miles e inclusive millones de usuarios es una tarea demandante, tedioso y cansado. Para esto, se desarrolla un algoritmo encargado de clasificar y mostrar gráficamente los resultados del análisis dentro de la base de datos, este estudio sigue los principios de una de las ramas de la Inteligencia Artificial “Las Redes Neuronales Artificiales”. Para el desarrollo de este script se tomo como referencia la Base de Datos de Reddit de Mayo del 2015. A la vez se realizo encuestas a los estudiantes de la Carrera de Ing. En Sistemas Computacionales de la Universidad de Guayaquil que han cursado desde 5to a 8vo semestre, para así conocer que tan familiarizados se encuentran con el tema a desarollar. Dando como conclusión que el proyecto es factible, reutilizable y mejorable para futuros estudios investigativos o desarrollos más complejos. A la vez se otorga recomendaciones de como adentrarse al mundo de las Python y ANN (Artificial Neural Networks) y así sacar el mayor provecho sin descarrilarse de este amplio mundo.The differents companies that run a forum where different users interact, regardless of ethnicity, location or native language, perform differents sets of proceses to make a good communication between users when it comes to share ideas, resources or opinions. Some companies - institutions, regulate these websites through traditional technological techniques, therefore, the time of analysius may not be the most optimal. Performing an analysis and classifying the comments of hundreds, thousands and even millions of users is a demanding, tedious and tiring task. That’s why an algorithm is developed in charge of classifying and graphically show the results of the analysis within the database, this study follows the principles of one of the brances of Artificial Intelligence “Artificial Neural Networks”. For the development of this script was taken as a reference of May2015 Reddit Database. At the same time, surveys were carried out on the students in Computer Engineering of the University of Guayaquil who have almost studied from 5th to 8th semester, in order to know how familiar they are with the topic. Concluding that the project is feasible, reusable and it can be improved for future research studies or mroe complx developments. At the same time it offers recommendations on how to get into teh world of Python and ANN (Artificial Neural Networks) and thus get the most benefit without derailing from this wide world.\n"}
{"prompt":"Análisis de imágenes de rayos X de Covid-19 a través de redes neuronales artificiales. ->","completion":" PDFEn la actualidad, las pruebas más efectivas para la detección de Covid-19 como el análisis de imágenes por tomografía axial computarizada (TAC) y las evaluaciones médicas de laboratorio como la prueba de reacción en cadena de la polimerasa (PCR), son uno de los métodos más efectivos para el diagnóstico de esta enfermedad. La única desventaja es que estos métodos tradicionales son muy costosos y eso implicaba que la población de clase media-baja no tenga acceso a estas pruebas de detección. Las redes neuronales artificiales juegan un papel muy importante en el campo de la medicina y en investigaciones tecnológicas que contribuyan a la detección de enfermedades como el Covid-19. Este proyecto se centralizó con el fin de proporcionar un apoyo a los médicos en la toma de decisiones, utilizando herramientas tecnológicas. Se realizó un modelo de machine learning para el análisis de imágenes de rayos X para la detección de Covid-19 a través de redes neuronales convolucionales. El algoritmo fue realizado en el lenguaje de programación Python con el uso del entorno de desarrollo en la nube de Google Colaboratory. Por medio de los repositorios de acceso público de GitHub y Kaggle, se recolectaron bases de datos de imágenes de rayos X de tórax de pacientes con Covid-19 y pacientes normales (sanos) para generar un dataset con imágenes de entrenamiento y validación. Se realizaron pruebas experimentales con tres tipos de arquitectura de redes neuronales convolucionales para los modelos A, B y C. Siendo el modelo C el que obtuvo los mejores resultados.Currently, the most effective tests for the detection of Covid-19 such as computed axial tomography (CT) image analysis and laboratory medical evaluations such as the polymerase chain reaction (PCR) test, are one of the most effective methods for the diagnosis of this disease. The only disadvantage is that these traditional methods are very expensive and that meant that the lower-middle class population did not have access to these screening tests. Artificial neural networks play a very important role in the field of medicine and in technological research that contributes to the detection of diseases such as Covid-19. This project was centralized in order to provide support to doctors in decision-making, using technological tools. A machine learning model was performed for the analysis of X-ray images for the detection of Covid-19 through convolutional neural networks. The algorithm was carried out in the Python programming language with the use of the Google Colaboratory cloud development environment. Through the public access repositories of GitHub and Kaggle, databases of chest X-ray images of patients with Covid-19 and normal (healthy) patients were collected to generate a dataset with training and validation images. Experimental tests were carried out with three types of convolutional neural network architecture for models A, B and C. Model C being the one that obtained the best results.\n"}
{"prompt":"Desarrollo de una aplicación con redes neuronales artificiales para el diagnóstico preventivo de la retinopatía diabética ->","completion":" La retinopatía diabética es una de las causas principales de ceguera en la población ecuatoriana, se produce debido a altos índices de desórdenes alimenticios, provocando patologías graves como diabetes, el colesterol, la hipertensión arterial, entre otras, sin embargo, todas estas patologías podrían ser detectadas en etapas tempranas mediante el uso de técnicas de inteligencia artificial, para la implementación de sistemas expertos. En el presente trabajo de investigación se ha realizado una revisión de literatura para analizar trabajos relacionados, logrado evidenciar que la calidad de las imágenes de la retina (Retinografias) influye en la validación de los modelos planteados, ya que no disponen de datos de gran valor para el análisis de las imágenes. Este proyecto se enfoca en el desarrollo de una aplicación de predicción de retinopatía diabética, con el fin de brindar un aporte clínico. Por otra parte, toda la información referente a la base de retinografias fue proporcionada por el Hospital de Especialidades de las Fuerzas Armadas Nro.1, estas imágenes permitieron obtener los datos requeridos para el presente trabajo. Para el análisis de la información se utiliza algoritmos de procesamiento de imágenes realizando un pre-procesamiento a las imágenes obtenidos para evitar valores irrelevantes o incorrectos. En la última etapa se diseñó un modelo de red neuronal artificial con el fin de obtener predicciones con un alto índice de precisión y realizar un protocolo de pruebas que posteriormente servirá de referente para su próxima implementación. Palabras clave:\n"}
{"prompt":"Desarrollo de una aplicación con redes neuronales artificiales para el diagnóstico preventivo de la retinopatía diabética ->","completion":" La retinopatía diabética es una de las causas principales de ceguera en la población ecuatoriana, se produce debido a altos índices de desórdenes alimenticios, provocando patologías graves como diabetes, el colesterol, la hipertensión arterial, entre otras, sin embargo, todas estas patologías podrían ser detectadas en etapas tempranas mediante el uso de técnicas de inteligencia artificial, para la implementación de sistemas expertos. En el presente trabajo de investigación se ha realizado una revisión de literatura para analizar trabajos relacionados, logrado evidenciar que la calidad de las imágenes de la retina (Retinografias) influye en la validación de los modelos planteados, ya que no disponen de datos de gran valor para el análisis de las imágenes. Este proyecto se enfoca en el desarrollo de una aplicación de predicción de retinopatía diabética, con el fin de brindar un aporte clínico. Por otra parte, toda la información referente a la base de retinografias fue proporcionada por el Hospital de Especialidades de las Fuerzas Armadas Nro.1, estas imágenes permitieron obtener los datos requeridos para el presente trabajo. Para el análisis de la información se utiliza algoritmos de procesamiento de imágenes realizando un pre-procesamiento a las imágenes obtenidos para evitar valores irrelevantes o incorrectos. En la última etapa se diseñó un modelo de red neuronal artificial con el fin de obtener predicciones con un alto índice de precisión y realizar un protocolo de pruebas que posteriormente servirá de referente para su próxima implementación.\n"}
{"prompt":"Reconocimiento de caracteres de una placa de automóvil mediante redes neuronales artificiales utilizando Matlab ->","completion":" Este proyecto presenta un estudio y diseño de algoritmos necesarios para reconocer los caracteres alfanuméricos presentes en una placa vehicular, estos algoritmos son diseñados tanto en el campo de procesamiento digital de imágenes como en el de redes neuronales artificiales. Se realiza una breve descripción de los modelos de redes neuronales tipo perceptrón multicapa, base radial y Hopfield, estableciendo los fundamentos teóricos necesarios para la construcción y entrenamiento de dichas redes.Además, se establecen parámetros para el diseño de la arquitectura de cada tipo de red que nos permiten una solución satisfactoria al problema de clasificación de caracteres. El programa realizado extrae de la imagen la zona perteneciente a la placa basándose en la morfología de la misma, posteriormente se extrae cada uno de los objetos pertenecientes a los caracteres de la placa, para luego ser clasificados por medio de redes neuronales. Finalmente se realiza un análisis de resultados obtenidos evaluando con dos conjuntos de pruebas cada tipo de red neuronal estableciendo el tipo de red que mejor rendimiento presenta para la solución de este problema. Se diseña también una aplicación de control de acceso vehicular que permite visualizar de mejor manera los resultados obtenidos.\n"}
{"prompt":"Aplicación de redes neuronales artificiales en el reconocimiento de huellas dactilares ->","completion":" Propuesta. Marco téorico. Desarrollo del sistema. Conclusiones y recomendaciones.\n"}
{"prompt":"Pronóstico del recurso solar a corto plazo para Distritos industriales basado en redes neuronales artificiales ->","completion":" La energía tradicional y la no contaminante es un tema relevante para la humanidad debido a su crecimiento exponencial en los últimos años y a la necesidad que se tiene de la energía. Conociendo que la mayor fuente de energía que se dispone es la energía solar debemos aprovechar este recurso para así crear energías renovables que pueda sustituir a las no renovables y de paso disminuir las emisiones de gases a la atmosfera. Para un óptimo aprovechamiento se usarán sistemas fotovoltaicos y fototérmicos lo que conlleva la necesidad de un amplio conocimiento sobre la radiación solar que impacta la corteza terrestre, considerando que estos valores cambian en cuestión de horas, días o meses dependiendo de su latitud y los microclimas de cada zona. Para esta investigación expondremos el entrenamiento de una red neuronal artificial basado en multicapas para predecir un horizonte a corto plazo de radiación solar. Los modelos que consideramos varían de acuerdo al algoritmo utilizado para entrenar a la red neuronal artificial y esto hace que tengamos diferentes valores de potencia en la simulación de un módulo fotovoltaico.Traditional and non-polluting energy is a relevant issue for humanity due to its exponential growth in recent years and the need for energy. Knowing that the largest source of energy available is solar energy, we must take advantage of this resource in order to create renewable energies that can replace non-renewable ones and, incidentally, reduce gas emissions into the atmosphere. For optimal use, photovoltaic and photothermal systems will be used, which entails the need for extensive knowledge about solar radiation that reaches the earth's surface, considering that these values change in a matter of hours, days or months depending on its latitude and the microclimates of each zone. For this research we will expose the training of an artificial neural network based on multilayers to predict a short-term horizon of solar radiation. The models that we consider vary according to the algorithm used in the training of an artificial neural network and this means that we have different power values in the simulation of a photovoltaic module.\n"}
{"prompt":"Redes neuronales artificiales aplicadas en la predicción de caudales en la cuenca del Rio Paute ->","completion":" Sistemas que permiten la predicción en líneas de caudales en la cuenca del Rio Paute, usando redes neuronales artificiales. Para el desarrollo del sistema se utilizó como metodología el UML, proceso unificado y PSP. Como herramientas de desarrollo se utilizó Visual Studio, NET, Matlab y Braincom.Ingeniero de SistemasCuenca\n"}
{"prompt":"Modelo de pronóstico de ventas de vehículos livianos usando redes neuronales artificiales ->","completion":" La precisión en la predicción de las ventas es vital en cualquier tipo de industria ya que puede mejorar la calidad de las estrategias de negocios o de la toma de decisiones, específicamente en la industria automotriz juega un papel cada vez más importante debido a la creciente competencia registrada en el mercado, a los largos tiempos de desarrollo y producción y a su relación con las variables económicas. En este documento se compara el desempeño de los métodos clásicos de previsión contra las redes neuronales artificiales (RNA) al pronosticar las ventas de vehículos livianos de la empresa Neohyundai, se consideran variables internas y externas propias del sector. Primero, se llevó a cabo un paso de pre-procesamiento para asegurar la calidad de los datos de entrada a la RNA, en esta etapa se incluye la normalización y la selección de las variables más influyentes a través de la regresión de Lasso, a continuación se establece la arquitectura de la red y los parámetros de aprendizaje. Los resultados muestran que las RNA superan a los métodos tradicionales de predicción, esto significa que la demanda de vehículos que son bienes de consumo duradero puede ser pronosticada mediante el uso de diferentes variables. Además, al determinar la importancia relativa de las variables de entrada se encontró que las variables económicas contribuyen de forma significativa en la previsión.Accuracy in sales prediction is vital in any type of industry as it can improve the quality of business strategies or decision making. Specifically, in the automotive industry it plays an increasingly important role due to the growing competition registered in the market, to the long development and production times and to its relationship with the economic variables. This study compares the performance of the classical forecasting methods against artificial neural networks (ANN) when forecasting light vehicle sales of the Neohyundai company, internal and external variables characteristic of the sector are considered. First, a preprocessing step was carried out to ensure the quality of the input data to the ANN, in this stage the normalization and selection of the most influential variables through Lasso regression is included, then Network architecture and learning parameters are established. The results show that ANN exceed traditional prediction methods, this means that the demand for vehicles that are durable consumer goods can be predicted by using different variables. Furthermore, when determining the relative importance of the input variables, it was found that the economic variables contribute significantly to the forecast.Ingeniero IndustrialCuenca\n"}
{"prompt":"Reconocimiento de caracteres del alfabeto dactilológico mediante redes neuronales artificiales: un enfoque experimental ->","completion":" En este artículo se presenta el desarrollo de un sistema orientado a facilitar la comunicación de aquellas personas con discapacidad auditiva, del habla o ambas; y que se ven obligados a utilizar otras formas de comunicación como el uso del lenguaje de señas. Para solventar el problema de comprensión de este lenguaje, se propone un enfoque experimental de reconocimiento de caracteres del alfabeto dactilológico mediante la adquisición y procesamiento de imágenes digitales, y la aplicación de un clasificador basado Redes Neuronales Artificiales (RNA).This article presents the development of a system aimed to aid people with speech and\/or communication disabilities, who must use the sign language and the dactilologic alphabet in order to transmit their ideas. To assist others in understanding such language, we present an experimental approach for sign language characters recognition through digital image acquisition and processing techniques and the use of a Neural Network based classifier.Cuenca\n"}
{"prompt":"Pérdida de memoria a corto plazo en los estudiantes de la Unidad Educativa Rosa Zárate ->","completion":" This research work is aimed at a bibliographic review with different authors, whichproposes as a general objective; to analyze short-term memory loss in first and second-year high schoolstudents from the Rosa Zárate Educational Unit, through research withscientific articles. Short- term memory is itself a temporary storage and fast programming, in which said collected information is detailed, demonstrated, andestablished for later storage, where the informationis retained for a minimum period ofapproximately twenty seconds. On the other hand, short-term memory works actively,which is why it is called working memory. The research presentsa quantitative approachwith a non-experimental and descriptive design in itself, taking into account what wasanalyzed and what are the characteristics presented by the first and second high schoolstudents of the Rosa Zárate educational Unit. For data collection, first and secondhighschool students were evaluated with a population of 60 students, including men and women, where the test Developed by Gilewski, Zelinsky and Sahie, (1990) validated by Alarcón, Rubio, and Fernández was applied (2008) where it is composed of 31 items.El presente trabajo de investigación está encaminado en una revisión bibliográficacon diferentes autores, que propone como objetivo general; analizar la pérdida dememoria a corto plazo en los estudiantes de primero y segundo de bachillerato de la unidad Educativa Rosa Zárate, mediante una investigación con artículos científicos. La memoria a corto plazo se trata en si de un almacenamiento temporal y de programación rápida, en lo cual dicha información recopilada es detallada, demostrada y establecida para su posterior almacenamiento, donde la información es retenida durante un periodo mínimo de tiempo aproximadamente de veinte segundos. Por otra parte, la memoria a corto plazo trabaja de manera activa, es por eso por lo que se lo denomina memoria operativa de trabajo. La investigación presenta un enfoque cuantitativo con un diseño noexperimental y descriptivo en si tomando en cuenta lo que se analizó y cuáles son las características que presentan los estudiantes de primero y segundo de bachillerato de la unidad educativa Rosa Zárate. Para la recopilación de datos fueron evaluados los estudiantes de primero y segundo de bachillerato con una población de 60 estudiantes entre ellos hombres y mujeres donde fue aplicado el test Desarrollado por Gilewski, Zelinsky y Sahie, (1990) validado por Alarcón, Rubio, y Fernández. (2008) donde estar compuesto por 31 ítems.UNACH, Ecuador\n"}
{"prompt":"La lúdica para fortalecer la memoria a corto plazo en la asignatura de matemática de los estudiantes del colegio Don Bosco de la ciudad de Quito ->","completion":" La memoria a corto plazo juega un papel muy importante en la vida del ser humano, debido a que permite retener y manipular temporalmente información, mientras participa en procesos de aprendizaje, comprensión y razonamiento. Actualmente en el contexto ecuatoriano la matemática es la asignatura que más problemas presencia, sea ya por la complejidad, el poco de interés de los educandos o debido a las estrategias tradicionales que se aplican para su enseñanza, Ecuador participó por primera vez en las pruebas PISA en al año 2018, donde el 70,9% de los estudiantes no alcanzaron el nivel de desempeño básico. En la ciudad de Quito en la escuela particular Don Bosco, en los estudiantes de sexto y séptimo año se observó que solo el 1% de la población investigada alcanza un desarrollo adecuado de la memoria a corto plazo en relación a su rango de edad, 11 y 12 años, presentan dificultad en la retención de información para el aprendizaje de los contenidos matemáticos. La presente investigación tiene como objetivo determinar la influencia de la lúdica como herramienta para el fortalecimiento de la memoria a corto plazo en la asignatura de matemáticas en los estudiantes del colegio Don Bosco. El estudio es de carácter cuasi experimental mediante la aplicación del test Wisc de dígitos como estrategia en la recolección de información. Se concluye que la lúdica influye en el desarrollo de la memoria a corto plazo en la matemática, pues las calificaciones negativas en esta asignatura pasaron del 31% en el tercer parcial al 5% en cuarto parcial, disminuyendo en un 26% la cantidad de estudiantes que no logran nota mínima de 7,00 puntos. Además, la cantidad de estudiantes que alcanzaron el rango de edad adecuado, paso de ser el 1% al 40%, según la aplicación del post test Wisc.\n"}
{"prompt":"Trastornos de la memoria a corto plazo en los adultos mayores del hogar geriátrico Daniel Álvarez Sánchez de la ciudad de Loja ->","completion":" The purpose of this research is to show and to detect the presence of memory disorders short term and potential risk factors that trigger the aforementioned disorders in older adults residing her nursing home Jan Daniel Alvarez Sanchez de Loja, as data from research conducted in populations of 50 and 95 years show high prevalence of impaired short-term memory, being more frequent memory disorders in women and in people with risk factors such as stress, habit smoking, alcohol consumption, history of head trauma, drug use, exposure to trauma and low education. This research was descriptive, quantitative and transversal, with the data collection method using a data-data collection from medical records of the inmates, plus an interview about the risk factors that trigger memory disorders used short-term and finally a test called CODEX, for the detection of disorders of short-term memory in older adults was applied. Results from this investigation showed the existence of memory disorders short term 30% of the population studied, showing a low incidence of impaired short term memory; between the main memory disorders in the short term that was found in this population were; Alzheimer's by 33%, 27% dementia, amnesia and 13% respectively Korsakof syndrome, delirium and 7% respectively retrograde amnesia. Among the risk factors, we have 58% alcohol, snuff consumption 54%, 14% drug use, exposure to traumatic events 26%, exposure to stressful situations 52%. What we can conclude that the disorder short term memory in older adults the nursing home Daniel Alvarez Sanchez de Loja occur in low incidence and that the main risk factors found were alcohol, snuff and drugs ; low educational level, exposure to traumatic and stressful situations. Keywords: memory disorders, aging, risk factors, memory.El propósito de este trabajo de investigación es mostrar y detectar la presencia de TRASTORNOS DE MEMORIA A CORTO PLAZO y los posibles factores de riesgo que desencadenan los mencionados trastornos en los adultos mayores que residen en el hogar geriátrico Daniel Álvarez Sánchez de la ciudad de Loja, ya que datos de investigaciones realizadas a nivel nacional, muestran alta prevalencia de trastornos de memoria a corto plazo, siendo más afectado el sexo femenino, personas estresadas, fumadores, consumistas de alcohol, personas que sufrieron traumatismos craneoencefálicos, por uso de otras drogas, por estar expuestas a situaciones traumáticas. Esta investigación fue de tipo descriptiva, cuantitativa y transversal, teniendo como método el uso de una ficha de recolección de datos de las historias clínicas de los asilados, además se utilizó una entrevista sobre los factores de riesgo que desencadenan trastornos de memoria a corto plazo y finalmente se aplicó un test llamado CODEX, destinado a la detección de trastornos de memoria a corto plazo. Los resultados arrojados por esta investigación mostraron la existencia de TRASTORNOS DE MEMORIA A CORTO PLAZO en un 30% de la población estudiada, mostrando una baja incidencia de los mencionados trastornos; entre los principales trastornos que se encontró en esta población fueron; alzhéimer en un 33%, demencia senil 27%, amnesia anterógrada y síndrome de korsakof 13%, delirium y amnesia retrograda 7 %, hay que mencionar que el Alzheimer, amnesia anterógrada, síndrome de korsakof y delirium son trastornos de memoria de corto y largo plazo. Entre los factores de riesgo presentes tenemos consumo de alcohol 58%, 54% consumo de tabaco, 14% consumo de otras drogas, exposición a situaciones traumáticas 26%, exposición a situaciones estresantes 52%. Con lo que podemos concluir que los trastornos de memoria a corto plazo en los adultos mayores del hogar geriátrico Daniel Álvarez Sánchez de la ciudad de Loja se presentan en baja incidencia y que los principales factores de riesgo encontrados fueron el consumo de alcohol, tabaco y drogas; bajo nivel educativo, exposición a situaciones traumáticas y estresantes. Palabras clave: trastornos de la memoria, envejecimiento, factores de riesgo, memoria.\n"}
{"prompt":"Aprendizaje perceptivo - discriminativo para fortalecer el desarrollo de la memoria a corto plazo, en niños con síndrome de down de 6 a 7 años incluidos a la educación regular, en el centro educativo particular bilingüe Dirigentes del Futuro, de la ciudad de Loja. Período 2013-2014 ->","completion":" This thesis was conducted in order to determine the discriminative Perceptual Learning to strengthen the development of Short Term Memory in Children with Down Syndrome 6-7 years included the Regular Education in Private Bilingual School leaders Future , of the City of Loja. 2013-2014, the research design was descriptive, social intervention, transversal, the methods used were: hermeneutic, analytical, statistical and descriptive. The population was constituted for 43 students and the sample was selective in which 2 children were taken with Down syndrome included in regular education, The initial diagnosis was a level showed fair to good short-term memory, perceptual learning discriminative subsequently applied and making a comparison with the results of the pre and post tests may be noted that the implementation of the program demonstrate perceptual learning discriminative a significant advance because the final results placed the children in levels of good and very good short-term memory of children.Esta tesis fue realizada con el fin de determinar el Aprendizaje Perceptivo-Discriminativo para fortalecer el desarrollo de la Memoria a Corto Plazo, en niños con Síndrome de Down de 6 a 7 años incluidos a la Educación Regular, en el Centro Educativo Particular Bilingüe Dirigentes del Futuro, de la Ciudad de Loja. 2013-2014, el diseño de la investigación fue descriptiva, de intervención social, de tipo transversal. Los métodos usados fueron: analítico, hermenéutico, estadístico y descriptivo; la población fue constituida por 43 estudiantes y la muestra fue selectiva en donde se tomó a 2 niños con Síndrome de Down incluidos a la educación regular, el diagnóstico inicial que presentaron fue un nivel de regular y buena memoria a corto plazo, posteriormente se aplicó el aprendizaje perceptivo discriminativo y haciendo una comparación con los resultados de las pre y post pruebas se puede notar que la aplicación del programa del aprendizaje perceptivo discriminativo demuestran un avance significativo debido a que los resultados finales ubicaron a los niños en niveles de buena y muy buena memoria a corto plazo de los niños.\n"}
{"prompt":"La memoria a corto plazo y su incidencia en el proceso de enseñanza aprendizaje en los niños y niñas del séptimo grado de la escuela de educación básica “bernardo darquea” del caserío san vicente, cantón quero, parroquia quero, provincia de tungurahua ->","completion":" El presente trabajo de investigación se ha tomado en cuenta debido a que este problema tiene gran incidencia en el proceso de enseñanza aprendizaje en los niños de esta escuela. La atención y memoria es un problema de vital importancia dentro de la educación, mediante la aplicación de nuevas técnicas activas de aprendizaje se podrá dar solución a este inconveniente que tienen los educandos. El propósito de esta investigación es plantear una alternativa de solución ante este problema, el cual ayudará a los niños a desarrollar la atención y memoria. Y así no tengan dificultad en el proceso de enseñanza aprendizaje y en sí en el futuro. Durante el proceso enseñanza aprendizaje en la escuela Bernardo Darquea se ha detectado que los niños presentan bajo rendimiento escolar, debido a que su memoria es insuficiente para poder desarrollar con facilidad sus actividades escolares, por lo que es factible aplicar nuevas metodologías de aprendizaje, para que los niños logren desarrollar sus capacidades y así alcanzar aprendizajes significativos, poniendo en práctica el proceso de Memoria. Es muy importante xvi tomar en cuenta que el avance de la ciencia y tecnología, nos presentan diferentes alternativas, que a través de su aplicación nos permite ir mejorando día a día y así llegar a obtener una educación de calidad.\n"}
{"prompt":"Diseño de objetos para estimular la memoria ->","completion":" Este trabajo de tesis hace referencia al uso, la forma y la función del diseño de objetos como un medio de respuesta ante trastornos cognitivos. El propósito es responder a la interrogante de cómo un objeto, puede convertirse en una herramienta de prevención, atención y mejora de enfermedades mentales, tal como es el caso de la pérdida de memoria a corto plazo. La metodología, se fundamentará en una investigación etnográfica basada en la recopilación de entrevistas a personas que padecen esta enfermedad. Proceso que buscará determinar cuál es la relación que existe entre la pérdida de memoria y el uso de objetos. El resultado de esta investigación será el diseño de una propuesta de objetos lúdicos y dinámicos, en donde mediante la aplicación y funcionalidad del diseño podrá poner en evidencia como las imágenes, colores y figuras llamativas pueden aportar a la calidad de vida de las personas que padecen de esta enfermedad.Diseñador de Objetos\n"}
{"prompt":"ESTRATEGIA PSICOEDUCATIVA PARA CONTRIBUIR A LA ESTIMULACIÓN DE LA MEMORIA OPERATIVA DE ESCOLARES QUE ASISTEN A LA FUNDACIÓN NURTAC ->","completion":" PDFLa presente investigación tuvo como objetivo general diseñar una estrategia psicoeducativa para contribuir a la estimulación de la memoria operativa de escolares que asisten a la Fundación Nurtac. El estudio se realizó desde una perspectiva sociocrítica, dentro de un diseño de investigación-acción, considerando una muestra no probabilística de 15 escolares con alteración leve en la memoria. Para la recolección de información se emplearon técnicas e instrumentos como la observación participante, entrevista semiestructurada y Neuropsi (2da edición). Los resultados evidenciaron que el componente con mayor deficiencia fue el bucle fonológico, seguido de los componentes ejecutivo central y agenda visoespacial, siendo este último el de menores deficiencias. La estrategia psicoeducativa propuesta asumió como principales fundamentos el Enfoque Histórico Cultural, los procesos de enseñanza – aprendizajes desarrolladores y la interfuncionalidad de los procesos cognitivos. Se estructuró a través de una planificación estratégica, en la cual se detallaron los objetivos a corto y mediano plazo, así como las etapas y sus respectivas acciones, recursos, medios y métodos. Dentro de la instrumentación se detallaron especificaciones por dimensiones, tipos de actividades y el tiempo requerido. La evaluación consideró momentos de cierres parciales y finales. Todo ello se apoyó en la elaboración de un folleto de actividades dirigido a los escolares, las familias, personal de Nurtac e instituciones educativasThe present investigation had as general objective to design a psychoeducational strategy to contribute to the stimulation of the operational memory of schoolchildren attending the Nurtac Foundation. The study was carried out from a sociocritical perspective, within an action-research design, considering a non-probabilistic sample of 15 schoolchildren with memory level impairment. Techniques and instruments such as participant observation, semi-structured interview and Neuropsi (2nd edition) were used to collect information. The results showed that the component with the greatest deficiency was the phonological loop, followed by the central executive components and the viso-spatial agenda, the latter being the one with less deficiencies. The proposed psychoeducational strategy assumed as its main foundations the Historical Cultural Approach, the teaching-learning processes and the interfunctionality of the cognitive processes. It was structured through strategic planning, which details the short and medium term objectives, as well as the stages and their respective actions, resources, means and methods. Within the instrumentation specifications were detailed by dimensions, types of activities and the time required. The evaluation considered moments of partial and final closure. All this was supported by the elaboration of a brochure of activities aimed at schoolchildren, families, Nurtac staff and educational institutions\n"}
{"prompt":"DESARROLLAR LA MEMORIA MEDIANTE EL JUEGO SIMBÓLICO PARA LOGRAR UN APRENDIZAJE A LARGO PLAZO EN NIÑOS Y NIÑAS DE 3 AÑOS DE EDAD. GUÍA DE ACTIVIDADES LÚDICAS DIRIGIDA A MADRES COMUNITARIAS DEL C.I.B.V “MANANTIAL DE AMOR” DEL DISTRITO METROPOLITANO DE QUITO EN EL AÑO 2015-2016 ->","completion":" TECNÓLOGA EN DESARROLLO DEL TALENTO INFANTILEl presente trabajo de investigación está desarrollado sobre la base de la memoria mediante el juego simbólico para lograr un aprendizaje a largo plazo, en la cual organizaciones verifican que un indicador importante es la metodología del juego y sus clasificaciones. El juego es un ente importante ya que estimula el desarrollo de las capacidades intelectuales y psicomotoras, en general proporciona al niño y niña experiencias, de aquí parte el juego simbólico el cual desarrolla la capacidad de simbolizar, lo que contribuye a la comprensión, asimilación y desenvolvimiento de cualquier tipo de aprendizaje futuro, sus forma de manifestación son la mímica, la fantasía simbólica, la simbolización, la imitación diferida, el dibujo, la imagen mental y el lenguaje, adquiriendo beneficios los cuales le favorecen a los niños y niñas en el desarrollo cognitivo e imaginativo y a la vez les ayuda para la fácil comprensión de las cosas a través de las dimensiones de sustitución, descentración y planificación formando secuencias ordenadas. La memoria es el componente elemental para el aprendizaje y desenvolvimiento del ser humano, la cual contiene diferentes tipos como lo son la memorial sensorial que es la que permanece activa por poco tiempo e identifica a la memoria ecoica y la icónica, otro de los tipos es la memoria a corto plazo la cual desaparece en un lapso de 45 segundos, y por último la memoria a largo plazo la cual mantiene información de manera permanente y se encuentra dividida en declarativa, procedimental, episódica, semántica, implícita y explícita. A la vez se complementa con las funciones básicas que son la codificación la cual prepara a la información antes de ser almacenada, el almacenamiento se da de acuerdo a la necesidad de las personas y la recuperación es recordar información que fueron guardados del pasado.\n"}
{"prompt":"LA ATENCI?N Y SU INFLUENCIA EN LA MEMORIA FUNCIONAL EN LOS ESTUDIANTES DE QUINTO A?O DE EDUCACI?N B?SICA DE LA UNIDAD EDUCATIVASAN P?O X ->","completion":" Este proyectose realiz? con el objetivo de investigar, c?mo la atenci?n influye en la memoria funcional en los estudiantes de quinto a?o de Educaci?n B?sica de la Unidad Educativa San Pio X. Siendo la atenci?n un proceso cognitivo de selecci?n de est?mulos,estos deben ser procesados con la finalidad de generar informaci?n que se almacena en la memoria, convirti?ndose en funcional como un proceso mental b?sico importante para el aprendizaje y la elaboraci?n de tareas que permite al cerebro retener la nueva informaci?n a corto plazo,en donde los procesos de evocaci?n permiten mantenerla vigente al realizar una tarea espec?fica.Para la investigaci?n se cont? con una poblaci?nde 70 estudiantes,en edades comprendidas entre los 9 y 10 a?os;a quienes se les aplic? dos reactivos psicol?gicos; el Test de Percepci?n de Diferencias CARAS-R, el cual mide niveles de atenci?n;y la escala de Memoria de Trabajo del WISC-V, que mide niveles de memoria.Por medio de la aplicaci?n del estad?stico Chi cuadrado se consigui? un valorde13,561, aceptando la hip?tesis nula,es decir la atenci?n no influye en la memoria funcional. Finalmente ha sido posible la elaboraci?n de una propuesta de intervenci?n psicol?gica orientada a la realizaci?n de talleres para estimular la memoria en los estudiantes de quinto a?o de la Unidad Educativa San P?o X.\n"}
{"prompt":"SISTEMATIZACIÓN DE EXPERIENCIAS DE PRÁCTICAS DE INVESTIGACIÓN: CARACTERIZACION: TIPOS DE MEMORIA EN NIÑOS DE 6 A 11 AÑOS QUE PRESENTAN DEFICIT ATENCIONAL ->","completion":" PDFEl presente trabajo de titulación en modalidad de sistematización de experiencias, que se realizó en el C.D.I.D., tuvo como objetivo principal caracterizar los tipos de memoria en niños de 6 a 11 años, usuarios del C.D.I.D., que presentan déficit atencional. El eje con el que se trabajó fue el proceso de caracterización de los tipos de memoria en niños de 6 a 11 años, usuarios del CDID que presentan déficit de atención. Esta investigación es de tipo cualitativa de alcance descriptivo, realizado en 4 casos, con lo cual se logró identificar los tipos de memoria, niveles y principales dificultades relacionadas a la memoria que presentaron los niños de la muestra estudiada. Los instrumentos que se utilizaron fueron: ficha de datos socio-demográficos, entrevista semi estructurada para los niños, y otra entrevista semi estructurada para los padres de familia, el test de Funcionamiento Familiar y la Batería Neuropsicológica para la Evaluación de los Trastornos del Aprendizaje (BANETA). Como resultado se obtuvo que entre los cuatro niños la memoria que predomina y se encuentra más desarrollada es la memoria a corto plazo, presentando un nivel normal. Además, en lo que respecta en la memoria a largo plazo presentó puntuaciones bajas, mientras que en la memoria de trabajo se encontró niveles entre normales y bajos. Al mismo tiempo se pudo conocer las principales dificultades relacionadas a la memoriaThe main objective of this systematization of experiences, which was carried out in the C.D.I.D., was to characterize the types of memory found in children aged 6 to 11 years, patients of the C.D.I.D., who present an attentional deficit. The axis with which I worked was the process of characterization of the types of memory in children from 6 to 11 years old, users of the CDID who show an attentional déficit. This is a qualitative investigation with descriptive scope, carried out in 4 cases, with which, the identification of the types of memory, each of their levels and main dificulties related to the memory presented by children in the sample studied. The instruments used were: socio-demographic data sheet, semi-structured interview for children, and another one for parents, the family functionality test and the Neuropsychological battery for the evaluation of Learning Disorders (BANETA). As a result, I found that the dominating memory between the 4 children was the short term memory, this one being the most developed, while the long term memory showed scores below average. This led me to a connection between attentional deficit and low scores in long term memory\n"}
{"prompt":"EVALUACIÓN DE LA MEMORIA EN CONSUMIDORES DE CANNABIS ->","completion":" La manifestación de problemas sociales y de salud a consecuencia de déficits neuropsicológicos causados por el consumo de drogas, excluyen al enfermo adicto y afectan su estilo de vida en varios ámbitos. Diversos estudios han confirmado que la drogodependencia al cannabis así como a otras drogas genera alteraciones en la cognición debido a la modificación neurobiológica y química. Por lo tanto el, objetivo general es evaluar varios componentes de la memoria en consumidores de cannabis. Método Estudio transversal y explicativo en 40 individuos, 57.50% hombres y 42.50% mujeres, de entre 20 y 40 años de edad y con 6 a 18 años de escolaridad. El grupo provenía de dos centros de recuperación de adicciones y tenían entre 5 y 10 años de consumo de cannabis. Se aplicó la batería Neuropsi (Ostrosky, Gómez, Matute, Rosselli, Ardila, &Pineda, Neuropsi Atención y Memoria, 2012). Se aplicaron criterios de inclusión y exclusión. Se obtuvo la muestra, mediante los resultados de un panel de drogas para determinar el tipo y grado de toxicidad en el organismo, obteniéndose puntuaciones bajas en la memoria sensorial, memoria a corto plazo, memoria de trabajo, con afectación de la curva de aprendizaje, fallos en la integración de información semántica, pero no se encontraron diferencias significativas en torno a la codificación. Los resultados son aportaciones al campo de estudio a través de una muestra ecuatoriana.The manifestation of social and health problems as a result of neuropsychological deficits caused by drug use, exclude the sick addict and affect their lifestyle in several areas. Several studies have confirmed that drug dependence on cannabis as well as other drugs generates alterations in cognition due to neurobiological and chemical modification. Therefore, the general objective is to evaluate various components of memory in cannabis users. Method Cross-sectional and explanatory study in 40 individuals, 57.50% men and 42.50% women, between 20 and 40 years of age and with 6 to 18 years of schooling. The group came from two addiction recovery centers and had between 5 and 10 years of cannabis use. The Neuropsi battery (Ostrosky, Gómez, Matute, Rosselli, Ardila, & Pineda, Neuropsi Atención y Memoria, 2012) was applied. Inclusion and exclusion criteria were applied. The sample was obtained through the results of a panel of drugs to determine the type and degree of toxicity in the organism, obtaining low scores in the sensory memory, short term memory, working memory, affecting the learning curve, failures in the integration of semantic information, but no significant differences were found around coding. The results are contributions to the field of study through an Ecuadorian sample.\n"}
{"prompt":"Diseño de juego y sistema de productos para evitar el deterioro de la memoria a causa de la dependencia a la tecnología Sinap ¡a que no te acuerdas! ->","completion":" The fast paced technological advancement that seeks to simplify the lives of all human beings nowadays has caused us to lose certain capabilities. Long and short term memory are rapidly deteriorating due to the dependence that we have created on any sort of device that performs these tasks for us. Through communication design, I propose a solution to this lack of memory usage to regain the ability to remember. Quantitative and qualitative theoretical research regarding general themes, such as time and its conception throughout history, memory and its different forms and processes, the analysis of the target group and ontologically subjective experiences, have led to the development of a video game. Using the positive traits of technology, the player will exercise his\/her memory through his\/her own experiences and a series of additional physical products that serve the same purpose. Furthermore, an advertising campaign would be used to raise awareness on our proposal.En la actualidad, debido al rápido avance tecnológico que busca simplificar la vida del ser humano, capacidades como la memoria a corto y largo plazo se están deteriorando debido a la dependencia que han creado las personas a todo tipo de dispositivos que hacen este tipo de trabajo por nosotros. A través del diseño comunicacional se plantea una solución a esta falta de uso de la memoria, devolviendo al ser humano su capacidad de recordar por sí mismo. Una extensa investigación teórica, cuantitativa y cualitativa acerca de temas generales como el tiempo, sus diferentes concepciones a través de la historia, la memoria, su funcionamiento y tipos, análisis de grupos objetivos y experiencias ontológicamente subjetivas llevaron al planteamiento de un videojuego, utilizando los aspectos positivos de la tecnología, donde el usuario ejercitará su memoria mediante sus propias experiencias, además de productos físicos que cumplen la misma función y una campaña publicitaria para dar a conocer la propuesta.\n"}
{"prompt":"Análisis de la eficiencia en el mercado de valores ecuatoriano en el período 2002-2013 ->","completion":" La presente disertación estudia los métodos cuantitativos para analizar la eficiencia de información de los mercados de valores, con la finalidad de evaluar la situación de eficiencia del mercado ecuatoriano. La hipótesis de eficiencia del mercado, una de las teorías más trascendentes en economía financiera, señala que los precios de activos financieros de renta variable, acciones, siguen una caminata aleatoria, es decir no tienen memoria y no se pueden predecir. Se analiza pues las series de índices de precios del mercado ecuatoriano en busca de memoria de corto y largo plazo. La memoria de corto plazo se estudia con herramientas corrientes de econometría de series de tiempo: coeficientes de autocorrelación; en cambio la memoria de largo plazo, las correlaciones existentes sobre todas las escalas de tiempo, se evalúan por medio del coeficiente de Hurst, que mide la autosimilaridad de las series a través del escalamiento en distintas escalas de tiempo y constituye un estimador de la dimensión fractal. Se construye un índice de eficiencia de información. Los resultados muestran evidencia de memoria en los índices de precios del mercado de valores ecuatoriano en el periodo estudiado, no obstante se contextualiza estos hallazgos con otros mercados de la región.\n"}
{"prompt":"Memoria y Aprendizaje en los estudiantes de la Unidad Educativa del milenio “Guano”. Guano. marzo – julio 2017 ->","completion":" The present research addressed the theme \"Memory and Learning in the students of the Educational Unit of the Millennium\" Guano Guano March July 2017 he objective of the present work is to determine the relationship of short-term memory with the learning styles of the students of First of Baccalaureate: theoretically, short-term memory is the distinction between memories that last a short time and long-term memories. Learning depends on the previous cognitive structure that is related to the new information; to the set of concepts, ideas that an individual possesses in a certain field of knowledge, as well as their organization. The research design is qualitative non experimental; the descriptive and field-bibliographic research; the type of study was cross-sectional and the level of research was exploratory descriptive. The techniques used are the Wisc IV psychosometric tests, and the CHAEA, applied to 17 women and 13 male students. After performing the analysis and interpretation of data is concluded that, students present a high level of short-term memory, in the pragmatic style since it easily retains the information they receive; followed by reflective style; the Active style and to finally the theoretical style.La presente investigación abordó el tema “Memoria y Aprendizaje en los estudiantes de la Unidad Educativa del Milenio “Guano”. Guano. Marzo – Julio 2017”; por ser una temática que cobra gran importancia considerando que la memoria a corto plazo es de gran relevancia en el proceso de aprendizaje en los estudiantes; teóricamente, la memoria a corto plazo es la distinción entre los recuerdos que duran un tiempo breve y los recuerdos a largo plazo. El aprendizaje depende de la estructura cognitiva previa que se relaciona con la nueva información; al conjunto de conceptos, ideas que un individuo posee en un determinado campo del conocimiento, así como su organización. El diseño de investigación es de corte cualitativo no experimental; el tipo de investigación descriptivo y de campo-bibliográfico; el tipo de estudio fue trasversal y el nivel de investigación fue exploratorio descriptivo. Las técnicas utilizadas son los test psicosometricos de Escala de retención de dígitos (números y letras.) Wisc IV, y el CHAEA, aplicado a 30 estudiantes. Luego de realizar el análisis e interpretación de datos se concluye que, que los estudiantes presenta un nivel alto de memoria a corto plazo, en el estilo pragmático ya que retiene con facilidad la información que receptan; seguido de estilo reflexivo; el estilo Activo y para finalizar el estilo teórico.UNACH, sede Ecuador\n"}
{"prompt":"Memoria y aprendizaje en los estudiantes de la unidad educativa “Capitán Edmundo Chiriboga”, Riobamba. Marzo – Julio 2017 ->","completion":" The present investigation deals with the title \"Memory and Learning in the Students of the Educational Unit\" Captain Edmundo Chiriboga \", Riobamba. March - July 2017 \", is a theme of great importance so the memory is a fundamental part of our educational and personal experiences, which it is an important space in the academic and learning activities; process in which the students acquire necessary skills in order to subsist and develop in the society; there are two processes in the educational field, so it is important to develop the present theme, to develop this project, was used the scientific inductive­ deductive and analytical-synthetic method, the design of the research was non-­ experimental; the type of research was cross-field-bibliographic and the level of exploratory-descriptive-correlational research was handled. The population were the students of the Educational Unit “Captain Edmundo Chiriboga\", while the sample was intentional non-probabilistic. Psychometric techniques were applied. After the results or discussion it is concluded that they used information of the moment especially auditory conserving the information during a short time; the learning style that predominates in the majority of students is the reflective because they consider experiences observing from different perspectives; the theoretical, active and pragmatic style should be mentioned in a lower percentage; The relationship between short-term memory and active and reflective learning styles is evident.La presente investigación aborda la temática “Memoria y Aprendizaje en los Estudiantes de la Unidad Educativa “Capitán Edmundo Chiriboga”, Riobamba. Marzo – Julio 2017”, es un tema de gran importancia puesto que la memoria es parte fundamental de nuestras vivencias educativas y personales, lo que forma un espacio importante en las actividades académicas; y el aprendizaje proceso mediante el cual los estudiantes adquieren destrezas necesarias para subsistir y desarrollarse en la sociedad; son dos procesos presentes en el ámbito educativo, por lo que es importante desarrollar el presente tema. Para la realización de este este proyecto se utilizó el método científico inductivo-deductivo y analítico-sintético; el diseño de la investigación fue no experimental; el tipo de investigación fue de campo-bibliográfica-transversal y se manejó el nivel de investigación exploratoria-descriptiva-correlacional. La población fue los estudiantes del Unidad Educativa “Capitán Edmundo Chiriboga”, mientras que la muestra fue no probabilística intencionada. Se aplicaron técnicas psicométricas. Luego de los resultados o discusión se concluye que utilizaron información del momento sobre todo auditiva, conservando la información durante un tiempo corto; el estilo de aprendizaje que predomina en la mayoría de estudiantes es el reflexivo pues tienden a considerar experiencias observándolas desde diferentes perspectivas; cabe mencionar en porcentaje inferior el estilo teórico, activo y pragmático; se evidencia la relación entre la memoria a corto plazo con los estilos de aprendizaje Activo y Reflexivo.UNACH, sede Ecuador\n"}
{"prompt":"El desarrollo cognitivo en el proceso de enseñanza-aprendizaje de los niños de 5 a 6 años del sub nivel de educación preparatoria ->","completion":" El presente trabajo de investigación se orientó a la indagación profunda en torno al problema del deficiente nivel de desarrollo cognitivo en los estudiantes del sub nivel de Educación Preparatoria, el cual se ve perjudicado por la falta de conocimiento y aplicación por parte del cuerpo docente de actividades didácticas que se enfoquen en el desarrollo de los procesos cognitivos de atención, percepción y memoria. El objetivo general establecido para el desarrollo de la investigación fue mejorar el desarrollo cognitivo a través de la ejecución de actividades didácticas en los estudiantes del sub nivel de educación preparatoria de la Escuela Ciudad de San José. El diseño metodológico se enmarcó en el enfoque mixto en la modalidad de proyecto factible, se aplicó una entrevista a la docente, una ficha de observación a los estudiantes y una encuesta a los padres de familia, para diagnosticar la situación del problema, donde se obtuvo resultados que evidenciaron las deficiencias en cuanto a desarrollo cognitivo, el 57% de estudiantes no tienen un adecuado nivel de atención dentro del proceso de enseñanza-aprendizaje, un 37% de estudiantes que no recuerdan los contenidos impartidos la clase anterior, así como el 47% de padres de familia que consideran que el nivel de aprendizaje de sus hijos es regular y que por lo tanto puede ser mejorado. Lo cual permitió desarrollar una propuesta con 18 actividades enfocadas al entrenamiento de los procesos cognitivos de atención selectiva, dividida, alternada, sostenida; percepción visual, auditiva, táctil; memoria episódica a corto y largo plazo.\n"}
{"prompt":"Memoria de la producción y logística del producto audiovisual experimental “Fuguet Penetra Guayaquil” ->","completion":" El Jefe de producción es el responsable de la organización del trabajo (plan de trabajo), de la selección de parte del personal, de gestionar los permisos pertinentes de las distintas autoridades y propietarios para el rodaje en locaciones fuera de los estudios, de supervisar la compra de bienes y contactar con los proveedores. Controla también el funcionamiento diario de la oficina de producción, coordinando el trabajo de los diferentes profesionales que intervienen para que se cumplan los plazos previstos y la película no se salga del presupuesto. (Jara). Para documentar el trabajo realizado y expuesto en esta memoria se utilizó una bitácora que da cuenta del proceso de producción durante las grabaciones del corto y también se utilizó una herramienta denominada desglose de producción, en la cual se ha llevado el registro de la pre producción. Desglose de producción, es el análisis pormenorizado del guion, que sirve para determinar el conjunto de elementos necesarios en el rodaje del mismo. Consiste en establecer de manera detallada las necesidades para llevar a cabo el guion desde el punto de vista artístico, material, técnico y de talento; secuencia por secuencia. Esto permite determinar el conjunto de elementos necesarios para el rodaje y así elaborar un plan de trabajo. (Narración audiovisual, 2011) La producción y logística del corto fue un proceso que se llevó a cabo desde que inició hasta su culminación, dirigido por el jefe de producción. Este proceso fue una instancia de aprendizaje, en la cual hubo errores, aciertos y lecciones aprendidas, para lograr obtener un material de primera calidad. De tal manera que esta memoria pueda servir como una herramienta para que futuros estudiantes realicen de manera correcta el proceso de pre producción, producción y logística de un producto audiovisual experimental con pocos recursos económicos.GuayaquilLicenciatura en Comunicación Social con mención en Relaciones Públicas y Comunicación Organizacional\n"}
{"prompt":"Atención y memoria en pacientes con consumo de marihuana del Centro de Salud ESPOCH – LIZARZABURU. Riobamba, 2020 ->","completion":" The main objective of the present study was to analyze the attention and memory rates of patients who consume marijuana at the Intensive Outpatient Unit of the ESPOCH Type C Health Center - Lizarzaburu with a sample of 30 medical records, the methodology used was documental, bibliographic, non-experimental cross-sectional design and of a descriptive level. The technique used was the observation, an observation file was prepared, and it recorded important sociodemographic data and also the results of the accomplishment of the Neuropsi Neuropsychological Battery Attention and Memory previously applied by psychologists in charge of the Intensive Outpatient Clinic of the Health Center. Among the results with the greatest impact, it was found that in the average of subtests, memory curve and logical memory subtests of short-term memory with 6.85 and 6.66 respectively; pairs associated with 7.57 and long-term logical memory with an average of 7.57 and 5.79 correspondingly, which are related to an impairment. Consequently, to the percentage obtained that relate an alteration to the consumption of marijuana, neuropsychological rehabilitation strategies focused on memory were developed, which may be put to consideration for application by the mental health professionals of the health center.El presente estudio tuvo como principal objetivo alizar la atención y memoria de los pacientes consumidores de marihuana del Ambulatorio Intensivo del Centro de Salud Tipo C ESPOCH – Lizarzaburu con una muestra de 30 historias clínicas, la metodología que se utilizo fue de tipo documental, bibliográfico, de diseño trasversal no experimental y nivel descriptivo. La técnica utilizada fue la observación, donde elaboró ficha de observación donde se registró datos sociodemográficos de importancia y también resultados de la ejecución de la Batería Neuropsicológica Neuropsi Atención y Memoria aplicada previamente por los psicólogos a cargo del ambulatorio intensivo del Centro de Salud. Entre los resultados de mayor impacto se encontró que en las medias de las subpruebas curva de la memoria y memoria lógica de memoria a corto plazo con 6,85 y 6,66 respectivamente; pares asociados con 7,57 y memoria lógica de memoria a largo plazo con una media de 7,57 y 5,79 correspondientemente, mismos que se relacionan con una alteración. En consecuencia, al porcentaje obtenido que relacionan una alteración con el consumo de marihuana se elaboraron estrategias de rehabilitación neuropsicológica enfocadas a la memoria, las mismas que podrán ser puestas a consideración para ser aplicadas por los profesionales de la salud mental del centro de saludUNACH,Ecuador\n"}
{"prompt":"Estudio comparativo del deterioro mnémico de los adultos mayores del barrio de Cochapamba y el hogar Santa Catalina de Laboure ->","completion":" El envejecimiento se ha convertido en un tema mundial y de actualidad. Se ha visto una revolución en la longevidad con el aumento en la esperanza de vida en caso veinte años y la expectativa es que se extienda en diez años más hacia 2050. El proceso de envejecimiento tiene características comunes a todas las personas como son el deterior físico, psíquico y social. Dentro de la pérdida de facultades psíquicas las más notorias son: el control de la matricida, la memoria a corto plazo y la capacidad para resolver problemas nuevos.\n"}
{"prompt":"Terapia de reminiscencia para mejorar la memoria del adulto mayor del hogar “Estancia de Paz” Francisco Valdivieso del barrio Landangui de la parroquia Malacatos del cantón Loja, en el período marzo–julio 2015 ->","completion":" The present thesis entitled: REMINISCENCE THERAPY TO IMPROVE ELDERLY PEOPLE MEMORY AT \"ESTANCIA DE PAZ\" NURSING HOME FRANCISCO VALDIVIESO LOCATED AT LANDANGUI NEIGHBORHOOD MALACATOS PARISH - LOJA CANTON, IN THE PERIOD MARCH-JULY 2015, was developed with the purpose ofHelp to what the elderly peopleimproves their memory, since the difficulty the same that bring as a consequence memory decrease in short-term, the difficulty in performing familiar tasks, difficulty in language, disorientation of time and place,changes in mood, finally they neglect their hygiene and nutrition.The general objective: To improve elderly people memory through the Reminiscence Therapy at “Estancia de Paz” HomeFrancisco Valdivieso located at Landangui neighborhood Malacatos parish - Loja canton, in the period March-July 2015.The research work is part of action research model; through an intervention period, this research topic has been approached from a descriptive and explanatory study, with a mixed approach in other words qualitative and quantitative;the research were basedon three areas: theoretical assessment, design and implementation of the alternative; the methods and development and evaluation of the effectiveness of the strategy, the methods used were:the scientific, synthetic, inductive, hermeneutical, dialectical, which allowed to make the discussion and comparison of the alternatives proposed.The technique used was theMMSE (Folstein) 1 test, to assess the level of memory which wasapplied to the six elderly.Finally concludes that, more than half of beneficiaries improved their memory, for that reason Reminiscence Therapy is recommended for the elderly populationLa presente tesis titulada:TERAPIA DE REMINISCENCIA PARA MEJORAR LA MEMORIA DEL ADULTO MAYOR DEL HOGAR “ESTANCIA DE PAZ” FRANCISCO VALDIVIESO DEL BARRIO LANDANGUI DE LA PARROQUIA MALACATOS DEL CANTÓN LOJA, EN EL PERÍODO MARZO–JULIO 2015,se desarrolló con el propósito de ayudar a que el adulto mayor mejore su memoria, ya que la dificultad de la misma ha traído como consecuencia disminución de la memoria a corto plazo, dificultad en la ejecución de tareas familiares, dificultad del lenguaje, desorientación en tiempo y lugar, cambios en el estado de ánimo, descuido de la higiene personal y la alimentación.El objetivo general Mejorar la memoria a través de la terapia de reminiscencia del adulto mayor del hogar “Estancia de Paz” Francisco Valdivieso del barrio Landangui de la parroquia Malacatos del cantón Loja, en el período marzo–julio 2015.El trabajo se enmarca en el tipo de investigación-acción, a través de la intervención, se lo ha abordado desde un tipo de estudio descriptivoy explicativo, con un enfoque mixto es decir cuanti-cualitativo; la investigación se enmarca en tres áreas: teórico-diagnóstico, diseño y aplicación de la alternativa; y evolución y valoración de la efectividad de la alternativa los métodos que abarca estas áreasson:el científico, analítico- sintético, inductivo, hermenéutico, dialéctico,permitiendo realizar la discusión y contrastación de los objetivos propuestos. La técnica utilizada fue el test MMSE (Folstein)1,para evaluar la memoriael cual fue aplicado a los 6 adultos mayores.Finalmente se concluye que más de la mitad de los beneficiariossegún el test aplicadomejoraron su memoria, es por ello que se recomienda la aplicación de la terapia de Reminiscencia para ayudar a la población adulta mayor\n"}
{"prompt":"Comparación entre redes neuronales artificiales y regresión múltiple para la predicción de la rugosidad superficial en el torneado en seco ->","completion":" Los métodos de regresión múltiple y redes neuronales artificiales son técnicas usadas en muchas aplicaciones de la industria. En este trabajo se utilizaron dos métodos de predicción: regresión múltiple y redes neuronales artificiales (perceptrón multicapa) con el objetivo de predecir la rugosidad superficial en el torneado en seco del acero AISI 316l. En su implementación fueron considerados varios parámetros de corte como la velocidad, el avance y el tiempo de mecanizado. Las ecuaciones obtenidas por ambos métodos fueron comparadas desarrollando un diseño factorial completo para aumentar la fiabilidad de los valores registrados de rugosidad superficial. En el análisis se puede comprobar mediante los valores de coeficientes de determinación que los modelos propuestos son capaces de predecir la rugosidad superficial. Los modelos obtenidos demuestran que la técnica de redes neuronales artificiales tiene mejor precisión que la regresión múltiple para este estudio.\/\/ The simple regression and artificial neural network methods are techniques used in many industrial aplications. This work developed two models in order to predict the surface roughness in dry turning of AISI 316L stainless steel. In its implementation they were considered various cutting parameters such as cutting speed, feed, and machining time. The models obtained by both methods were compared to develop a full factorial design to increase reliability of the recorded values of roughness. The analysis can be corroborated by the values of coefficients of determination that the proposed models are able to predict for surface roughness. The obtained results show that the neural networks techniques are more accurate than the multiple regression techniques for this study.\n"}
{"prompt":"Diseño de un modelo para el reconocimiento de patrones de escritura mediante uso de redes neuronales artificiales ->","completion":" Esta tesis tiene como línea general el diseñar un modelo para reconocer patrones de escritura, basado en las actualmente y exitosas redes neuronales artificiales, por los grandes avances que ya se han registrado en diferentes estudios realizados. En la primera fase se comienza con un estado en el que se encuentra estas dos importantes áreas, reconocimiento de patrones y redes neuronales, detallando los tipos de estas y los algoritmos de entrenamiento que existen para iniciar con el estudio del más apropiado que nos sirva en el proyecto. La segunda fase se describe el problema para diseñar la solución, aquí también se hace referencia a la herramienta donde se diseñara la implementación para las pruebas. Se detalla en la fase tres como se realiza la implementación, y el programa desarrollado en MatLab, junto con las pruebas del modelo. La fase 4 se realiza la discusión de resultados, para a sus ves dar las conclusiones y recomendaciones necesarias.This thesis has as a general line the design of a model to recognize writing patterns, based on the currently successful artificial neural networks, for the great advances that have already been recorded in different studies. In the first phase we start with a state in which we find these two important areas, pattern recognition and neural networks, detailing the types of these and the training algorithms that exist to start with the most appropriate study that serves us in the project. The second phase describes the problem to design the solution, here also refers to the tool where the implementation for the tests will be designed. It is detailed in phase three as the implementation is done, and the program developed in MatLab, along with the tests of the model. Phase 4 is the discussion of results, so you can give the necessary conclusions and recommendations.\n"}
{"prompt":"Diseño de un modelo para la detección de obstáculos mediante la utilización de las redes neuronales artificiales ->","completion":" El presente trabajo se pretende aprovechar la capacidad de generalización de redes neuronales para resolver los problemas que se plantean en la navegación de un robot móvil en un ambiente desconocido. Hoy en día la ciencia y los avances tecnológicos han logrado que se pueda desarrollar de forma verás y objetiva redes neuronales a través un sin número de herramientas para su diseño, vasta tener conocimientos básico del funcionamiento de las mismas, una de las más utilizadas es Matlab que cuenta con una serie de librerías que se dedican exclusivamente a este fin, además proporciona un entorno amigable para el programador. Esta tesis esta dividida en 4 fases: En la primera se presenta el objetivo de la investigación que abarca el estudio de las características de las redes neuronales, reconocimiento de patrones y robots; en la segunda se describe el diseño a desarrollarse en el ambien Ete virtual SimRobot; en la tercera fase se aplican los algoritmos desarrollados para el modelo junto a las pruebas experimentales que se describen en esta fase, en la cuarta fase se trata acerca de las discusiones del proyecto de investigación y en la última se exponen las conclusiones y recomendaciones a futuro.The present work intends to take advantage of the generalization capacity of neural networks to solve the problems that arise in the navigation of a mobile robot in an unknown environment. Today, science and technological advances have been able to develop vertically and objectively neural networks through a number of tools for their design, vast have basic knowledge of the operation of them, one of the most used is Matlab Which has a series of bookstores dedicated exclusively to this purpose, in addition provides a friendly environment for the programmer. This thesis is divided in 4 phases: In the first one the objective of the investigation is presented that includes the study of the characteristics of the neural networks, recognition of patterns and robots; The second describes the design to be developed in the virtual environment SimRobot; In the third phase the algorithms developed for the model are applied together with the experimental tests described in this phase, the fourth phase is about the discussions of the research project and in the last one the conclusions and recommendations are presented in the future .\n"}
{"prompt":"Aplicación de redes neuronales en operaciones industriales de manufactura para productos prismáticos circulares en materiales metálicos no ferrosos ->","completion":" Actualmente en el Ecuador, el mercado ha dado acogida al mecanizado de varios materiales metálicos, en especial los no ferrosos como las aleaciones de aluminio con tratamiento térmico de la familia 6xxx y 7xxx, para hacer productos primaticos circulares. La presente investigación tiene como objetivo el estudio de la integridad superficial y la tabulación del caudal de material removido aplicando aprendizaje no supervisado (reglas de asociación y agrupación) y supervisado (red neuronal artificial) en el proceso de manufactura en un torno CNC para mecanizar los ejes de aluminio. Se utilizo dos parámetros de corte constantes, como lo son la velocidad de corte de 420 m\/min y volumen de material removido de 22.2 cm3. Previo al proceso de mecanizado se hicieron simulaciones utilizando software de manufactura y diseño asistido por computador para hacer un análisis comparativo con el tiempo real en el procesamiento de cada ensayo, determinando la correlación de los datos censados. En el desarrollo del aprendizaje no supervisado se estudió la correlación de los parámetros de corte y se diseñó el algoritmo de agrupamiento en función del valor máximo del análisis de Elbow, concluyendo que para estudiar los resultados de la aleación de aluminio AA 7075 T6, se necesita un arreglo ortogonal de veinte y siete niveles. Para el análisis neuronal se clasifico los resultados de la rugosidad superficial utilizando la escala Likert de cinco niveles (baja, regular, buena, muy buena y excelente) y en la estructura de la neurona se formuló en función de la profundidad, avance y velocidad de corte; presentando eficiencia del 75% en la arquitectura del avance de corte y la profundidad en la tabla de materiales AA 6061 T6 y AA 7075 T6 y eficiencia del 100% en la arquitectura del avance de corte y la profundidad en la tabla del material AA 6061 T6.Currently in Ecuador, the market has welcomed the machining of various metallic materials, especially non-ferrous ones such as aluminum alloys with heat treatment of the 6xxx and 7xxx families, to make circular primary products. The present research aims to study the surface integrity and the tabulation of the flow of removed material applying unsupervised learning (association and grouping rules) and supervised (artificial neural network) in the manufacturing process on a CNC lathe to machine the aluminum shafts. Two constant cutting parameters were used, such as the cutting speed of 420 m \/ min and the volume of material removed of 22.2 cm3. Before the machining process, simulations were made using computer-aided design and manufacturing software to make a comparative analysis with real time in the processing of each test, determining the correlation of the census data. In the development of unsupervised learning, the correlation of the cutting parameters was studied and the clustering algorithm was designed based on the maximum value of the Elbow analysis, concluding that to study the results of the aluminum alloy AA 7075 T6, it is necessary an orthogonal arrangement of twenty-seven levels. For the neuronal analysis, the results of the surface roughness were classified using the Likert scale of five levels (low, regular, good, very good and excellent) and in the structure of the neuron it was formulated according to the depth, advance and speed of court; presenting 75% efficiency in the architecture of the cutting feed and depth in the AA 6061 T6 and AA 7075 T6 material table and 100% efficiency in the architecture of the cutting feed and depth in the AA 6061 T6 material table.\n"}
{"prompt":"ANÁLISIS COMPARATIVO DE AJUSTE EN ENTRENAMIENTO DE REDES NEURONALES ARTIFICIALES A PARTIR DE LAS LIBRERÍAS OPEN NN Y ALGLIB ->","completion":" En las últimas décadas sonmuchos los avances que han tenido lugar en el desarrollo de aplicaciones y alcances de las redes neuronales artificiales, y de igual modo el desarrollo tecnológico en el área de la computación. Este tipo de avances han incidido directamente en el número de publicaciones de aplicaciones, en diversas áreas del conocimiento, basadas en este método de inteligencia artificial. Ahora bien, hasta el presente sigue siendo tema de discusión la idoneidad y aplicabilidad de herramientas de software libre para facilitar la implementación y la calidad de resultados. En este contexto, este trabajo representa un análisis comparativo de aplicaciones usando las librerías ALGLIB y Open NN (Open Source Neural Networks C++ Library), orientadas al entrenamiento y reproducción de redes neuronales artificiales. De igual modo, se establece una evaluación de los resultados obtenidos a partir de los niveles de correlación entre la salida de valores para redes entrenadas y un conjunto de datos de entrenamiento simulados. \/\/ In the last decades, there have been a considerable amount of innovations in the development of applications and the scope of artificial neural networks, and likewise the technological development in computer science. These improvements have had a direct effect in the number of publications on applications, in diverse areas of knowledge, based on this artificial intelligence method. Until now, the adequacy and applicability of free software tools to facilitate the implementation and the quality of results is still under discussion. In this context, this work presents a comparative analysis of such applications using libraries ALGLIB and Open NN, oriented to training and reproduction of artificial neural networks. Also, we propose an evaluation of the results obtained from the levels of correlation between the output values for trained networks and a set of data for simulated training.\n"}
{"prompt":"Análisis de las señales electromiográficas para implementar un prototipo de rehabilitación de la articulación tibioperoneoastragalina a través de un clasificador de redes neuronales artificiales. ->","completion":" El presente trabajo de titulación denominado Jampira es una estación de rehabilitación que se compone del diseño de un soporte estático para el análisis de señales electromiográficas del área tibioperoneoastragalina, que permita el entrenamiento de una red neuronal, a partir de estímulos eléctricos que le permiten la libertad de movimiento, a través de un equipo de sensores afín con las especificaciones técnicas de las señales obtenidas durante el diseño, para adquirir las señales de los músculos involucrados en el área afectada durante el proceso de recuperación. Una arquitectura de clasificación por software basado en redes neuronales artificiales (RNA) que tome los vectores para el reconocimiento de los movimientos que serán las entradas, y las salidas, de la misma manera vectores anidados identifican el tipo de movimientos que realiza el paciente, a partir del esfuerzo voluntario que aplica a cada sesión. Reúne la información relevante dentro de un interfaz de control gráfica que facilita la realización de movimientos desde la comodidad del hogar, con la facilidad que recupere el paciente la movilidad muscular con Jampira en un determinado tiempo, además comparte el informe de avance de la rehabilitación con el especialista y él determina el número de sesiones que deberá cumplir para que la rehabilitación sea un éxito. El propósito como ingeniero mecatrónico es adentrarse en el área del conocimiento y formar parte de la matriz productiva que saque adelante los objetivos del país, satisfacer las necesidades de una sociedad en innovar el área de la rehabilitación y mejorar su calidad de vida.ESPEL\n"}
{"prompt":"Prototipo de un aplicativo web para la predicción de avisos de aeródromo para la zona del aeropuerto de la ciudad de Guayaquil aplicando redes neuronales, bajo el histórico del servicio de información meteorológico de Ogimet. ->","completion":" PDFla actualidad es significativo cómo ha evolucionado la tecnología y las oportunidades que representan un nuevo entorno digital. Debido a estos avances se dispone de numerosas técnicas de aprendizaje automático con las que desarrollar un algoritmo para predecir los avisos de aeródromo en la zona del aeropuerto de la ciudad de Guayaquil ya no resulta inalcanzable. La inestabilidad atmosférica produce condiciones especiales ocasionando que los observadores las registren, calculen y codifiquen manualmente, ello provoca que los avisos de aeródromos sean emitidos con cierto margen de error humano, por esto el objetivo principal del presente proyecto es mejorar el nivel de precisión de los avisos de aeródromo a través de un modelo predictivo basado en el aprendizaje automático. Para esto se utilizó de un algoritmo de Red Neuronal Artificial considerando las siguientes variables para el desarrollo: dirección e intensidad del viento, visibilidad horizontal, cantidad y altura de nube, temperatura del aire y del punto de rocío y la presión atmosférica. Para entrenar y probar el modelo se utilizó la información obtenida del Portal Meteorológico de OGIMET, de los tres últimos años, datos utilizados para alcanzar así la predicción del aviso de aeródromo. Se contempla la utilización de la metodología de desarrollo de software en cascada y en base a un estudio de observación e investigación, recopilación de datos del estado de arte y análisis de modelos de IA. La página web que presenta los resultados de la predicción fue desarrollada en el lenguaje Python, diseñada en Streamlit y se utilizó la base de datos Firebase, siendo estos desplegados en los servicios de Google Cloud. Se realizó una comparación de la efectividad de algoritmos de aprendizaje supervisado como máquinas vectoriales SVM y regresión logística concluyendo que las redes neuronales artificiales alcanzan un mayor porcentaje de aprendizaje.Nowadays it is significant how technology has evolved and the opportunities that a new digital environment represents. Due to these advances, numerous machine learning techniques are available with which to develop an algorithm to predict aerodrome warnings in the airport area of Guayaquil city, it is no longer unattainable. Atmospheric instability produces special conditions causing observers to register, calculate and code them manually, this causes aerodrome warnings to be issued with a certain margin of human error, therefore the main objective of this project is to improve the level of precision of the aerodrome warnings through a predictive model based on machine learning. For this, an Artificial Neural Network algorithm was used considering the following variables for development: direction and intensity of the wind, horizontal visibility, amount and height of cloud, air temperature and dew point and atmospheric pressure. To train and test the model, the information obtained from the OGIMET Meteorological Portal, from the last three years, was used, data used to achieve the prediction of the aerodrome warning. The use of the software development methodology in cascade is contemplated and based on an observation and research study, collection of state-of-the-art data and analysis of AI models. The web page that presents the prediction results was developed in the Python language, designed in Streamlit and the Firebase database was used, being these deployed in Google Cloud services. A comparison of the effectiveness of supervised learning algorithms such as SVM vector machines and regression was made, concluding that artificial neural networks achieved a higher percentage of learning.\n"}
{"prompt":"Diseño e implementación de un sistema traductor de lengua de señas mediante inteligencia artificial para personas con discapacidad auditiva ->","completion":" This research project called \"Design and implementation of a sign language translator system through artificial intelligence for people with hearing disabilities\" aims to take advantage of the evolution of technology to reduce the communication barriers between hearing people and people who suffer from hearing loss. Hearing disability prevents people from interacting with their environment and hinders their development in different educational, work, and social environments. Given the lack of attention to these vulnerable groups, a system is developed that allows sign language translation to speed up the communication process, which is why artificial intelligence is used, one of the technological advances that improve the quality of people's lives. Neural networks were also used that, through prior training, can perform a number of tasks, obtaining results with great precision. To carry out the neural network training, it was necessary to use several tools and algorithms that optimize specific processes and provide quick solutions, one of them being Mediapipe, which facilitates the detection of the hand from the frames captured by the system. This is done thanks to the automatic learning models it has. Each frame is processed to obtain important information about the reference points of the hand, with 21 points being those that can be extracted from the hand and each one made up of coordinates X, Y, and Z that they are the position of each phalanx or knuckle of the hand. This information is later processed and stored to be used in the training of the neural network. Based on the results obtained, it is verified that the implemented system works correctly and is a beneficial tool for people with hearing disabilities. It allows them to improve their communication with a high level of reliability in good lighting conditions; the system detects 94 .46%, while in normal light conditions, it detects 92.08%. Finally, it detects 89.15% of bad light conditions the gestures made.RESUMEN: El presente proyecto de investigación denominado “Diseño e implementación de un sistema traductor de lengua de señas mediante inteligencia artificial para personas con discapacidad auditiva” tiene como objetivo aprovechar la evolución de la tecnología para disminuir las barreras de comunicación existentes entre personas oyentes y personas que padecen discapacidad auditiva, estas barreras impiden que las personas puedan interactuar con su entorno y dificultan su desenvolvimiento en los diferentes ambientes educativos, laborales y sociales. Ante la falta de atención en estos grupos vulnerables se desarrolla un sistema que permite la traducción de la lengua de señas de manera que agilice el proceso de comunicación, para ello se utiliza la inteligencia artificial que es uno de los avances tecnológicos que está mejorando la calidad de vida de las personas. También se emplearon redes neuronales que por medio de un entrenamiento previo pueden realizar una cantidad de tareas teniendo resultados con gran precisión. Para llevar a cabo el entrenamiento de la red neuronal fue necesaria la utilización de varias herramientas y algoritmos que optimicen ciertos procesos y brinden soluciones rápidas, siendo una de ellas Mediapipe que facilita la detección de la mano a partir de los fotogramas que capte el sistema, esto lo realiza gracias a los modelos de aprendizaje automático que posee, donde cada fotograma es procesado para obtener información importante acerca de los puntos de referencia de la mano, siendo 21 puntos los que se pueden extraer de la mano y cada uno conformado por coordenadas X, Y y Z que son la posición de cada falange o nudillo de la mano. Esta información posteriormente es procesada y almacenada para ocuparla en el entrenamiento de la red neuronal. En base a los resultados obtenidos se comprueba que el sistema implementado funciona de manera correcta y es una herramienta de gran ayuda para las personas con discapacidad auditiva permitiendo que mejore su comunicación con un alto nivel de confiabilidad, en condiciones lumínicas buenas el sistema detecta el 94,46%, mientras que en condiciones lumínicas regulares detecta el 92,08% y finalmente en condiciones lumínicas malas detecta el 89,15% de los gestos realizados.UNACH, Ecuador\n"}
{"prompt":"Herramientas avanzadas en el proceso de biosorción de ciprofloxacina en columna ->","completion":" En este trabajo, se investigó la remoción de ciprofloxacina en aguas sintéticas en columna de lecho fijo a escala de laboratorio y planta piloto utilizando como bioadsorbentes el bagazo de caña (BCA) y la mazorca de maíz (MZM). Se utilizó herramientas avanzadas como redes neuronales artificiales (RNAs) y software especializado para el modelado y simulación de la adsorción de ciprofloxacina (CFX) con ambos residuos agroindustriales. A escala de laboratorio la MZM presentó una capacidad de adsorción de 1,98 mg∙g-1 mientras que con BCA se obtuvo 1,28 mg∙g-1 en iguales condiciones de operación (concentración de CFX=5 mg∙L-1, caudal=7 mL∙min-1, diámetro de la columna= 2,2 cm). A escala de planta piloto (caudal=28 mL∙min-1, diámetro de la columna= 4,4 cm) la capacidad de adsorción para el BCA fue de 1,097 mg∙g-1, y para la MZM de 0,786 mg∙g-1. El modelo empírico matemático que mejor reprodujo la curva de ruptura de CFX en ambos biosorbentes y ambas escalas fue el modelo de Dosis-Respuesta. El modelado de las curvas de ruptura con redes neuronales artificiales presentó coeficientes de correlación (R2) muy altos, mediante un análisis de sensibilidad se determinó que la red creada en Tensorflow es más robusta que la red en Matlab para ambas escalas y ambos materiales biosorbentes. La simulación dinámica a escala de laboratorio para el BCA con Aspen Adsorption se generó una curva de avance con mejor ajuste a los datos experimentales que usando Comsol Multiphysics, sin embargo, usando MZM el ajuste es mayor en Comsol Multiphysics para ambas escalas.In this work, the removal of ciprofloxacin in synthetic waters was investigated in fixed bed column at laboratory and pilot plant scale using sugarcane bagasse (SCB) and corn cob (CC) as bioadsorbents. Advanced tools such as artificial neural networks(ANN) and specialized software were used for the modeling and simulation of the adsorption of ciprofloxacin (CFX) with both agro-industrial wastes. On a laboratory scale, corncob has an adsorption capacity of 1.98 mg∙g-1 while sugarcane bagasse has 1,28 mg∙g-1 under the same operating conditions (CFX concentration=5 mg∙L-1, flow rate = 7 mL∙min-1, column diameter = 2.2 cm). At the pilot plant scale (flow rate= 28 mL∙min-1) the adsorption capacity for the SCB is 1,097 mg∙g-1 as for the CC is 0.786 mg∙g-1, being lower in both cases. The empirical mathematical model that best reproduced the CFX breakthrough curve in SCB and CC at both scales was the Dose-Response model. The modeling of the rupture curves with ANN presented very high correlation coefficients (R2), it was determined that the network created in Tensorflow is more robust than the network in Matlab for both scales and both biosorbent materials by means of a sensitivity analysis. The dynamic simulation at laboratory scale for the SCB with Aspen Adsorption generated a breakthrough curve with better fit to the experimental data than using Comsol Multiphysics, however, using CC the fit is greater in Comsol Multiphysics for both scales.Ingeniero QuímicoCuenca\n"}
{"prompt":"Desarrollo de un modelo predictivo para la evaluación del riesgo crediticio en la Cooperativa de Ahorro y Crédito Virgen del Cisne. ->","completion":" Sin duda en la actualidad existe falencia en el análisis de información para otorgar un crédito o un préstamo, provocando pérdidas a la institución financiera que involucra gastos de cobranza, notificaciones, pago a abogados entre otros. Gracias a la transformación digital y el avance tecnológico hoy en día se puede utilizar la Inteligencia Artificial y en especial la rama de Machine Learning como estudio para el análisis de datos de los clientes y predecir el incumplimiento en el pago de sus obligaciones con la institución. El objetivo de este trabajo de investigación fue realizar un análisis de los modelos de Machine Learning de aprendizaje supervisado como Random Forest (XGBoots), Regresión Logística y Redes Neuronales y aplicar la metodología CRISP-DM para implementar un modelo predictivo que permita la evaluación del riesgo crediticio. Con este resultado podemos concluir que la utilización de herramientas de Machine Learning ayudan a optimizar la evaluación del riesgo de crédito en la entidad financiera. Con base en esta experiencia, se marca el camino para que, en futuros trabajos se implemente estos modelos en otras áreas como: detención de fraudes, segmentación de clientes o un motor de recomendaciones que pueda sugerir productos y servicios financieros basados en las necesidades y comportamientos de los clientes.ESPEL\n"}
{"prompt":"Estudio comparativo de las técnicas de inteligencia artificial para el diagnóstico de enfermedades en la agricultura ->","completion":" El proceso de diagnóstico mediante criterios y métodos complementarios es un arte muy complejo aplicado a la identificación de la enfermedad responsable del padecimiento o la estimación del riesgo de las complicaciones. El diagnóstico, tanto humano como animal y vegetal, es una tarea que requiere precisión, dada la importancia que puede tener una decisión equivocada. Gracias al desarrollo de las tecnologías de la información y la comunicación y a los inagotables avances de la informática, el diagnóstico fitosanitario en la agricultura, en la actualidad, se basa en las aplicaciones de la inteligencia artificial, que ve como referencia en varias de sus principales técnicas, así como en los sistemas expertos, la lógica difusa, las redes neuronales, la minería de datos.The diagnostic process using complementary criteria and methods is a very complex art applied to identifying the disease responsible for the condition or estimating the risk of complications. Diagnosis, both human, animal and plant, is a task that requires precision, given the importance that a wrong decision can have. Thanks to the development of information and communication technologies and the inexhaustible advances in information technology, phytosanitary diagnosis in agriculture is currently based on the applications of artificial intelligence, which it sees as a reference in several of its main techniques, as well as expert systems, fuzzy logic, neural networks, data mining.\n"}
{"prompt":"Reconocimiento de patrones para identificaci?n de usuarios en accesos inform?ticos. ->","completion":" La detecci?n y control de intrusos o accesos no autorizados en los sistemas inform?ticos ha sido desde siempre un tema a tener en cuenta en los sistemas de informaci?n donde la seguridad,integridad y privacidad de la informaci?n son aspectos fundamentales. El avance del conocimiento y la tecnolog?a es cada vez mayor, lo que permite el desarrollo y aplicaci?n de sistemas inform?ticos m?s sofisticados y eficientes, pero tambi?n aumenta la posibilidad de que sean vulnerados mediante accesos no leg?timos.\n"}
{"prompt":"Gestión de la información para la elaboración de un plan de mantenimiento basado en condición con monitoreo en línea de la maquinaria del área de vulcanización TT (Truck Tires) en Continental Tire Andina S.A. (2019) ->","completion":" El presente trabajo realiza una revisión de las condiciones existentes en los procesos productivos y las técnicas empleadas para las actividades de mantenimiento en el área de curado de una planta de manufactura de llantas; así como, las potenciales oportunidades de mejora de las actividades a través del avance de la tecnología, el aprovechamiento óptimo y eficiente de los recursos disponibles y el enfoque a la calidad; que generan el impulso y la necesidad de llevar a la vanguardia a las empresas en el siglo XXI; con los procedimientos que proveen las normas ISO para el Mantenimiento Basado en Condición (CBM por sus siglas en inglés) para la generación y su enfoque en el manejo de los datos y el uso de Redes Neuronales para la predicción de fallas, se analiza su aplicación e implementación.Magíster en Gestión de Mantenimiento\n"}
{"prompt":"Diseño de un modelo de aprendizaje automático para la predicción de la precipitación de lluvias en la ciudad de Guayaquil. ->","completion":" PDFEn la actualidad con el avance de la tecnología se puede contar con las técnicas de aprendizaje automático y lograr desarrollar un algoritmo fiable para la predicción de precipitaciones de lluvias. El objetivo principal del presente proyecto es mejorar la precisión de la precipitación de lluvias mediante el desarrollo de un modelo predictivo basado en las técnicas de Machine Learning, con la finalidad de tomar precauciones para reducir perdidas en la economía, daños en la vida social y humana, estas consecuencias se deben a los cambios de variaciones de las precipitaciones de lluvias en la ciudad de Guayaquil, por lo que se utilizó el algoritmo de Red Neuronal Recurrente (LSTM) con serie de tiempo, tomando en cuenta las siguientes variables para el desarrollo, como: velocidad de viento, humedad relativa, precipitación, temperatura (máxima y mínima), la información fue obtenida de Global Weather Data for Swat, datos que se utilizaron para realizar el entrenamiento y pruebas del modelo, obteniendo así a futuro la predicción de precipitaciones de lluvias de un día, también se realizó una comparación de los datos predichos con los datos reales de la Dataset, y los resultados obtenidos del algoritmo se visualizan en una página web desarrollada en el lenguaje de programación Python y diseñada en Django; se concluyó, a través de los resultados que las técnicas de Machine Learning son eficientes para predecir diversos eventos.At present with advancing technology you can count on machine learning techniques and to reach in developing a reliable algorithm for the prediction of precipitation. The main objective of this project is to improve the precision of rainfall through the development of a predictive model based on Machine Learning techniques, in order to take precautions to reduce losses in the economy, damage to social and human life , these consequences are due to the changes in rainfall variations in the city of Guayaquil, so that the Recurrent Neural Networks (LSTM) algorithm was used with a time serie, taking into account the following variables for the development, as: Wind Speed, Relative Humidity, Solar, Precipitation, Temperature (Maximum and Minimum), the information were provied from Global Weather Data for Swat, these data were used for training and testing the model, thus obtaining to future the prediction rainfall of one day, a comparison was be also made of the predicted data with of real data from the dataset, and the results obtained from the algorithm are displayed on a web page developed in the Python programming language and designed in Django; it was concluded through the results that machine learning techniques are efficient to predict various events.\n"}
{"prompt":"Desarrollo y análisis de sistemas de estimación y detección de objetivos de radar mediante algoritmos de machine y deep learning ->","completion":" La detección de objetivos de radar es un proceso que requiere de la recepción, procesamiento y análisis de las señales a analizar, donde es necesario cumplir con parámetros de alto rendimiento para garantizar la capacidad de respuesta ante posibles amenazas. Los sistemas actuales basan su funcionamiento en filtros y algoritmos que si bien cumplen su función presentan falencias frente a niveles de relación señal a ruido (SNR) bajos, situación que es común cuando se manejan señales a grandes distancias en un ambiente no controlado, generando complicaciones en el correcto funcionamiento de los sistemas. El avance de los algoritmos de Machine Learning y Deep Learning ha dado paso a sistemas de entrenamiento supervisados que reflejan mejores resultados trabajando como clasificadores. El objetivo del presente trabajo es comparar el rendimiento del algoritmo bayesiano tradicional (AR LMS MEAN) con los algoritmos de Machine Learning (Algoritmo de Bosque Aleatorio) y Deep Learning (Redes Neuronales LSTM). Los resultados muestran una mejora considerable en niveles de SNR bajos, cumpliendo con las exigencias de un sistema de detección de objetivos de radar óptimo, demostrando que si bien el entrenamiento de los algoritmos desarrollados tiene una duración mayor su desempeño es una mejora considerable con respecto a las técnicas antes utilizadas.\n"}
{"prompt":"Arquitectura clúster de alto rendimiento utilizando herramientas de software libre. ->","completion":" In recent years science and technology have made great advances with respect to the high performance computing, framed in architectures specifically designed for their operation and characterized by its high cost, being unreachable by research centers and higher education institutions (IES). Computing for researches use powerful tools and methods to process data in advanced academic researches. With a cluster built by conventional hardware and free software tools, the Systems Engineering Degree of National University Loja can obtain architecture with the speed and power of an expensive supercomputer at a fraction of the minimum cost. The purpose of this project is to provide and encourage academic and scientific research, teachers and students from the CIS, obtaining good results in: simulation process, neural network learning, pictures processing, patterns recognition, database processing, processing of large volumes of Big Data information, data mining, decryption of codes, assessment of algorithms, etc. The implementation of a platform of higher yield allows made billions of operations per second, allowing significant advances into the academic inquiry in any field of research into the university area. The implementation of the cluster was done with the GNU \/ Linux Debian \"Wheezy\" operating system, by its stability and efficiency as a server of high-performance used like a standard for the development of this project. For middleware we used Mosix in version 3.4.0.12 like a manager of process to get a unique image of the system oriented to distribute computing. MPICH was used in version 3.1.2 for parallel programming as one of the standard applications deployed Message Passing Interface (MPI). For the rendering process we used Blender, for the analysis of Big Data we used the Apache Hadoop framework. Among the configurations that we made they were: Remote access using public keys through Secure Shell protocol (SSH), sharing of network system through the Network File System protocol (NFS), also the design of network topology and the configuration of the motorization system Ganglia Monitoring System.En los últimos años la ciencia y la tecnología han tenido grandes avances en lo que respecta a la computación de alto rendimiento, enmarcados en arquitecturas diseñadas especialmente para su funcionamiento y caracterizadas por su elevado coste, siendo inalcanzables por centros de investigación e Instituciones de Educación Superior. La informática para investigaciones, usa potentes herramientas y métodos para procesar datos en investigaciones académicas avanzadas. Con un clúster construido por hardware convencional y herramientas de software libre, la Carrera de Ingeniería en Sistemas de la Universidad Nacional Loja, puede obtener una arquitectura con la velocidad y potencia de una supercomputadora, a una fracción del costo mínimo. La finalidad de este proyecto es aportar e incentivar a la investigación académica y científica de la UNL, optimizando el tiempo de procesamiento en tareas como: simulación de procesos, aprendizaje de redes neuronales, renderizado de imagen y video, reconocimiento de patrones, análisis de grandes volúmenes de datos Big Data, cifrado de códigos, evaluación de algoritmos, etc. La implementación de la arquitectura clúster de alto rendimiento permite realizar millones de operaciones por segundo, logrando avances importantes en la indagación académica, en cualquier campo de la investigación dentro del ámbito universitario. La implementación de la arquitectura clúster se la realizó con el sistema operativo GNU\/Linux Debian “Wheezy” por su estabilidad y su funcionamiento como servidor de alto rendimiento, usado como estándar para el desarrollo del proyecto. Para el middleware se utilizó Mosix como gestor de procesos para obtener una imagen única de sistema orientada a la computación distribuida. Para la programación paralela se implementó MPICH como una de las aplicaciones más importantes del estándar Message Passing Interface. Para el proceso de renderizado se usó Blender, para análisis de Big Data se empleó el framework Apache Hadoop. Dentro de las configuraciones realizadas tenemos: el acceso remoto utilizando claves públicas a través del protocolo Secure Shell, la compartición del sistema de ficheros en red a través del protocolo Network File System, además del diseño de la topología de red con direccionamiento IP estático y la configuración del sistema de monitorización Ganglia Monitoring System.\n"}
{"prompt":"Desarrollo de un prototipo clasificador de aceitunas de mesa por su origen aplicando técnicas de visión por computador. ->","completion":" PDFEl presente proyecto se centra en el desarrollo de un prototipo clasificador de imágenes, que permita catalogar las aceitunas de mesa de acuerdo a su forma de recolección por suelo o vuelo, con la finalidad de proporcionar una solución a la clasificación de aceituna manual, en la comunidad autónoma de Andalucía, España, y así poder contribuir con el aumento de la calidad del producto. Para el desarrollo de dicho proyecto se hizo uso del lenguaje de Programación Python, en el cual se desarrolló los algoritmos que permitieron realizar el Procesamiento Digital de Imágenes(PDI), por medio de distintas técnicas de preprocesamiento y segmentación para mejorar la calidad de las imágenes, posteriormente haciendo uso de las Redes Neuronales Convolucionales, mediante un aprendizaje supervizado por corrección de error, se pudo entrenar el algoritmo. Mediante sprints se determinaron las tareas a realizarse en cortos periódos de tiempo permitiendo llevar un orden y control de los avances del proyecto, y a su vez conocer los resultados obtenidos en el PDI, esto gracias al uso de la metodología híbrida Scrum-PDI. Finalmente el proyecto generó como resultado un sistema clasificador de aceitunas, capaz de identificar si la aceituna fue extraída del suelo o vuelo, mediante la evaluación del color, forma y textura de dicho fruto.This project focuses on the development of a prototype image classifier, which allows table olives to be catalogued according to their form of floor or flight harvesting, in order to provide a solution to the classification of manual olives, in the autonomous community of Andalucía, Spain, and thus be able to contribute to the increase in the quality of the product. For the development of this project, the Python programming language was developed, in which the algorithms that allowed Digital Image Processing(PDI) were developed, through different preprocessing and segmentation techniques to improve the quality of the images, subsequently using the Convolutional Neural Networks, through supervised learning by error correction, the algorithm was trained. Sprints determined the tasks to be carried out in short periods of time allowing to carry an order and control of the progress of the project, and in turn know the results obtained in the PDI, this thanks to the use of the hybrid methodology Scrum-PDI. Finally, the project resulted in an olive classifier system, capable of identifying whether the olive was extracted from the ground or flight, by evaluating the color, shape and texture of the fruit.\n"}
{"prompt":"Estrategia metodológica a través del pensamiento computacional para el aprendizaje de Matemática ->","completion":" Los resultados de las pruebas SER, evidencia bajo nivel de conocimientos en matemática, esto por la vigencia del modelo caduco de enseñanza. La investigación se orienta a desarrollar una estrategia metodológica con el pensamiento computacional para el aprendizaje de matemática en los estudiantes de básica superior de la Unidad Educativa “Francisco Flor”. Para lo cual se fundamenta sobre el Pensamiento Computacional con respaldo en autores actuales, la metodología aplicada parte de recopilar información documental y bibliográfica mediante el Perish versión 7, se aplica métodos teóricos y empíricos, el diagnóstico usa la técnica de la observación directa, encuestas a docentes y estudiantes. La problemática, el desconocimiento de los docentes el uso de estrategias del pensamiento computacional para el aprendizaje; la confiabilidad de los instrumentos se realizó a través de Alpha de CronBach quien dio como resultado alto 0,898, esto permite el conocimiento significativo de las principales características del tema de estudio. Propone una estrategia lúdica basada en los juegos dentro de diversos contextos del juego, se estructura las fases del proceso, primera fase, el diagnóstico que determina el contexto actual, segundo fase, la planificación del diseño de la estrategia metodológica con el uso de Google Blocky, la fase tres, la aplicación y familiarización con los bloques de rompecabezas, laberintos con sus niveles y la cuarta fase, el control y verificación del cumplimiento de las actividades de aprendizaje mediante la aplicación del retest a los estudiantes observados valida de esta manera la estrategia para la incorporación del PC en el aprendizaje de Matemáticas.Pontificia Universidad Católica del Ecuador, Dirección de Investigación y PosgradosMagíster en Tecnologías para la Gestión y Práctica Docente\n"}
{"prompt":"Desarrollo de una aplicación multimedia para la enseñanza de relaciones y funciones de matemática superior ->","completion":" Introducción. Objetivos y alcance del proyecto. Marco teórico. Desarrollo de la aplicación.\n"}
{"prompt":"Construcción de espacios asociados en análisis de Clifford usando una implementación computacional basada en matrices ->","completion":" Two di erential operators F and G are associated if F maps solutions of the di erential equation Gu = 0 into solutions of the same equation, that is, F is associated to G if G(Fu) = 0. A function space is a vector space whose objects are functions. The function space containing the solutions of Gu = 0 is called the space associated with the operator F...Dos operadores diferenciales F y G est an asociados si F mapea soluciones de la ecuaci on diferencial Gu = 0 en soluciones de la misma ecuaci on, es decir, F est a asociado a G si G(Fu) = 0. Un espacio funcional es un espacio vectorial cuyos objetos son funciones. El espacio funcional que contiene las soluciones de Gu = 0 se llama espacio asociado al operador F...\n"}
{"prompt":"Implementación computacional de medidas de concentración y un modelo de equilibrio con desviaciones para análisis estructural de mercados ->","completion":" In this paper, algorithms for estimating market concentration measures, and a unidimensional simulation scheme, are implemented using the computational systems R and Netlogo. With this perspective, in the rúst. section a detailed study of concentration measures is done, and the most used measures in the literature are formally described. Subsecuently, a market equilibrium model with deviations is developed, establishing its main characteristics and variations compared to traditional market structures of perfect competition, monopoly, and Cournot competition. It is noteworthy that the implementation proposal seeks to become a tool for structural market analysis, applicable in studies and investigations performed by national antitrust authorities; being also the starting point for the development of specialized software in this topic.En el presente trabajo se implementan a través de los sistemas computacionales R y Netlogo, algoritmos que permitan la estimación de medidas de concentración en mercados, así como un esquema de simulación unidimensional de agentes para evaluar desviaciones a la competencia perfecta por parte de operadores económicos. Para esto, en una primera parte se hace un estudio detallado de lo que son las medidas de concentración, y se describen formalmente los indicadores más utilizados en la literatura. Posteriormente, se desarrolla un modelo de equilibrio de mercado con desviaciones, estableciendo sus principales características y variaciones con respecto a las estructuras tradicionales de competencia perfecta, monopolio y competencia de Cournot. Es importante mencionar que la implementación propuesta busca convertirse en una herramienta para el análisis estructural de mercados, aplicable para estudios e investigaciones por parte de autoridades nacionales de competencia; y siendo el punto de partida para el desarrollo de software especializado en la materia.\n"}
{"prompt":"El aprendizaje de la matemática financiera en los terceros años de bachillerato de la especialidad de contabilidad y administración de los colegios fiscales urbanos de la ciudad de Ibarra ->","completion":" Diseñar una Guía Didáctica Interactiva para el aprendizaje de la Matemática Financiera en los Terceros años del bachillerato de la Especialidad de Contabilidad y Administración en los colegios fiscales Urbanos de la ciudad de Ibarra provincia de Imbabura.La presente investigación tiene como objetivo diseñar una guía didáctica interactiva para el aprendizaje de la matemática financiera en los terceros años de bachillerato, diagnosticar la forma de enseñanza, determinar la forma de aprendizaje de los estudiantes, y realizar y difundir una guía didáctica entre los profesores y estudiantes.\n"}
{"prompt":"Strategias didácticas para la enseñanza aprendizaje de la asignatura de matemática en los décimos años de educación básica en el colegio técnico Víctor Manuel Guzmán de la ciudad de Ibarra, durante el año lectivo 2008-2009. ->","completion":" Definir estrategias didácticas para la enseñanza- aprendizaje en la asignatura de matemática para los décimos años de educación básica del colegio Técnico ”Víctor Manuel Guzmán”, para mejorar el bajo rendimiento académico, a través de la elaboración de la guía didáctica con métodos y técnicas activas.La presente investigación trata sobre la definición de estrategias didácticas para la enseñanza de la matemática, con la finalidad de mejorar el bajo rendimiento académico de los alumnos de los décimos años de educación básica del colegio Víctor Manuel Guzmán, para ello se ha diagnosticado sobre la aplicación de métodos y técnicas en el proceso de aprendizaje, se ha diseñado una propuesta que permitirá una mejor enseñanza de la matemática, y a la vez, socializarla a los docentes y autoridades del colegio.\n"}
{"prompt":"Diseño y desarrollo de una herramienta computacional, para el cálculo del diámetro mínimo de ejes de transmisión, bajo la acción de cargas cíclicas. ->","completion":" The present degree project, consisted in design and develop a computational tool, to determine the minimum shaft diameter, subjected to cyclic loads. The computational tool was the result of a complete bibliographic search, regarding the shaft design available in commercial medium. Having analyzed and synthesized the information, mathematical models were identified for the calculation of the minimum shaft diameter, as well as certain analysis criteria, among which the Soderberg criterion was defined, according to the distortion energy theory (DET), when the element of interest (shaft) is under cyclic loads. From this, specific conditions were adopted for the parameters such as: forces existing in the transmission mechanisms mounted along the shaft, effective coefficients of concentration of bending and torsional stresses, types of materials, which, without a doubt they influence the determination of the calculation of the minimum shaft diameter. Subsequently, case studies were proposed, more usual in applications and situations that in practice are required. When determining the medullary part that characterizes the present final work, that is, the determination of the minimum shaft diameter, were also defined the mathematical models related to: transmission systems, forces and reactions, in addition to the deduction of those mathematical models for determine the elastic curve (deflection) on the solid axis of uniform circular cross section. The developed application focuses on analyzing the following axially mounted transmission systems on the shaft such as: belt - pulley, roller chain and straight gears and to provide the mechanical designer (user) with materials for axis , such as: AISI 1045, AISI 4340 (4337), AISI 4140, AISI 5115, SAE 1010, SAE 1015, SAE 1018, SAE 1020, AISI 304, AISI 316 - L , AISI 430. The programming of the different mathematical models and graphical interfaces, were carried out in Java - NetBeans IDE 8.2, to then, establish communication with the Inventor Professional 2019 ® parametric design software, to get a virtual representation of the final shaft in 3D. Finally, in annexes the different tables, graphs, and screenshots are presented, also to a quick user´s guide, to correct handling of the computational tool. Keywords: Mathematical models, shaft design, power transmission mechanisms, flow diagrams, object – oriented programming, parametric design.El presente proyecto de titulación, consistió en diseñar y desarrollar una herramienta computacional, para determinar el diámetro mínimo de ejes, sometidos a cargas cíclicas. La herramienta computacional, fue el resultado de una búsqueda bibliográfica íntegra, en lo concerniente a el diseño de ejes disponibles en medio comercial. Habiendo analizado y sintetizado la información, se identificaron los modelos matemáticos para el cálculo del diámetro mínimo del eje, así como de ciertos criterios de análisis, de entre los cuales se definió el criterio de Soderberg, según la teoría de la energía de distorsión (DET), cuando el elemento de interés (eje) se encuentra bajo cargas cíclicas. A partir de ello, se adoptaron condiciones específicas para los parámetros como: fuerzas existentes en los mecanismos de transmisión montados a lo largo del eje, coeficientes efectivos de concentración de tensiones a flexión y torsión, tipos de materiales, los cuales que, sin lugar a dudas influyen en la determinación del cálculo del diámetro mínimo del eje. Posteriormente, se propusieron casos de estudio, más usuales en aplicaciones y\/o situaciones que en la práctica se requieren. Al determinar la parte medular que caracteriza el presente trabajo de titulación, que es, la determinación del diámetro mínimo del eje, se definieron los modelos matemáticos relacionados a: los sistemas de transmisión, fuerzas y reacciones, además de la deducción de aquellos modelos matemáticos para determinar la curva elástica (deflexión) en el eje macizo de sección transversal circular uniforme. La aplicación desarrollada, se enfoca en analizar los siguientes sistemas de transmisión montados de manera axial en el eje como: banda – polea, cadena de rodillos y engranajes rectos. Además de proporcionar al diseñador mecánico (usuario) materiales para ejes, como: AISI 1045, AISI 4340 (4337), AISI 4140, AISI 5115, SAE 1010, SAE 1015, SAE 1018, SAE 1020, AISI 304, AISI 316 – L, AISI 430. La programación de los diferentes modelos matemáticos e interfaces gráficas, se realizaron en el entorno de desarrollo Java – NetBeans IDE 8.2, para luego establecer una comunicación con el software de diseño paramétrico Inventor Professional 2019®, para obtener una representación virtual del eje final en 3D. Finalmente, en anexos se presentan las diferentes tablas, gráficos, y capturas de pantalla, además de una guía rápida que permita al usuario, un correcto manejo de la herramienta computacional. Palabras clave: Modelos matemáticos, diseño de ejes, mecanismos de transmisión de potencia, diagramas de flujo, programación orientada a objetos, diseño paramétrico.\n"}
{"prompt":"Juego serio como apoyo en el acompañamiento de la enseñanza de las operaciones matemáticas de sumas y restas básicas en niños de seis años \/ ->","completion":" Resumen: Los juegos serios han sido uno de las principales intrusiones que se ha venido experimentando en la línea de renovación y modernización del proceso de enseñanza-aprendizaje que existe actualmente. De entre las áreas en donde ha sido experimentado el uso del juego serio; se destacan las áreas de salud, cultura, entrenamiento militar y el área de educación. En el presente trabajo de titulación se diseñó un juego serio que sirve como apoyo en el acompañamiento de la enseñanza de las operaciones matemáticas de sumas y restas básicas en niños de seis años. El videojuego está diseñado bajo la metodología Singapur, compuesta por una pedagogía constructivista; apoyada en la teoría de Jerome Brunner y la técnica del interrogativo. El desarrollo del prototipo de juego serio, se lo realizo en el motor de videojuegos Unity 3D.\n"}
{"prompt":"Juego serio como apoyo en el acompañamiento de la enseñanza de las operaciones matemáticas de sumas y restas básicas en niños de seis años \/ ->","completion":" Resumen:Los juegos serios han sido uno de las principales intrusiones que se ha venido experimentando en la línea de renovación y modernización del proceso de enseñanza-aprendizaje que existe actualmente. De entre las áreas en donde ha sido experimentado el uso del juego serio; se destacan las áreas de salud, cultura, entrenamiento militar y el área de educación. En el presente trabajo de titulación se diseñó un juego serio que sirve como apoyo en el acompañamiento de la enseñanza de las operaciones matemáticas de sumas y restas básicas en niños de seis años. El videojuego está diseñado bajo la metodología Singapur, compuesta por una pedagogía constructivista; apoyada en la teoría de Jerome Brunner y la técnica del interrogativo. El desarrollo del prototipo de juego serio, se lo realizo en el motor de videojuegos Unity 3D.\n"}
{"prompt":"Validación computacional de vertederos rectangulares y triangulares para generar un modelo nuevo triangular asimétrico que facilitaría la medición de las cargas en estructuras hidráulicas ->","completion":" En el presente proyecto de investigación se ha determinado la relación entre el caudal y el nivel de agua en un vertedero asimétrico de pared delgada de forma triangular mediante un modelo de simulación computacional en lugar del uso de laboratorios convencionales que requieren de un alto tiempo y costo económico de inversión en su equipamiento.In the present research project, the relationship between flow and water level in an asymmetric thin-walled triangular-shaped landfill was determined by a computational simulation model instead of the use of conventional laboratories that require a high time and cost economic investment in their equipment.\n"}
{"prompt":"Sistema Interactivo de Matemáticas financieras ->","completion":" Se realiza el diseño y desarrollo de un sistema interactivo financiero, que es un paquete computacional desarrollado en visual basic. principalmente la intención es de dotar a la comunidad d un paquete computacional que ayude a resolver los problemas financieros, infiriendo sobre las opciones optimas de rentabilidad, convirtiéndose de esta manera en una herramienta potente. en muchos casos se utiliza la simulación para ver los posibles resultados que distintos escenarios del ambiente económico pueden deparar. el paquete computacional trata de abarcar todos los análisis financieros básicos, posee un total de 18 módulos, cada uno de ellos ayudara a resolver un problema económico distinto.GuayaquilIngeniería en Estadística Informática\n"}
{"prompt":"Sistema Interactivo de Matemáticas Financieras ->","completion":" En el presente trabajo se realiza el diseño y desarrollo de un sistema interactivo financiero, que es un paquete computacional desarrollado en Visual Basic. Principalmente la intención es de dotar a la comunidad d un paquete computacional que ayude a resolver los problemas financieros, infiriendo sobre las opciones optimas de rentabilidad, convirtiéndose de esta manera en una herramienta potente. En muchos casos se utiliza la simulación para ver los posibles resultados que distintos escenarios del ambiente económico pueden deparar. El paquete computacional trata de abarcar todos los análisis financieros básicos, posee un total de 18 módulos, cada uno de ellos ayudara a resolver un problema económico distinto.GuayaquilINGENIERO EN ESTADÍSTICA INFORMÁTICA\n"}
{"prompt":"Elaboración de un manual para la enseñanza de Álgebra Lineal usando el pensamiento computacional ->","completion":" El presente manual operativo fue desarrollado con el fin de apoyar el aprendizaje en la asignatura de Algebra Lineal en estudiantes de Segundo de BGU, valiéndose del pensamiento computacional como medio para la resolución de problemas de manera imaginativa consolidando el razonamiento abstracto matemático. Se utilizó Python debido a que es un software libre como una estrategia metodológica que ayude a operativizar y optimizar el tiempo de los estudiantes de Segundo de BGU en la resolución de ejercicios que a posteriori recibirán el curso de Algebra Lineal más formal. Está diseñado de manera que sea usado a la par de un libro de texto, en el cual se presenta la importancia del pensamiento computacional, aspectos relevantes de la herramienta Python, como la realización de operaciones matemáticas sencillas y el uso de algunas funciones matemáticas que se utilizan en la resolución de ejercicios en los capítulos II, III y IV del presente manual. Así mismo, se desarrollaron los laboratorios que nos enseñan cómo resolver los ejercicios de cada capítulo paso a paso utilizando Python, con el objetivo de que el estudiante se familiarice con el lenguaje de programación. Se presentará al final del manual el código fuente de las funciones creadas para la resolución de los ejercicios. Para obtener la validación del presente manual, se utilizó el criterio de expertos, para lo cual se seleccionó un experto en Álgebra Lineal, uno en Programación y uno en Pedagogía, los mismos que validaron la propuesta metodológica del presente proyecto.\n"}
{"prompt":"Robótica aplicada en el proceso de enseñanza aprendizaje en el área de computación ->","completion":" PDFEl presente proyecto de investigación se enmarca en la Robótica aplicada en el proceso de enseñanza aprendizaje que se convierte en una herramienta que ayuda a potenciar el desarrollo de habilidades y competencias en los estudiantes. Esta metodología estimula el aprendizaje colaborativo el cual permite activar procesos cognitivos y sociales en la cual los mismos estudiantes van construyendo su propio conocimiento y así, obtener un aprendizaje significativo. Basado en la metodología STEM (Ciencias, Tecnología, Ingeniería y Matemáticas), que es una metodología interdisciplinaria porque integra a cuatro disciplinas científicas como una sola enseñanza en lugar de áreas del conocimiento compartidas. La modalidad de esta investigación es mixta tanto cuantitativa y cualitativa, porque se utilizó técnicas e instrumentos pertinentes para la obtención de los datos a través de encuestas realizadas a estudiantes de primero de bachillerato general unificado, y entrevistas a docentes y autoridades de la Unidad Educativa del Milenio Ileana Espinel Cedeño.This research project is part of the applied Robotics in the teaching-learning process that becomes a tool that helps to enhance the development of skills and competencies in students. This methodology stimulates collaborative learning which allows activating cognitive and social processes in which the students themselves build their own knowledge and thus obtain meaningful learning. Based on the STEM methodology (Science, Technology, Engineering and Mathematics), which is an interdisciplinary methodology because it integrates four scientific disciplines as a single teaching instead of shared areas of knowledge. The modality of this research is mixed, both quantitative and qualitative, because techniques and relevant instruments were used to obtain the data through surveys applied to students of the first general unified baccalaureate, and interviews to teachers and authorities of the Educational Unit of the Millenium Ileana Espinel Cedeño.\n"}
{"prompt":"Análisis de seguridad en plataformas de computación distribuida con arquitectura de edge computing. ->","completion":" PDFEl siguiente trabajo de investigación se encuadra en el esfuerzo multidisciplinario para generar una plataforma de servicios médicos la cuál va a ser de utilidad para la comunidad local. El desarrollo de una plataforma de servicios médicos constituye un desafío para todas las áreas inmersas en el desarrollo de este proyecto, por la sensibilidad de los datos a manejar, ya que los historiales médicos de los pacientes tienen carácter de confidencial en la totalidad de jurisdicciones a nivel mundial y constituye en sí mismo un derecho humano. En una arquitectura de Edge Computing, existe poco desarrollo de técnicas y políticas de seguridad a nivel de la capa intermedia entre el alojamiento en la nube y el dispositivo final del usuario, siendo esta capa intermedia, la que representa el mayor peligro en la seguridad de la transmisión de datos. El presente trabajo analiza la dinámica de la transmisión de datos a nivel de la capa intermedia en una arquitectura de Edge Computing, para luego plantear una solución que se ajuste a dicha dinámica, identificando en el proceso las fortalezas y debilidades de las arquitecturas de Edge Computing como base y sus diferentes variantes.The following research project discusses a multidisciplinary approach to develop a system of medical services that will be useful to the local community. The creation of this system represents a challenge for all the areas involved in its development due to the sensitivity of the data to be handled, since patient medical records are confidential in all jurisdictions worldwide and constitute a human right. In Edge Computing architecture, there is limited development of security techniques and policies at the level of the intermediate layer between the cloud hosting and the user's device, being this intermediate layer the one that represents the greatest danger in the safety of data transmission. This paper analyzes the dynamics of data transmission at the intermediate layer level in an Edge Computing architecture. The project also presents a solution that adjusts to these dynamics by identifying the strengths and weaknesses of the edge computing architectures as a starting point and their different alternatives.\n"}
{"prompt":"La metodología tradicional en el proceso de enseñanza aprendizaje en la asignatura de computación asignatura de computación de los estudiantes del bachillerato del colegio nacional mixto “los Guayacánes” del Cantón Quevedo, Provincia de los Rios, año lectivo 2011 -2012. ->","completion":" Los sistemas de educación más antiguos conocidos tenían dos características comunes: enseñaban religión y mantenían las tradiciones del pueblo. en el antiguo Egipto, las escuelas de los templos enseñaban religión, pero también los principios de escritura, ciencias, matemáticas y arquitectura. De forma semejante, en la India la mayor parte de la educación estaba en las manos de sacerdotes. La India fue la fuente del budismo, doctrina que enseñaba en sus instituciones a los chicos , y que se extendió por la mayoría de los países de Oriente. La educación en la antigua China se centralizaba en la filosofía, la poesía y la religión, de acuerdo con las enseñanzas de Kung-Fu-Tsé (conocido en occidente como Confucio), Lao-Tséy otros filósofos. El sistema chino de una prueba civil, iniciado en ese país ya hace más de dos mil años, se ha mantenido hasta hoy, pues, en teoría, permite la selección de los mejores estudiantes para cargos importantes en el gobierno, este legado dejado no solo por esta corriente si no la romana, egipcia, tailandesa, en general europea y Asiática han marcado la evolución de la educación en toda América.\n"}
{"prompt":"El conectivismo pedagógico en la transferencia de conocimientos ->","completion":" PDFEl trabajo investigativo se basa en la necesidad constante de una transformación profunda en la enseñanza, para realzar la calidad del aprendizaje de los escolares en la actualidad, dicha transición propone retos e innovación, ante un mundo cambiante, para los alumnos de séptimo grado de educación general básica, de la Unidad Educativa “Dr. Alfredo Raúl Vera Vera” en la ciudad de Guayaquil, el objetivo propone realizar una guía interactiva que influya en la transferencia de conocimientos, se utiliza un enfoque mixto de investigación bibliográfica y de campo, se aplica encuesta de cinco preguntas a las autoridades y entrevista de diez ítems a docentes y estudiantes, basada en la escala de Likert, las cuales son plasmadas en los cuadros y gráficos estadísticos. Se concluye manifestado que el conectivismo pedagógico favorece la transferencia de conocimientos, ya que los educandos pueden reforzar los aprendizajes y reducir las debilidades en el proceso enseñanza aprendizaje.The investigative work is based on the constant need for a profound transformation in teaching, to enhance the quality of learning of schoolchildren today, this transition proposes challenges and innovation, in the face of a changing world, for students in seventh grade of education basic general, of the Educational Unit “Dr. Alfredo Raúl Vera Vera ”in the city of Guayaquil, the objective proposes to make an interactive guide that influences the transfer of knowledge, a mixed approach of bibliographic and field research is used, a survey of five questions is applied to the authorities and an interview of ten items to teachers and students, based on the Likert scale, which are reflected in the tables and statistical graphs. It is concluded that pedagogical connectivism favors the transfer of knowledge, since students can reinforce learning and reduce weaknesses in the teaching-learning process.\n"}
{"prompt":"Clústers : ¿generadores de transferencia de conocimiento, tecnología e innovación en el Ecuador ->","completion":" Los retos de la globalización y los grandes cambios productivos han forzado a los diferentes sectores a considerar estrategias enfocadas en el desarrollo del conocimiento, investigación, avance tecnológico e innovación dentro concentraciones geográficas de empresas (clúster) que influyen directamente en los cambios de los proceso productivos. Para ello una sociedad debe contar con recursos y condiciones que les permitan aprovechar las oportunidades existentes y generar ideas nuevas en base a la calidad de la formación académica, participación activa de los agentes públicos y privados, y la articulación del conocimiento con la tecnología e innovación; teniendo como resultado la productividad, competitividad y crecimiento económico.\n"}
{"prompt":"Aseguramiento de la transferencia de conocimiento en puestos claves en una empresa comercializadora ->","completion":" 1. Problema de investigación. --2. Marco Teórico. --3. Metodología del trabajo. --4. Análisis e interpretación de resultados. --5. Propuesta. --6. Conclusiones y Recomendaciones.El interés en el presente proyecto de investigación, está enfocado en la importancia sobre la transferencia y gestión del conocimiento. El desarrollo de este trabajo parte de una revisión bibliográfica y de la construcción de un marco conceptual en el que se determinó los referentes teóricos y metodológicos necesarios para el diseño de un proceso de transferencia del conocimiento empresarial. Posteriormente se describen los puestos claves en base a la información que facilitó la empresa; se revisó esta información y se detectó la necesidad de modificación de la misma con nuevos criterios. Se trabajó con las personas designadas en los puestos claves y sucesores, para los puestos claves se creó y aplicó a un representante por cargo el instrumento caracterización de puestos. Al obtener los puestos claves se procedió a crear un plan de sucesión considerando a dos candidatos por cada puesto clave a los cuales se les aplicó el segundo instrumento llamado adecuación persona puesto. También se analizó los manuales de funciones para poder proceder a la creación del modelo del sistema, el mismo que fue validado por el criterio de expertos y por la empresa beneficiada. Así como también sustentada por una entrevista aplicada a la gerente de talento humano de la empresa. El principal objetivo de este proyecto fue diseñar una estrategia que asegure la transferencia del conocimiento dentro de la empresa, por medio de instrumentos que permiten el uso y la construcción del conocimiento.Disertación (Psicóloga Organizacional) - Pontificia Universidad Católica del Ecuador, Escuela de Psicología.Psicóloga Organizacional\n"}
{"prompt":"Transferencia de conocimiento en el emprendimiento de candelabros artesanales hechos a base de porcelana Fría ->","completion":" Este trabajo de titulación trata de la transferencia de conocimiento en el emprendimiento de los candelabros artesanales hechos a base de porcelana fría se presenta con el interés de dar a las personas una mejor opción de realizar un emprendimiento. La investigación muestra que hay ventajas en realizar el mismo, ya que se muestra antecedentes de como los productos artesanales han tenido acogida no solo en el lugar que se los fabrica sino también en otras ciudades inclusos países. La transferencia de conocimiento del emprendimiento artesanal que brinda este proyecto es dar a conocer a las personas como emprender un negocio tomando como ejemplo este tipo de producto el cual se lo caracteriza por tener un envase que se puede dar a conocer en diferentes presentaciones, de esta manera llegará a cubrir las expectativas del cliente, por lo tanto el nivel de conocimiento que se transfiera será óptimo de esta manera no existirá problemas al momento de realizar este emprendimiento. Ya que son las unidades educativas de tercer nivel las indicadas a para brindar este tipo de conocimiento. La demanda de este producto artesanal aumentará a través del tiempo, ya que los mismos son considerado como recuerdos, la comercialización de estos no sólo se centrarán en un tipo de mercado, las personas podrán obtenerlas por las diversas necesidades que cubre el producto; por ejemplo: las personas lo adquieran para decorar sus hogares para darles un toque más rústico o utilizarlo para decorar un lugar donde se llevará a cabo reuniones y eventos especiales, también lo pueden adquirir para darlo como un presente. Como parte de este proyecto se propondrá un modelo de presupuesto, en el cual se planteará los recursos primordiales que se necesitan para realizar este tipo de emprendimiento. También se presentará un pequeño plan estratégico para que las personas conozcan el nuevo producto por medio de redes sociales. Esto se expondrá como parte del asesoramiento para el desarrollo de este emprendimiento.This work of degree is of knowledge transfer in the entrepreneurship of the handicrafts chandeliers made of cold porcelain is presented with the interest of giving people a better option to make an entrepreneurship. The research shows that here are advantages to do it, because it shows a history of how the handicraft products have had acceptation not only in the place that the factory but also in other cities included countries. The knowledge transfer of the handicraft entrepreneurship that give this project is to inform people how to start a business taking the example of this type of product which is characterized by having a packaging that may be in different presentations, this way you will arrive to meet the expectations of the client, therefore the level of knowledge that is transferred will be optimal in this way there will be no problems at the time to carry out this entrepreneurship. Universities are indicated to provide this type of knowledge. The demand for this handicraft product will increase over time, since they are considered as souvenirs, the marketing of these not only focus on one type of market, people may be obtained by the various needs that covers the product; for example: people buy to decorate their homes to give them a touch more rustic or use it to decorate a place where you will conduct meetings and special events, also can also acquire in order to give it as a present. As part of this project will propose a budget model, in which there will be key resources that are needed to perform this type of entrepreneurship. Also there will be a small strategic plan so that people are aware of the new product by means of social networks. This will exhibited as part of the advice for the development of this entrepreneurship.\n"}
{"prompt":"Evolución de los modelos de transferencia del conocimiento en Emprendimientos Sociales ->","completion":" La transferencia de conocimiento actualmente tiene un campo amplio de aplicación en diferentes ciencias y ramas de la ingeniería, un emisor transmite por medio de varios pasos o procesos el conocimiento a un receptor. El objetivo del presente trabajo fue analizar la evolución de los modelos de transferencia de conocimiento, a fin de determinar el modelo idóneo que permita la transferencia de conocimiento de la parroquia Salinas de Guaranda hacia la comuna de Sacachún Parroquia Simón Bolívar del Cantón Santa Elena. La metodología aplicada fue un enfoque cualitativo, alcance descriptivo, diseño no experimental y documental. Por medio de la revisión bibliográfica se pudo establecer la evolución de los modelos de transferencia de conocimiento, para esto se usó el software Sci2 Tool que trabaja bajo la teoría de grafos encontrando un total de 506 artículos, que fueron depurados por duplicación por medio de Mendeley, eligiendo de entre los 104 artículos los que cumplían el criterio de inclusión obteniendo un total de 6 artículos que hablan sobre modelos de transferencia de conocimiento. Se pudo concluir que el modelo apto para transferir el conocimiento a la Comuna Sacachún de la parroquia Simón Bolívar, fue el modelo propuesto por Liyanage et al. 2012, ya que cuenta con las variables necesarias que facilitan su transferencia, la misma que se basa en las variables aplicación, asociaciones, traducción y conciencia.The transfer of knowledge currently has a broad field of application in different sciences and branches of engineering, an issuer transmits knowledge through a number of steps or processes to a receiver. The objective of this work was to analyze the evolution of knowledge transfer models, in order to determine the ideal model that allows the transfer of knowledge from the Salinas de Guaranda Parish to the Sacachún Commune Simón Bolívar Parish of the Santa Elena Canton. The methodology applied was a qualitative approach, descriptive scope, non-experimental and documentary design. Through the literature review, the evolution of knowledge transfer models could be established, for this the Sci2 Tool software was used, which works under the theory of graphs, finding a total of 506 articles, which were purified by duplication through Mendeley, choosing from among the 104 articles those that met the inclusion criteria obtaining a total of 6 articles that talk about knowledge transfer models. It was concluded that the model suitable for transferring knowledge to the Sacachún Commune of the Simón Bolívar parish was the model proposed by Liyanage et al. 2012, since it has the necessary variables that facilitate its transfer, which is based on the application, associations, translation and awareness variables.\n"}
{"prompt":"Técnicas de abstracción tardía para promover la transferencia ->","completion":" La transferencia de conocimiento es un objetivo fundamental para la psicología del aprendizaje. El paradigma analógico de resolución de problemas cuenta con una extensa historia de investigaciones que, a pesar de su relevancia, no han logrado superar una tasa media de transferencia espontánea. Si bien es claro que la información relacional y abstracta es crítica, aún queda abierta la cuestión de si es posible facilitar el proceso abstractivo del enunciado de un problema mediante un heurístico más accesible a los participantes que la reformulación del enunciado en términos más generales utilizada en investigaciones previas. En este trabajo se proponen el uso de pronombres indefinidos en construcciones semánticas que facilitan la recuperación según dos tipos de formulaciones: formulaciones generales que refieren a la totalidad de relaciones en un problema, y formulaciones de orden intermedio, que hemos denominado “definiciones relacionales” construidas en torno a los objetos críticos del problema. En el experimento 1 probamos el uso de pronombres indefinidos como sustituto de sustantivos concretos. En el experimento 2, probamos el uso del pronombre indefinido “algo” en las “definiciones relacionales” de objetos. Los resultados indican que la indefinición de los sustantivos alcanza para eliminar el contenido superficial pero los esquemas que se obtienen para describir el problema son extensos y demasiado complejos como para desencadenar la recuperación espontánea. Sin embargo, se obtuvo una diferencia significativa en la recuperación mediante definiciones relacionales de los objetos críticos del problema.\n"}
{"prompt":"Redes de política en el diseño de la política púbica de transferencia de conocimiento: Proyecto Prometeo ->","completion":" En el periodo de 2007 al 2017 el Ecuador se encontraba en el camino de implementar un nuevo modelo de desarrollo que buscaba transformar al país de un país que usa principalmente recursos finitos por uno que utilice recursos finitos. Además, de anteponer al ser humano sobre el capital, lo cual se denominó Buen Vivir. El resultado fue la implementación de varias políticas que abarcaban diferentes ámbitos de la sociedad ecuatoriana entre ellos, la importancia del conocimiento para generar un cambio social, la inversión en educación, el nivel de investigación en el país, entre muchos otros. El Gobierno de turno reconociendo que era necesario mejorar el talento humano en el país, la investigación y generar conocimiento para lograr desarrollo tecnológico, ciencia e innovación planteo diferentes políticas públicas y normativa.\n"}
{"prompt":"Plataformas digitales como herramienta de transferencia de conocimiento en la Facultad de Comunicación Social. ->","completion":" pdfLa educación desde el punto de vista de las plataformas digitales, son tecnologías virtuales en que se ayudan los docentes de la facultad de comunicación social, posee elementos tecnológicos que hacen que las personas e instituciones involucradas en propuestas de procesos de enseñanza aprendizaje consideren lo digital que va tomando con el transcurso del tiempo, la cultura y generaciones. Ya entrando en el plano de las modalidades educativas cada día crece a pasos agigantados la educación a distancia con soportes en plataformas educativas virtuales. Este proyecto de investigación está orientado a investigar el uso y el conocimiento de las Plataformas digitales, a fin de fortalecer sus conocimientos y proponer el diseño de un manual digital. Las interrogantes que surgen para la investigación provienen de la utilización de Plataformas digitales y las Nuevas Tecnologías de la Información en la educación, la cual implica que se debe estar permanentemente actualizando los conocimientos en el manejo de la Tecnología en especial en lo que se refiere bondades que provee la navegación por Internet donde se constituye la gran biblioteca virtual donde se adquiere información muy valiosa para la educación. Hoy en día la implementación de software educativo en la enseñanza de los docentes es muy importante, en especial en la utilización de Plataformas digitales que será algo indispensable para el mejoramiento del Proceso docente educativo, donde se requiere estar al nivel de la educación que existe en otros países que usan las Plataformas digitales y así lograr el desarrollo Científico Tecnológico exigencias del mundo moderno.Education from the point of view of digital platforms, they are virtual technologies in which the teachers of the faculty of social communication are helped, it has technological elements that make the people and institutions involved in proposals for teaching-learning processes consider digital that is taking over time, culture and generations. Already entering the plane of educational modalities, distance education is growing by leaps and bounds every day with supports on virtual educational platforms. This institutional research project is aimed at investigating the use and knowledge of digital platforms, in order to strengthen their knowledge and propose the design of a digital manual. The questions that arise for the research come from the use of digital Platforms and New Information Technologies in education, which implies that knowledge in the management of Technology must be constantly updated, especially in regard to benefits that provides Internet browsing where the great virtual library is constituted where very valuable information for education is acquired. Nowadays the implementation of educational software in the teaching of teachers is very important, especially in the use of digital platforms that will be indispensable for the improvement of the educational teaching process, where it is required to be at the level of education that exists in other countries that use digital platforms and thus achieve the Scientific Technological development demands of the modern world.\n"}
{"prompt":"Propuesta de un modelo conceptual de transferencia de conocimiento a la comuna de Sacachún Provincia de Santa Elena ->","completion":" En la comuna Sacachún perteneciente a la parroquia Simón Bolívar de la provincia de Santa Elena se desarrolló un proyecto del MAGAP el que consistió en la implementación de hatos caprinos doble propósito, incorporando valor agregado (Queso artesanal), luego de la implementación del proyecto antes mencionado en la comuna no se ha evidenciado la existencia de emprendimientos con la leche caprina, por tanto se requirió conocer los factores que pueden fomentar los emprendimientos, con la finalidad de propiciar la transferencia de conocimientos desde la parroquia Salinas de Guaranda hacia la comuna. El objetivo fue diseñar un modelo que establezca los factores para la transferencia de conocimiento a los emprendimientos de la comuna Sacachún. El enfoque de investigación que se utilizó fue cuantitativo y cualitativo, el tipo de investigación fue exploratoria y descriptiva, el diseño fue no experimental, transversal, los instrumentos de medición que se aplicaron fueron el uso de encuestas, que consistió en el desarrollo de preguntas cerradas con opción múltiple, la entrevista semi-estructurada u observación directa no participativa. Los resultados de la investigación fueron que hasta el momento no se han realizado emprendimientos individuales en base a la leche caprina pero si manifestaron la disposición a realizar emprendimientos asociativos, por lo que se diseñó como propuesta un modelo de transferencia de conocimiento sobre el proceso de elaboración de queso artesanal, desde Salinas de Guaranda hacia la comuna Sacachún, que permitirá mejorar la calidad de vida de ellosIn the Sacachún commune belonging to the Simón Bolívar parish of the province of Santa Elena, a MAGAP project was developed which consisted of the implementation of double purpose goat herds, incorporating added value (artisanal cheese), after the implementation of the project mentioned in the commune has not been evidenced by the existence of entrepreneurship with caprine milk, therefore it was necessary to know the factors that can encourage entrepreneurship, in order to encourage the transfer of knowledge from the parish of Salinas de Guaranda to the commune. The objective was to design a model that establishes the factors for the transfer of knowledge to the ventures of the Sacachún commune. The research approach that was used was quantitative and qualitative, the type of research was exploratory and descriptive, the design was non-experimental, transversal, the measuring instruments that were applied were the use of surveys, which consisted of the development of multiple-choice closed questions, semi-structured interviewing or non-participatory direct observation. The results of the research were that so far no individual initiatives have been carried out on the basis of caprine milk but did manifest a willingness to carry out associative ventures, so a model of transfer of knowledge about the process of making artisan cheese, from Salinas de Guaranda to the Sacachún commune, which will improve the quality of life of them.\n"}
{"prompt":"La transferencia de conocimientos tecnológicos y su influencia en el proceso de enseñanza aprendizaje de los estudiantes del primer año de bachillerato de la Unidad Educativa Unidad Popular ->","completion":" Based on a systematic analysis of the literature, a proposal for a model of knowledge transfer and technology for universities is presented. The problem posed by the study is about how the economic, social and technological context demands that the institutions link up with the productive sector in order to respond to the needs of society, although in developing countries this relationship has not been consolidated despite the recognized potential. The study, mainly qualitative, allowed knowing the phases of the process and identifying the factors that constitute the proposal of a management model whose viability should be corroborated through research with greater depth and methodological rigor. The transfer of knowledge and technology (TCT, hereafter) in recent years has gained relevance. Some specialists consider it as the main factor to increase innovation in organizations (Davenport and Prusak, 2000), a crucial source of economic, social and transformation of modern society (OECD, 2004). TCT is the result of creating, storing and recovering knowledge to transfer it to organizations in the generation of new products or services, as well as in the improvement of their productive processes (Chang Lee, Lee, and Kang, 2005). However, an important component for this to occur is the link between the sender and the receiver of the transfer. Some scholars point out that universities and some research centers, public or private, are the main drivers of the generation and transfer of knowledge and technology, which has led them to build bridges with the productive sectors to respond together to what society demands. The subsidies received mainly by public universities are insufficient for the development of some substantive activities, and the link is one of the ways to attract these additional resources to support research and other academic activities.A partir de un análisis sistémico de la literatura, se presenta una propuesta de modelo de transferencia de conocimiento y de tecnología para universidades. El problema que plantea el estudio versa sobre cómo el contexto económico, social y tecnológico demanda que las instituciones se vinculen con el sector productivo a fin responder a las necesidades de la sociedad, aunque en los países en vías de desarrollo esta relación no se ha consolidado pese al potencial reconocido. El estudio, preponderantemente cualitativo, permitió conocer las fases del proceso e identificar los factores que constituyen la propuesta de un modelo de gestión cuya viabilidad deberá ser corroborada mediante investigaciones con mayor profundidad y rigor metodológico. La transferencia de conocimiento y tecnología (TCT, en adelante) en los últimos años ha cobrado relevancia. Algunos especialistas la consideran como el factor principal para incrementar la innovación en las organizaciones (Davenport y Prusak, 2000), fuente crucial de desarrollo económico, social y de transformación de la sociedad moderna (OCDE, 2004). La TCT es el resultado de crear, almacenar y recuperar el conocimiento para transferirlo a las organizaciones en la generación de nuevos productos o servicios, así como en la mejora de sus procesos productivos (Chang Lee, Lee, y Kang, 2005). Sin embargo, un componente importante para que esto ocurra es la vinculación entre el emisor y el receptor de la transferencia. Algunos estudiosos destacan que las universidades y algunos centros de investigación, públicos o privados, son de los principales impulsores de la generación y de la transferencia de conocimiento y de tecnología, lo que los ha llevado a tender puentes con los sectores productivos para dar respuesta juntos a aquello que demanda la sociedad. Los subsidios que reciben principalmente las universidades públicas son insuficientes para el desarrollo de algunas actividades sustantivas, y la vinculación es una de las vías propicias para captar esos recursos adicionales para apoyar la investigación y para otras actividades académicas.\n"}
{"prompt":"La gesti?n basada en procesos y su protagonismo en la transferencia del conocimiento. Universidad de Guayaquil . ->","completion":" Currently is vital the role of universities in promoting regional and economic development. Universities accelerate innovation and entrepreneurship through the transfer of knowledge. Since the early eighties of last century, process management has been widely used by universities and organizations employing Systems of Quality Management. This approach shows a systemic vision of the key processes that allow responding to the needs of society. The purpose of this paper is to model the process of knowledge transfer at the University of Guayaquil. This modeling is performed based on a process approach. The main theoretical methods include the analysis and synthesis of information obtained Inductive - deductive and systemic - structural. The empirical methods are related to psychosocial information search tools and process modeling, the study of potential markets for products or services derived from processes of entrepreneurship and innovation in the University.En la actualidad es vital el rol de la universidad en el fomento del desarrollo regional y econ?mico. Las universidades aceleran la innovaci?n y el emprendimiento mediante la transferencia de conocimiento. Desde la d?cada de los a?os ochenta del pasado siglo, la gesti?n por procesos ha sido ampliamente utilizada por universidades y organizaciones que emplean Sistemas de Gesti?n de la Calidad. Este enfoque muestra una visi?n sist?mica de los procesos claves que permiten dar respuestas a las necesidades de la sociedad. Este trabajo tiene como objetivo modelar el proceso de transferencia de conocimiento en la Universidad de Guayaquil. Esta modelaci?n se realiza basada en un enfoque de proceso. Entre los principales m?todos te?ricos empleados se encuentran el an?lisis y s?ntesis de la informaci?n obtenida, Inductivo ? deductivo y el sist?mico ? estructural. Los m?todos emp?ricos est?n relacionados con instrumentos psicosociales de b?squeda de informaci?n y la modelaci?n de procesos, la revisi?n de posibles mercados para productos o servicios derivados de procesos de emprendimiento e innovaci?n de la Universidad.http:\/\/revistauniversidad.edu.ec\/EduQuil\/index.php\/edicion-121\/18210-la-gestion-basada-en-procesos-y-su-protagonismo-en-la-transferencia-del-conocimiento-universidad-de-guayaquil\n"}
{"prompt":"Factores que determinan la transferencia de conocimientos en los estudiantes de la Carrera de Ingenier?a Comercial. ->","completion":" The research is aimed at determining the factors that limit the transfer of knowledge to the students of the Commercial Engineering Degree as a study problem. The objective of the project is to show the influential factors in the transfer of knowledge because it has been observed that there is a greater ignorance of the subject in the students, on the topics taught by the teachers in the class hours, the learning is not significant. To learn more about this problem, a theoretical, technical support was used, together with a thorough and thorough review of bibliographical sources. The methodological approach is quantitative, in the research project was carried out the application of a survey to teachers and students, descriptive research and field methods, and bibliographic are the mechanisms used for the collection of information, with which valuable information was obtained and useful for the benefit of the career, teachers and students, in the same way when tabulating the data it was observed that the scholars have deficiencies in the knowledge transfer factors such as the relationship with the student, affective communication and active learning, being active learning with greater disadvantages from both the perspective of teachers and students, the reasons that led to this consensus is that both parties have clearly identified that the classes should be largely practical and less theoretical, the students who expressed likewise problems with the relationship that exists between teacher and student. All this information contributed with results of the limitations that exist in the race to transfer the knowledge, in the end it concludes with a report in which the affectations that each factor has in the transfer of knowledge on the part of the professors are specified, towards the teachers. Finally, precise recommendations were developed for the corresponding actions on the part of those involved with teaching in higher education of the Commercial Engineering Degree at the Technical University of Cotopaxi.La investigaci?n est? orientada a determinar los factores que limitan la transferencia de conocimiento a los estudiantes de la Carrera de Ingenier?a Comercial como problema de estudio. El objetivo del proyecto es mostrar los factores influyentes en la transferencia del conocimiento porque se ha observado que existe un mayor desconocimiento de la asignatura en los estudiantes, sobre las tem?ticas impartidas por los docentes en las horas clase, el aprendizaje no es significativo. Para conocer m?s a fondo esta problem?tica se recurri? a un sustento te?rico, t?cnico, conjuntamente a una revisi?n profunda y minuciosa de fuentes bibliogr?ficas. El enfoque metodol?gico es cuantitativo, en el proyecto investigativo se realiz? la aplicaci?n de una encuesta a docentes y estudiantes, la investigaci?n descriptiva y los m?todos de campo, y bibliogr?fico son los mecanismos utilizados para la recolecci?n de informaci?n, con la cual se obtuvieron informaci?n valiosa y ?til para el beneficio de la carrera, docentes y estudiantes, del mismo modo al tabular los datos se observ? que los becarios tienen deficiencias en los factores de transferencia del conocimiento como la relaci?n con el estudiante, la comunicaci?n afectiva y el aprendizaje activo, siendo el aprendizaje activo con mayores inconvenientes tanto desde la perspectiva de docentes y estudiantes, los motivos que permitieron llegar a este consenso es que las dos partes tienen claramente identificado que las clases deben ser en gran parte de forma pr?ctica y menos te?ricas, los estudiantes qui?nes manifestaron de igual manera problemas con la relaci?n que existe entre docente y estudiante. Toda esta informaci?n aport? con resultados de los limitantes que existen en la carrera para transferir el conocimiento, al final se concluye con un informe en el cual se especifican las afectaciones que cada factor tiene en la transferencia del conocimiento de parte de los catedr?ticos, hacia los estudiantes. Por ?ltimo se desarrollaron recomendaciones precisas para las acciones correspondientes de parte de los involucrados con la ense?anza en la educaci?n superior de la Carrera de Ingenier?a Comercial de la Universidad T?cnica de Cotopaxi.Universidad T?cnica de Cotopaxi\n"}
{"prompt":"Gestión de ventas y transferencia del conocimiento de marketing digital en pymes Provincia de los Rios año 2021 ->","completion":" pdfLa presente investigación aborda la temática de la aplicación de a transferencia de conocimiento del marketing digital para la gestión de ventas de las pequeñas y medianas empresas. OBJETIVO: El objetivo principal del presente estudio se basa en diseñar la gestión de ventas y transferencia de conocimiento de marketing digital en PYMES, provincia de Los Ríos, año 2021. METODOLOGÍA: Desde el punto de vista metodológico la investigación posee un enfoque mixto, misma que través de un estudio descriptivo se recopila información generalizada acerca de la situación actual de la gestión de PYMES a partir del marketing digital. Tomando como universo a 28,697 pequeñas y medianas empresas de la provincia de Los Ríos y como muestra a 380 de las mismas seleccionadas de manera aleatoria RESULTADOS: De los colaboradores miembros de pequeñas y medianas empresas de la provincia de Los Ríos, se puede identificar que el 100% de las empresas considera que generaría mayores ventas si el producto fuera conocido. CONCLUSIONES: Dentro de las estrategias de transferencias de conocimiento de Marketing Digital para la gestión de ventas PYMES propuestas a través del estudio se encuentran el marketing en redes sociales, email marketing, campañas de engagement y campañas de publicidad pagada. This research addresses the issue of the application of a knowledge transfer of digital marketing for the sales management of small and medium-sized companies. OBJECTIVE: The main objective of this study is based on evaluating the management of sales and knowledge transfer of digital marketing in SMEs, Los Ríos province, year 2021. METHODOLOGY: From the methodological point of view the research has a mixed approach; same that through a descriptive study generalized information is collected about the current situation of SME management from digital marketing. RESULTS: Of the collaborators who are members of small and medium-sized companies in the province of Los Ríos, it can be identified that 100% of the companies consider that they would generate higher sales if the product were known. CONCLUSIONS: Within the Digital Marketing knowledge transfer strategies for SME sales management proposed through the study are social media marketing, email marketing, engagement campaigns and paid advertising campaigns.\n"}
{"prompt":"Gestión de ventas y transferencia del conocimiento de marketing digital en pymes Provincia de los Rios año 2021 ->","completion":" pdfLa presente investigación aborda la temática de la aplicación de a transferencia de conocimiento del marketing digital para la gestión de ventas de las pequeñas y medianas empresas. OBJETIVO: El objetivo principal del presente estudio se basa en diseñar la gestión de ventas y transferencia de conocimiento de marketing digital en PYMES, provincia de Los Ríos, año 2021. METODOLOGÍA: Desde el punto de vista metodológico la investigación posee un enfoque mixto, misma que través de un estudio descriptivo se recopila información generalizada acerca de la situación actual de la gestión de PYMES a partir del marketing digital. Tomando como universo a 28,697 pequeñas y medianas empresas de la provincia de Los Ríos y como muestra a 380 de las mismas seleccionadas de manera aleatoria RESULTADOS: De los colaboradores miembros de pequeñas y medianas empresas de la provincia de Los Ríos, se puede identificar que el 100% de las empresas considera que generaría mayores ventas si el producto fuera conocido. CONCLUSIONES: Dentro de las estrategias de transferencias de conocimiento de Marketing Digital para la gestión de ventas PYMES propuestas a través del estudio se encuentran el marketing en redes sociales, email marketing, campañas de engagement y campañas de publicidad pagada.This research addresses the issue of the application of a knowledge transfer of digital marketing for the sales management of small and medium-sized companies. OBJECTIVE: The main objective of this study is based on evaluating the management of sales and knowledge transfer of digital marketing in SMEs, Los Ríos province, year 2021. METHODOLOGY: From the methodological point of view the research has a mixed approach; same that through a descriptive study generalized information is collected about the current situation of SME management from digital marketing. RESULTS: Of the collaborators who are members of small and medium-sized companies in the province of Los Ríos, it can be identified that 100% of the companies consider that they would generate higher sales if the product were known. CONCLUSIONS: Within the Digital Marketing knowledge transfer strategies for SME sales management proposed through the study are social media marketing, email marketing, engagement campaigns and paid advertising campaigns.\n"}
{"prompt":"Factores que influyen en la transferencia de conocimientos a través de las incubadoras universitarias : dos casos de estudio ->","completion":" La investigación busca identificar las condiciones necesarias a nivel macro, meso y micro para que las incubadoras representen una política viable de transferencia de conocimientos e indagar cómo influye este canal sobre la calidad de la investigación universitaria. Mediante una revisión de la literatura concerniente a la transferencia de conocimientos y el papel de las universidades en la economía del conocimiento, los trabajos sobre configuración y factores de éxito de las incubadoras, la importancia de las redes institucionales de apoyo, y las características de los emprendedores; se identifican cuatro grupos de factores interrelacionados que afectan la transferencia de conocimientos para la conformación de nuevas empresas de base científica.Capítulo 1 Tema, problema y preguntas de investigación. -- Capítulo 2 Factores que influyen en la transferencia de conocimientos a través de las incubadoras universitarias. -- Capítulo 3 La Transferencia de Conocimientos Mediada por la Incubadora de Negocios del Sur de Tamaulipas (INEST). -- Capítulo 4 La Transferencia de Conocimientos Mediada por la Incubadora de Negocios del ITESM campus Monterrey\n"}
{"prompt":"Análisis de la generación y transferencia de conocimiento en emprendimientos del sector tecnológico en la ciudad de Loja, año 2017 ->","completion":" El objetivo del presente estudio es analizar la generación y transferencia de conocimientos en los emprendimientos del sector tecnológico con la finalidad de determinar si las organizaciones están aprovechando al máximo los recursos estratégicos que poseen, sus competencias internas y ventajas competitivas. En el desarrollo de la investigación se describen aspectos generales como la importancia de la administración de conocimiento en el desarrollo de ventajas competitivas, la generación de conocimientos y transferencia de conocimiento. La aplicación del modelo SECI, mediante sus constructos permite determinar la generación y transferencia de conocimientos si se está aplicando en los emprendimientos del sector tecnológico, se pudo determinar que los emprendimientos del sector no están realizando estos procesos eficientemente, ya que solo realizan algunos procesos, les falta algunos que deben cumplir para aprovechar al máximo los recursos que poseen. Además en el análisis individual de cada emprendimiento se efectúa algunas sugerencias que deberían tomar en cuenta para que sean competitivas.The objective of the present study is to analyze the generation and transfer of knowledge in technological sector enterprises in order to determine if organizations are taking full advantage of the strategic resources they possess, their internal competencies and competitive advantages. The development of the research describes general aspects such as the importance of knowledge management in the development of competitive advantages, the generation of knowledge and transfer of knowledge. The application of the SECI model, through its constructs allows to determine the generation and transfer of knowledge if it is being applied in the enterprises of the technological sector, it was possible to determine that the enterprises of the sector are not performing these processes efficiently, since they only perform some processes, they lack some that they must fulfill in order to take full advantage of the resources they possess. Further in the individual analysis of each undertaking some suggestions are made that should be taken into account to be competitive\n"}
{"prompt":"Diagnóstico de la Transferencia de Conocimiento Arquitectónicos en Obras Sociales Comunitarias Trabajadas por los Estudiantes de la Facultad de Arquitectura y Urbanismo de la Universidad ->","completion":" El problema del presente trabajo de grado se basa en que los estudiantes de la Facultad de Arquitectura de la Universidad de Guayaquil no vinculan los conocimientos arquitectónicos adquiridos en las aulas de clase con proyectos sociales para las comunidades siendo de gran importancia para la colectividad educativa si se resuelve el problema. Para esto se proyecta la participación de los estudiantes en proyectos comunitarios y su vinculación en el proceso de enseñanza aprendizaje, se plantea existencia y vigencia de pasantías tanto para estudiantes como a docentes, convenios que permitan el intercambio de recursos humanos. La interacción de los factores socio culturales y el desarrollo cognitivo facilita que los estudiantes de la Facultad de Arquitectura compartan proyectos únicos para las construcciones de obras sociales puesto que constituyen la clave en la explicación de la educación y la inserción en la sociedad, hallándose en la manifestación del paradigma del constructivismo. Los estudiantes de la Facultad de Arquitectura al desarrollar sus conocimientos deben poder identificar las necesidades de las comunidades del contexto rural y urbano y por ende transferir sus conocimientos a obras sociales en beneficio de la comunidad, producto de la combinación de la teoría y práctica. Sin embargo es necesario determinar si el diseño macrocurricular responde a la demanda actual del mercado, si no lo hace es necesario proponer una guía para la aplicación efectiva de los aprendizajes. En la metodología la investigación será descriptiva, se aplicarán encuestas, observación y focus group como instrumentos, a una población de cuatrocientos setenta estudiantes y la muestra obtendremos el error de margen. La modalidad de grado será de intervención según Yépez.The problem of the present work is based on undergraduate students from the Faculty of Architecture of the University of Guayaquil not binding architectural knowledge acquired in the classroom with social projects for communities is of great importance for the educational community if that solves the problem. For this project the student participation in community projects and his involvement in the teaching-learning process, there is existence and validity of internships for students and teachers, agreements for the exchange of human resources. The interaction of sociocultural factors and cognitive development allows students of the Faculty of Architecture share unique projects for the construction of social work since they are the key in explaining education and integration into society, being in the manifestation of the paradigm of constructivism. Students the Faculty of Architecture to develop their knowledge should be able to identify the needs of rural communities and urban context and thus transfer their knowledge to social work for the benefit of the community, due to the combination of theory and practice. However it is necessary to determine if the design meets the demand macrocurricular current market, if you do not need to propose a guidance for the effective implementation of learning. In the method the descriptive research will be applied surveys, observation, and focus groups as instruments, to a population of four hundred seventy students and shows get the error margin. The type of degree will be according Yepez intervention.\n"}
{"prompt":"Estructura organizacional y relaciones en el entorno socioeconómico de la Universidad Laica “Eloy Alfaro” de Manabí y Escuela Superior Politécnica Agropecuaria de Manabí “Manuel Félix López” para la transferencia de conocimientos científico-tecnológicos ->","completion":" In the present investigation, with the objective of carrying out a comparative study between the ULEAM universities and the ESPAM MFL within the organizational structure and relations with the socioeconomic environment for the transfer of scientific-technological knowledge, we proceeded from scientific and legal theories that gave credibility to the research. In this way, when diagnosing the organizational structure of educational institutions with respect to the transfer of scientific-technological knowledge to the socioeconomic environment, it was established that it has a mission, vision and organic structure of the departments and obligations that each institution has, which are located in different areas due to their hard work inside and outside the institution since they require their own space to optimally perform their functions. Subsequently, techniques such as a survey of the teachers of the institutions were used with the aim of knowing how the transfer of knowledge is carried out in the universities and their relationship with the environment. The results revealed the participation of the aforementioned universities in linked projects in recent years; subsequently, the number and type of companies benefited by the field of action of knowledge transfers in the executed projects were determined, where it was shown that ESPAM MFL has had agreements with 6 companies and ULEAM with 8 companies in the last 2 years.En la presente investigación con el objetivo de realizar un estudio comparativo entre las universidades ULEAM y la ESPAM MFL dentro de la estructura organizacional y relaciones con el entorno socioeconómico para la transferencia de conocimientos científico-tecnológicos, se procedió a partir de teorías científicas y legales que le dieron un sustento de credibilidad a la investigación. De esta forma al diagnosticar la estructura organizacional de las instituciones educativas con respecto de la transferencia de conocimientos científico-tecnológicos hacia el entorno socioeconómico, se logró establecer que cuenta con una misión, visión y estructura orgánica de los departamentos y obligaciones que tiene cada institución, las cuales están ubicadas en áreas distintas debido a su arduo trabajo dentro y fuera de la institución puesto que requieren de su propio espacio para desempeñar de manera óptima sus funciones. Posteriormente se utilizaron técnicas como encuesta a los docentes de las instituciones con el objetivo de conocer de qué manera se realiza la transferencia de conocimientos en las universidades y relación con el entorno. Los resultados dieron a conocer la participación de las mencionadas universidades al participar en proyectos de vinculación en los últimos años; posteriormente se determinó el número y tipo de empresas beneficiadas por el campo de acción de las transferencias de conocimientos en los proyectos ejecutados donde se determinó que la ESPAM MFL ha tenido convenios con 6 empresas y ULEAM con 8 empresas los últimos 2 años.\n"}
{"prompt":"Determinar la incidencia del género como influencia en las actividades socieconómicas laborarbles de la comunidad que permitan el desarrollo de un emprendimiento focalizado en la Isla Tinitaria en la Ciudad de Guayaquil ->","completion":" Esta investigación tiene un enfoque en el área social en el que se buscaba DETERMINAR LA INCIDENCIA DEL GÉNERO COMO INFLUENCIA EN LAS ACTIVIDADES SOCIOECONÓMICAS LABORABLES DE LA COMUNIDAD QUE PERMITAN EL DESARROLLO DE UN EMPRENDIMIENTO FOCALIZADO EN LA ISLA TRINITARIA EN LA CIUDAD DE GUAYAQUIL, por medio de este análisis se desarrolló una propuesta para la creación de un centro de capacitación que ayude a mujeres con niños pequeños a desarrollar su propio emprendimiento desde sus hogares. Esta propuesta está basada en los conocimientos adquiridos durante la etapa universitaria para la creación de nuevos negocios. La propuesta fue planteada para satisfacer las necesidades que se obtuvieron de la encuesta realizada. Ofrecer un servicio diferente es la prioridad de este centro de capacitación que los hijos de las emprendedoras tengan un espacio dentro del centro donde estén cuidados mientras sus madres aprenden un oficio para desarrollar un emprendimiento en sus hogares sin descuidar a su familia y para mejorar su situación económica.This research has a focus on the social area in which it was searched to DETERMINE THE INCIDENCE OF GENDER AS AN INFLUENCE ON THE SOCIOECONOMIC LABORABLE ACTIVITIES OF THE COMMUNITY THAT ENABLE THE DEVELOPMENT OF A FOCUSED ENTREPRENEURSHIP IN THE ISLA TRINITARAIA IN THE CITY OF GUAYAQUIL, by means of this analysis developed a proposal for the creation of a training center that helps women with young children to develop their own enterprise from their homes. This proposal is based on the knowledge acquired during the university stage for the creation of new businesses. The proposal was raised to meet the needs that were obtained from the survey. Offering a different service is the priority of this training center so that the children of the entrepreneurs have a space inside the center where they are cared for while their mothers learn a trade to develop a new bussiness in their homes without neglecting their family and to improve their situation economic.\n"}
{"prompt":"Compresión de datos con Algoritmo de Huffman para transmisión de datos mediante Li-Fi utilizando hardware libre. ->","completion":" In recent years, communication through visible light has become one of the most important developments in telecommunications, as it will allow significant improvements in terms of the speed at which information is transmitted and its security. Considering this, the present project focuses on the construction of a unidirectional Li-Fi communication prototype which, together with the implementation of the Huffman coding algorithm, allows to reduce the total size of the data to be transmitted to be reduced and also the use of the spectrum within the communication link, thus increasing the alternatives that allow optimizing the use of the communication channel. It is also presented a comparative analysis between Arduino and Raspberry Pi as well as the software available for each one, which allow us to obtain the best results and above all, that are economically accessible. Finally, the different tests performed regarding speed parameters and communication spectrum utilization are shown, as well as their respective analysis within two scenarios, the first one without implementing the Huffman coding algorithm and the second scenario making use of said coding ; for such tests the use of the Agilent oscilloscope has been made.La comunicación mediante la luz visible se ha convertido en los últimos años en uno de los avances más importantes dentro de las telecomunicaciones, pues permitirá alcanzar mejoras significativas con respecto a la velocidad en la que se transmite la información y su seguridad. Teniendo en cuenta esto, el presente proyecto se centra en la construcción de un prototipo de comunicación Li-Fi unidireccional que junto con la implementación del algoritmo de codificación de Huffman, permita disminuir el tamaño total de los datos a transmitir y la utilización del espectro dentro del enlace de comunicación, aumentando así, las alternativas que permitan optimizar el uso del canal de comunicación. Se presenta también un análisis comparativo entre Arduino y Raspberry Pi así como el software disponible para cada uno de estos, los cuales permitan obtener los mejores resultados y sobre todo, que sean accesibles económicamente. Finalmente, se muestran las distintas pruebas realizadas con respecto a parámetros de velocidad y utilización del espectro de comunicación, así como sus respectivos análisis dentro de dos escenarios, el primero sin implementar la codificación Huffman y, el segundo escenario haciendo uso de dicha codificación; para tales pruebas se ha hecho uso del osciloscopio Agilent.\n"}
{"prompt":"Modelo de compresión de imágenes de extensión JPEG mediante Matlab para el mejoramiento de la transmisión de datos ->","completion":" El presente trabajo investigativo que se detalla a continuación, corresponde al estudio sobre la compresión de imágenes de extensión .jpeg y como este proceso reduce los recursos esenciales para su almacenaje y mejoramiento de su transmisión. Este informe cubre ciertos aspectos del análisis compresión de datos, profundizando acerca la Transformada Discreta Wavelet (DWT) y cómo ésta se puede utilizar para la compresión de imágenes de extensión .jpeg. Su utiliza la herramienta Guide de Matlab para la elaboración de una aplicación que cumple el proceso de compresión – descompresión de las imágenes de extensión .jpeg, a más de incluir en este proyecto un manual de usuario para su fácil manipulación, permitiendo la visualización de las imágenes obtenidas durante el proceso. En la aplicación también se visualizan los datos obtenidos que sirven para el análisis de compresión de las imágenes. Con el uso del software libre llamado HFS (HTTP File Server) versión 2.2f, se crea un servidor gratuito que permite subir y descargar archivos y es muy útil para analizar la transmisión de las imágenes originales con sus respectivas imágenes comprimidas y descomprimidas. Por último, se realizan las conclusiones y recomendaciones luego de finalizar el desarrollo del proyecto y haber realizado pruebas para la comprobación del funcionamiento de la aplicación realizada.\n"}
{"prompt":"Estudio y análisis de la compresión de datos de almacenamiento de información, diseño e implementación del código de Huffman adaptativo. ->","completion":" Este proyecto que se realiza en este trabajo, tiene por objetivo el de implementar un sistema que realice la compresión y descompresión de información. Para esto va a ser muy útil el empleo del paquete MATLAB, el mismo que se define como un Laboratorio Matricial. Con la ayuda del paquete MATLAB, se desarrollaran las funciones que permitan realizar la compresión y descompresión de la información a través de la implementación del Código Huffman Adaptativo, las mismas que constituyen los programas para la aplicación. Para el desarrollo del presente proyecto se elaboraron los siguientes capítulos: En el capítulo I, se realiza un análisis de la teoría de la información y una introducción a la medida de la misma, dando conceptos básicos que forman la base para los procesos aleatorios. En el capítulo II, se presenta un estudio de la generación de la información, analizando las fuentes generadoras de símbolos con sus respectivas probabilidad de ocurrencia y términos empleados por las mismos.\n"}
{"prompt":"Análisis y estudio de las técnicas de compresión de datos para la integración de la tecnología PDH\/SDH sobre redes ethernet e implementación de un algoritmo de compresión mediante software de simulación ->","completion":" El presente Proyecto de Grado, titulado: Análisis y estudio de las técnicas de compresión de datos para la integración de la tecnología PDH\/SDH sobre redes Ethernet e implementación de un algoritmo de compresión mediante software de simulación, comprende un estudio investigativo de las características, ventajas y desventajas de las técnicas de compresión de datos, comprende también de la implementación de un algoritmo de compresión que demuestre mediante un software de simulación dichas ventajas o desventajas. Las comunicaciones son una herramienta importante en el diario convivir de los seres vivos y esto se evidencia claramente desde tiempos remotos hasta nuestros días. Desde el inicio se ha evidenciado grandes desarrollos en las telecomunicaciones y cada vez existe una mayor exigencia para mejorar las condiciones de esta, es por eso que día a día se están desarrollando nuevas tecnologías que ayuden a satisfacer las necesidades de comunicación del ser humano de una manera eficiente e integradora. En estos momentos, donde la tecnología avanza a pasos acelerados es imprescindible disponer de redes que puedan soportar altas velocidades y de esta manera brindar servicios de calidad para la satisfacción del cliente. Por consiguiente, en este proyecto se realizará un estudio de las redes de transporte PDH y SDH, estas últimas se encuentran constituidas principalmente por fibra óptica, es por ello su alta velocidad y gran confiabilidad, seguidamente se estudiará la tecnología Ethernet y la tendencia que se está viviendo actualmente por llegar a obtener una convergencia de redes y servicios; se analizará las diferentes técnicas de compresión de datos para finalmente aplicar un algoritmo de compresión mediante una aplicación de software de simulación que complemente este tema de estudio. Se espera alcanzar a cubrir todas las expectativas que se puedan presentar acerca de las redes de transporte PDH, SDH y la interacción con la tecnología Ethernet, se analizará los elementos y topologías que se utilizarán en la implementación de la misma, para posteriormente realizar el estudio más detallado de de la formación de las tramas básicas PDH y SDH, E1 y STM-1 respectivamente y cada una de las etapas de multiplexación, tanto en PDH como en SDH.\n"}
{"prompt":"Analisis de Comparación de Rendimiento del Algoritmo de Douglas-Peucker con la Incorporación del Filtro de Kalman ->","completion":" ADOBEEl presente trabajo hace una propuesta para un mejor rendimiento en los datos, simplificando líneas de trayectorias vehiculares, el algoritmo de simplificación de línea de Douglas-Peucker es reconocido por ser el algoritmo que ofrece mejor representaciones perceptivas de las líneas originales, utiliza tanto gráficos informáticos como geográficos. Para el filtro de DP existe dos variantes, el método (nm) original, donde denota n el número de vértices de entrada y m el número de segmentos de salida, que funciona en cualquier dimensión. El filtro de Kalman recopila datos donde realiza dos pasos que es la predicción y la actualización.The present work a proposal has been made for a better performance in the data, simplifying lines of vehicular trajectories, the Douglas-Peucker line simplification algorithm is recognized for offering better visual representations of the original lines, as geographic. For the DP filter there are two variants, the original (nm) method, denoting the number of input vertices and the number of output segments, which works in any dimension. The Kalman Filter that collects the data where it performs the steps that is the prediction and the update.\n"}
{"prompt":"Guía multimedia para el estudiante de pregrado - caso de aplicación base de datos 1. ->","completion":" La animación digital es la técnica de crear una ilusión de movimiento al visualizar una sucesión de imágenes fijas generadas por computador. (1) Para crear la ilusión del movimiento, una imagen se muestra en pantalla sustituyéndose rápidamente por una nueva imagen en un fotograma diferente...\n"}
{"prompt":"Comprensión de datos de medición inteligente para optimización del sistema de comunicación inalámbrica ->","completion":" This paper presents a proposal to show the relationship between a smart metering with mass communication media. The first one is the measurement system of the electric power, through a database, which represents the residential electrical consumption, this content has a big amount of data and its advantage is to transmit by means of the wireless communication without any drawbacks, the technique applied to this system is the use of a mathematical tool, that displays some special features of how to perform analysis in time and frequency, plus translations and dilations parent function from among others. When handling a large amount of information certain drawbacks such as sending all the data for a given environment is presented, there are also problems of storage and collection of such information. This tool is known like Wavelet and it allows to compress information into big volumes since its structure gives a selection of parameters, which would be taken into consideration in the structure, and those that are below the threshold and those that are not mentioned in the parameters, will be set to zero. There is a requirement for this, and it is to convert the compressed signal to a signal that maintains its authenticity and not to differ from the original signal. The resulting value of the compression is a wave that will be affected in translation and scale, later must decompress the signal, so that information back to their original dataEn este trabajo se presenta una propuesta que relacione, la medición inteligente con un medio de comunicación, el primero es el sistema de medición de la energía eléctrica, a través de una base de Datos, que representa el consumo eléctrico residencial, este contenido tiene una cantidad grande de datos y su ventaja es transmitir mediante la comunicación inalámbrica sin que exista Inconvenientes, la técnica aplicada para este sistema es el uso de una herramienta matemática, que presenta ciertas características especiales de cómo realizar análisis en tiempo y frecuencia, además de traslaciones y dilataciones a partir función madre entre otras. Al manejar una gran cantidad de información se presenta ciertos inconvenientes por ejemplo enviar todos los datos por un determinado medio, también existe problemas de almacenamiento y recopilación de esa información. Esta herramienta es conocida como Wavelet y permite comprimir información de grandes volúmenes ya que su estructura, permite la selección de ciertos valores, dentro de un rango, que estarían tomados en cuenta y aquellos que estén por debajo del umbral y aquellos que no estén en el rango mencionado, serán puestos a cero. Existe un condicionamiento para este requerimiento y es recuperar la señal que está compresa, a una señal que mantenga su fidelidad y no difiera de la original. Los valores resultantes de la compresión forman una onda que estará afectada en traslación y escala, posteriormente se debe descomprimir la señal, para que la información vuelva a sus datos originales\n"}
{"prompt":"Comparación entre compresión de audio en diferentes formatos de imágenes equivalentes y el formato de compresión mp3 ->","completion":" El presente reporte muestra una comparación entre el ya conocido formato de compresión MP3 y la novedosa técnica de compresión de audio en diferentes formatos de imágenes equivalentes. Mediante un algoritmo, cuyo código ha sido desarrollado por los autores de este reporte, se explica cómo implementar la técnica de convertir archivos de audio en imágenes equivalentes, para luego ser comprimidas en tres formatos de imágenes como lo son JPG, PNG y TIF. También se explica el método de recuperación del audio equivalente al original a partir de las imágenes obtenidas. La reducción significativa en el tamaño de un archivo de audio usando esta nueva técnica de compresión, es decir la cantidad de bytes que el archivo ocupa en memoria, determinará una ventaja que se traduce en una mayor capacidad de almacenamiento. Se podrá obtener una compresión incluso mayor que la que ofrece el formato MP3 y un audio recuperado de tan buena calidad que será casi imperceptible los datos que se pierden del archivo original de audio, tal como sucede con MP3. Se ha utilizado el software Matlab para desarrollar la técnica de compresión de audio en imágenes equivalentes y otro software libre llamado Format Factory para la compresión de audio en el formato MP3. En Matlab se utiliza como parte de la técnica la transformada rápida de Fourier fft, los tres tipos propuestos de formatos de compresión de imágenes, la transformada de Wavelet aplicada para la reducción de ruido blanco y los diferentes procesos digitales para audio e imágenes con el uso de los comandos que ofrece este software.\n"}
{"prompt":"Recuperación y puesta a punto del equipo de compresión de aire de dos etapas gilbert gilkes del laboratorio de conversión de energía ->","completion":" El presente proyecto tiene como objetivo realizar la recuperación y puesta a punto del equipo de compresión de doble etapa del laboratorio de conversión de energía perteneciente a la Universidad de las Fuerzas Armadas ESPE, para lo cual se contrasto toda la documentación e información existente del equipo. Una vez establecido el estado inicial físico de la unidad de aire y las condiciones de operación, así como la funcionalidad de los instrumentos propios de la máquina, se implementó una metodología que permita realizar una puesta a punto en su funcionamiento, mediante un mantenimiento correctivo y preventivo donde se realizó el cambio, mejoramiento y reemplazo de componentes así como la instalación de un sistema de apoyo de monitoreo de datos para una mejor y rápida apreciación de variables que intervienen dentro del proceso de compresión. Además, se implementó una rehabilitación del graficador de accionamiento mecánico del compresor de doble etapa el cual hizo posible establecer longitudes de carrera dentro del diagrama, así como áreas del ciclo real de compresión, por otro lado, se realizó la actualización de la guía de prácticas del banco de pruebas LT-15-E Gilbert Gilkes en función de los parámetros que se aprecian después de la recuperación y puesta a punto. Finalmente, a partir de un análisis comparativo mediante el uso de gráficas entre los parámetros dependientes como eficiencia, trabajo, rendimiento, índice politrópico, etc, y con la gráfica de presión volumen obtenidas de cada etapa del sistema de compresión con y sin intercambiador de calor se determina como influye y beneficia en cuanto a la generación trabajo y presión de descarga del equipo.\n"}
{"prompt":"Implementación de un sistema de compresión, transmisión y recepción de datos utilizando dispositivos de radio definido por software (USRP) para evaluar el rendimiento de los radio enlaces usados en medición eléctrica inteligente ->","completion":" El presente proyecto describe la implementación de un sistema transmisor - receptor para el envío de datos de la lectura del consumo eléctrico generados por medición inteligente, con la finalidad de analizar la cobertura, capacidad y atenuación de los radio enlaces utilizados para transferir datos confiables y disponibles. Para llevar a cabo este proyecto se trabajó con LabView permitiendo comparar y comprender el comportamiento de la recepción de información de los radio enlaces al transmitir datos aprovechables por medio de los VIs (Instrumentación Virtual) top Tx y top Rx que ofrece National Instrument. Los niveles de potencia captados por el medidor inteligente son almacenados como datos, utilizados para definir el comportamiento de la curva de carga con respecto al tiempo. Empleando algoritmos matemáticos, mediante la transformada de wavelet se obtiene la recuperación de datos con la que se realiza la curva respecto al tiempo. Se visualizan los datos enviados en QPSK, en el diagrama de constelación. Para el funcionamiento del sistema se utilizan antenas VERT 450 que trabajan en rangos de frecuencias de 1.71 - 2.2 GHz, estas se conectan a los equipos USRP de National Instruments y estos a su vez en comunicación ethernet con dos computadoras. Tomando en cuenta según el fabricante estos equipos trabajan a su mejor rendimiento con temperaturas inferiores a los 24°C, este proyecto se lo realizó en un ambiente con temperatura de 20°C.This project describes the implementation of a transmitter - receiver system to send data from the reading of electricity consumption generated by smart metering, in order to analyze the coverage, capacity and attenuation of the radio links used to transfer reliable and available data. . To carry out this project, we worked with LabView allowing us to compare and understand the behavior of the reception of information from radio links when transmitting usable data through the VIs (Virtual Instrumentation) top Tx and top Rx that National Instrument offers. The power levels captured by the smart meter are stored as data, used to define the behavior of the load curve with respect to time. Using mathematical algorithms, by means of the wavelet transform the data recovery is obtained with which the curve is made with respect to time. The data sent in QPSK is displayed on the constellation diagram. For the operation of the system, VERT 450 antennas are used that work in frequency ranges of 1.71 - 2.2 GHz, these are connected to the USRP equipment of National Instruments and these in turn in ethernet communication with two computers. Taking into account, according to the manufacturer, these teams work at their best performance with temperatures below 24 ° C, this project was carried out in an environment with a temperature of 20 ° C.\n"}
{"prompt":"Correlaciones múltiples entre propiedades geomecánicas, velocidades de onda de compresión (VP), corte (VS) y datos de clasificación SUCS en el suelo de cimentación del bloque G de la Universidad Politécnica Salesiana Sede Quito - Campus Sur ->","completion":" La presente investigación, tiene como objetivo desarrollar correlaciones múltiples entre las propiedades geomecánicas (Cohesión c, Ángulo de Fricción φ, Módulo de Elasticidad 50), número de golpes , en función de la Clasificación SUCS y datos obtenidos en ensayos Geofísicos; los cuales ayudarán a reducir la cantidad de ensayos a ejecutarse, traduciéndose en costos y tiempos de ejecución de los estudios geotécnicos, en áreas de estudio extensas. Una vez definida la zona de estudio, se realizaron ensayos de campo como Sísmica de Refracción, MASW & MAM, para obtener las velocidades de onda de compresión y corte, posteriormente se ejecutó una perforación mediante el ensayo SPT, donde se obtuvo el número de golpes, muestras alteradas e inalteradas para el desarrollo de los ensayos de laboratorio (Clasificación SUCS y Corte Directo) para obtener las propiedades geomecánicas antes mencionadas. Para el análisis de varianzas (ANOVA), se complementó la base de datos con resultados obtenidos del estudio de suelos del Bloque G y de las estaciones cercanas de la Empresa Pública Metropolitana Metro de Quito para determinar las variables estadísticamente representativas que intervienen en la regresión lineal múltiple, posteriormente se sometieron a un análisis de supuestos de residuos y niveles de confianza para obtener las ecuaciones con un coeficiente de correlación adecuado.The current research is developed using multiples correlations between geomechanical properties (Cohesion c, Friction angle φ, Elastic Modulus) and number of blows according to the SUCS Classification and data obtained in Geophysical tests; which will help to reduce the number of tests to be performed, resulting in costs and execution times of geotechnical studies in large study areas. Once the study area was defined field tests were done such as, Seismic Refraction, MASW & MAM, to get the compression and shear wave velocities, next a drilling was made using the SPT test where the number of blows was measured, altered and unaltered samples were obtained, for the development of laboratory tests (SUCS Classification and Direct Shear) to obtain the geomechanical properties mentioned before. For the analysis of variances (ANOVA), the database was added to the results obtained from the soil study at Block G and the nearby stations of the Metropolitan Public Company Metro de Quito, to determine the statistically representative variables which are involved in the multiple linear regression, which were then subjected to an analysis of residual assumptions and confidence levels to obtain the equations with an adequate correlation coefficient.\n"}
{"prompt":"“Compresión Medular a Nivel de C3, C4” ->","completion":" Lesión medular es aquella afectación de la médula espinal que se da “a consecuencia de un traumatismo, enfermedad o degeneración. Según la OMS no existe datos fiables de su prevalencia pero se calcula que su incidencia mundial anual oscila entre 40 y 80 casos por millón de habitantes”2, los accidentes de tránsito son la principal causa de trauma en la médula espinal y representa el 50% de todas las muertes ocasionadas por los mismos, afecta más a hombres y están relacionados con el consumo de alcohol. El objetivo general es: Analizar el proceso de evolución del paciente con diagnóstico de Compresión Medular a nivel de C3, C4. La información recolectada de los datos de la Historia Clínica del Paciente, fueron obtenidos bajo autorización previa del Departamento médico, en el Hospital IEES Ambato. Paciente que ingresa por el Servicio de Emergencia con antecedente de accidente de tránsito el cual ocasiona “Contusión Medular desde C3-C4 hasta C5-C6 mas Hematoma Agudo Prevertebral Anterior”, se le realizó una Hemilaminectomía descompresiva de C3, C4, permaneció 20 días en Hospitalización recibiendo tratamiento médico; paciente es remitido a Fisioterapia con diagnóstico de Paraplejía y Cuadriplejia no especificada para tratamiento diario y permanente. De acuerdo a los datos recolectados encontramos como factores de riesgo principales al sexo masculino, y edad del paciente, el consumo de alcohol e imprudencia del conductor así como también el manejo prehospitalario que fue llevado a cabo. La Terapia Acuática de Bad-Ragaz es una excelente alternativa de tratamiento para la recuperación del paciente, la finalidad de esta técnica es ganar la mayor independencia del paciente dentro del medio acuático mejorándose así la condición física fuera del mismo.\n"}
{"prompt":"Refrigeración mecánica por compresión para lanchas de pesca artesanal. ->","completion":" Este documento contiene archivo en PDF.Este estudio tiene como objetivo presentar una alternativa de refrigeración al método utilizado para enfriar la pesca en lanchas en el sector artesanal, actualmente la pesca es enfriada con hielo, éste método precario genera peso extra a la embarcación, limita el tiempo de permanencia en las faenas, la temperatura de enfriamiento siempre tiende a subir, reduce el espacio de almacenamiento además del necesario desembolso de dinero en cada zarpe sin tener la certeza que la pesca va a ser exitosa. Con la aplicación de un sistema de refrigeración mecánica por compresión se podrá enfriar el agua de mar para ser utilizada como medio de enfriamiento de la pesca y así reemplazar la utilización del hielo. Siendo la refrigeración la que detiene la acción destructiva bacteriana, esta se torna indispensable en este tipo de actividad, para poder mantener un alimento seguro, de buena apariencia comercial y calidad nutricional, la implementación del sistema garantiza mantener la temperatura ideal de la pesca durante todo el tiempo que dure la faena hasta llegar a puerto, se reduce el consumo de combustible al reducir el peso en la embarcación, se evita mayor desgaste del motor además de tener mayor autonomía en alta mar. La aplicación de este proyecto es para las embarcaciones de 1 a 4 toneladas brutas, las mismas que son alrededor de 9.000, según datos de la Federación Nacional de Cooperativas de Pesca del Ecuador (Fenacopec).This study has as main purpose to expose a cooling alternative for the method used to cool the fish in the vessels of the artisanal sector, nowadays fishing is cooled with ice, this precarious method generates an extra weight to the fishing vessel, limits the time spent in the fishing labor, the cooling temperature is always tending to increase, reduces the storage space as well as the necessary inversion of money for every trip without knowing if the fishing results will be successful. With the application of mechanical refrigeration by a compression system, the sea water can be cooled so it can be used as a cooling mechanism for fishing and so then replace the use of ice. Being the refrigeration the mechanism that stops the bacterial destructive action, it becomes indispensable in this kind of activity, so the food can be kept safe, with good commercial appearance and nutritional quality, the system implementation guarantees to maintain the fish’s ideal temperature during the whole fishing labor to the port arrival, it reduces the fuel consumption by reducing the fishing vessel’s weight, prevents the motor’s impairment besides having autonomy in high seas. The applicability of this project is for vessels with 1 to 4 gross tons of weight which are about 9.000 according to the data base of the “National Federation of fishing union of Ecuador” (Fenacopec for its meaning in Spanish)\n"}
{"prompt":"Análisis y modelado del comportamiento de los datos obtenidos de resistencia a la compresión por la introducción de un aditivo de 25 % de limolita y curado en aire en el cemento tipo I ->","completion":" Investigación realizada para conocer experimentalmente y por medio de un modelo matemático el cambio en la propiedad mecánica de la resistencia a la compresión del cemento, por medio de la adición de un aditivo puzolánico como la limolita en un 25%, con un tratamiento específico de curado, para varios días distintos.GuayaquilIngeniero Mecánico\n"}
{"prompt":"Análisis y modelado del comportamiento de los datos obtenidos de resistencia a la compresión por la introducción de un aditivo de 25 % de limolita y curado en aire en el cemento tipo i ->","completion":" El topico de graduacion \"Simulacion del comportamiento de materiales\" pretendio conocer, experimentalmente y por medio de un modelo matematico el cambio en la propiedad mecanica de la resistencia a la compresion del cemento, por niedio de la adicion de un aditivo puzolanico como la Limolita en un 25%, con un tratamiento especifico de curado, para varios dias distintos. Se hara uso de la literatura tecnica existente para determinar 10s antecedentes del problema planteado. En la actualidad no existe un material alternativo que pueda ser utilizado como material de bajo costo en construcciones de gran volumen, que pueda resolver algunos de estos problemas y que ademas pueda mejorar las propiedades tecnologicas de construccion del hormigon. Analizar el efecto que tiene la introduccion de un material puzolanico como la Limolita y el tiempo de curado en la resistencia a la compresion del material compuesto como el cemento mediante el modelo teoricn y el analisis estadistico. Con 10s diferentes ensayos de laboratorio vamos a obtener ciertos resultados que seran analizados estadisticamente y modelados con el fin de observar y analizar si ha mejorado la resistencia uniaxial a la compresion, de un material compuesto como el cemento de manera significativa con respecto al cemento Tipo I de referencia. Para dicho efecto se utilizara una adicion de 25% de Limolita.\n"}
{"prompt":"Evaluación de algoritmos de compresión de audio para su transmisión en tiempo real utilizando redes Zigbee ->","completion":" La investigación de evaluación de algoritmos de compresión de audio para su transmisión en tiempo real usando redes ZigBee se realizó en la Escuela de Ingeniería en Electrónica Telecomunicaciones y Redes de la Escuela Superior Politécnica de Chimborazo. El objetivo es analizar la tecnología ZigBee, ventajas, características y aplicaciones, conocer los diferentes algorítmos de compresión de audio, características principales y también desarrollar un prototipo que permita transmitir audio. El método de investigación deductivo permitió comprender aspectos generales que intervienen para transmitir audio en ZigBee como frecuencias operativas, capacidad de transmisión y topologías de red. El método inductivo permitió observar parámetros específicos que pueden determinar mejor transmisión de audio entre ellos los diferentes algorítmos de compresión, finalmente el método analítico permitió analizar valores para determinar el algoritmo más eficiente estos parámetros fueron frecuencia global, Espectro de Frecuencia Audible, Potencia RMS y una encuesta. La implementación del sistema se realizó mediante software como Proteus8, X-CTU y AVR Studio, para realizar mediciones de audio Adobe Audition 3.0, hardware como ATmega84, Módulos Xbee y Vs1063. El algoritmo ADPCM obtuvo mejores medidas en comparación al resto, comprobándolo con la técnica de ponderación y obteniendo los siguientes datos: frecuencia global 228.59Hz, Espectro de Frecuencia Audible 2000Hz, Potencia RMS -11,78dB y 71% en resultados por encuesta. Se concluye que usar redes ZigBee para transmitir audio es posible y ADPCM es el algoritmo más eficiente. Se recomienda usarlo en aplicaciones de audio como domótica, vigilancia, donde se puede aprovechar el bajo costo, consumo energético y alcance de dispositivos.\n"}
{"prompt":"Optimización de las técnicas estándares de compresión para imágenes, sonidos y videos ->","completion":" Proceso de reducción del volumen de datos necesario para poder representar una determinada información. Aclarando que los datos son el medio a través del cual se conduce la información. CLASIFICACIONSin Pérdida (Recuperación exacta) - CODIFICACIONES ENTROPICAS HUFFMAN - ARITMETICA Con Pérdida (Recuperación similar) Basadas en Predicción Los valores siguientes se predicen de acuerdo a valores previos Orientadas por la frecuencia Aplican la transformada discreta del Coseno Orientadas por la importancia Usan características de la imagen como base Híbridas Combinan las tres anteriores Fractal Utilizan chips Se introducen entre H y S y es muy lenta\n"}
{"prompt":"Análisis de Algoritmos de Compresión: Simplificación de Lineas Douglas-Peucker, TD- TR, Visvalingam ->","completion":" ADOBEEn el presente proyecto de tesis constan los estudios de efectividad y factibilidad al dar uso de los algoritmos de compresión para trayectorias espaciales. Como es de conocimiento hoy en día la información que genera un objeto en movimiento es de gran importancia para instituciones y empresas. En este documento mediante el uso de la metodología de campo-experimental, se busca dar a conocer fortalezas y debilidades de estos algoritmos; esto debido a que se da uso de datos reales los cuales serán analizados para las diferentes métricas de rendimiento, realizando experimentos con las bases de datos. Esta información será validada mediante el test de hipótesis después de los cuáles se dará las conclusiones finales.En el presente proyecto de tesis constan los estudios de efectividad y factibilidad al dar uso de los algoritmos de compresión para trayectorias espaciales. Como es de conocimiento hoy en día la información que genera un objeto en movimiento es de gran importancia para instituciones y empresas. En este documento mediante el uso de la metodología de campo-experimental, se busca dar a conocer fortalezas y debilidades de estos algoritmos; esto debido a que se da uso de datos reales los cuales serán analizados para las diferentes métricas de rendimiento, realizando experimentos con las bases de datos. Esta información será validada mediante el test de hipótesis después de los cuáles se dará las conclusiones finales.\n"}
{"prompt":"Determinación de la resistencia a compresión de hormigón preparado con policarbonato, vidrio templado y hormigón reciclado ->","completion":" Para el desarrollo del presente proyecto se empezó recolectando los materiales necesarios para su ejecución, los agregados se recogieron de la mina Alvarado-Ortiz y la mina A&P ubicada en Ambato sector la Península , también fue necesario la recolección de residuos de vidrio templado (FAIRIS), policarbonato, y trozos de hormigón reciclado provenientes de cilindros ensayados, residuos de veredas, bordillos entre otros; a todos los materiales requeridos se comprobó su calidad determinando sus propiedades a través de los diferentes ensayos de laboratorio en base a los parámetros que indica la norma INEN y código ASTM, adicionalmente se realizó la dosificación de un hormigón de 210 kg\/cm2 para la comparación de la resistencia a compresión en las muestras realizadas a partir de materiales reciclados con las diferentes proporciones del material reciclable. Con todos los datos obtenidos se pudo realizar un cuadro comparativo de la resistencia a comprensión del hormigón preparado con policarbonato, vidrio templado y hormigón reciclado dando por finalizado el proyecto experimental.\n"}
{"prompt":"Velocidad de corte en rocas y su relación con la resistencia a la compresión simple ->","completion":" El presente trabajo evaluó una correlación entre la velocidad de corte sobre rocas y la resistencia a la compresión simple o uniaxial, como alternativa para la valoración de esta última propiedad en el campo. Se prepararon quince probetas elaboradas de una roca tomada del sector Cojitambo y otras quince muestras de roca tomadas del sector Pumayunga. Las dimensiones de las probetas elaboradas fueron de 120 mm de longitud, 100 mm de ancho y 50 mm de espesor, con la diferencia de que las muestras de Pumayunga tuvieron 40 mm de espesor. En una primera fase se realizaron cortes sobre las probetas, estos ensayos se efectuaron con una cortadora eléctrica, en donde se les aplicó dos cortes, uno vertical y otro horizontal. Como resultado se obtuvieron velocidades de corte, con las que se proyectó una correlación, a través de la resistencia a la compresión simple de cada roca. La resistencia a la compresión uniaxial se obtuvo de las mismas probetas, las cuales se enviaron al laboratorio para aplicar una fuerza de compresión. Finalmente se encontró una ecuación por la cual se adquiere la resistencia a la compresión gracias al valor de la velocidad de corte. Esta ecuación es una buena alternativa para obras mineras y civiles, si su coeficiente de determinación se encuentra entre los valores de 0,5 a 1.Ingeniero de Minas\n"}
{"prompt":"Sistema de predicción de la complejidad léxica implementando machine learning y redes neuronales para reducir barreras de la compresión lectora en los estudiantes universitarios. ->","completion":" PDFLa identificación de palabras complejas (CWI) es la tarea de detectar en el contenido de los documentos las palabras que son difíciles o complejas de entender por las personas de un determinado grupo. El objetivo de esta investigación es el desarrollo de un sistema de predicción de la complejidad léxica tanto del idioma inglés como del idioma español. El sistema se basa en la implementación de características lingüísticas a nivel de la palabra y oraciones, y en la implementación de las técnicas de redes neuronales BERT y XLM-RoBERTa para la generación de nuevas características que permitan resultados mucho más precisos. Se aplicó el algoritmo Random Forest Regressor. Para el entrenamiento de algoritmo se utilizó un conjunto de datos conformado por un corpus de textos en español y otro corpus de textos en inglés. La evaluación del algoritmo se lo realizó mediante la partición 90% - 10%. La metodología de desarrollo que se aplicó fue Kanban, y la metodología de investigación se basó en el Estudio de Caso por lo cual sus unidades de análisis se fundamentaron en las características lingüísticas generadas. Tras varias ejecuciones del algoritmo fue necesario implementar una validación cruzada de 5 variaciones para lograr resultados más precisos. El sistema será de mucho beneficio para la generación de soluciones dirigidas a los estudiantes con bajo nivel de comprensión lectora.Complex Word Identification (CWI) is the task of detecting in the content of documents words that are difficult or complex to understand by the people of a certain group. The objective of this research is the development of a system for predicting the lexical complexity of both the English and Spanish languages. The system is based on the implementation of linguistic characteristics at the level of the word and sentences, and in the implementation of BERT and XLM-RoBERTa neural network techniques for the generation of new features that allow much more accurate results. The Random Forest Regressor algorithm was applied. For the algorithm training, a dataset consisting of a corpus of texts in Spanish and another corpus of texts in English was used. The evaluation of the algorithm was performed by partitioning 90% - 10%. The development methodology that was applied was Kanban, and the research methodology was based on the Case Study, for which its units of analysis were based on the linguistic characteristics generated. After several runs of the algorithm, it was necessary to implement a cross validation of 5 variations to achieve more accurate results. The system will be of great benefit for the generation of solutions aimed at students with a low level of reading comprehension.\n"}
{"prompt":"Procesamiento de datos de espectrometría de masas: algoritmos y metodologías ->","completion":" El cáncer es una enfermedad asintomática en una etapa temprana y muy difícil de diagnosticar. En muchos de los casos no es percibida hasta que ya alcanza la metástasis. Es la segunda causa de muerte en el Ecuador a pesar de que los avances conseguidos en los últimos tiempos han sido revolucionarios, existen casos en donde el cáncer es detectado en su etapa terminal y aún no se ha encontrado ninguna metodología científica ni empírica que indique la presencia de esta patología. Las metodologías tradicionales de diagnóstico en cualquiera de sus tipos aciertan a un número relativamente bajo de casos en sus etapas tempranas, usando métodos invasivos con el riesgo de ser falsos positivos o falsos negativos. Centros de investigación y universidades han juntado esfuerzos para buscar alternativas de diagnóstico y tratamiento del cáncer usando métodos que permitan mejorar la eficacia del diagnóstico. En este trabajo se aborda un análisis de las diferentes etapas implicadas en el procesamiento de datos de muestras de tejidos cancerosos y saludables usando espectrometría de masas, usando plataformas computacionales, aplicados al mejoramiento de la calidad de las mediciones para posteriores aplicaciones de definición de biomarcadores.Cancer is an asymptomatic disease at an early stage and very difficult to diagnose in many cases it is not perceived until it has already reached the stage of metastasis, spreading in other organs of the body. It is the second cause of death in Ecuador despite progress made in recent years have been revolutionary, there are cases where the cancer is detected in its terminal stage and still has not found any scientific or empirical methodology to indicate the presence of this pathology. Traditional methods of diagnosing cancer in any of its types are relatively ineffective in early stages, using invasive methods and at risk of being detected as false positive or false negative. Research centers and universities have joined forces to seek alternative diagnosis and treatment of cancer using methods to improve the efficiency of diagnosis and detection of cancer in its early stages. This paper discusses a group of algorithms and methodologies for processing data sets of mass spectrometry measurements of cancer and normal analyzed samples using computing platforms aimed at improving the quality of measurements for biomarkers definition applications.Cuenca\n"}
{"prompt":"Centros de procesamientos de datos en la nube ->","completion":" La presente documentación contiene un estudio sobre la Computación en la Nube, que es una tecnología relativamente nueva y que promete grandes bondades a las empresas que buscan reducir sus costos de TI (Tecnologías de Información). Computación en la Nube es una tecnología que va de la mano con la Virtualización, la cual nos ayudará a compartir recursos y optimizar las cargas de trabajo. Nos centraremos de manera más profunda en el estudio de un Centro de Procesamiento de Datos en la Nube, donde analizaremos esta tecnología y la compararemos con los centros de procesamientos de datos tradicionales, a fin de encontrar las virtudes y debilidades de cada una de estas soluciones propuestas. En virtud de brindar robustez al diseño estudiado, se agregará medidas de seguridad al mismo, además de un sistema de recuperación de desastres.This documentation contains a study on computing in the cloud, which is a relatively a new technology that promises great benefits to companies seeking to reduce their IT (information technology) cost. Cloud computing is a technology that goes hand in hand with virtualization, which will help us share resources and optimize workloads. We will focus in a way deeper into the study of a center of data processing in the cloud, where we'll look at this technology and will compare it with the traditional datacenters, in order to find the strengths and weaknesses of each of these proposed solutions. By virtue of providing robustness studied design, security measures will be added to it, as well as a disaster recovery system.\n"}
{"prompt":"Centros de procesamientos de datos en la Nube ->","completion":" La presente documentación contiene un estudio sobre la Computación en la Nube, que es una tecnología relativamente nueva que promete grandes bondades a las empresas que buscan reducir sus costos de TI (Tecnologías de Información). Computación en la Nube es una tecnología que va de la mano con la Virtualización, la cual nos ayudará a compartir recursos y optimizar las cargas de trabajo. Nos centraremos de manera más profunda en el estudio de un Centro de Procesamiento de Datos en la Nube, donde analizaremos esta tecnología y la compararemos con los centros de procesamientos de datos tradicionales, a fin de encontrar las virtudes y debilidades de cada una de estas soluciones propuestas. En virtud de brindar robustez al diseño estudiado, se agregará medidas de seguridad al mismo, además de un sistema de recuperación de desastres.GuayaquilLicenciado en Redes y Sistemas Operativos\n"}
{"prompt":"Procesamiento de Datos Usando Análisis de Correspondencia Múltiples ->","completion":" Trata sobre el procesamiento de datos usando un análisis de correspondencias múltiples, se ha aplicado a los datos obtenidos de una encuesta acerca del desempeño de los egresados de una carrera que pertenece a una institución superior ecuatoriana, teniendo como finalidad dotar a esta ultima de información actual acerca de los profesionales de la promoción del año 1994, que le permita establecer si se cumplieron sus objetivos de ubicación, y desempeño profesional de aquellos profesionales que pasaron por sus aulas. Se presenta una visión general de ideas que sostienen los estudios de egresados en las instituciones educativas; un marco teórico estadístico, un modelo matemático que resulta de la aplicación del método de correspondencias múltiples. Finalmente se presenta un análisis de variables latentes que se formaron como combinación lógica o algebraica de variables directamente observables.GuayaquilIngeniería en Estadística Informática\n"}
{"prompt":"Procesamiento de datos usando Análisis de Correspondencia Múltiples ->","completion":" El presente proyecto se trata sobre el procesamiento de datos usando un análisis de correspondencias múltiples, se ha aplicado a los datos obtenidos de una encuesta acerca del desempeño de los egresados de una carrera que pertenece a una institución superior ecuatoriana, teniendo como finalidad dotar a esta ultima de información actual acerca de los profesionales de la promoción del año 1994, que le permita establecer si se cumplieron sus objetivos de ubicación, y desempeño profesional de aquellos profesionales que pasaron por sus aulas. se presenta una vision general de ideas que sostienen los estudios de egresados en las instituciones educativas; un marco teorico estadistico, un modelo matematico que resulta de la aplicacion del metodo de correspondencias multiples. Finalmente se presenta un análisis de variables latentes que se formaron como combinación lógica o algebraica de variables directamente observables.GuayaquilINGENIERO EN ESTADÍSTICA INFORMÁTICA\n"}
{"prompt":"Implementación del framework Apache Flink para el procesamiento de grandes cantidades de datos en tiempo real ->","completion":" Resumen: En la época actual existe la producción de grandes cantidades de información que son procedentes de diferentes fuentes como: bancos, entidades, negocios, páginas web, redes sociales, entro otros, siendo las redes sociales las que mayor volumen de informaciónproducen. El destino de estos grandes volúmenes de información es el almacenamiento y respaldo, provocandoque no exista un uso adecuado para el procesamiento y extracción de información de manera rápida y fiable. En el presente trabajo de titulación se realiza la implementación del Framework Apache Flink, que integra elAPI DataStream la cualpermite realizar el procesamiento de flujos de datos en tiempo real, utilizando operadores y funciones propias de esta API para cumplir con este tipo de procesamiento y mostrar resultados de forma automática. La implementación del entorno de operación de esta herramientase la realiza en un solo nodo o host, y mediante el uso de los diferentes escenarios de prueba planteados en el presente proyecto, se logradeterminar que Apache Flink realiza el procesamiento de flujos de datos de manera eficiente y cumple con las expectativas planificadas.\n"}
{"prompt":"Sistemas computarizado de adquisición y procesamiento de datos para un laboratorio de calidad de aguas ->","completion":" Desarrolla un programa computarizado aplicado al campo científico para optimizar el trabajo en el análisis de mediciones de parámetros físicos en muestras de aguas para un mejor control en el análisis de contaminación del agua. Cuenta con un sensor de temperatura y circuitería necesaria para adaptar electrodos que sean eficientes exactos, rentables y de beneficio tecnológico más desarrollo para el país.GuayaquilIngeniero en Computación\n"}
{"prompt":"Programación y control de proyectos de Ingeniería Civil mediante procesamiento automático de datos ->","completion":" El presente tema se ha desarrollado con el ánimo de que tanto estudiantes y profesionales de Ingeniería Civil, así como las personas dedicadas a la construcción dispongan de un instrumento simple y práctico, del que tenemos la seguridad se beneficiarán ellos y sus colaboradores\n"}
{"prompt":"Diseño de un centro de procesamiento de datos, de aproximadamente 2000m2, para certificación TIER 1 ->","completion":" Esta tesis trata de un modelo con el cual se espera optimizar los tiempos de respuesta de los dispositivos de comunicación como son los servidores tipo blade, de virtualización, servidores rackeables, conmutadores de acceso, conmutadores de distribución y ruteadores de core, aplicando dos tecnologías de almacenamiento para el respaldo: Nas y San.GuayaquilLicenciado en Redes y Sistemas Operativos\n"}
{"prompt":"Diseño de un centro de procesamiento de datos, de aproximadamente 300 m2, para certificación Tier iv ->","completion":" Esta tesis enfoca el diseño del centro de procesamiento de datos para que sea tolerante a fallos, que permita clasificar actividades de mantenimiento sin que ningún servicio crítico se vea afectado. El informe elaborará el diseño de un centro de datos en un área de trescientos metros cuadrados usando tecnología de punta y que cumpla la certificación tier iv, para prestar servicios de almacenamiento de datos, respaldo de información y alojamiento web.GuayaquilLicenciado en Redes y Sistemas Operativos\n"}
{"prompt":"DISEÑO DE UN CENTRO DE PROCESAMIENTO DE DATOS, DE APROXIMADAMENTE 1000 M2, PARA CERTIFICACIÓN TIER II ->","completion":" En el presente documento se describe el diseño de un centro de procesamiento de datos. Dentro de sus objetivos está proveer de servicios a sus clientes, lo que obliga a disponer de tecnología y de una excelente infraestructura que permita el cumplimento de la calidad de los servicios, seguridad del personal operativo y de los equipos, Para obtener la viabilidad del funcionamiento del mismo. Como primer paso para alcanzar los objetivos propuestos se realizó un análisis de las ventajas y desventajas de la elección de la locación y distribución de los espacios dentro del centro del procesamiento de datos, Posteriormente se elaboró un diseño que cumpla con las recomendaciones de la norma TIA-942 [1] en cuanto se refiere a topología física y lógica de la red, tipos de cableado estructurado y fibra óptica, tipos de canalizaciones para cada tipo de cableado y para los diferentes tipos de sistemas. Adicionalmente que cumpla con las normas Uptime Institute que avalen una alta disponibilidad y continuidad del mismo. Además, permitir que dicha infraestructura sea de fácil administración, segura, escalable, confiable, ya que tendrá tecnologías que garanticen una adecuada gestión de comunicación justificando las necesidades de la empresa. Se dan soluciones con alta tecnología para los sistemas eléctricos, climatización, seguridad, monitoreo, iluminación y telecomunicaciones. También se estableció costos actuales para la implementación de los mismos y así servir como modelo o guía de consulta para ser implementado en otros centros de procesamiento de datos que aspiren tener una certificación TIER 2[2] en Ecuador.In this document the design of a data center is described. Among its objectives it is to provide services to its customers, which requires the availability of technology and excellent infrastructure to compliance with the quality of services, safety of operating personnel and equipment, For the viability of the operation thereof. As a first step to achieve the objectives an analysis of the advantages and disadvantages of the choice of location, distribution of space within the data processing center was made, subsequently the design to comply with the recommendations of TIA -942 as regards physical and logical network topology, types of structured cabling and fiber optics, types of pipes for each type of cabling and for different types of systems. In addition to complying with the Uptime Institute standards that support high availability and continuity. Moreover, allowing such infrastructure is easily managed, secure, scalable, reliable, and technologies that will ensure proper management of communication justifying the needs of the company. High-tech solutions for electrical systems , HVAC, security , monitoring , lighting and telecommunications are given. Also present costs to implement them was established and thus serve as a model or reference guide to be implemented in other data processing centers that aspire to have a TIER 2 [2] certification in Ecuador.\n"}
{"prompt":"Auditoría de sistemas para el área de procesamiento automático de datos de la distribuidora Marceci de la ciudad de Ambato ->","completion":" En la primera época de la informática, los sistemas automatizados se limitaban a reproducir los sistemas de contabilidad manuales. Mantenían controles e informes similares, es decir, repetían el mismo procedimiento pero con el ordenador. El entorno de trabajo era poco amigable y la aplicación poco flexible pero, aun así, se dio un avance adecuado a la posibilidad de obtener los estados contables a partir de los datos del diario. Al principio el problema para los auditores, el computador se había convertido en un obstáculo que representaba a una máquina compleja y desconocida manipulada por operadores que empleaban un lenguaje no menos conocido. La situación se complica aún más con la aparición del teleproceso y de las técnicas de acercamiento de la informática al usuario. Se llega así a una etapa que exige otra clase de auditor más especializado y con mayores conocimientos técnicos en materia de informática, alguien que sea capaz de comunicarse con el personal de proceso de datos. Para el logro de esto se requerirá ya sea formar a personas seleccionadas de la unidad de proceso de datos en técnicas de auditoría, o bien, que el personal de auditoría financiera se adiestre en técnicas de proceso de datos.El proyecto de tesis titulado “AUDITORÍA DE SISTEMAS PARA EL ÁREA DE PROCESAMIENTO AUTOMÁTICO DE DATOS DE LA DISTRIBUIDORA MARCECI DE LA CIUDAD DE AMBATO”. Se presta la auditoría de sistemas enfocada al área de procesamiento automático de datos (PAD) desde el punto de vista del auditor, en la presente investigación se presenta los contenidos que involucra a la auditoría de sistemas es decir las distintas posiciones teóricas, de diferentes autores que complementa el entendimiento y el trabajo que se realizó. Contenido: primera parte, comprende la introducción de la auditoría de sistemas. A su vez, se plantea: la situación problemática, el problema científico, el objetivo general, los objetivos específicos que se pretende lograr en la investigación, la hipótesis. Asimismo, se específica la novedad del tema y los métodos, técnicas y herramientas empleados en la investigación y desarrollo del tema. La segunda parte, está formada por el Capítulo I, corresponde a la parte conceptual y teórica de la auditoría de sistemas, lo que permite un mejor entendimiento y compresión del alcance y objetivos de la misma. Estudio que ayuda analizar los componentes a utilizar determinando elementos que rodeen la conceptualización del área de procesamiento automático de datos (PAD). La tercera parte, está formada por el Capítulo II, corresponde al marco propositivo de la evaluación del área de procesamiento automático de datos, identificando procesos de auditoría de sistemas. La cuarta parte, está formada por el Capítulo III, corresponde a los procedimientos y resultados de la investigación en base a la propuesta sobre el área de procesamiento automático de datos. La investigación en el presente trabajo hace uso del razonamiento para explicar algo, partiendo de lo general a lo particular, o a su vez iniciar de un estudio individual de los hechos para formar conclusiones universales, que permita establecer una mejor compresión del área de procesamiento automático de datos. Utilizando técnicas y herramientas de investigación basada en la auditoría de sistemas, análisis documental, recolección de datos, observación directa, entrevistas, cuestionarios y análisis de datos, para desarrollar y establecer estrategias que faciliten estudio del objeto de investigación y los distintos obstáculos que pueden presentarse. El estudio se concreta con una estructura lógica de investigación en la cual se profundiza todos los contenidos que necesita la empresa para realizar una auditoría de sistemas para el área de procesamiento automático de datos en la Distribuidora “MARCECI”\n"}
{"prompt":"Diagnóstico del cumplimiento de aspectos contables y de riesgos en el procesamiento de datos de software basados en la nube. ->","completion":" En el capítulo 1 se detalla las normas y metodologías que se van a emplear para este trabajo de investigación como lo son: La norma ISO 27001:2013 y la metodología del control de las actividades, la información y comunicación que debe existir en las empresas. Al igual que la información de Conocimiento de pequeñas y medianas entidades en Ecuador, aplicarán la norma internacional de información financiera para pequeñas y medianas Entidades, para el registro, preparación y presentación de estados financieros. En el capítulo 2 se detalla la metodología a utilizar para este trabajo de investigación en el que indicaremos que se aplicará el diseño no experimental porque no se pretende cambiar ni manipular la información sino analizarla en su ambiente natural. Para el desarrollo de esta investigación, se utilizó el método de estudio de caso, el cual permite describir y analizar el cumplimiento de aspectos contables que representan la mecánica contable aplicable en el país y las seguridades en los accesos e ingreso de información en los módulos de compra y venta de un software ERP basado en la nube. En el capítulo 3 se presenta el desarrollo completo de los objetivos alcanzados en este trabajo de investigación utilizando la metodología de estudio de casos realizando los cinco pasos de investigación para cumplir con el diagnósticos de cumplimiento de aspectos contables y riesgos en la seguridad de la información usando una entrevista de preguntas semi estructuradas y encuestas de valoración en escala de Likert, logrando identificar las fortalezas, oportunidades, debilidades y amenazas del uso de estos software con procesamientos en la nube.Chapter 1 details the rules and methodologies that will be used for this research work, such as: The ISO 27001: 2013 standard and the methodology for controlling activities, information and communication that should exist in companies. As well as information on Knowledge of small and medium entities in Ecuador, they will apply the Internation al Financial Reporting Standard for Small and Medium Entities, for the registration, preparation and presentation of financial statements. Chapter 2 details the methodology to be used for this research work in which we will indicate that the non-experimental design will be applied because it is not intended to change or manipulate the information but to analyze it in its natural environment. For the development of this research, the case study method was used, which allows to describe and analyze the compliance of accounting aspects that represent the accounting mechanics applicable in the country and the assurances in the access and information entry in the modules of buying and selling an ERP software based on the cloud. Chapter 3 presents the complete development of the objectives achieved in this research work using the case study methodology, performing the five steps of research to comply with the diagnosis of compliance with accounting aspects and risks in information security using an interview of semi-structured questions and survey surveys on Likert scale, managing to identify the strengths, opportunities, weaknesses and threats of the use of these software with processing in the cloud.\n"}
{"prompt":"Análisis de orientación de anuncios en páginas web utilizando Mahout para procesamiento masivo y escalable de datos ->","completion":" Los sistemas de recomendación son muy utilizados hoy en día, son sistemas que brindan a los usuarios sugerencias de diversos ítems relacionados con el tema que estén buscando, estos sistemas han mejorado la interacción entre el usuario y el sitio web, se basan en opiniones de usuarios, su historial e incluso en el contenido del sitio web que se está analizando, para así brindar una recomendación efectiva al usuario final. En el presente proyecto de análisis de orientación de anuncios en páginas web se analiza los antecedentes, descripción del problema, justificación, objetivo y alcance que con lleva a la realización del presente trabajo.GuayaquilIngeniero en Ciencias Computacionales Especialización Sistemas de Información\n"}
{"prompt":"Análisis de la web de la espol y afines, utilizando hadoop como una plataforma de procesamiento masivo de datos ->","completion":" El presente documento muestra los resultados del análisis de la red de la espol, se utiliza hadoop como plataforma de procesamiento masivo de datos, de la misma manera se demuestra que la estructura de la web de la espol no tiene propiedades de pequeño mundo (no es una red libre de escala), forma que usualmente toman muchas de las redes reales, y que tiene gran incidencia en la navegabilidad y accesibilidad de la información en grandes redes de documentos. esto dificulta la exploración de la web de la espol, y tiene una incidencia negativa en la percepción de la utilidad (a los usuarios) de nuestra web.GuayaquilIngeniero en Computación Especialización Sistemas Multimedia.\n"}
{"prompt":"Diseño de un centro de procesamiento de datos, de aproximadamente 1000 m2, para certificación Tier II ->","completion":" El documento se realizó con el fin de determinar el diseño de una implementación adecuada para un centro de procesamiento de datos que disponga de un plan de contingencia para diferentes circunstancias como pérdidas de información, caída de enlace, riesgos por desastres naturales y etc. Para obtener la viabilidad del funcionamiento del mismo.GuayaquilLicenciado en Redes y Sistemas Operativos\n"}
{"prompt":"Diseño de un centro de procesamiento de datos, de aproximadamente 600 m2, para certificación TIER III ->","completion":" En este proyecto se realizará el diseño de un centro de procesamiento de datos (CPD) para un proveedor de servicios de internet (Internet Service Provider, ISP). Dicho centro contará con un área útil de aproximadamente 600 m2 y el mismo estará orientado a brindar el servicio de alojamiento de servidores (housing). El diseño del CPD está realizado con la finalidad que se pueda realizar la implementación futura del mismo y que cumpla con la certificación TIER 3, la cual avala un grado alto de redundancia y fiabilidad del centro garantizando una tasa elevada de disponibilidad de servicios.GuayaquilLicenciado en Redes y Sistemas Operativos\n"}
{"prompt":"Análisis de la web de la ESPOL y afines, utilizando hadoop como una plataforma de procesamiento masivo de datos ->","completion":" El presente documento muestra los resultados del análisis de la red de la ESPOL, utilizando Hadoop como plataforma de procesamiento masivo de datos. Gracias al estudio que se ha realizado, se ha podido demostrar que la estructura de la Web de la ESPOL no tiene propiedades de pequeño mundo (no es una red libre de escala), forma que usualmente toman muchas de las redes reales, y que tiene gran incidencia en la “navegabilidad y accesibilidad de la información en grandes redes de documentos” [18]. Esto dificultaría la exploración de la Web de la ESPOL, y tendría una incidencia negativa en la percepción de la utilidad (a los usuarios) de nuestra Web. Para este estudio, utilizamos los índices obtenidos de la indexación de los enlaces entrantes como salientes de las páginas Web del dominio espol.edu.ec. Estos datos fueron procesados para así obtener la cantidad de enlaces entrantes y salientes para cada uno de ellos. Además, los mismos datos nos permitieron conseguir la distribución estadística de enlaces (entrantes y salientes) de las paginas del dominio de la ESPOL, y así poder comprobar que la misma no tiene las propiedades de una distribución de ley de potencias (power law), un criterio fundamental que debe cumplir una red para poder ser clasificada como libre de escala (scale free). Finalmente, para validar este análisis se ha considerado estudios previos a las redes de otras universidades, que sí muestran una estructura pequeño mundo.\n"}
{"prompt":"Análisis de datos meteorológicos del Valle de los Chillos usando datos funcionales ->","completion":" The analysis of functional data (ADF) is a statistical area that has as main objective to study variables whose data vary in a continuous space, and within these variables you can find the time-dependent. Currently you can have a lot of data because most of them the gathering is done automatically, therefore to adjust this data to a function or functional data is one of the characteristics of the functional analysis. These data once converted into functions allow its derivatives to be extracted and explain in a better way how the phenomena under study works. The Meteorological Station Hacienda El Prado, located in the valley of Chillos has systematically analog and automatically registered a variety of meteorological data. With these data what is aimed to do is to model the behavior of the atmospheric variables in that Valley and its area of influence. In this statistical analysis free software R is used, with emphasis on the use of the fda and fda.usc librarys. Its development is based on the exploratory data analysis, selection of the base type, the number of bases, the building of a system based on Fourier series and a model based on the construction of a linear functional operator. In this study two variables have been selected to be studied, they are the daily minimum temperature and daily maximum temperature. The intention of the before mentioned is to give the door open for other studies by selecting other variables, or choosing another weather station and to establish comparisons.El análisis de datos funcionales (ADF) es un área de la estadística que tiene como objetivo principal estudiar variables cuyos datos varíen en un espacio continuo, dentro de ´estas se encuentran las que dependen del tiempo. Actualmente se puede disponer de una gran cantidad de datos debido a que la mayoría de ellos su recolección se hace de manera automática, por lo tanto ajustar ´estos datos a una función o dato funcional es una de las características del análisis funcional, ´estos datos una vez convertidos en funciones permiten que se puedan extraer sus derivadas y explicar de mejora manera los fenómenos en estudio. La Estación Meteorológica de la Hacienda El Prado, ubicada en el valle de los Chillos, ha registrado sistemáticamente y de manera analógica y automática una gran variedad de datos meteorológicos, con ´estos datos lo que se pretende es modelar el comportamiento de las variables atmosféricas en dicho valle y su área de influencia. En ´este análisis se usa software estadístico de libre distribución R, con énfasis en el uso de las librerías fda y fda.usc. Su desarrollo se basara en el análisis exploratorio de datos, la selección del tipo de base, el número de bases, la construcción de un modelo basado en las series de Fourier y un modelo basado en la construcción de un operador funcional lineal. En ´este estudio se ha seleccionado dos variables para estudiar que son las temperaturas diaria mínima máxima. Con esto se pretende dejar una puerta abierta a otros estudios seleccionando otras variables, o escogiendo otra estación meteorológica y poder establecer comparaciones.\n"}
{"prompt":"Análisis, diseño y construcción de un almacén de datos de colocaciones de crédito y captaciones de los bancos privados para aplicar algoritmos de minería de datos ->","completion":" This technical project aims to publicize data mining and applied to private entities for the purpose of discovering information that exists within the data useful, this information is handled through flat files that are publicly accessible, making with the results generated business opportunities in sites not yet overcrowded, increasing revenue and reducing expenditures for organizations. Data mining, you need to study and inquiry into their use and interpretation, also uses algorithmic tools for finding hidden information. This document consists of three chapters, where depth is detailed the relationship and utility proposed to grant proper use and handling of the data mining algorithms. Chapter one describes the tools and materials provided to begin the processing and analysis of information to further streamline the decision-making process. Chapter two describes the scientific and theoretical basis covered with artifacts and terminology used in project implementation. Chapter three describes the implementation of the data obtained and implemented in different data warehouses as well as the results of the study and application of data mining algorithms to predict future behavior in the business of each bank. Finally, they report for bank loans and deposits for them to be manipulated by people interested and are within the decision-making entities are generated.El presente proyecto técnico pretende de dar a conocer la minería de datos y su utilidad aplicada a entidades privadas, con el propósito de descubrir información que existe dentro de la data, esta información es manejada mediante archivos planos que son de acceso público, haciendo que con los resultados obtenidos se generen posibilidades de negocio en sitios aun no abarrotados, incrementando ingresos y reduciendo egresos para las organizaciones. La minería de datos, necesita de estudio y de indagación acerca de su uso e interpretación, así mismo utiliza herramientas algorítmicas para la búsqueda de información oculta. El presente documento consta de tres capítulos, en donde se detalla a profundidad la relación y utilidad propuesta para otorgar adecuado uso y manipulación a los algoritmos de minería de datos. El capítulo uno, describe los instrumentos y materiales proporcionados para comenzar la elaboración y análisis de la información para posteriormente agilizar el proceso de toma de decisiones. El capítulo dos, describe toda la sustentación científica y teórica que cubre con los artefactos y terminología utilizada en la ejecución del proyecto. El capítulo tres, describe la implementación de la data obtenida e implantada en distintos Data Warehouses, así como los resultados obtenidos del estudio y aplicación de algoritmos de minería de datos para predecir futuros comportamientos dentro del negocio de cada entidad bancaria. Por último, se generan reportes para colocaciones y captaciones bancarias para que estos sean manipuladas por personas interesadas y que estén dentro de la toma de decisiones de las entidades.\n"}
{"prompt":"Análisis comparativo entre bases de datos relacionales con bases de datos no relacionales ->","completion":" El documento consiste en realizar un análisis comparativo entre bases de datos relacionales y bases de datos no relacional con respecto a sus funcionalidades, estructuras de almacenamiento, en la determinación de las desventajas del uso de bases de datos relacionales en aplicaciones web no transaccionales, analizar los beneficios de las bases de datos no relacionales frente a las relacionales para aplicaciones web no transaccionales y en la implementación de dos aplicaciones web prototipo tanto para una base de datos relacional como para una base de datos no relacional, estableciendo las condiciones en las que es mejor usar las bases de datos no relacionales en lugar de las bases de datos relacionales.The document consist in a comparative analysis of relational databases and non-relational databases with respect to their functionalities, storage structures, in the determination of the disadvantages of using relational databases in non-transactional web applications, analyzing the benefits of the bases of non-relational data against relational not transactional web applications and implementation of two web application prototype either a relational database as a non-relational databases, establishing the conditions under which it is better using non-relational databases rather than relational databases.\n"}
{"prompt":"Análisis dinámico de la pobreza en el Ecuador: un modelo de factores estructurales de riesgo con datos de panel. ->","completion":" La pobreza, junto con la desigualdad, es quizá el problema más grave y transcendental que enfrentan las sociedades actuales y por lo tanto se ha convertido en una de las principales preocupaciones de la política pública, sus alcances llegan a afectar prácticamente a todas la dimensiones de una sociedad y se ha convertido en objeto de estudio desde todas las ramas de las ciencias sociales. Este documento pretende estudiar la pobreza en el Ecuador desde un enfoque distinto y relativamente novedoso. Al tratar la dinámica de la pobreza se pretende brindar una visión más global que no implique únicamente identificar y cuantificar a los pobres, sino que presente conceptos y resultados que sea útiles para entender de manera empírica cuales son las condiciones socioeconómicas influyentes en el fenómeno. Al final de este trabajo se encuentra que en el país existen variables tanto demográficas como laborales que tienen importancia para influenciar los movimientos alrededor de la pobreza.\n"}
{"prompt":"Estudio del uso de MongoDB como alternativa a las bases de datos relacionales tradicionales en aplicaciones web que requieren rapidez de lectura\/escritura de los datos almacenados ->","completion":" El término web ha tenido un increíble avance en los últimos años, en la actualidad son pocos los sitios web que ofrecen información estática, la mayoría de ellos ofrecen cierto nivel de dinamismo e interacción con el usuario por ejemplo en fórums, gestores de contenido, suscripciones rss, etc. Este avance ha provocado que ya no se hable solo de sitios web, sino de aplicaciones web, surgiendo la Web 2.0 con la idea de una web más social dando origen a servicios como Facebook, MySpace, Hi5, Twitter, en otros; en los que la web se apoya en el uso de varias tecnologías combinadas. El desarrollo de la web avanzó aún más y se acuñaron términos como “Software como Servicio” con nuevos retos para la web, entre ellos el de atender las peticiones de miles y millones de usuarios distribuyendo la carga de trabajo generada en varios equipos para que atiendan atienden estas solicitudes, a esto se le conoce como escalabilidad. Toda la información generada por las aplicaciones web necesitan almacenarse en un motor de base de datos y es allí en donde se origina la necesidad de escalabilidad ha llevado a grandes empresas como Amazon, Google, Facebook, etc. A desarrollar alternativas a las bases de datos tradicionales y es así como se popularizan una variante de las bases de datos documentales llamadas NoSQL (“not only SQL”) que brindan sobre todo velocidad y escalabilidad. En la actualidad se aplican bases de datos NoSQL como complementos a las bases de datos relacionales tradicionales en empresas como Amazon que vende servicios “en la nube”, Google con su conocida aplicación “Google Maps”, Facebook, etc. Y la lista sigue creciendo día a día. Es por eso que en el presente trabajo estudiaremos las bases de datos NoSQL y en particular a MongoDB, presentándola como alternativa y\/o complemento a las bases de datos relacionales tradiciones especialmente en aplicaciones web.\n"}
{"prompt":"Proyecto de minería de datos para el análisis del comportamiento de los clientes de telecomunicaciones ->","completion":" El objetivo es predecir con cierto grado de exactitud los clientes que se convertirán en posibles deudores de la Empresa mediante un análisis previo sobre su comportamiento de pago y consumo con el fin de evitar pérdidas económicas por incumplimiento de pago de servicios de Telefonía Fija. La Minería de Datos a través de sus técnicas permite usar grandes cantidades de información que posee una Empresa de forma óptima extrayendo información que generalmente permanece oculta convirtiéndola en conocimiento. La Minería de Datos integra a ciencias como la Estadística y la Inteligencia Artificial con el fin de buscar patrones de comportamiento, precisamente el algoritmo que se usa para el análisis pertenece a la rama de la Inteligencia Artificial.\n"}
{"prompt":"Análisis de datos aplicado en el marketing directo ->","completion":" El presente estudio busca ofrecer un servicio de análisis de datos a pequeñas y medianas empresas ecuatorianas con la intención de implementar estrategias comunicacionales que promuevan la potenciación de las ventas. En el estudio se aplicó una metodología con diseño de campo, de nivel explicativo, y enfoque cualitativo, por lo cual se empleó la técnica de entrevista a 4 dueños de pymes de Guayaquil para determinar su conocimiento de la data mining. Se organizó un Focus Group conformado por 6 expertos en marketing, con la intención de obtener su valoración sobre la factibilidad de las estrategias planteadas. Acorde a los resultados se comprobó que, los dueños de los pequeños restoranes ubicados en la ciudad de Guayaquil no conocen sobre la Data Mining, sin embargo, muestran interés en su adquisición, debido a las estrategias que pueden implementarse con base a sus resultados, favoreciendo al crecimiento del target y en consecuencia el volumen de ventas. Los expertos en marketing reconocieron la factibilidad y bondades de las estrategias de inbound y outbound marketing planteadas en el estudio, con la recomendación de elegir los medios más empleados por los ecuatorianos, y tener un mayor alcance de difusión, para atraer y aumentar el público objetivo.This study seeks to offer a data analysis service to small and medium-sized Ecuadorian companies with the intention of implementing communication strategies that promote sales enhancement. In the study, a methodology with a field design, explanatory level, and qualitative approach was applied, for which the interview technique was used with 4 SME owners in Guayaquil to determine their knowledge of data mining. A Focus Group made up of 6 marketing experts was organized, with the intention of obtaining their assessment of the feasibility of the proposed strategies. According to the results, it was found that the owners of the small restaurants located in the city of Guayaquil do not know about Data Mining, however, they show interest in its acquisition, due to the strategies that can be implemented based on their results, favoring to the growth of the target and consequently the volume of sales. Marketing experts recognized the feasibility and benefits of the inbound and outbound marketing strategies proposed in the study, with the recommendation to choose the most used media by Ecuadorians, and have a greater scope of dissemination, to attract and increase the target audience. Key words: DATA, MARKETING, DIRECTGuayaquilMaestría en Comunicación con Mención en Comunicación Digital\n"}
{"prompt":"Eficiencia Técnica mediante Análisis Envolvente de Datos del Sector Educativo ->","completion":" With increased student enrolment at universities and limited funding, it is no longer an option for these institutions to operate at a greater degree of efficiency, but has become a necessity. Enrolment in higher education will continue to expand and public funding will become more and more diluted, especially as competition from other recipients of public funds increases, educational institutions must be subject to the surrender of performance assessments. The design of the study was proposed under a cross-cutting proposal, and focused on the purpose of evaluating technical efficiency, through immersive data analysis, in Higher Education Institutions. With this design configuration, a sample of 54 Higher Education Institutions was presented as an instrument by the 2009 National Council for the Evaluation and Accreditation of Higher Education of Ecuador (CONEA). An adaptation of the COOPER Methodological Order was made as a reference framework with more empirical evidence in the efficient evaluation, in organizations. The framework consists of six interrelated phases: concepts and objectives, data structuring, operational models, results comparison model, evaluation and outcome and implementation. Procedures are applied that allow the reduction of variables to an appropriate amount for DEA results to be reliable, and edge conditions to meet the objectives assumed for the University. The results are contrasted with the evaluation instrument currently held by the University. In conclusion, discrepancy is identified between the two results, with the necessary changes being made by the University in its assessment tools towards improving efficiency, so that it is applicable to other institutions of higher education.Con el aumento de la matrícula de estudiantes en las universidades y el financiamiento limitado, ya no es una opción para estas instituciones operar a un mayor grado de eficiencia, sino que se ha convertido en una necesidad. La matrícula en la educación superior continuará su expansión y la financiación pública será cada vez más diluida, sobre todo a medida que aumenta la competencia de los otros receptores de fondos públicos, las instituciones educativas deben someterse a la rendición de cuentas, evaluaciones de desempeño. El diseño del estudio se planteó bajo una propuesta de corte transversal, y se enfocó bajo el propósito de evaluar la eficiencia técnica, mediante el análisis envolvente de datos, en las Instituciones de Educación Superior. Con esta configuración del diseño, se planteó una muestra de 54 Instituciones de Educación Superior, y se utilizó como instrumento los informes presentados por el Consejo Nacional de Evaluación y Acreditación de la Educación Superior del Ecuador (CONEA) del año 2009. Se realizó una adaptación del Ordenamiento Metodológico COOPER como marco de referencia con más evidencias empíricas en la evaluación eficiente, en las organizaciones. El marco consta de seis fases interrelacionadas: conceptos y objetivos, estructuración de datos, modelos operacionales, modelo de comparación de resultados, evaluación y resultado e implementación. Se aplica procedimientos que permiten la reducción de variables a una cantidad apropiada para que los resultados del DEA sean confiables, y condiciones de borde para atender a los objetivos supuestos para la Universidad. Los resultados se contrastan con el instrumento de evaluación que en la actualidad posee la Universidad. Como conclusión se identifica discordancia entre ambos resultados, estableciéndose las modificaciones que se debieran hacer por parte de la Universidad en sus instrumentos de evaluación hacia la mejora de la eficiencia, para que sea aplicable a otras instituciones de educación superior.\n"}
{"prompt":"Análisis de los diferentes medios de transmisión de datos existentes, para los predios de la Pontificia Universidad Católica del Ecuador Sede Ambato, utilizando una Red Metropolitana Man ->","completion":" 1. Conceptos generales 2. Uso de las redes de computadoras 3. Descripción de los diferentes medios de transmisión 4. Marco propositivo 5. Desarrollo de páginas web.Universidades, industrias e instituciones públicas y privadas exigen posibilidades cada vez mayores de servicios de comunicación de datos, enlazando computadoras centrales son diferentes usuarios. En las décadas de los 60 y 70 la información se concebía como un servicio estructurado jerárquicamente, reflejado en gran medida la estructura intenta de las organizaciones. En la década de los 80 surgieron las redes de área local LAN, a la vez que nuevos métodos de organización proponiendo una estructuración de las organizaciones basada en grupos de trabajo especializado y coordinación entre sí, mediante mecanismos más dinámicos y flexibles.Pontificia Universidad Católica del Ecuador, Escuela de SistemasIngeniero en Sistemas\n"}
{"prompt":"Analisis factorial de los casos de cancer de esofago en pacientes asintomaticos e implementacion de una base de datos ->","completion":" trata sobre el analisis factorial de los casos de cancer de esofago en pacientes asintomaticos e implentacion de una base de datos. se desarrollan los conceptos basicos sobre el cancer y las causas que la producen. se revisan los fundamentos teoricos para el analisis de las variables con las tecnicas univariadas y multivariadas. se realiza la estadistica descriptiva de las variables investigadas. se realiza la injerencia sobre la independencia de las variables, el analisis de correlaciones, se utiliza el metodo de las componenetes principales y el analisis de correspondencias.GuayaquilINGENIERÍA EN ESTADÍSTICA INFORMÁTICA\n"}
{"prompt":"Efectos de la imputación en el análisis de datos multivariados ->","completion":" El presente trabajo consiste en un análisis estadístico de los Efectos de la Imputación en el Análisis de Datos Multivariados, basados en la generación de muestras con variables aleatorias dependientes e independientes de diferentes tamaños y distribuciones. El objetivo de este estudio es el comparar los Métodos de Imputación para el manejo de datos incompletos, tales como: Imputación por la Media e Imputación por Regresión, utilizando diferentes tamaños de muestras: 30, 50 y 100 y distribuciones tales como: Normal, Poisson y Exponencial, con el fin de comprobar que método de imputación brinda resultados de predicción que tiendan al dato observado.GuayaquilIngeniera en Estadística e Informática\n"}
{"prompt":"Efectos de la imputación en el análisis de datos multivariados ->","completion":" El presente trabajo consiste en un estudio estadístico acerca de los efectos de la imputación en el analisis de datos multivariados basados en muestras con variables aleatorias dependientes e independientes de diferentes tamaños y distribuciones asi como tambien el análisis de un caso real.GuayaquilIngeniería en Estadística Informática\n"}
{"prompt":"Análisis de rendimiento entre la base de datos relacional: MySQL y una base de datos no relacional: MongoDB ->","completion":" El presente trabajo de graduación realiza un análisis comparativo de dos gestores de bases de datos: MySQL y MongoDB, en lo referente al comportamiento del motor en tiempos de respuestas ante diferentes operaciones de consulta y manipulación; inicialmente se realiza un resumen de las nuevas tecnol ogías a las que se enfrentan las bases de datos relacionales y las bases de datos NoSQL. Se da una perspectiva de los diferentes modelos de consultas, datos y arquitecturas de base de datos y se procede con la instalación e implementación de los dos gestores; paralelamente se desarrolla un esquema de base de datos, en el cual se realizan pruebas de rendimiento que incluyen: el tiempo de inserción, consulta y eliminación de n registros. Los resultados se presentan en varios cuadros comparativos y gráfico s que miden los tiempos de las diferentes pruebas en los dos gestores, y justifica el porqué el uso de una u otra base de datos, así también se subrayan las ventajas de usabilidad de una base de datos no - relacional frente a otra no relacional en el campo e mpresarial.Ingeniero en Sistemas y Telemática\n"}
{"prompt":"Análisis estadísticos de los datos de consumo de agua potable para la ciudad de Cuenca ->","completion":" La presente tesis comprende tres capítulos, el primer capítulo desarrolla las series cronológicas de tiempo en el cual se define ciertos parámetros como: tendencia, variación estacional, variaciones cíclicas aleatorias, además encontramos diversos métodos para dibujar las curvas de tendencia, el capítulo dos desarrolla la variación de la dotación debido al poco control en conexiones, costo mínimo, desperdicio y fugas, por último tenemos en el capítulo tres la relación de variaciones de consumo en el tiempo.Ingeniero CivilCuenca\n"}
{"prompt":"Análisis estadístico multivariado de los datos obtenidos en la encuesta nacional de ingresos y gastos de los hogares urbanos - 2003 ->","completion":" Objetivo principal de esta tesis es proporcionar la informacion estaditica adecuada para realizar el cambio de base del indice de precios al consumidor urbano. se muestra un marco teorico conceptual que se basa la encuesta de ingresos y gastos de los hogares urbanos que va desde la planificacion hasta el analisis de la informacion obtenida. se detallan todas las tecnicas y metodos estadisticos, tanto del analisis univariado como multivariado. se muestra el analisis estadistico univariado y multivariado de cad una de las variables.GuayaquilIngeniero Estadística Informática\n"}
{"prompt":"Análisis estadístico multivariado de los datos obtenidos en la encuesta nacional de ingresos y gastos de los hogares urbanos - 2003 ->","completion":" El objetivo principal de esta tesis es proporcionar la información estadística adecuada para realizar el cambio de base del indice de precios al consumidor urbano. Se muestra un marco teórico conceptual que se basa la encuesta de ingresos y gastos de los hogares urbanos que va desde la planificación hasta el análisis de la información obtenida. Se detallan todas las técnicas y métodos estadísticos, tanto del análisis univariado como multivariado. se muestra el análisis estadístico univariado y multivariado de cada una de las variables.GuayaquilINGENIERÍA EN ESTADÍSTICA INFORMÁTICA\n"}
{"prompt":"Análisis de Estudio de Big Data Orientados a los Grandes Volúmenes de Datos y los Principales Usos de Información Recolectada ->","completion":" ADOBEEn la actualidad, el desarrollo progresivo de la tecnología ha ido acaparando diferentes áreas, tanto así que se vive en una sociedad donde minuto a minuto se va generando una inmensa cantidad de datos que provienen desde el uso de un computador, hasta el uso de un simple sensor lo cual para analizar tanta información nace el término Big Data. Por tal motivo en la presente investigación se aclara en qué consiste Big Data, los beneficios que proporciona al implementarla, por lo que será importante detallar varios casos de éxito en la inserción de Big Data, lo que permitirá ampliar los conocimientos y notar como de un sin número de datos se puede llegar a tomar buenas decisiones que permitan el crecimiento de las empresas. Además, se realizará una comparativa de las distintas distribuciones basadas en Apache Hadoop para elegir la que resulte más conveniente para poder realizar la recopilación de datos que provengan de una red social y luego proceder a analizar si los comentarios obtenidos son positivos, negativos o neutros haciendo uso del software Cloudera y otras herramientas como lo son: Flume, Hive, HDFS, MapReduce y Power View.Today, the progressive development of technology has been taking different areas, so much so we live in a society where minute to minute is generating an immense quantity of information that come from the use of a computer, up to the use of a simple sensor which to analyze so much information is born the term Big Data. This is why in the present investigation is made clear in what is Big Data, the benefits it provides when you deploy it, so it will be important to detail several success stories in the insertion of Big Data, which will expand on the knowledge and noted as of a number of data you can reach good make good decisions that will allow the growth of enterprises. There will also be a comparison of various distribution based on Hadoop to choose the one that is most convenient to make the collection of data that come from a social network and then proceed to analyze whether the comments obtained are positive, negative or neutral using the software Cloudera and other tools such as: Flume, Hive, HDFS, MapReduce and Power View.\n"}
{"prompt":"Análisis y desarrollo de aplicación web para el análisis estadístico de datos de encuestas ->","completion":" Muchos proyectos de investigación se fundamentan en el uso de encuestas para conocer y describir ciertos hechos y realidades. Además de los análisis estadísticos descriptivos e inferenciales comúnmente usados para este tipo de proyectos, resulta útil a los investigadores contar con una aplicación que permita, de manera intuitiva, realizar exploración de datos y cruces de variables de interés. Este proyecto describe el procedimiento seguido para la definición, estructuración e implementación de una aplicación web con las características descritas, utilizando el paquete Shiny que permite generar páginas web dinámicas para el análisis de datos inicial (de forma exploratoria) con R. Como caso de estudio, se utilizaron los datos de la encuesta de movilidad de escolares llevadas a cabo en el proyecto CEPRA-RES “Evaluación de entornos urbanos peatonales para la identificación de rutas escolares seguras en ciudades intermedias del Ecuador, 2020.” El proyecto cuenta también con herramientas que facilitan el descargar y usar la aplicación. Los resultados y conclusiones alcanzados demuestran que la aplicación desarrollada es de gran utilidad para los usuarios que requieren un análisis exploratorio de datos de encuestas, y para los usuarios que desean estudiar o extender el código.Ingeniero en Sistemas y Telemática\n"}
{"prompt":"Estudio de un sistema de recopilación de datos (caja negra) para buses interprovinciales ->","completion":" En este trabajo se realizó un estudio de un sistema de recopilación de datos \"caja negra\" para buses interprovinciales. El estudio se basó en la adaptación de un sistema ya probado en la industria aeronáutica para determinar accidentes aéreos comúnmente llamada \"caja negra\". Se creó la necesidad de este estudio por la creciente accidentabilidad de buses interprovinciales y para determinar las causas reales de los mismos, se realizó la selección de los periféricos para su monitoreo, modelado digital del prototipo y costos del sistema. Como resultado final se encontró que el proyecto es confiable y con el debido apoyo de las instituciones estatales es ejecutable.\n"}
{"prompt":"Prototipo de robot submarino autónomo tipo torpedo para recopilación de datos oceanográficos. ->","completion":" El presente documento presenta el diseño y construcción de un robot submarino tipo torpedo este equipo está diseñado de tal manera que pueda llegar a desplazarse en el mar con gran rapidez por su diseño hidrodinámico, es utilizado para la recolección de datos oceanográficos, se inicia el diseño 3D del robot con el software Freecad para luego imprimir las piezas más importantes de la estructura del robot y demostrar su flotabilidad e hidrodinámica, la mayoría de los elementos que componen la estructura se encuentran a nivel local como son tubos PVC, tapones PVC y ejes acerados. El diseño realizado posee 2 pares de timones que darán motricidad al robot, el dispositivo encargado de accionarlos son los servomotores que son dispositivos que dependiendo del ancho de pulso enviado se colocaran en posiciones diferentes que van desde los 0° a los 180°, los propulsores son de diseño profesional adquiridos para este trabajo, la parte de control y autonomía del robot está basada en el uso de software y hardware libre. Se diseñó e imprimió un mando inalámbrico para el control del robot para que se utilice cuando esté en la superficie, el robot submarino y el mando inalámbrico tendrán un alcance de máximo 200 metros, en la PCB de la tarjeta de control se realizó una etapa para cargar inalámbricamente un firmware, este proceso se lo realiza para evitar desmontar la parte electrónica de los recipientes herméticos cada vez que se necesite hacer algún cambio en el firmware de la tarjeta principal, además el mando inalámbrico se comunica con la aplicación móvil para presentar en mapas virtuales la trayectoria recorrida por el robot. El robot tiene la capacidad de desplazarse utilizando el método de recorrido deducido y en su interior posee un sensor lm35 que ha sido hermetizado en la parte de los pines para evitar que tengan contactos con el agua, con la finalidad de recolectar datos oceanográficos como temperatura y mostrar en la aplicación.\n"}
{"prompt":"Sistema automático georreferenciado para recopilación de datos técnicos en estaciones Base ->","completion":" El presente proyecto de grado comprende el estudio, diseño e implementación de un sistema automático que permite controlar el trabajo realizado por un proveedor de mantenimiento externo a las estaciones base de Telefónica-Movistar Ecuador, usando para ello un sistema integral georeferenciado, el cual está constituido por la aplicación móvil que se encuentra en los equipos celulares de los técnicos de campo, conectividad de los mismos con los servidores de La Compañía, y la presentación de datos en forma de reportes ejecutivos a través de la página web de Telefónica. Mediante la georeferencia incluida en la recopilación de datos en campo, se pudo determinar si los reportes se estaban completando desde las estaciones correspondientes así como en la fecha planificada, esto, mediante la comparación con una tabla de coordenadas geográficas pre-cargadas de las estaciones base en el servidor de intranet de La Compañía.\n"}
{"prompt":"Interfaz de recolección de datos mediante bluetooth de presiones plantares en la caminata ->","completion":" Implementar una interfaz de recolección de datos mediante bluetooth de presiones plantares en la caminata.El presente documento es la investigación y desarrollo de una interfaz baropodométrica, donde se emplea principios básicos en programación para el desarrollo de un HMI amigable para el usuario, aplicando la estandarización de las normas ISO 9241 de ergonomía visual y la creación de una base de datos para el almacenamiento del historial médico del paciente, así como también para las señales de sensores que posteriormente se usarán como fotogramas. Las superficies plantares están diseñadas acorde a las indagaciones con respecto a la podometría. También se utiliza conocimientos fundamentales en electrónica donde se usa microcontroladores, módulos, reguladores de voltaje entre otros. Adicional a esto se hace uso de métodos matemáticos para la conversión de señal análoga a digital, digital a pixeles y funciones para el uso un filtro pasa bajas. Los resultados están basados bajo el criterio de la variación de resistencia, así como también el uso de sensores de fuerza modelo FSR 402, esta última permite cargas de hasta 10kg con lecturas relativamente precisas. Finalmente, se muestra el dispositivo de adquisición de datos como un elemento estándar, es decir, que permite la variación del acondicionamiento, así como también de sus ecuaciones para el uso de otros sensores de fuerza FSR.Ingeniería\n"}
{"prompt":"Desarrollo de una aplicación móvil que permita la recopilación automática de datos relacionados con imperfecciones en la calzada para el Distrito Metropolitano de Quito ->","completion":" En este documento se presenta el desarrollo de un sistema informático que está conformado por una aplicación móvil y una aplicación web, en donde el apartado móvil se encargará de capturar y registrar automáticamente datos que estén relacionados con la posible existencia de desperfectos en las vías, haciendo uso de los recursos de hardware de los dispositivos móviles tales como, el acelerómetro y el GPS, ayudando a que el usuario interactúe lo menos posible con la aplicación móvil, por otro lado, el apartado web tendrá la finalidad de que los usuarios puedan tener acceso libre a los datos recolectados, para visualizar los registros y con opción a descargar los datos para su análisis. La recolección de los datos en este proyecto se enfoca en las vías de la ciudad de Quito DM, todo esto con la finalidad de delimitar el espacio geográfico para una mejor recolección de datos al momento de entrar en la fase de pruebas del aplicativo. La construcción de este sistema informático permite usar uno de los bienes más comunes de hoy en día por los usuarios como son los dispositivos móviles inteligentes, de manera que se pueda optimizar recursos, es decir, obtener buenos resultados con la mayor eficiencia a la hora de recolectar los datos mientras el usuario conduce su vehículo.This document presents the development of a computer system that is made up of a mobile application and a web application, where the mobile section will be in charge of automatically capturing and recording data that are related to the possible existence of damage to the roads, making use of the hardware resources of mobile devices such as the accelerometer and GPS, helping the user to interact as little as possible with the mobile application, on the other hand, the web section will have the purpose that users can have access free to the data collected, to view the records and with the option to download the data for analysis. The data collection in this project focuses on the roads of the city of Quito DM, all this with the purpose of delimiting the geographical space for a better data collection when entering the testing phase of the application. The construction of this computer system allows users to use one of the most common assets today, such as smart mobile devices, so that resources can be optimized, that is, obtain good results with the greatest efficiency when it comes to collect the data while the user drives their vehicle.\n"}
{"prompt":"Creación de un plan promocional para la distribuidora de llantas comercial Marthita dirigido a la cooperativa de taxis 5 de febrero. ->","completion":" pdfEl marketing como recurso en una organización cumple un papel fundamental mediante el cual se espera obtener un reconocimiento de la marca, constancia y acercamiento con los clientes potenciales y reales, con el fin de generar incremento en los ingresos económicos de la empresa. La crisis económica al ser un problema de índole mundial, repercute en el Ecuador, ya que ocasiona que las empresas tengan que ajustar sus gastos de operaciones y esto conlleva a un funcionamiento limitado. Hay muchas compañías que no aprovechan de manera correcta las estrategias de marketing que es una clave muy importante para promover los negocios y aumentar sus ventas. La comercializadora de llantas \"Marthita\" ofrece a su clientela una gama de productos como llantas, baterías y tubos, además servicios que se basan en el confort, garantía y economía. El presente trabajo propone analizar la situación de la comercializadora para planificar una estrategia promocional que permita captar la clientela de la cooperativa de taxis enfocándose en la Cooperativa de taxis “5 de Febrero”. Con la información recabada de los instrumentos de recolección de datos más los fundamentos teóricos basados en Marketing, planeación estratégica, segmentación y análisis del mercado se pudo determinar estrategias de marketing dirigidas a la cooperativa de taxis “5 de Febrero” Los actores involucrados en esta investigación fueron la autora, el dueño del negocio y los socios de la cooperativa de taxis.\n"}
{"prompt":"“Desarrollo de un prototipo para automatizar el proceso de recopilacion de datos de tanques de hipoclorito aplicado en una RED LAN” ->","completion":" PDFEl presente proyecto de titulación tiene como objetivo el desarrollo de un sistema de recopilación de datos de tanques de hipoclorito aplicado en una red LAN , esto se realiza de forma manual por un operador que recopilar esa información en papeles que pueden alterarse o destruirse la información exponiendo al trabajador a ir al área de llenado exponiéndose a algún accidente laboral se necesita automatizar el proceso de recopilación de datos con el sistema los pesos exactos de la balanzas ip llegarían al servidor de manera automática para administrar de manera eficiente y garantizar datos fiables. Proporcionar una herramienta para las industrias que requieren tener un sistema que pueda dar el valor exacto de llenado en los tanques de hipoclorito y llevarlos a un servidor y hacer reportes detallados mensuales de la venta de su producto. A través de un sistema informático el cual automatizara el proceso de registro de llenado de tanques de hipoclorito así evitar la manipulación humana y así reducir los accidentes laborales.This qualification project deals with the compilation of the weight data by means of an Ip balance, this is done manually by an operator that collects that information in papers that can alter or destroy the information exposing the worker to go to the area of Filling exposing yourself to a job accident you need to automate the data collection process with the system the exact weights of the IP scales would automatically reach the server to efficiently manage and ensure reliable data. Provide a tool for industries that need to have a system that can give the exact filling value in the hypochlorite tanks and take them to a server and make detailed monthly reports of the sale of their product. Through a computer system which will automate the process of registering the filling of hypochlorite tanks thus avoiding human manipulation and thus reducing work accident.\n"}
{"prompt":"Desarrollo de un prototipo computacional de diagnóstico de averías mediante recopilación de datos del sensor CKP de un motor Daewoo GM F16D3A ->","completion":" El documento muestra la metodología empleada para el análisis de la señal del sensor CKP de tipo inductivo, en un motor Daewoo GM F16D3A con el fin de crear un sistema de diagnóstico de averías basado en redes neuronales y por consecuencia la clasificación de parámetros estadísticos de acuerdo a condiciones de funcionamiento supervisadas.The paper shows the methodology used for the analysis of the CKP sensor signal of inductive type, in a Daewoo GM F16D3A engine in order to create a fault diagnosis system based on neural networks and consequently the classification of statistical parameters according to supervised operating conditions.\n"}
{"prompt":"Diseño e implementación de sistema de información y recopilación de datos sobre lugares turísticos para visitantes, gestionado mediante una plataforma web y códigos QR. ->","completion":" PDFEste proyecto de tesis se realizó con el propósito de fomentar el turismo mediante el uso de nuevas tecnologías como los códigos QR y una plataforma web, en la cual se compartirá información relevante sobre los lugares turísticos de un sector en particular, en esta ocasión la Cabecera Cantonal del cantón San Jacinto de Yaguachi, la cual fue recopilada de fuentes fidedignas y confiables, cabe recalcar que el uso de los códigos QR ha ido en aumento debido a la facilidad con la que se puede difundir información manteniendo las normas de bioseguridad adecuadas.This thesis project was carried out with the purpose of promoting tourism through the use of new technologies such as QR codes and a web platform, in which relevant information about the tourist places of a particular sector will be shared, on this occasion the Header Cantonal of the San Jacinto de Yaguachi canton, which was compiled from reliable and reliable sources, it should be emphasized that the use of QR codes has been increasing due to the ease with which information can be disseminated while maintaining adequate biosafety standards.\n"}
{"prompt":"Recopilación y análisis de datos sobre la experiencia de usuario de redes 4G&#150; LTE en zonas urbanas de la ciudad de Loja ->","completion":" Resumen: A nivel mundialcomo en el Ecuador, se percibe una gran evolución de los sistemas de telecomunicaciones como la tecnología 4G LTE prestadas por operadoras de servicio móvil avanzado; las mismas que garantizan un mejor servicio y mayor capacidad de red. En este estudio,se recopiló y analizó estadísticamente la experiencia delusuario de redes 4G-LTE en zonas urbanas de la ciudad de Loja,obteniendo dicha información mediante la aplicación móvil (G-Net Track Pro). Además,se recolectó datos subjetivos mediante encuestas,para obtener una base de datos, fundamentada en la metodología experimental;que a través del análisis estadístico correlacional y de regresión, permitió obtener como resultado una ecuación que de acuerdo a los parámetros: nivel de potencia (RSRP), velocidad de bajada (DL) y subida (UL). Se predice el índice de experiencia de usuario de acuerdo al estado de la red; concluyendo que, las variables mencionadas estadísticamente son significativas, en cuanto a la experiencia del usuario en el uso de la red móvil de datos.\n"}
{"prompt":"Desarrollo de un modelo para la recopilación de datos geoespaciales de la infraestructura productiva del gobierno provincial de Chimborazo con dispositivos móviles ->","completion":" 1.Introducción. --2.Planteamiento de la Propuesta de Trabajo. --3. Marco Teórico. --4. Metodología. --5. Resultados. --6. Conclusiones y Recomendaciones.El presente trabajo de investigación tiene como objetivo el desarrollo de un modelo para la recopilación de datos geoespaciales de la infraestructura productiva del Gobierno Provincial de Chimborazo usando dispositivos móviles y herramientas open source. El modelo se basa en una adecuación del método de Desarrollo Rápido de Aplicaciones en sus fases de modelado de gestión, datos, procesos, aplicaciones y pruebas. Se utiliza el método inductivo así también las técnicas de investigación como: observación y encuesta; para la observación se utiliza la ficha como instrumento y para la encuesta la aplicación de dos cuestionarios y una entrevista. Previo al proceso de recopilación de la información se configura el servidor de datos y de aplicaciones, posteriormente se crea un formulario electrónico con la información de las características de la infraestructura productiva, para ser descargado e instalado desde los dispositivos móviles del personal a cargo. Dicho formulario sirve para el levantamiento de la información en sitio, tanto de datos geoespaciales como no geográficos. Para validar el modelo propuesto se utiliza una encuesta de satisfacción del cliente, y además se realiza un análisis con indicadores de eficiencia en tiempo, disminución del número de errores y masificación de la información. De los resultados obtenidos se puede afirmar que existe una mejora en el proceso de recolección de datos en sitio y con ello una optimización de tiempo y recursos; disminuyendo errores, centralizando la información y proporcionando información fiable y a tiempo.Pontificia Universidad Católica del Ecuador, Dirección de Investigación y PosgradosMagíster en Gerencia Informática\n"}
{"prompt":"Automatización del proceso de recopilación de información para realizar encuestas a través de una aplicación con datos georeferenciados utilizando la herramienta Maven ->","completion":" Automatizar el proceso manual de recopilación de información para realizar encuestas a través de un sistema webLas Encuestas son una herramienta fundamental al momento de medir impactos, y realizar investigaciones, pero los métodos actuales de recopilación de información son demasiado costosos, extensos además de iterativos por lo que el presente trabajo de grado propone sustituir el procedimiento manual por uno automático que no solo tabule las encuestas sino que además almacene una localidad georeferenciada del usuario y retribuya la información obtenida por el mismo con un pago en monedas electrónicas denominadas FastCoins. En el Primer Capítulo, se describe brevemente la situación actual del proceso de recopilación de encuestas y la manera en la que el sistema propuesto resolverá dichos inconvenientes, los principales objetivos que componen los patrones a seguir para desarrollar el trabajo de grado. En el Segundo Capítulo, se detalla el marco teórico que describe una a una las herramientas de desarrollo y la metodología que permitirán la creación del sistema encuestador. En el Tercer Capítulo, se realiza un breve estudio comparativo de varias herramientas que permiten el alojamiento y ejecución de proyectos en la nube, basados en varias métricas que permiten analizar la herramienta idónea para este proyecto. En el Cuarto Capítulo, se realiza la construcción e implementación de cada una de las fases que componen la metodología XP y los documentos que de esta se desprenden además de detallar las iteraciones y cada uno de los requisitos para el desarrollo del sistema de encuestas. En el Quinto Capítulo, se mencionan cada uno de los gastos correspondientes al desarrollo del trabajo de grado, además de las conclusiones y recomendaciones que se han generado a lo largo del proyecto.Ingeniería\n"}
{"prompt":"Evaluación de la presencia de especies nativas, endémicas e introducidas en remanentes alrededor de la ciudad de Quito ->","completion":" Este trabajo intenta evaluar la presencia de especies vegetales que habitan en remanentes ubicados alrededor de la ciudad de Quito. Se colectaron especímenes que presentan formas de vida arbórea, arbustiva, subarbustiva, herbácea y epífita en 10 localidades. La ubicación fue la siguiente: hacia el norte de la ciudad, el volcán extinto Casitahua y Culebrillas en San Antonio de Pichincha, al noreste Tababela, al este Sigsipamba, al sureste el Ilaló en dos puntos, hacia Tumbaco y Guangopolo; al sur el volcán Pasochoa, al suroeste el volcán Atacazo y al oeste la parroquia de Lloa. Se colectaron 526 muestras, clasificadas en 291 especies, de las cuales 213 son nativas, 9 son endémicas, 30 introducidas, 2 cultivadas y 38 no identificadas.\n"}
{"prompt":"Etnografía visual de las prácticas estatales en el Registro Civil, años 1965-2005: interpretación sobre la base de la película \"La muerte de un burócrata\" ->","completion":" The present scientific article, reasons on the visual resources interpreted in the light of the film \"The death of a bureaucrat\", that show the visual ethnography, the manifestations and behaviors that approach the reality of the social meanings of the practices of the street bureaucracy and how it influences the daily rapprochement with citizens who so much need public services, reflected through the film industry as a modus of everyday life to be shown as a resource that awakens many perceptions. This study in the first instance deciphers the repetitive social meanings of the language forms of the people's apparatus of the film, analyzes the social reliefs that occurred in a real entity (Ecuadorian Civil Registry), and finally compares, reflects and corroborates, whether the modes of conduct; past and present of both corpus, can be associated and converted into organizational competencies.El presente artículo científico, razona sobre los recursos visuales interpretados a la luz de la película “La muerte de un burócrata”, que muestran la etnografía visual, las manifestaciones y conductas que se acercan a la realidad de los significados sociales de las prácticas de la burocracia callejera y cómo ésta influye en el diario acercamiento con la ciudadanía que tanto necesita de los servicios públicos, plasmados éstos a través de la industria cinematográfica como un modus de la cotidianidad para ser mostrados como un recurso que despierta muchas percepciones. Este estudio en primera instancia descifra las significaciones sociales repetitivas de las formas de lenguaje del aparato de personas de la película, analiza los relieves sociales acaecidos en una entidad real (Registro Civil ecuatoriano), y finalmente compara, reflexiona y corrobora, si los modos de conducta; pretéritos y actuales de ambos corpus, se pueden asociar y convertir en competencias organizacionales.\n"}
{"prompt":"Implementación de túnel termoencogible para mejorar la rentabilidad en la Empresa Pintec S.A. ->","completion":" Este documento contiene archivo en PDF.El principal objetivo de esta tesis es la implementación de un túnel termoencogible en la empresa Pinturas Ecuatorianas S.A. para mejorar su rentabilidad automatizando su sistema de embalaje, se realizó un estudio de la situación actual de la empresa por medio de la recopilación de datos actuales y pasados, con los cuales se pudo desarrollar los capítulos de esta tesis. En primer momento se recopiló información básica tales como sus orígenes, su estructura organizacional, sus políticas empresariales, las características de los productos que comercializa, volúmenes de producción, el tamaño de participación en el mercado, su capacidad instalada y utilizada, ventajas y desventajas del producto que comercializa. Por medio de las diferentes herramientas y técnicas del ingeniero industrial se realizó el análisis interno y externo de la empresa. Utilizando los diagramas de flujo, análisis de la cadena de valor (actividades primarias y actividades de apoyo), análisis de las cinco fuerzas de Porter (el poder del comprador, el poder del proveedor, productos sustitutos, los competidores potenciales, la rivalidad entre sus competidores), análisis FODA, Diagrama de Ishikawa, de esta forma de determinaron los diferentes problemas que existen en la empresa y cual de ellos tiene mayor incidencia en la eficiencia de la productividad. Buscando a través del análisis económico respectivo las soluciones mas idóneas que ayuden a mitigar el problema analizado se realizó un cronograma de actividades para el desarrollo de la solución presentada y puesta a consideración en la empresa.The main objective of this thesis is the implementation of a tunnel shrink in the company Pinturas Ecuatorianas S.A. to improve your profitability by automating its packaging system, a study of the current situation of the company by collecting current data and past, with which the chapters of this thesis could be developed. In first At the time, basic information was collected such as its origins, its structure organization, its business policies, the characteristics of the products who sells, production volumes, the size of participation in the market, its installed and used capacity, advantages and disadvantages of the product that it sells. Through the different tools and techniques of the An industrial engineer, the internal and external analysis of the company was carried out. Using the flow charts, analysis of the value chain (activities primary and supporting activities), analysis of Porter's five forces (the power buyer, supplier power, substitute products, competitors potentials, rivalry between your competitors), SWOT analysis, Ishikawa, in this way they determined the different problems that exist in the company and which of them has the greatest impact on the efficiency of the productivity. Looking through the respective economic analysis for solutions most suitable that help mitigate the problem analyzed, a schedule was made of activities for the development of the solution presented and put into consideration in the company.\n"}
{"prompt":"Implementación de un sistema HMI mediante aplicaciones de código abierto para el control y monitoreo de un sistema dinámico real ->","completion":" Implementar un sistema HMI mediante aplicaciones de Código abierto para el control y monitoreo de un sistema dinámico real.Los sistemas de automatización modernos requieren de sistemas de Supervisión, Control y Adquisición de Datos (SCADA) e Interfaz Hombre Máquina (HMI) para el control y monitoreo de plantas, procesos y actividades industriales. La implementación de estos sistemas conlleva a las empresas, y proyectos académicos a invertir grandes sumas de dinero y conseguir operadores especializados para la adaptación de estos sistemas dinámicos. En este trabajo se presentan resultados sobre el diseño e implementación de un dispositivo HMI basado en aplicaciones de código abierto para controlar y monitorear un sistema de presión y temperatura de agua dentro del laboratorio de control, en la carrera de Electricidad perteneciente la Universidad Técnica del Norte. Se utilizó el microcomputador Raspberry Pi 3B como un controlador, conectado a una pantalla LCD Touch de 5 pulgadas para formar el sistema HMI que consta del conjunto hardware y software. El diseño de la Interfaz Gráfica de Usuario (GUI) se realizó con Programación Python y la herramienta Qt Designer basado en widgets clásicos de tecnología de código abierto. La comunicación entre Raspberry y PLC S71200 se realiza mediante el protocolo Modbus TCP\/IP, además, se utiliza el protocolo de comunicación Modbus RTU conexión RS-485 para la comunicación del PLC con el variador de frecuencia Altivar312. Finalmente, la programación en Python escrito en el editor Visual Studio Code junto con la librería PyModbus permitió transferir datos de lectura y escritura en formato real flotante, desde la base de datos dentro del programa del PLC, para controlar los actuadores y monitorear las variables de temperatura, presión y nivel de agua mediante sensores.Ingeniería\n"}
{"prompt":"El investigador: una relación entre sujeto y objeto realmente intensa ->","completion":" Abordamos de manera descriptiva la situación común para el lector en general y aun entre los académicos respecto al estereotipo estrafalario de la figura del investigador, así como lo que desde nuestra perspectiva es su principal característica: la pasión inextinguible por saciar su ansia de conocimiento vinculada a su objeto de estudio. La finalidad es estimular entre la juventud el quehacer de la investigación e incidir en la perspectiva popular de ciertos mitos acerca del hombre de ciencia.\n"}
{"prompt":"Recopilación de la normativa legal que regula la erradicación del trabajo infantil en el Ecuador ->","completion":" En la actualidad es visible que el país ha avanzado a pasos firmes en el tema de la garantía de derechos de niños, niñas y adolescentes, esto lo podemos ver tanto en la normativa nacional, Constitución y el Código de la Niñez y Adolescencia que abrazan la concepción de niño, niña y adolescentes SUJETO DE DERECHOS, y la normativa internacional que en particular protege a estas personas respecto de las diversas situaciones de trabajo infantil; A pesar de los avances normativos y de las intervenciones que ha tenido el Estado a través de los diversos Ministerios es necesario fortalecer una estrategia que ordene los pasos a seguir, al encontrar casos de trabajo infantil. Según datos del INEC existe una importante reducción de la incidencia de trabajo infantil en los últimos años, entre el 2004 y el 2009 por ejemplo se reduce del 16% al 10%; es importante señalar que de acuerdo con el estudio de Juan Ponce y FanderFalconí, anteriormente se encontraba un comportamiento pro clínico del trabajo infantil, es decir aumenta en las épocas de auge económico y se reducía en las épocas de recesión , sin embargo según los estudios realizados por estos mismo autores indican que desde el 2007 existe una tendencia permanente a la disminución de manera independiente del ciclo económico.Diplomado Superior en Derecho Constitucional y Derechos FundamentalesCuenca\n"}
{"prompt":"Recopilación de información sobre materiales de puentes construidos en los últimos años en Ecuador ->","completion":" This work consists on the compilation and classification of several bridges built in Ecuador. The collected bridges will be used as a database for an Artificial Neural Network or ANN program. For this reason, all the bridges shown in this work were classified according to their structural system and the length of their spans...El presente trabajo consiste en la recopilación y clasificación de varios puentes construidos en Ecuador. Los puentes recopilados servirán como base de datos para un programa de Artificial Neural Network o ANN. Por esta razón, todos los puentes mostrados en este trabajo fueron clasificados según su sistema estructural y por la longitud de sus luces...\n"}
{"prompt":"Recopilación y sistematización de las condicionantes técnicas y funcionales de las aulas de educación básica ->","completion":" Este trabajo consiste en la recopilación y sistematización de las normas técnicas y funcionales que deben cumplir las aulas en los espacios de educación básica. El objetivo es conocer cómo se encuentra actualmente nuestra Normativa en comparación con casos internacionales. La tesis aborda, a partir de la conceptualización espacio – educación, una recopilación de toda la información de normas técnicas y estándares tanto nacionales como internacionales, para posteriormente realizar una sistematización y ejemplificación de la aplicación de estos datos encontrados. El trabajo realizado nos permite, finalmente, visualizar la situación de las normas ecuatorianas en el contexto internacional.Magíster en Diseño de Interiores\n"}
{"prompt":"Propuesta de una metodología para la evaluación de métodos de preprocesamiento de trayectorias GPS. ->","completion":" PDFEl presente trabajo de titulación plantea la creación de una metodología generalizada que permita la evaluación de métodos utilizados en el área del preprocesamiento de trayectorias GPS, para ello se plantea la clasificación de trayectorias de manera generalizada en base a la identificación de sus características que pueda abarcar una gran variedad de estas. El desarrollo de la investigación se basa en la exploración de diversos métodos utilizados para el preprocesamiento de trayectorias, que se utilizan para realizar una clasificación en etapas de acuerdo a la aplicabilidad la cuales fueron evaluadas mediante experimentación, utilizando cinco diferentes conjuntos de datos. Para validación de la propuesta se aplicó un juicio de expertos y un análisis mediante estadística descriptiva para identificar si la metodología propuesta es factible, al final los resultados han sido favorablesThis degree work proposes the creation of a generalized methodology that allows the evaluation of methods used in the area of GPS trajectory preprocessing, for it is proposed the classification of trajectories in a generalized manner based on the identification of their characteristics that can cover a wide variety of these. The development of the research is based on the exploration of various methods used for the preprocessing of trajectories, which are used to perform a classification in stages according to the applicability which were evaluated by experimentation, using five different data sets. In order to validate the proposal, an expert judgment and an analysis by descriptive statistics were applied to identify if the proposed methodology is feasible, at the end the results have been favorable\n"}
{"prompt":"Aplicación de La Red Neuronal Artificial Feedforward Backpropagation para la predicción de demanda de energía eléctrica en la Empresa Eléctrica Riobamba S.A. ->","completion":" Esta investigación propone un modelo basado en la red neuronal Artificial Feedforward Back propagation capaz de predecir la demanda de energía eléctrica con un porcentaje de error absoluto inferior al generado por la metodología utilizada por una distribuidora, con lo cual se pretende contribuir con la planificación de operación y mantenimiento de las centrales eléctricas y a su vez servir de modelo para otras instituciones con similares características. Se realizó la observación de campo a las subestaciones y medidores de las tres salidas, donde se obtuvieron 70128 observaciones de los cuales 61344 se utilizó para el entrenamiento de la red y 8784 para las pruebas del modelo. Mediante preprocesamiento de datos se detectó y corrigió 406 datos perdidos y 320 datos atípicos, mismos que en su mayoría corresponden al año 2009 y 2014, se determinó que el porcentaje del error medio absoluto (MAPE) del modelo de predicción de la demanda de energía eléctrica basado en la red neuronal FeedForward Backpropagation fue del 2,63%, mientras que el basado en regresión lineal múltiple fue del 4,56%. Se concluye que el modelo de predicción de la demanda de energía eléctrica basado en la red neuronal FeedForward Backpropagation es tiene mejor rendimiento de predicción. Se recomienda antes de diseñar un modelo neuronal realizar el pre-procesamiento de los datos para corregir datos atípicos, perdidos y suavizado de la serie temporal con el fin de obtener resultados satisfactorios.This research proposes a model based on the artificial neural network Feedforward Back propagation capable of predicting the demand of electric power with a percentage of absolute error lower than the one generated due to the methodology used by a distributor, with which it is intended to contribute to the planning of operation and maintenance of power plants and at the same time to serve as a model for other institutions with similar characteristics. Field observations was performed on the substations and measurers of the three outputs where 70128 observations were obtained, of which 61344 were used for the training of the network and 8784 for tests of the model. Through pre-processing of data it was detected and corrected 406 lost data and 320 atypical data, which the majority correspond to the year 2009 and 2014, it was determined that the percentage of mean absolute error (MAPE) of the prediction model of the demand electrical energy based on the neural network Feedforward Back propagation was 2.63%, while the one based on multiple linear regression was 4.56%. It is concluded that the prediction model of the demand for electrical energy based on the neural network FeedForward Backpropagation holds better prediction performance. Before designing a neural, it is recommended to perform the preprocessing of data to correct atypical data, lost and softened of the time series in order to obtain satisfactory results.\n"}
{"prompt":"Modelo de predicción de la calidad del aire a partir de datos meteorológicos e información del tráfico automovilístico ->","completion":" Air pollution poses a major environmental risk to health. Only by seeking to reduce the levels of this pollution, countries can reduce the burden of disease resulting from stroke, lung cancers and chronic and acute pneumopathies, including asthma. (World Health Organization, 2016). In the article Modeling PM2.5 Urban Pollution Using Machine Learning and Selected Meteorological Parameters published on June 18,2017 by Yves Rybarczyk, Mario Gonzalez and Rasa Zalakeiciute, professors at the University of the Americas; they propose an automatic learning approach based on six years of analysis of meteorological data and pollution in order to predict concentrations of fine particulate matter (PM2).5) from wind levels (speed and direction) and precipitation by applying the Linear Regression algorithm. In this thesis document, Machine Learning concepts are defined as: Supervised Learning, Classifiers, Regression, among other topics. In order to obtain the information, two applications were executed in data collection, which were obtained by the following methods: traffic time data managed by Google Maps. Screens captured from Google Maps, obtaining traffic information represented in red, orange and green, graphically rectangular shape. And finally, data was collected by making a circular area cut. All the information obtained in these three methods was stored in a CSV file, which is refreshed every 10 minutes. Once the CSV files had been obtained, the data preprocessing was carried out, cleaning the information by filling the empty spaces of the CSV files with the ? sign. To load them into the Weka software, we worked with Linear Regression, classifiers such as Neural Networks, SVM, Logistic Regression and KNN. Using the results obtained, confusion matrices were developed for the construction of the ROC curve in order to obtain the best performing supervised learning technique. In the future, an application can be developed with the aim of making this entity aware of the level of contamination to which the population is exposed and taking corrective measures.La contaminación del aire representa un importante riesgo medioambiental para la salud. Únicamente buscando disminuir los niveles de esta contaminación, los países pueden reducir la carga de morbilidad derivada de accidentes cerebrovasculares, cánceres de pulmón y neumopatías crónicas y agudas, entre ellas el asma. (Organización Mundial de la Salud, 2016). En el artículo Modeling PM2.5 Urban Pollution Using Machine Learning and Selected Meteorological Parameters publicado el 18 de Junio de 2017 por Yves Rybarczyk, Mario Gonzalez y Rasa Zalakeiciute, docentes de la Universidad de las Américas; proponen un enfoque de aprendizaje automático basado en seis años de análisis de datos meteorológicos y de contaminación con el fin de predecir las concentraciones de material particulado fino (PM2.5) a partir de los niveles de viento (velocidad y dirección) y precipitación aplicando el algoritmo de Regresión Lineal. En el presente documento de tesis, se definen conceptos de Machine Learning como: Aprendizaje Supervisado, Clasificadores, Regresión, entre otros temas. Para obtener la información, se ejecutaron dos aplicaciones en la recolección de datos, los cuales se obtuvieron por los métodos que a continuación se detallan: datos del tiempo de tráfico administrado por Google Maps. Pantallas capturadas de Google Maps, obteniendo información del tráfico representado en colores rojo, naranja y verde, graficados en forma rectangular. Y, por último, se recolectaron datos realizando un corte de área circular. Toda la información obtenida en estos tres métodos se almacenó en un archivo CSV, el mismo que se refresca cada 10 minutos. Ya obtenidos los archivos CSV, se realizó el preprocesamiento de datos procediendo a una limpieza de la información llenando los espacios vacíos de los archivos CSV con el signo ? para cargarlos en el software Weka, se trabajó con Regresión Lineal, los clasificadores como Redes Neuronales, SVM, Regresión Logística y KNN. Con los resultados obtenidos se elaboraron matrices de confusión para la construcción de la curva ROC a fin de obtener la técnica de aprendizaje supervisado con mejor desempeño. A futuro se podrá desarrollar una aplicación, con el objetivo de que este ente conozca el nivel de contaminación al que la población se expone y tomar medidas correctivas.\n"}
{"prompt":"Diseño de un prototipo de entorno de video vigilancia integrado Open Source utilizando cámaras integradas en vehículos. ->","completion":" El objetivo es el desarrollo de un sistema de video vigilancia utilizando visión artificial para la detección automática y monitoreo en tiempo real del flujo peatonal en el parqueadero de la Facultad de Informática y Electrónica. Utilizando el método científico experimental ya que existe manipulación de la variable independiente directa e indirectamente. Se creó una base de datos que contiene cuatro imágenes características del sistema, posteriormente se realizó una evaluación de los métodos de extracción de contenidos que utilizan CBIR como son SURF y SIFT que permite detector puntos de interés de una imagen invariantes a la escala, rotación y cambio de iluminación. Finalmente, a partir de la detección y descripción de puntos característicos se combinó las imágenes que tengan una porción en común, para ello se localizó los keypoints de ambas y se logró obtener una imagen panorámica. Se determinó que la implementación del Sistema tiene una eficiencia del 89% utilizando el algoritmo Surf con respecto al 56% del algoritmo Sift. Se concluye el sistema de video vigilancia open source basado en cámaras integradas en vehículos si mejoró la localización de la ubicación y mayor cobertura visual para la detección de incidentes en el parqueadero de la Facultad de Informática y Electrónica, utilizado el algoritmo Surf. Se recomienda realizar una combinación de sistemas de extracción de características, ya que esto permitirá construir sistemas de imágenes más robustos.The objective is the development of a video surveillance system using artificial vision for the automatic detection and real-time monitoring of pedestrian flow in the parking lot of the Faculty of Informatics and Electronics, using the experimental scientific method since there is manipulation of the independent variable directly and indirectly. A database containing four characteristic images of the system was created. Subsequently, an evaluation of content extraction methods using CBIR such as SURF and SIFT was performed, which allows detecting points of interest of an image invariant to scale, rotation and illumination change. Finally, based on the detection and description of characteristic points, the images that have a portion in common were combined, for which the keypoints of both were located and a panoramic image was obtained. It was determined that the implementation of the system has an efficiency of 89% using the Surf algorithm with respect to 56% of the Sift algorithm. It is concluded that the open source video surveillance system based on cameras integrated in vehicles did improve the location of the location and greater visual coverage for the detection of incidents in the parking lot of the Faculty of Informatics and Electronics, using the Surf algorithm. It is recommended to perform a combination of feature extraction systems, as this will allow building more robust image systems.\n"}
{"prompt":"Generación de una metodología para el procesamiento de nubes de puntos LIDAR mediante el uso de vehículos aéreos no tripulados, UAV, en el campus ESPE, Sangolquí ->","completion":" Los datos LiDAR hoy en día ya cuentan con un preprocesamiento; información: sin ruido, clasificada y modificada en su densificación; donde se desconoce los procesos de: planificación, toma y depuración. Por lo cual, se ha propuesto establecer una metodología de procesamiento de nubes de puntos provenientes del escaneo LiDAR abordo de UAVs, con el objetivo de optimizar su captura y llevar un control de los productos. La propuesta metodológica inicia con: el conocimiento de las especificaciones técnicas de la aeronave como del sensor, aplicativo que se dará, planificación del vuelo y control, parámetros ideales para la ejecución del vuelo, obtención el archivo LAS, modificar la densidad de la nube de puntos, depuración tanto en errores groseros como en ruido, clasificación automática y manual, obtención de productos (MDS y MDE) y finalmente el control de calidad referente a la exactitud posicional. En la ejecución del escaneo LIDAR con diferentes parámetros, los valores óptimos de captura son: altura de vuelo 50m, velocidad de 4,5 m\/s, utilizando un FOV de 90° y traslapo lateral de 20%. Con respecto a la exactitud posicional planimétrica se ha obtenido en el vuelo 8 (Zona de mayor densidad de puntos) el menor RMSEr de 1,130m y en altimetria para el vuelo 3 (Zona de menor densidad de puntos) un RMSEz de 2,903m (metodología NSSDA). En conclusión, tanto en planimetría como en altimetría los datos se encuentran desplazados, lo cual difiere con lo citado en la teoría, destacando la relevancia de esta investigación con respecto a la evaluación de todo el proceso y los desplazamientos en cuanto a calidad tridimensional.\n"}
{"prompt":"“Aplicación de técnicas de inteligencia artificial para el proyecto piloto de telemedicina – Cayapas” ->","completion":" PDFEl objetivo principal del presente proyecto de titulación es desarrollar un módulo predictivo a través de la implementación de algoritmos de entrenamiento supervisado técnicas de inteligencia artificial machine learning, su uso en el área médica nos permitirá ofrecer grandes avances tecnológicos y el alcance a los servicios en plataformas web ofreciendo una mayor efectividad al momento de realizar los diversos diagnósticos médicos, de este modo los especialistas en el área de la salud, podrán utilizar todos los recursos de la telemedicina, modernizar su área de trabajo y servicios médicos. Con la finalidad de analizar las diferentes enfermedades que puede presentar un paciente, para luego llegar a clasificarlos y codificarlos correctamente en código CIE-10 el cual forma un conjunto de variables con el objetivo de dar apoyo al médico en sus diagnósticos y tratamiento de cada uno de sus pacientes. Para el desarrollo del algoritmo informático el cual hace uso de la minería de datos, el preprocesamiento de lenguaje natural a numérico consta con registros en texto plano, de los cuales se obtuvo, el análisis propuesto, sugerido o corregido por el personal médico de Telemedicina – Cayapas. El algoritmo de predicción implementa técnicas de árboles de decisiones el cual nos permitirán agrupar los datos por patrones que nos ayudarán a calcular el valor esperado y encontrar la decisión óptima para así luego de analizar el respectivo pronostico llegar a clasificarlos por etiquetas o conjuntos de salida mediante cálculos matemáticos permitiendo crear grupos con características o patrones nuevos.The main objective of this degree project is to develop a predictive module through the implementation of supervised training algorithms, artificial intelligence machine learning techniques, its use in the medical area will allow us to offer great technological advances and the scope of platform services. web that offers greater efficiency when making various medical diagnoses, in this way specialists in the health area will be able to use all the resources of telemedicine, modernize their work area and medical services. In order to analyze the different diseases that a patient can present, to then classify them and code them correctly in the ICD-10 code, which forms a set of variables with the aim of supporting the doctor in his diagnoses and treatment of each one. of his patients. For the development of the computer algorithm which makes use of data mining, the preprocessing from natural to numerical language consists of plain text records, from which the analysis proposed, suggested or corrected by the medical staff of Telemedicine was obtained - Cayapas. The prediction algorithm implements decision tree techniques which will allow us to group the data by patterns that will help us calculate the expected value and find the optimal decision so that, after analyzing the respective forecast, we can classify them by labels or output sets using mathematical calculations allowing to create groups with new characteristics or patterns.\n"}
{"prompt":"Reconocimiento de señales de tránsito de velocidad en condiciones extremas de iluminación en el espectro visible ->","completion":" En el presente proyecto se desarrolla un algoritmo de reconocimiento de señales de tránsito de velocidad en condiciones extremas de iluminación en el espectro visible, utilizando visión por computadora e inteligencia artificial, al ingresar la imagen de la señal de tránsito, inicialmente se realiza un preprocesamiento de la imagen para mejorar la calidad de la misma y evitar la variación de iluminación, para luego utilizar el método de extracción de características HOG y utilizar su resultado en el algoritmo de multiclasificación ELM. El algoritmo se entrenó y evaluó sobre una base de datos de señales de tránsito regulatorias (pare, ceda el paso y velocidad) del Ecuador con 17.437 muestras positivas y 30.000 muestras negativas, obteniendo una exactitud de 99,85%, sensibilidad de 99,78% y tiempo de procesamiento de 1,0574 ms, para la clasificación de señales de límite de velocidad se utilizó 15.694 muestras positivas y se obtuvo una exactitud de 96,71%, sensibilidad de 94,16% y tiempo de procesamiento de 6,8223 ms, en total el tiempo de procesamiento de todo el algoritmo alcanzo 8,2087 ms y se comparó con otros algoritmos de aprendizaje de máquina como SVM y Kd-tree utilizando curvas ROC, con su parámetro AUC y tiempos de procesamiento para determinar cuál de los algoritmos tienen mejor desempeño en aplicaciones ADAS en tiempo real.\n"}
{"prompt":"Modelo de detección de intrusos para detectar y evitar la inserción de Malware en una red, basado en técnicas de aprendizaje automático. ->","completion":" PDFLos ciberataques son uno de los principales problemas que afectan a las empresas a nivel mundial. Los causantes detrás de los ataques son conocidos como ciberdelincuentes. Estos aprovechan vulnerabilidades existentes en los sistemas informáticos para efectuar el ataque, ocasionando robo de información confidencial y pérdidas económicas para las empresas u organizaciones afectadas. Es por ello que se busca una alternativa para disminuir este problema, una opción a considerar es el aprendizaje automático como herramienta para mejorar la seguridad informática. El presente trabajo de titulación tuvo como finalidad presentar un modelo de detección de intrusos que hace uso de la tecnica propuesta en el presente trabajo de titulación, la cual combina las técnicas filter y wrapper para la selección de características en la fase de preprocesamiento de datos. El conjunto de datos utilizado para el entrenamiento y prueba de los modelos fue obtenido del repositorio GitHub2 . Se utilizaron algoritmos de clasificación para el entrenamiento de los modelos. En base a la métrica de exactitud se seleccionó al mejor modelo de detección de intrusos, el cual fue entrenado mediante el algoritmo RandomForest. Este modelo consiguió una media del 99,42% de exactitud con la técnica de selección de características propuesta, mejorando en un 0.10% al resultado del modelo entrenado con el mismo algoritmo pero sin el uso de la metodología propuesta. Con ello se evidencia que los modelos entrenados con la metodología propuesta proporcionan rendimientos similares a los modelos que no hacen uso de la misma, contando con 2 Disponible en: https:\/\/github.com\/Te-k\/malware-classification\/blob\/master\/data.csv 23 la ventaja de eliminar aquellas características redundantes del conjunto de datos.Cabe mencionar que, el tiempo de entrenamiento de los modelos con cada unos de los algoritmos para poder evaluar su desempeño y seleccionar al mejor fue de aproximadamente un minuto con diez segundos.Cyberattacks are one of the main problems that affect companies worldwide. The perpetrators behind the attacks are known as cybercriminals. These take advantage of existing vulnerabilities in computer systems to make the attacks, causing theft of confidential information and economic losses for the affected companies or organizations. That is why an alternative is being sought to reduce this problem, an option to consider is machine learning as a tool to improve computer security. The purpose of this thesis work was to present an intrusion detection model that makes use of the technique proposed in the thesis work itself, which combines the filter and wrapper techniques for the selection of characteristics in the data pre-processing phase. The data set used for the training and testing of the models was obtained from the GitHub3 repository. Classification algorithms were used to train the models. Based on the accuracy metric, the best intrusion detection model was selected, which was trained using the RandomForest algorithm. This model achieved a mean of 99.42% accuracy with the proposed feature selection technique, improving by 0.10% the result of the model trained with the same algorithm but without the use of the proposed methodology. This shows that models trained with the proposed methodology provides similar performance to the models that don't use it, with the advantage of eliminating redundant characteristics from the data set. It's worth mentioning that the training time of the models with 3 Available in: https:\/\/github.com\/Te-k\/malware-classification\/blob\/master\/data.csv 25 each one of the algorithms to be able to evaluate their performance and select the best one was approximately one minute and ten seconds.\n"}
{"prompt":"Sistema de desarrollo de estrategias de marketing e inteligencia de negocios usando web mining ->","completion":" Cuando los visitantes interactúan con su sitio, proveen información acerca de ellos y de como responden a su contenido: que enlaces visitaron, donde gastaron más su tiempo, y cuando navegaron. Algunos visitantes pueden incluso dar información de su estilo de vida o proveer nombres y direcciones, productos de competitividad o complementarios. Toda esta información es usualmente almacenada en una base de datos. Como resultado, se tiene mucha información de la Web, visitantes y contenido; pero probablemente no se esta haciendo el mejor uso de esta información. En este artículo describimos el uso de actividades de minería en la Web, que apuntan a la extracción de modelos del comportamiento navegacional de los usuarios de un sitio Web. Los modelos son inferidos del Log de un servidor Web por medio de datos y técnicas de Web Mining. La extracción de conocimiento es realizada con el propósito de ofrecer una vista personalizada y proactiva de los servicios Web para el usuario. Primero describimos el preprocesamiento, pasos en el Log necesarios para limpiar, seleccionar y preparar datos para la extracción de conocimiento. Luego, mostramos y explicamos las tres principales técnicas de Web Mining que usaremos: Reglas de Asociación , Clustering y Patrones Secuenciales.\n"}
{"prompt":"Clasificación y etiquetado de mensajes de Twitter de Ecuador para determinar qué tema tratan utilizando un modelo Transformer de Procesamiento De Lenguaje Natural. ->","completion":" PDFActualmente las redes sociales generan grandes cantidades de datos diariamente, pero muchos de estos datos no son analizados ni procesados, resultando una tarea complicada a la hora de manipularla de forma manual, sin embargo, gracias a las técnicas y métodos del Procesamiento de lenguaje Natural (PLN) es posible poder automatizar estos procesos, debido a que se encarga de comprender la comunicación que existe entre un ser humano y un ordenador. El presente trabajo tiene como objetivo clasificar y etiquetar textos cortos en español utilizando mensajes de Twitter en Ecuador mediante un modelo Transformer pre-entrenado para el procesamiento de lenguaje natural. Se procederá a experimentar y utilizar el modelo Selectra-Medium un modelo ya entrenado para la clasificación y etiquetado de textos, el cual recibe como fuente de datos un conjunto de tweets extraídos y almacenados en un archivo para su posterior análisis, preprocesamiento, clasificación y etiquetados de categorías de manera automática, se establecieron categorías como sociedad, economía, entretenimiento, salud, deportes y delincuencia pudiendo identificar de qué temas tratan o se relacionan dichos textos. Los resultados obtenidos muestran el correcto funcionamiento del modelo, así mismo a través de la comparación y estudio con otros modelos Transformers se identifica que el modelo Selectra-Medium arroja resultados más precisos con un mejor comportamiento y rendimiento. El uso de los modelos Transformers es una herramienta importante para la clasificación y etiquetado de textos en español, obteniendo grandes avances y aportes a investigaciones relacionadas, incluso para mejorar el proceso de toma de decisiones en diferentes entidades.Currently, social networks generate large amounts of data daily, but much of this data is not analyzed or processed, resulting in a complicated task when manipulated manually, however, thanks to the techniques and methods of Natural Language Processing (NLP) it is possible to automate these processes, because it is responsible for understanding the communication that exists between a human being and a computer. The present work aims to classify and label short texts in Spanish using Twitter messages in Ecuador by means of a pre-trained Transformer model for natural language processing. We will proceed to experiment and use the Selectra-Medium model, a model already trained for the classification and labeling of texts, which receives as a data source a set of tweets extracted and stored in a file for subsequent analysis, preprocessing, classification and labeling of categories automatically, categories such as society, economy, entertainment, health, sports and crime were established, being able to identify what topics these texts deal with or are related to. The results obtained show the correct functioning of the model; likewise, through the comparison and study with other Transformers models, it is identified that the Selectra-Medium model yields more accurate results with better behavior and performance. The use of Transformers models is an important tool for the classification and labeling of texts in Spanish, obtaining great advances and contributions to related research, even to improve the decision making process in different entities.\n"}
{"prompt":"Diseño de un sistema de reconocimiento automático de emociones a partir del análisis de la señal de voz ->","completion":" A lo largo del tiempo las emociones han representado un elemento inherente de los seres vivos, mediante una expresión emocional los seres humanos pueden expresar cualquier acción, sentimiento o información de manera implícita y natural. El presente proyecto de investigación tiene como finalidad la identificación de emociones a partir de la señal de voz, utilizando el software Matlab®, mediante la teoría de Machine Learning a través de la técnica de clasificación supervisada. Para la detección de emociones se trabajó con dos bases de datos que contienen un total de 312 audios repartidos equitativamente entre hombre y mujer. Con el objetivo de diferenciar cuatro emociones fundamentales felicidad, enojo, miedo y tristeza; se evaluó las variaciones de un conjunto de características tales como, Entropía, Energía entre otras, logrando un total de 68 características obtenidas de dos maneras diferentes, señal de voz sin ningún preprocesamiento y mediante la Transformada Wavelet; en cada una de ellas se ejecutó un análisis descartando las características que no presentaban gran relevancia para el estudio mediante métodos de selección características propias para cada modelo de clasificación. Obteniendo así un total de 53 características para hombres y 57 para mujeres, las cuales fueron utilizadas para la detección automática de emociones. Lo resultados fueron analizados bajo cuatro parámetros que son exactitud, precisión, sensibilidad y especificidad.\n"}
{"prompt":"Implementación de un módulo de reconocimiento de voz para niños mediante el procesamiento de señales aplicado en un caso práctico. ->","completion":" Se realizó un Módulo de reconocimiento de voz para niños mediante el procesamiento de señales aplicado en el control de un carro robot 4wd a través de comandos de voz: derecha, izquierda, adelante, atrás y para. El programa consta de dos interfaces gráficas desarrolladas en Matlab denominadas base de datos y reconocimiento de voz para niños. En la interfaz base de datos se realizaron los procesos correspondientes a la adquisición de la voz utilizando un micrófono Stereo Headset, una vez adquirida la señal de voz se realizó el preprocesamiento cuyo objetivo fue eliminar silencios indeseados de la señal para lo que se empleó el método de cálculo de energía el que engloba procesos de normalización, determinación del umbral y segmentación. A esta nueva señal se empleó un filtro preénfasis para la acentuación de las frecuencias altas y suavizar el espectro, de esta señal filtrada se extrajo las características de voz a través del Cálculo de Coeficientes de Predicción Lineal (LPC), para obtener la señal patrón se realizó un promedio entre los coeficientes de cada grabación. La segunda interfaz gráfica realiza los mismos procesos descritos anteriormente para la señal de voz a reconocer, luego se realiza una comparación de distancias entre la señal de voz a reconocer y cada una de las señales patrón siendo reconocida el comando de voz cuya distancia sea mínima. De acuerdo a las pruebas realizadas con el Módulo de reconocimiento de voz para niños se determinó que tiene una efectividad total de 84,70% estos resultados fueron comparados con el Módulo existente en el mercado SR-07 utilizado en la tesis “Diseño e implementación del sistema de movimiento direccional de una silla de ruedas para ser controlada por reconocimiento de un patrón de voz mediante electrónica de potencia y motores DC como actuadores”, por lo que concluye que se cumplió con cada uno de los objetivos propuestos en este trabajo de titulación debido a que el módulo implementado proporcionó mejores resultados, sin embargo se recomienda probar los métodos actuales utilizados en el reconocimiento de voz con la finalidad de optimizar aún más los resultados.A Child voice recognition was developed by signal processing applied to the control of 4wd robot car througth voice commands: right, left, forward, backward and halt. The program consists of two graphical interfaces developed in Matlab called database and voice recognition for children. In the database interface processes were performed corresponding to the acquisition of the voice using a Stereo Headset microphone, once acquired the speech signal processing was performed whose objective was to eliminate unwanted silences of the signal for which the method was used of energy calculation which encompasses normalization, threshold determination and segmentation processes. To this new signal, we used a pre-emphasis filter to accentuate the high frequencies and smooth the spectrum, from this filtered signal we extracted the voice characteristics through the Calculation of Linear Prediction Coefficients (LPC), to obtain the signal was performed an average between the coefficients of each recording. The second graphical interface performs the same processes described above for the speech signal to be recognized, then a comparison of distances between the speech signal to be recognized and each of the pattern signals is performed, the speech command having a minimum distance being recognized. According to the tests carried out with the Voice Recognition Module for children, it was determined that it has a total effectiveness of 84.70%.These results were compared with the existing Module in the SR-07 market used in the thesis \"Design and implementation of the System of directional movement of a wheelchair to be controlled by recognition of a voice pattern by means of power electronics and DC motors as actuators \", thus concluding that it fulfilled each of the objectives proposed in this titration work due to that the implemented module provided better results, however it is recommended to test the current methods used in voice recognition in order to further optimize the results.\n"}
{"prompt":"Análisis de amenazas de seguridad basado en la detección de anomalías en el tráfico de red de la infraestructura tecnológica de instituciones de educación superior mediante el uso de técnicas de machine learning ->","completion":" Las redes de comunicaciones han experimentado una evolución sin precedentes, debido principalmente a un aumento significativo del tráfico de datos. Esto convierte el tema de la seguridad de las infraestructuras tecnológicas en un punto importante a tratar dentro del ámbito de las Instituciones de Educación Superior (IES). Este tipo de instituciones manejan grandes cantidades de datos, que implican un aumento en el tráfico de red; por ello, el número de anomalías o vulnerabilidades han ido aumentado progresivamente. Estos ataques a la seguridad implican amenazas a la confidencialidad, integridad y\/o disponibilidad de los datos manejados. Sin embargo, existen herramientas tales como los algoritmos de Machine Learning (ML), que permiten la detección previa de este tipo de eventos. En este marco, el presente trabajo experimental realiza la implementación de un framework que permita la detección de anomalías dentro del tráfico de red de las IES mediante la aplicación de técnicas de ML, concretamente en el caso de la Universidad Nacional del Chimborazo (UNACH). Para ello, se analizó una recopilación de eventos correspondientes a un lapso de tiempo a través de la pila Elasticsearch, Logstash y Kibana (ELK); sometiéndolos a etapas de preprocesamiento, almacenamiento y visualización de datos para su análisis. A través de la aplicación del algoritmo K-Means, desarrollado mediante la librería Scikit-Learn de Python y el software Weka, se realizó un total de tres experimentos sobre los eventos recolectados. Esto permitió la detección de potenciales amenazas o anomalías, que serán presentadas y corroboradas mediante el uso de dashboards desarrollados en Kibana. A través de la implementación de este framework, se verificó la utilidad de los algoritmos de clusterización como herramienta óptima para la detección de anomalías dentro de una red universitaria. Obteniendo comportamientos anómalos dentro de la red tales como interferencias, solapamientos de canales, autenticación de usuarios no identificados o identificación de Access Points (AP) no autorizados.Communications networks have undergone unprecedented developments, mainly due to a significant increase in data traffic. This makes the issue of the security of technological infrastructures an important point to be addressed within the scope of Higher Education Institutions. These types of institutions handle large amounts of data, which imply an increase in network traffic; therefore, the anomalies or vulnerabilities number’s have been progressively increasing. These security attacks involve threats to the confidentiality, integrity and\/or availability of the data handled. However, there are tools such as ML algorithms, which allow pre-detection of such events. The present experimental work carries out the framework’s implementation that allows anomalies’ detection in the Higher Education Institutions network’s traffic applying ML techniques, specifically in the UNACH case. To do this, a collection of events corresponding to a time lapse was analyzed through the ELK stack; subjected to data’s preprocessing stages, storage and visualization for the analysis. Through the application of the K-Means algorithm, developed through Python’s Scikit-Learn library and Weka software, a total of three experiments were performed on the collected events. This allowed the detection of potential threats or anomalies, which will be presented and corroborated using dashboards developed in Kibana. Through the implementation of this framework, the clusterization algorithms’ utility was verified as an optimal tool for the anomalies’ detection within a university network. Obtaining anomalous behaviors within the network such as interference, channel overlaps, authentication of unidentified users or identification of unauthorized AP.Ingeniero en Electrónica y TelecomunicacionesCuenca\n"}
{"prompt":"Diseño e implementación de un algoritmo de control predictivo para una planta de flujo utilizando un controlador de automatización programable para el Laboratorio de Redes Industriales y Control de Procesos de la Universidad de las Fuerzas Armadas - ESPE Extensión Latacunga. ->","completion":" En este proyecto se realiza el diseño, simulación e implementación de un controlador predictivo basado en modelos, conocido como MPC (del inglés Model Predictive Control), aplicado a una planta de control de flujo en el laboratorio de Redes Industriales y Control de Procesos de la Universidad de las Fuerzas Armadas ESPE Extensión Latacunga. La simulación se realiza en el software LabVIEW, la implementación es sobre un dispositivo NI myRIO, gracias a la flexibilidad que ofrecen en software y hardware para este tipo de control en particular. El MPC diseñado cuenta con las siguientes características: una función de costo que busca minimizar las acciones de control necesarias para corregir el error futuro, calculado en base al modelo de predicción, sujeto a restricciones de desigualdad que vienen definidas por el proceso y sus condiciones de operación, además se requiere de una etapa de optimización que envia las acciones de control óptimas. Para un buen diseño del MPC se requiere de un buen modelo de la planta y del modelo de predicción. El modelamiento de la planta de flujo se realiza empleando ecuaciones en espacio de estados, para lo cual se propone y valida una metodología que incluye las etapas de: obtención de datos, adquisición de datos, preprocesamiento de datos, modelamiento y validación. Se muestran la simulación del comportamiento del controlador en lazo cerrado, esto principalmente para obtener valores de diseño ajustables como: tamaño del horizonte de predicción y control, matrices de ponderación y restricciones del sistema; que son usados de referencia para la implementación. Finalmente se implementa el algoritmo de control en el proceso de flujo real para analizar su desempeño. Este controlador fue comparado con un PID evaluando: tiempo de estabilización, porcentaje de sobreimpulso y acciones de control, demostrando su superioridad.\n"}
{"prompt":"Artículo Científico - Diseño e implementación de un algoritmo de control predictivo para una planta de flujo utilizando un controlador de automatización programable para el Laboratorio de Redes Industriales y Control de Procesos de la Universidad de las Fuerzas Armadas - ESPE Extensión Latacunga. ->","completion":" En este proyecto se realiza el diseño, simulación e implementación de un controlador predictivo basado en modelos, conocido como MPC (del inglés Model Predictive Control), aplicado a una planta de control de flujo en el laboratorio de Redes Industriales y Control de Procesos de la Universidad de las Fuerzas Armadas ESPE Extensión Latacunga. La simulación se realiza en el software LabVIEW, la implementación es sobre un dispositivo NI myRIO, gracias a la flexibilidad que ofrecen en software y hardware para este tipo de control en particular. El MPC diseñado cuenta con las siguientes características: una función de costo que busca minimizar las acciones de control necesarias para corregir el error futuro, calculado en base al modelo de predicción, sujeto a restricciones de desigualdad que vienen definidas por el proceso y sus condiciones de operación, además se requiere de una etapa de optimización que envia las acciones de control óptimas. Para un buen diseño del MPC se requiere de un buen modelo de la planta y del modelo de predicción. El modelamiento de la planta de flujo se realiza empleando ecuaciones en espacio de estados, para lo cual se propone y valida una metodología que incluye las etapas de: obtención de datos, adquisición de datos, preprocesamiento de datos, modelamiento y validación. Se muestran la simulación del comportamiento del controlador en lazo cerrado, esto principalmente para obtener valores de diseño ajustables como: tamaño del horizonte de predicción y control, matrices de ponderación y restricciones del sistema; que son usados de referencia para la implementación. Finalmente se implementa el algoritmo de control en el proceso de flujo real para analizar su desempeño. Este controlador fue comparado con un PID evaluando: tiempo de estabilización, porcentaje de sobreimpulso y acciones de control, demostrando su superioridad.\n"}
{"prompt":"Estudio de la deforestación de bosque tropical amazónico mediante un análisis multitemporal de imágenes RADAR (SAR). ->","completion":" The research’s aims is to analyze deforestation in the Amazonian tropical forest by using SAR images, taking as a starting point the significant problem related to forest cover loss due to anthropic activities such as the expansion of the agricultural, livestock or logging frontier. SAR images have advantageous characteristics when detecting changes in an area; therefore, a chain of pre-processing and data management was established to obtain deforested sites and calculate forest loss rates from 2016 to 2020. Two different methodologies were applied: the first developed by Vargas et al. (2019) with automatic deforestation detection using VH polarization on an annual basis; and the second through a change detection algorithm developed by Canty (2020) on Google Colab portal every two years. Each methodology subjected to validation yielded positive precision results, with Canty's algorithm (2020) being the methodology that best detects changes due to deforestation by managing two polarizations (VH-VV). Regarding the deforestation analysis, rates of around -0.85% were reported. However, the results obtained are slightly lower than those calculated with data from the environmental authority (-1.09% for the 2016-2018 period). Both methodologies indicate the great potential of SAR images in detecting deforestation in tropical forests.El presente trabajo tiene como objetivo el análisis de deforestación en el bosque tropical amazónico con el uso de imágenes SAR, tomando como punto de partida la gran problemática relacionada a la pérdida de cobertura de bosque a causa de actividades antrópicas como la expansión de la frontera agrícola, ganadera o la explotación de la madera. Las imágenes SAR poseen características muy útiles al momento de detectar cambios en un área, por ello se estableció una cadena de preprocesamiento y manejo de datos que nos permita obtener zonas deforestadas y calcular tasas de pérdida de bosque desde el año 2016 hasta el año 2020. Se aplicaron dos metodologías distintas: la primera desarrollada por Vargas et al. (2019) con detección automática de deforestación utilizando la polarización VH de manera anual; y la segunda a través de un algoritmo de detección de cambios desarrollado por Canty (2020) en el portal Google Colab de forma bianual. Cada metodología sometida a validación arrojó resultados de precisión positivos, siendo el algoritmo de Canty (2020) la metodología que mejor detecta los cambios por deforestación a través del manejo de dos polarizaciones (VH-VV). En cuanto al análisis de deforestación, se reportan tasas de alrededor de -0,85%; no obstante los resultados obtenidos son ligeramente inferiores a los calculados con datos de la autoridad ambiental (tasa de -1,09% en el periodo 2016-2018). Las dos metodologías indican el gran potencial de las imágenes SAR en la detección de deforestación en bosques tropicalesUNACH, Ecuador\n"}
{"prompt":"Análisis de técnicas de validación en modelos aprendizaje automático aplicadas en series tiempo de variable energéticas de un edificio universitario. ->","completion":" PDFEl ahorro de energía o reducción del consumo de energía es la forma más fácil y efectiva de reducir las emisiones de dióxido de carbono y otros gases contaminantes a la atmósfera; a fin de combatir el calentamiento global y el cambio climático. En este trabajo de titulación se propone tres modelos de Machine Learning supervisado para que sean evaluadas por técnicas de validación cruzada y poder elegir el mejor luego de comparar los valores de sus métricas de pronósticos entre los modelos. Se utiliza la metodología de experimentación de prueba y error como herramienta de investigación a un conjunto de datos obtenido de sensores ubicados en el edificio de la Facultad de Ciencias Matemáticas y Físicas. El conjunto de datos fue sometido a un preprocesamiento para tratamiento de datos nulos y atípicos. Los modelos de aprendizaje automático supervisado escogidos para la experimentación son Random Forest, SVR y XGBoost. Estos modelos pasaron por una afinación de hiperparámetros y así elegir el mejor modelo de cada uno para una mejor precisión de resultados. Se proponen cuatro escenarios considerando cada técnica de validación escogida luego de un análisis de literatura como KFold, ShuffleSplit, RepeatedKFold y TimeSeriesSplit. Los resultados que arrojaron la evaluación de las cuatro técnicas, utilizando el conjunto de datos de prueba o testing indican que el modelo Support Vector Regression (SVR) es el más adecuado y que podrá predecir con más exactitud en escenarios para series de tiempo.Saving energy or reducing energy consumption is the easiest and most effective way to reduce emissions of carbon dioxide and other polluting gases into the atmosphere; in order to combat global warming and climate change. In this degree work, three supervised Machine Learning models are proposed to be evaluated by cross-validation techniques in order to choose the best one after comparing the values of their forecast metrics among the models. Trial and error experimentation methodology is used as a research tool to a dataset obtained from sensors located in the Faculty building. The data set was subjected to preprocessing for treatment of null and outlier data. The supervised machine learning models chosen for experimentation are Random Forest, SVR and XGBoost. These models underwent hyperparameter tuning to choose the best model of each for better accuracy of results. Four scenarios are proposed considering each validation technique chosen after a literature analysis such as KFold, ShuffleSplit, RepeatedKFold and TimeSeriesSplit. The results of the evaluation of the four techniques using the test data set indicate that XGBoost is the best model for predicting future values of electricity consumption in the building of the Faculty of Mathematical and Physical Sciences according to KFold, ShuffleSplit and TimeSeries Split. In the case of RepeatedKFold technique its results indicated that the best model is SVR.\n"}
{"prompt":"Normalización de entradas de una red de Kohonen para clasificación de síndrome metabólico en adultos mayores de la ciudad de Cuenca ->","completion":" One of the challenges in using Kohonen self-Organizing maps (SOM) is the pre-processing or normalization of input variables. In the present work two pre-processing techniques (binary and by ranges) of the variables to diagnose Metabolic Syndrome (MS) in older adults of the urban districts of Cuenca are explored. Three experiments were carried out considering the entire population (N=387) and dividing the population by sex; in each experiment 3 clusters were defined. The results, using pre-processing by ranges allow a better classification of the population in all cases. This study allowed us to select the type of pre-processing for the diagnosis of MS in the elderly population of the city of Cuenca using SOM.Uno de los desafíos al usar mapas autoorganizativos de Kohonen (SOM) es el preprocesamiento o normalización de las variables de entrada. En el presente trabajo se exploran dos técnicas preprocesamiento (binaria y por rangos) de las variables para diagnosticar Síndrome Metabólico (SM) en adultos mayores de las parroquias urbanas de Cuenca. Se realizaron tres experimentos: considerando toda la población (N=387) y dividiendo la población por sexos, en cada experiencia se definieron 3 clústeres. Los resultados, usando un preprocesamiento por rangos, permiten una mejor clasificación de la población en todos los casos. Este estudio ha permitido seleccionar el tipo de preprocesamiento para el diagnóstico de SM en la población de Adultos Mayores (AM) de la ciudad de Cuenca usando SOM.\n"}
{"prompt":"Evaluación de técnicas de procesamiento de lenguaje natural para textos cortos en lenguaje español ->","completion":" El Procesamiento de Lenguaje Natural identifica información clave, generando modelos predictivos y explicando eventos o tendencias mundiales, creando conocimiento, por ello, es importante aplicar técnicas de refinamiento en etapas principales como el pre-procesamiento, al producirse con frecuencia datos y procesamiento con resultados deficientes. Este documento analiza y mide el impacto de combinaciones de técnicas y librerías para textos cortos en español, mediante su aplicación en tweets aplicados al análisis de sentimiento, tomando en cuenta parámetros de evaluación en su análisis, el tiempo de procesamiento y características de las técnicas en cada librería. La experimentación demostró que elegir combinaciones de técnicas adecuadas en el pre-procesamiento, proporciona una mejora de hasta un 5% y 9% en el rendimiento de la clasificación.Ingeniero en Sistemas y Telemática\n"}
{"prompt":"Minería de opinión para textos en español usando procesamiento natural del lenguaje ->","completion":" Este artículo se propone el desarrollo de una herramienta que permite la minería de opiniones de textos exclusivamente en español. Para ello, se realizó la construcción de un corpus lingüístico a través de tweets. Este corpus se caracteriza por tener tweets en idioma español latinoamericano y español castellano. Los algoritmos de clasificación usados son: Naïve Bayes, SVM y LSTM. Para la evaluación de la propuesta se realizaron experimentos con un corpus de 14.666 con una clasificación en dos clases (positivo y negativo), luego en tres clases (positivo, negativo, neutro). Los Resultados obtenidos muestran que la clasificación binaria obtuvo mejores resultados que en la clasificación a tres clases en los tres algoritmos.This paper proposes development of a tool that allows opinion mining of texts exclusively in Spanish. For this, a linguistic corpus has been constructed through tweets. This corpus is characterized by having tweets in Latin American Spanish and Castilian Spanish. The evaluated classification algorithms were: Naive Bayes, SVM, and LSTM. The experiments were carried out with a corpus of 14,666 with a classification in two classes (positive and negative) in three classes (positive, negative, neutral). The results obtained show that the binary classification got better results than the three-class classification in the three algorithms.\n"}
{"prompt":"Clasificación de documentos científicos mediante técnicas de procesamiento de lenguaje natural y minería de texto ->","completion":" Abstract:The Universidad Técnica Particular de Loja, , with the aim of promoting scientific research, creates groups of research lines to create, socialize research and disseminate in several scientific databases. The articles that are included in the different lines. This degree work aims to determine the relationships between the research lines and the terms of the articles uploaded to SCOPUS from 2003 to 2017; through the collection of information, elaboration of vocabulary, supervised classification, preprocessing and data training. The methodology is the \"metametodología\", composed of four principles that allow to obtain the result of the proposed research: obtain the result of 623 documents in plain text; Information on the abstract, the author and the keywords of each article was compiled, and a new classification was made due to inconsistencies in the classification. The application of the nearest k algorithms (KNN) and linear discriminant analysis (LDA) shows the accuracy of the classification of the articles, as well as the relationship that exists between them.\n"}
{"prompt":"Aplicación de DSP's para la transcripción de lenguaje de señas a texto ->","completion":" En el Ecuador existen gran cantidad de personas con deficiencias auditivas, por lo cual el proyecto fue desarrollado para las personas sordomudas que de alguna manera se sienten excluidas de la sociedad y mediante la ayuda del software puedan comunicarse no solo con sus familiares, sino también con el resto de personas que desconocen el lenguaje dactilológico. Para ayudar a mejorar el nivel de vida de las personas sordomudas se diseñó un sistema Traductor de lenguaje de señas a texto, que se enfoca principalmente en traducir la señas y números que realizan la personas con deficiencias auditivas y transformarlas a texto para que aquellas personas que desconocen este lenguaje puedan comunicarse. El proyecto también ofrece un entrenador, el cual cuenta con el abecedario y los números para que aquellas personas que desconocen el lenguaje de señas puedan realizar un aprendizaje adecuado. Basado en el procesamiento digital de imágenes en visión artificial, se reconoce el alfabeto dactilológico ingresado para luego transformarlo a texto, considerando que no existe error en el programa debido a que reconoce cada una de las señas realizadas. Los resultados tienen significado social debido a que el proyecto se desarrolló pensando en las personas con deficiencias auditivas, para que de alguna manera puedan comunicarse con la sociedad en cualquier momento y en cualquier lugar, un ejemplo básico de implementación seria en bancos los cuales aún no cuentan con la tecnología capaz para comunicarse con personas sordomudas sin tener que depender de externos. ABSTRACT In Ecuador there are plenty of people with hearing loss, for which the project was developed for deaf and dumb people who somehow feel excluded from society and through the help of the software can communicate not only with family, but also with other people that not know the language dactilologico. To help improve the living standards of people deaf and dumb system “Traductor de language de Señas a Texto”, which focuses primarily on translating signs and numbers that made the hearing impaired and is designed to transform text to those who know this language they can communicate. The project also offers a trainer, which count with the alphabet and numbers for people that not Know the sign language can perform appropriate learning. Based on digital image processing in artificial vision, recognizes the alphabet dactilologico admitted then transforms to text, whereas there is no error in the program because it recognizes perfectly each of the signs carried. The findings have social significance because the project was developed considering the people with hearing impairments, for that somehow may communicate with society anytime and anywhere, a basic implementation example is a banks which does not yet have the technology to communicate with deaf and mute people without having to rely on outside.\n"}
{"prompt":"Aplicación de técnicas de procesamiento de Lenguaje Natural y Minería de Texto para la clasificación de preguntas dentro de un cuestionario digital. ->","completion":" Along with the increasing number of digital documents that are generated daily in companies, organizations and institutions, arises the necessity to analyze and extract relevant information. This process leads to better management and organization of these data. Therefore this work is focused on establishing a reference guide for the automatic classification of digital questionnaires concerning Discrete Mathematics First Bimestre of the Open Method of the Universidad Técnica Particular de Loja. For the development of this project is the use the CRISP-DM methodology (acronym in English, Cross Industry Standard Process for Data Mining) using text mining techniques (Text Mining) and Natural Language Processing (Natural Language Processing) . The representation of the data is performed by the TDM (Matrix -Term Document) method. Among the best text classification algorithms in Weka, we can mention the DMNtext-I1 and NavieBayesMultinominalUpdateable as between the results of these two algorithms have similarities in their final values Accuracy 0.847, 0.824 and 0.436 Recall of accuary, so both have a 0177 error. These values are the product of the Percentage Split configuration of 66%, 66 training data and 34 test data.Junto con el creciente número de documentos digitales que se generan día a día en las empresas, organizaciones e instituciones surge la necesidad de analizarlos y de extraer información relevante. Este proceso conlleva a una mejor gestión y organización de estos datos. Por tal motivo este trabajo está enfocado en establecer una guía de referencia para la clasificación automática de cuestionarios digitales de la materia de Matemáticas Discretas del Primer Bimestre de la Modalidad Abierta de la Universidad Técnica Particular de Loja. Para el desarrollo de este proyecto se ha utilizado la metodología CRISP-MD (Siglas en inglés, Cross Industry Standard Process for Data Mining) haciendo uso de técnicas de Minería de Texto y de Procesamiento de Lenguaje Natural (PLN). La representación de los datos se realizó mediante los métodos TDM (Matrix -Term Document). Dentro de los mejores algoritmos de clasificación de texto en Weka, se puede mencionar el DMNtext-I1 and NavieBayesMultinominalUpdateable, ya que entre los resultados obtenidos estos dos algoritmos presentan similitudes en sus valores finales Precisión de 0.847, Recall 0.824 y 0.436 de Accuary, por lo tanto se tiene un Error de 0.177. Estos valores son producto de la configuración Porcentaje Split de 66%, datos de entrenamiento 66 y 34 datos de prueba.\n"}
{"prompt":"Desarrollo de un sistema de análisis de textos basado en procesamiento de lenguaje natural y servicios en la nube para determinar delitos de telecomunicaciones ->","completion":" El desarrollo tecnológico permite que diversas plataformas oferten servicios en la nube, donde destacan los servicios de inteligencia artificial como el procesamiento de lenguaje natural (PLN), la traducción de texto a voz y los asistentes virtuales. Así mismo, los delitos informáticos han experimentado un crecimiento, en Ecuador han sido presentadas 53463 denuncias sobre delitos informáticos entre 2014 y 2020. No obstante, la persecución de los delitos puede resultar compleja y retrasar a los organismos de justicia e incluso puede conducir a la prescripción de los mismos. En este trabajo, se propone una aplicación con una arquitectura orientada a servicios para el análisis de procesos judiciales mediante el uso de un asistente virtual de voz o texto, relacionado posibles delitos informáticos y de telecomunicaciones con la normativa jurídica, a través de modelos de PLN desarrollados en Amazon Web Services (AWS), Microsoft Azure e IBM Watson. Para el entrenamiento de los modelos se recopiló información de diversas fuentes como la Ley Orgánica de Telecomunicaciones, el Código Orgánico Integral Penal y diversos procesos judiciales. Los modelos entrenados han sido comparados y evaluados obteniendo que el modelo de Azure presenta los mejores resultados con un F1 Score de 0.8838, un tiempo de respuesta promedio de 251.8 ms y soporta hasta 80 peticiones simultaneas. El modelo de AWS con un F1 score de 0.8588, tiempo promedio de respuesta 327.43 ms soportando hasta 50 peticiones simultáneas. Luego, el modelo de IBM con un F1 Score de 0.7669, un tiempo promedio de 365.15 ms tolerando hasta 50 peticiones simultáneas.\n"}
{"prompt":"Implementación de herramienta para la extracción de información de documentos de importación utilizando tecnología OCR ->","completion":" El presente trabajo de titulación consiste en la implementación de una herramienta que permita extraer información de documentos de importación utilizando tecnología OCR. El objetivo es desarrollar un programa que permita automatizar el proceso de transcripción de texto de un documento de importación escaneado a un formulario web de manera más efectiva y en menor tiempo. Actualmente este trabajo es realizado por empleados quienes en ciertas ocasiones cometen errores; esto perjudica en el tiempo del proceso y económicamente a la empresa, que debe cancelar un valor para solicitar el reenvío del formulario corregido. Los documentos escaneados muchas veces son capturados de manera incorrecta con una mala calidad en la imagen obtenida, lo cual influye en la interpretación de la información del formulario.GuayaquilIngeniero en Ciencias Computacionales Especialización Sistemas Multimedia\n"}
{"prompt":"Desarrollo de un sistema para reconocimiento de texto y conversión a audio, utilizando Raspberry Pi para personas no videntes ->","completion":" El presente proyecto tiene como objetivo principal ayudar a las personas con discapacidad visual. Se presenta un prototipo que su principal objetivo será detectar un documento impreso y transformarlo a un formato de audio, el cual reproducirá el texto detectado de la captura previamente realizada. El concepto presenta un solo módulo que permite reproducir un archivo de audio mediante la tecnología de detección de imágenes en tiempo real. El proyecto utiliza la tarjeta Raspberri Pi para la parte de procesamiento y una cámara compatible con la tarjeta antes mencionada para la captura de imágenes. Finalmente, los resultados obtenidos muestran el diseño del prototipo de captura y conversión a audio, se realiza varios experimentos para mostrar la precisión de captura y lectura del texto impreso. Este proyecto tiene la ventaja de utilizar dispositivos portátiles que aparte de este prototipo se puede usar para más tareas. De acuerdo a las pruebas realizadas se puede determinar que la distancia óptima para el buen enfoque es 30 cm desde la cámara hacia el documento ya que a esa distancia enfoca el total de la hoja, la iluminación es una parte importante a la hora de procesar texto impreso ya que con una buena iluminación el prototipo puede reconocer mejor el texto y entregar mejor información a la persona que lo solicita, la tarjeta Raspberry Pi 4 ofrece los recursos necesarios para el correcto funcionamiento del prototipo ya que cuenta con 4 GB en RAM para su procesamiento, adicional es compatible con la cámara IR-CUT.The main objective of this project is to help people with visual disabilities. A prototype is presented whose main objective will be to detect a printed document and transform it into an audio format, which will reproduce the text detected from the previously made capture. The concept features a single module that allows an audio file to be played back using real-time image detection technology. The project uses the Raspberri Pi card for the processing part and a camera compatible with the aforementioned card for image capture. Finally, the results obtained show the design of the prototype of capture and conversion to audio, several experiments are carried out to show the precision of capture and reading of the printed text. This project has the advantage of using portable devices that apart from this prototype can be used for more tasks. According to the tests carried out, it can be determined that the optimal distance for good focus is 30 cm from the camera to the document since at that distance the entire sheet focuses, lighting is an important part when processing text printed since with good lighting the prototype can better recognize the text and deliver better information to the person requesting it, the Raspberry Pi 4 card offers the necessary resources for the correct functioning of the prototype since it has 4 GB of RAM for its Additional processing is supported by IR-CUT camera.\n"}
{"prompt":"Análisis y diseño de un sistemas de conversión texto-voz para dispositivos celulares aplicadas a las personas con necesidades especiales ->","completion":" Este trabajo presenta un sistema de conversión texto voz para celular programado bajo plataforma J2ME el cual es capaz de generar de forma automática una secuencia de sonidos que produciría una persona al leer un texto cualquiera en voz alta, este permitirá generar en la gran mayoría de los casos cualquier enunciado en español, incluyendo la reproducción de números. Al ser la síntesis de voz la producción artificial del habla humana, el estudio incluyo un análisis general del aparato fonador, se realizó un breve estudio de los órganos implicados en la producción del habla obteniendo así una idea general de cómo se forma la voz y sus características principales. De igual manera se presentó la arquitectura más completa para el desarrollo de estos conversores texto a voz y se han analizado aquí cada fase siempre aplicado al desarrollo de nuestro proyecto de conversor para celular. Se planteó tres fases para el desarrollo primeramente el procesamiento lingüístico, el procesamiento prosódico y la síntesis de voz. El procesado lingüístico se dedica fundamentalmente a determinar los sonidos que se van a producir y como producirlos para la lectura del texto de entrada. Para esto se realiza un preprocesado del texto y de tal manera que se quiten los diferentes números, símbolos y signos y se pueda realizar la selección de sonidos. Se analizó además el análisis y categorización gramatical, la formulación de un corpus, marcación de palabras, segmentación de frases, estructuración de diccionarios y análisis de los mismos. Se examinó la manera en que se podrían establecer las pausas dentro de las oraciones en función de los acentos y su posición dentro de la oración. Para el procesado lingüístico la investigación incluyo un estudio teórico muy completo de FONÉTICA Y FONOLOGÍA específico para nuestro país (especialmente el habla de las personas que viven en la sierra del ecuador), punto fundamental para poder realizar la conversión de texto a voz, ya que los humanos reproducimos un texto en palabras, sin embargo el tratar que un conversor utilice palabras como unidad para la síntesis de voz es imposible esto debido a que no se podría almacenar en un móvil una base de datos con todas las palabras que incluye el léxico español, por lo tanto se debe realizar un división de menor nivel como es el caso de las silabas, ya que la cantidad de silabas es mucho menor que las palabras, en el proyecto se incluyó 164 silbas grabadas, las mismas que son reproducidas de acuerdo a la división silábica del texto de entrada en donde dicha división silábica se la logra en base a las reglas de fonética y fonología. Para el procesamiento prosódico se estudió sus principales parámetros como son las pausas y el ritmo. Además se revisó los procesos de estilización de patrones melódicos para las diferentes tipos de frases para el español. Se planteó los patrones melódicos en función de las frases definiendo conceptos como la curva melódica que genera la señal de la voz. Se investigó como se podría de esta manera asignar las curvas y frecuencias fundamentales a las frases. Como ya se mencionó anteriormente para la conversión de texto voz es necesaria la utilización de una base de datos de sonidos, ya que esta deberá contener el grupo de unidades digitalizadas pregrabadas, que posteriormente deberá emplear el sintetizador, para este primer avance del proyecto se utilizó una base de datos con voz femenina, la misma que puede ser obtenida en base a la grabación de frases, párrafos, palabras las cuales posteriormente con la utilización herramientas como \"Speech Analyzer\" deberán ser divididas en silabas, igual procedimiento se podrá seguir para la creación de una base de datos de voz masculina. El conversor texto a voz está construido en base a la metodología de desarrollo RUP (RATIONAL UNIFIED PROCESS), el cual junto con UML (Lenguaje Unificado de Modelado), constituye la metodología estándar más utilizada para el análisis, implementación y documentación de sistemas orientados a objetos, otra razón por la que se utilizó el RUP es porque se trata de un conjunto de metodologías que se adapta a las necesidades de cada usuario, en este caso nuestro equipo de desarrollo.\n"}
{"prompt":"Diseño e implementación de una plataforma genérica para desarrollar y probar nuevas técnicas de detección de plagio en textos ->","completion":" En este trabajo se presenta un modelo de plataforma de software para desarrollar y evaluar diferentes algoritmos de detección de plagio, esta plataforma se denomina PlaMDeP, la plataforma se basa en un diseño modular escalable, que implementa un conjunto de servicios que posibiliten realizar automáticamente tareas referentes al procesamiento de textos para detección de plagio.In this work presents a model of software platform to develop and evaluate different algorithms plagiarism detection, this platform is called PlaMDeP, the platform is based on a scalable modular design that implements a set of services that allow automatically perform tasks relating processing of texts for plagiarism detection.\n"}
{"prompt":"Comprensión del léxico en textos narrativos y explicativos ->","completion":" Esta tesis estudia la comprensión del léxico en estudiantes de séptimo año de la escuela primaria en el marco de tipos textuales que son objeto de indagación de la Psicología Cognitiva y objetos de enseñanza según los currículos oficiales: los narrativos y los explicativos. Asume la perspectiva teórica del procesamiento de los textos en general y de los tipos narrativo y explicativo, en particular, los modos de pensamiento que esos tipos de texto movilizan y los diferentes modelos sobre la comprensión de palabras y sus relaciones de significado. La metodología se basa en la construcción y aplicación de de dos instrumentos del tipo objetivo a una muestra de 400 estudiantes, representativa de escuelas públicas y privadas, de sectores altos y populares de la Provincia de Buenos Aires. Parte de la hipótesis que los sectores socioeconómicos y culturales altos conocen en buena medida el sociolecto de los sectores socioeconómicamente desfavorecidos por mayor dominio del vocabulario y conocimiento sobre el mundo. En línea con esta conjetura postula que estos sectores tienen menos dificultades para resolver tareas en las que entran en juego tecnolectos. Esto se debería a que, a mayor estatuto sociocultural, mayor competencia lingüística. Los resultados obtenidos se analizan en diferentes niveles: el de la prueba, el del ítem y el de cada una de las alternativas del ítem. Las conclusiones provisorias del estudio indican que la interiorización más temprana de la estructura narrativa (o su innatismo, según algunos autores), no se correlacionaría con la mayor facilidad para interpretar términos clave de la narración, como los que designan las acciones de los personajes, si estos términos son de uso poco frecuente o infrecuente. Al mismo tiempo, la estructura del texto explicativo – principalmente el establecimiento de relaciones de equivalencia entre términos mediante sinonimias, paráfrasis, ejemplos, etc. - colaboraría co la interpretación de palabras clave, como los sustantivos que designan los conceptos.\n"}
{"prompt":"Desarrollo de un prototipo de “BOT conversacional” empleando procesamiento de lenguaje natural ->","completion":" El uso de la Inteligencia artificial en los últimos tiempos se ha convertido en un foco de desarrollo y generación de información, tal es el caso de que, el uso de bots conversaciones están actualmente suprimiendo al personal dedicado en los sectores que brindan atención al cliente como es el caso: de las entidades bancarias, puntos de información, ventas y traductores de idiomas; también se han desarrollado aplicaciones que brindan respuestas automáticas para las principales redes sociales como asistentes personales. Este proyecto brinda información a manera de chat en tiempo real mediante el uso de librerías de Procesamiento del Lenguaje Natural para PHP, donde las consultas realizadas por el usuario en un programa de servidor web (local y externo) pasan por un proceso de filtrado donde son Tokenizadas para posteriormente calcular el Índice de Jaccard, para permitir el acceso una base de datos en el cual se almacena la información relativa, en los casos de ambigüedad en la pregunta, este proceso se repite con las características principales de la búsqueda, que automáticamente se presentan como respuesta en un campo de texto dentro de la aplicación web. Este trabajo concede el acceso a la información de una forma ordenada y automática facilitando al Departamento de Electrónica y Electrónica de la Universidad de las Fuerzas Armadas ESPE los tiempos de respuesta a inquietudes por parte de los estudiantes u otros usuarios.\n"}
{"prompt":"Introducción al análisis grafico para obtener frecuencias de simbolos escritos en imagenes de texto ->","completion":" Este proyecto nace del interés que tengo por conocer el pensamiento original que los autores quisieron transmitir a través de las Sagradas Escrituras, y dado que el lenguaje escrito es un medio sensitivo utilizado para transmitir un pensamiento, se requiere hallar la relación escritura - pensamiento. La manera de conocer este pensamiento inicia en el descubrimiento de la esencia del lenguaje original y sin duda alguna el hombre ya ha ingresado en el estudio de este lenguaje prácticamente desaparecido, puesto que el hebreo bíblico tiene diferencias con el hebreo moderno. Automatizar estos estudios mediante el uso de los avances tecnológicos y por su puesto el procesamiento digital de señales, fue lo que dio origen a este aplicativo, muy básico, muy elemental, pero es el inicio de una herramienta de mucha utilidad al combinar eficientemente las técnicas de procesamiento con la imaginación. El objetivo de esta aplicación es básicamente el tratamiento de una imagen obtenida por fotografiar algún conjunto de símbolos hebreos y obtener las frecuencias de estos símbolos así como su ubicación en la imagen total, de esta manera el especialista en escritura antigua podrá sacar conclusiones útiles para la comprensión del lenguaje.\n"}
{"prompt":"Análisis de la información de foros en cursos MOOC mediante técnicas de procesamiento de lenguaje natural ->","completion":" El aprendizaje online es una de las características de este milenio, debido a la gran cantidad de información que se genera a diario y la accesibilidad a dispositivos para acceder a la web. A partir de este cambio en la perspectiva del aprendizaje varias instituciones a nivel mundial han concebido el nuevo paradigma de la enseñanza online como una oportunidad para globalizar sus programas. Así desde ya hace unos cuantos años, se dictan cursos, seminarios e incluso carreras universitarias por medio de la web, lo que ha generado una gran cantidad de interacción entre docentes y estudiantes ubicados en diferentes partes del mundo, interacción que crea masividad de datos que no han sido explorados, por lo que se pretende en este proyecto realizar tal exploración mediante técnicas de inteligencia artificial. En el presente trabajo se realiza la extracción de los mensajes en foros que se generan a partir de interacción de estudiantes en los cursos abiertos masivos online (MOOC) de la plataforma Udacity(mediante técnicas de scraping), con el fin de rescatar patrones de texto mediante el uso de técnicas de procesamiento de lenguaje natural (como el reconocimiento de entidades y el análisis de n-gramas) y técnicas de aprendizaje automático(utilizando el algoritmo Naïve Bayes).The online learning is one of the characteristics of this millennium, due to the large amount of information generated daily and accessibility devices to access the web. From this change in the perspective of several learning institutions worldwide they have conceived the new paradigm of online education as an opportunity to globalize their programs. So from a few years ago, offers courses, seminars and even university courses via the web, which has generated a lot of interaction between teachers and students located in different parts of the world, creating massive interaction data that have not has been explored, so it is intended to conduct such exploration project using artificial intelligence techniques. This proyect makes the extraction and analysis of data generated from interaction of students in massive open online course (MOOC) of Udacity platform by scraping techniques, in order to rescue text patterns using techniques of processing natural language(like entity recognition and\n"}
{"prompt":"Estrategia lectora interactiva para desarrollar la comprensión autónoma de textos literarios en estudiantes de sexto grado aplicando tics, año 2020 ->","completion":" La investigación tuvo como objetivo general explicar la contribución de la estrategia lectora interactiva en la comprensión autónoma de textos literarios en los estudiantes de sexto grado de la Unidad Educativa Santa Teresita mediante el desarrollo de un plan lector basado en las Tecnologías de la Información y Comunicación (TICs). La población y muestra contó con 57 estudiantes. La metodología fue de tipo cuantitativa, se utilizó como técnica de recolección de datos la encuesta y la entrevista online. Los aspectos teóricos estuvieron sustentándose en las posturas de Solé (1992) citado por Pérez (2015) definiendo a las estrategias metacognitivas y sus fases (antes, durante y después de la lectura); a Alaís (2015) con los niveles literal, inferencial y crítico de la comprensión lectora. También Cruz (2014) indicó el significado de un plan lector, Chanto (2020) conceptualizando a las TICs y Lamour (2018) con la noción del Portal Web. Además, para el procesamiento de la información y posterior tratamiento estadístico se utilizaron gráficos circulares con subgráficos de barras, análisis de hipótesis en Excel, Coeficiente del Alfa de Cronbach y la Escala de Likert; a continuación, se realizó el análisis y discusión de los resultados, siendo el más significativo que la estrategia lectora interactiva contribuyó a mejorar el nivel de compresión autónoma de textos literarios porque se ejecutó un plan lector basado en las TICs. Se concluye que su alta efectividad y aplicación despertó interés e interactividad y se recomienda implementar el proyecto investigativo a los distintos subniveles de la Educación General Básica.\n"}
{"prompt":"Diseño e implementación de un prototipo para análisis de comentarios para la de recomendación de contenido y formación de grupos de aprendizaje en una plataforma educativa ->","completion":" El propósito de este proyecto es realizar el análisis y evaluación de comentarios para la recomendación de contenidos (libros, videos, artículos) y formación de grupos de aprendizaje (compañeros con gustos y preferencias similares) en una plataforma educativa, a través de la utilización de los estándares y tecnologías de la Web Semántica y el uso de PLN (Procesamiento del Lenguaje Natural), apoyado en la inteligencia artificial. El desarrollo de esta implementación se basa en el interés de crear y añadir datos semánticos a los recursos (libros, videos, enlaces) con los que cuenta el sistema de recomendación y formación de grupos, desarrollado por el proyecto OPPIA (OPPortunistic Intelligent Ambient learning) perteneciente al Grupo de Investigación en Telecomunicaciones y Telemática (GITEL) de la Universidad Politécnica Salesiana (UPS), sede Cuenca.The purpose of this project is to accomplish the analysis and evaluation of comments for the recommendation of contents (books, videos, articles) and formation of learning groups (classmates with similar tendencies and preferences) in an educational platform, through the use of the standards and technologies of the Semantic Web and the use of PLN (Natural Language Processing), supported by artificial intelligence. The development of this implementation is based on the interest of creating and adding semantic data to the resources (books, videos, links) which the system of recommendation and formation of groups have, developed by the OPPIA project (OPPortunistic Intelligent Ambient learning). Belonging to the Grupo de Investigación en Telecomunicaciones y Telemática (GITEL) of the Universidad Politécnica Salesiana (UPS), Cuenca.\n"}
{"prompt":"Diagnóstico de las afectaciones socio-ambientales por el ruido en el procesamiento de cacao de la corporación CAORO en el sitio Río Negro ->","completion":" En el sector Río Negro perteneciente a la parroquia La Victoria del cantón Santa Rosa, la corporación CAORO (Corporación Agroexportadora El Oro) ha venido desarrollando la actividad de la compra de cacao, donde se realiza la fermentación y secado del mismo, para la comercialización a nivel nacional y posterior exportación, esta actividad presenta impactos sociales y ambientales. Entre los impactos sociales se encontró que los trabajadores están expuestos por un periodo de tiempo extenso al ruido con decibeles que superan los límites permisibles establecidos en el TULSMA (Texto Unificado de Legislación Secundaria Medio Ambiental). En los impactos ambientales se observó que el ruido afecta a las aves terrestres como Furnarius cinnamomeus, Dives warszewiczi, Ara chloroptera, Eastern bluebird, Columba livia, Turdus merula, del sector, causando que se perturben en la búsqueda de alimentos por estar siempre alerta a los depredadores, también algunas aves modifican su comportamiento natural al trinar en este entorno ruidoso. Las vibraciones generadas por la maquinaria utilizada tienen efectos adversos en la salud del trabajador que habita en la corporación, causando espondilitis, calcificación de discos e incluso menor habilidad manual. En la fauna las vibraciones causan daños mecánicos al aparato digestivo y sistemas respiratorios.\n"}
{"prompt":"Detección de tópicos de texto en español utilizando técnicas de Machine Learning y atribución de autoria: Caso discursos Guillermo Lasso Presidente del Ecuador. ->","completion":" PDFEl presente trabajo de titulación tiene como objetivo analizar y estudiar el estado del arte de la atribución de autoría y asignación de tópicos de textos en español tomando como referencia artículos científicos enfocados sobre el tema los cuales serán escogidos de fuentes confiables, también se investigarán las distintas técnicas de machine learning para el modelado de tópicos en corpus de texto con la finalidad de evaluar los modelos e identificar cuáles están más orientados a la detección de tópicos en el idioma español. Además, se procederá a evaluar los modelos LDA y NMF para el procesamiento de lenguaje natural, modelado y detección de tópicos usando como lenguaje de programación Python para el análisis de los diferentes discursos del Sr. Guillermo Lasso, presidente del Ecuador, los mismos que serán tomados de forma aleatoria de páginas oficiales, con lo que se generará un análisis comparativo de los dos modelos antes mencionados. Se concluye presentando los diferentes resultados obtenidos por ambos modelos en su proceso de evaluación de los diferentes discursos políticos del primer mandatario del Ecuador.The objective of this degree work is to analyze and study the state of the art of attribution of authorship and assignment of topics of texts in Spanish, taking as reference scientific articles on the subject that will be chosen from reliable sources, the different techniques will also be sought. of machine learning for the assignment of topics of texts in Spanish in order to evaluate the models and identify which ones are more oriented to the detection of topics. In addition, the LDA and NMF models will be evaluated for natural language processing, modeling and topic assignment using Python as a programming language for the analysis of the different speeches of Mr. Guillermo Lasso, President of Ecuador, the same ones that They will be taken randomly from official pages, which will generate a comparative analysis of the aforementioned models. It concludes by presenting the different results obtained by the models in their evaluation process of the different political speeches of the president of Ecuador.\n"}
{"prompt":"Desarrollo de un envoltorio del api-rest de mendeley con Graphql ->","completion":" Desarrollar un envoltorio del API-REST del gestor bibliográfico Mendeley utilizando el lenguaje de consultas GraphQL y validado con un marco de trabajo de calidad en uso basado en el estándar ISO\/IEC 25000La creación de sistemas ha experimentado cambios en su proceso de construcción, la separación del servidor y cliente ha impulsado la innovación tecnológica por medio de la creación de tecnologías más útiles y eficientes. La integración entre el cliente y servidor normalmente es realizada por una API, comúnmente usando tecnología REST la cual es muy aceptada en la comunidad de desarrollo de software, aunque es muy aceptada también presenta inconvenientes como la complejidad que presenta su consumo lo que hace necesario la creación y utilización de alternativas, una de estas alternativas es GraphQL que es un lenguaje de consultas para las APIs y que pretende ser más eficiente y mejorar circunstancialmente la experiencia de desarrollo del lado del cliente. El presente trabajo describe la creación de una API que envuelve la tecnología API-REST y la convierte en tecnología GraphQL (envoltorio), se tomó a la API-REST de Mendeley como caso de desarrollo. Para la creación del envoltorio se definió una base teórica que permitió conocer conceptos que involucra crear el envoltorio. El desarrollo del producto se lo hizo siguiendo la metodología ágil Scrum que comprende ciclos interactivos llamados Sprints. Para validar la usabilidad del software, se usó un taller práctico y una encuesta que fueron validadas estadísticamente y que permitieron recolectar datos los cuales fueron usados para evaluar la calidad en uso con un marco de trabajo basado en el estándar ISO\/IEC 25000, por lo cual se obtuvo resultados satisfactorios.Ingeniería\n"}
{"prompt":"Implementación de una solución e-commerce en ambiente móvil con flutter usando los servicios Rest Api de Woocomerce. ->","completion":" PDFActualmente por la pandemia que atraviesa el mundo, ocasionada por el COVID-19 muchos negocios se han visto en la obligación de ofrecer y realizar sus transacciones de ventas por medio de medios digitales o crear sus propios aplicativos móviles para llevar sus productos a mayor cantidad de consumidores ya que 53% de compras en líneas son realizadas por medio de dispositivos móviles . El presente trabajo busca el desarrollo de una aplicación móvil con Flutter , el cual es un Framework de código abierto desarrollado por Google que ofrece la creación de un solo proyecto para iOS y Android ejecutandose como auténticas aplicaciones nativas en los dispositivos, la aplicación hára uso de los servicios Rest API de WooCommerce para el manejo de una tienda electrónica, que es una plataforma en la que mezcla la destreza de un módulo de e-commerce altamente personalizable y a su vez eficiente en un ecosistema experimentado como lo es WordPress, administrador de contenidos con módulos, extensiones y plugins que pueden funcionar en cualquier aplicación web. Existen aplicaciones que incorporan los servicios Rest pero en su mayoría no son de libre acceso o no cumple con las características requeridas por los usuarios. Por medio de la metodología de investigación se podrá recolectar información de múltiples fuentes bibliográficas que serán de apoyo para el correcto desarrollo y funcionamiento de la aplicación, así mismo el desarrollo de esta aplicación permitirá la portabilidad y acceso a los consumidores de las tiendas online para así brindar oportunidades a las PYMES de la ciudad de Guayaquil de tener una solución E-commerce desde sus dispositivos Android o iOS ya que siendo Open Source y multiplataforma tendrán una oportunidad de llegar a más usuarios de forma gratuita.Currently, due to the pandemic that is going through the world, caused by COVID -19, many businesses have been forced to offer and carry out their sales transactions through digi tal means or create their own mobile applications to take their products to a greater number of consumers since 53% of online purchases are made through mobile devices. The present work seeks the development of a mobile application with Flutter which is an open source Framework developed by Google that offers the creation of a single project for iOS and Android running as authentic native applications on devices, the application will use the WooCommerce Rest API services for managing an electronic store, wh ich is a platform that mixes the skills of a highly customizable and efficient e-commerce module in an experienced ecosystem such as WordPress, content manager with modules, extensions and plugins that can work in any web application. There are applications that incorporate Rest services, but most of them are not freely accessible or do not meet the characteristics required by users. Through the research methodology, information can be collected from multiple bibliographic sources that will be of support fo r the correct development and operation of the application, likewise the development of this application will allow the portability and access to consumers of online stores in order to provide opportunities to SMEs in the city of Guayaquil to have an E -commerce solution from their Android or iOS devices since being Open Source and multiplatform they will have an opportunity to reach more users for free.\n"}
{"prompt":"Análisis de frameworks de desarrollo de api rest y su impacto en el rendimiento de aplicaciones web con arquitectura Spa ->","completion":" Analizar el impacto del WBAF (Web Backend Application Framework) de API REST en el rendimiento de aplicaciones web dinámicas con SPA (Single Page Application) para definir el WBAF que mejor se adapte al desarrollo de aplicaciones web del Gobierno Provincial de Imbabura.Para decidir el WBAF (Web Backend Application Framework) para el desarrollo de API REST, que mejor se ajuste a las necesidades y arquitectura de una aplicación web, es importante referirse al rendimiento de las aplicaciones. La alta demanda de una mejor funcionalidad y usabilidad en aplicaciones web puso en funcionamiento nuevas técnicas, con la arquitectura SPA utiliza la técnica de buscar datos asincrónicamente y actualizar el contenido de la página o el componente entero sin actualizarlo. El frontend debe tener un bajo acoplamiento a las API REST desarrolladas en el backend; en esta investigación planteamos si el framework de desarrollo de las API REST impacta en el rendimiento de la aplicación web con arquitectura SPA. Los WBAF analizados son: Express.js que es un web application framework para Node.js y el framework ASP.NET Core. Mediante el Mapping Study se determinó que las métricas Response Time y Throughput determinan el rendimiento de las aplicaciones web y la metodología de benchmark nos sirve para obtener información sobre el comportamiento del rendimiento de las API REST, con los frameworks Express.js y ASP.NET Core para posteriormente compararlos con respecto al rendimiento de la aplicación web. Como conclusión podemos decir que si impacta el framework de desarrollo de API REST sobre el rendimiento de ejecución de aplicaciones web con SPA solamente cuando es una cantidad elevada de usuarios concurrentes, caso contrario ante la percepción del usuario no impactaría el framework de desarrollo.\n"}
{"prompt":"Diseño de un ecosistema de software, para la interoperabilidad entre sistemas de E-Commerce y Courier mediante Apis Restful Eficientes y Seguras ->","completion":" Diseñar un ecosistema de software que permita y optimice de manera segura la interacción entre los E-Commerce y sistemas Courier, desarrollando un prototipo de arquitectura de software que implemente condiciones óptimas aplicando la ISO 8583.El E-Commerce y Courier en Ecuador necesitan interoperar para llevar a cabo el comercio electrónico en el país, por ello se propone un diseño de ecosistema de software que en base a buenas prácticas permita la interoperabilidad a sistemas de E-Commerce y Courier. Para el desarrollo y diseño de este ecosistema de software se considera buenas prácticas las cuales fueron aplicadas para desarrollar un sistema distribuido de arquitectura orientada a servicios, es por ello por lo que el giro de negocio y el acceso a su data se desarrolla en base en APIs Restful las cuales deben cumplir todas las restricciones Rest, por otra parte este ecosistema debe tener la característica de poder cohesionar con otros módulos de un macroecosistema de software, para ello se aplica la ISO 8583 en puntos de acceso de interés que engloban transacciones financieras con mensajes originados en una tarjeta, además para comprobar su eficiencia se realiza varias pruebas de carga hasta llegar al estrés del API, obteniendo un resultado cuantitativo del índice APDEX con el que se determina la eficiencia y satisfacción, por otro lado para asegurar los sistemas Restful se utilizó las recomendaciones emitidas por OWASP, se evaluó el sistema con pruebas de vulnerabilidades realizado por un ente interno y externo. Se obtuvo resultados en la comprobación de eficiencia y seguridad, se construyó un cliente móvil de las APIs desarrolladas. Todo el prototipo de ecosistema de software fue puesto en producción fuera de localhost, en sistemas de hosting compartido y nube.Ingeniería\n"}
{"prompt":"Integración de las APIs REST de OSF y GitHub mediante una Aplicación Orientada a Servicios para publicar contenido Open Science ->","completion":" Integrar las APIs REST de OSF y GitHub mediante una aplicación orientada a servicios para publicar contenido Open Science.En los últimos años se ha hecho evidente la necesidad de adoptar las políticas de movimientos sin fines de lucro que buscan lograr que los componentes de una determinada investigación científica no sean centralizados. Por lo general los grandes conglomerados invierten enormes recursos para desarrollar nuevas técnicas, tecnologías, metodologías u otro elemento, sin embargo, pocas personas tienen acceso a dicha información. La Unión Europea durante los últimos años le ha dado gran importancia al tema e inclusive va más allá, pues en palabras de sus representantes el hecho de que el conocimiento científico sea centralizado genera desigualdades muy graves y es aquello que impide a los países en vías de desarrollo integrarse a nuevos modelos de generar conocimiento; es entonces cuando la Unión Europea apuesta por un movimiento llamado Open Science que permite mitigar los problemas subyacentes de aquella centralización. El presente trabajo consta de tres capítulos y busca elaborar una arquitectura de software que permita integrar los servicios de dos herramientas relacionadas a los términos Open Source y Open Science. En dicha arquitectura se pretende aplicar técnicas DevOps y tecnologías modernas que permitan acceder a elementos de investigaciones científicas que se encuentran en colecciones de Open Science Framework y en repositorios de código en GitHub. Previo al desarrollo de la arquitectura se llevó a cabo una revisión sistemática de literatura SLR para conocer la información relevante acerca de métodos de publicación de contenido abierto y las herramientas que pueden ayudar a lograr tal fin. En el desarrollo de los componentes de la plataforma se usaron varias tecnologías que ayudaron a que la arquitectura resultante sea eficiente. Finalmente se realizó el análisis del producto de software a ser evaluado, mediante los requisitos según el estándar IEEE 830 y las métricas de la calidad en uso según la ISO\/IEC 25022. También se monitorearon los componentes y servicios de la arquitectura para verificar su correcto funcionamiento, entre los elementos que fueron evaluados están: Clúster AWS, Contenedor Docker, Aplicación Nativa, Base de Datos MySQL y otros componentes de la arquitectura final.Ingeniería\n"}
{"prompt":"Plataforma tecnológica para contribuir la planeación urbana en la ciudad de Guayaquil dirigido a la transportación, enfocado a la elaboración de APIS para los módulos: recomendador, análisis de sectores, recolector de puntos georeferenciales, conteo vehicular, indicadores, análisis de sentimiento en redes sociales. ->","completion":" PDFLa plataforma Lesstraffic fue creada con el objetivo principal de promover la planeación urbana de la ciudad de Guayaquil dirigida a la transportación, que consiste en determinar la existencia o inexistencia de congestión vehicular en varias zonas de la urbe mediante la recolección de trayectorias y análisis de estas a través de distintos algoritmos. En la primera fase del proyecto se implementaron los módulos Algoritmo Recomendador y Análisis de sectores como los módulos más importantes. La forma de comunicación entre dichos módulos hacia la base de datos era directa. En vista de que existían conexiones directas entre la capa de aplicación (Sistema Lesstraffic) y la capa de datos (Base de datos PostgreSQL) es decir que el sistema como tal crecerá en número de módulos, se decidió implementar APIS REST, las cuales sirven de intermediario entre las dos capas. Se desarrollaron APIS para todos los módulos existentes y nuevos detallados en el alcance de este documento con el objetivo de optimizar recursos y tiempo de respuesta entre la plataforma Lesstraffic y la base de datos. En base a los resultados de pruebas de carga y estrés se pudo evidenciar una mejora en los procesos, confirmando así que es una gran ventaja para el sistema como tal usar APIS para la independización de procesos, debido a su alta disponibilidad, flexibilidad, fiabilidad.The platform was created with the main objective of promoting the urban planning of the city of Guayaquil aimed at transportation, which consists of determining the existence or nonexistence of vehicular congestion in various areas of the city by collecting trajectories and analyzing the same through the different algorithms. In the first phase of the project, the modules Algorithm Recommender and Analysis of sectors were implemented as the most important modules. The way of communication between said modules towards the database was direct. The connection networks are based on the application layer and the database (PostgreSQL Database). between the two layers. APIS will be developed for all data modules and new details in the scope of this document with the aim of optimizing resources and response time in the platform. Based on the results of load and stress tests, an improvement in the processes was evidenced, confirming that it is a great advantage for the system as such APIS use for the independence of the processes, due to its high availability, flexibility, reliability.\n"}
{"prompt":"Implementación De Una Aplicación Móvil Desarrollada Para Sistemas Operativos IOS Para El Aseguramiento De La Alta Disonibilidad De Los Servidores Críticos De La Empresa Saycript Ecuador S.A. Utilizando Web Service Restful. ->","completion":" ADOBEEste proyecto proveerá de una herramienta de tipo móvil a la empresa Dayscript Ecuador S.A. , para la administración de los servicios instalados en los servidores que se encuentra bajo su dominio, donde se observa la necesidad a los usuarios administrativos que posean teléfonos con sistemas operativos iOS el cual podrán hacer uso de la misma aplicación, para aprovechar el uso de esta aplicación el usuario administrador deberá estar previamente configurado por el administrador de la aplicación, el cual es el responsable de la creación de los recursos a administrarse por medio de un módulo web. En estos módulos se podrá crear, modificar y eliminar usuarios, servidores, filesystem y comandos de base de datos MySql configurada. Estos recursos se podrán acceder mediante un aplicativo móvil el cual se conectara por medio de un Api que tendrá disponibles los métodos para la autenticación de los usuarios, listados de servidores configurados y ejecución del comando escogido. Adicional se contara con envió de un Push notificación para informar del estado de los recursos y servicios.This project will provide a portable tool for the company Dayscript Ecuador S.A. aimed at the administration of the services installed on servers that work in their domain, where there is a need from the administrators’ users with phones with iOS operating systems which may use the application. To use and take advantage of this tool the administrator user must already be configured by the administrator of the application, which is responsible for the creation of the resources that will be administered by a web module. In these modules you can create, modify and delete users, servers, and filesystem and MySql database commands already configured. These resources may be accessed through a mobile application which will be connected by an Api that will have available the authentication methods for users, configured servers list and the execution of the selected command. In addition to everything already said, there will be a Push notification sent to report the status of resources and services.\n"}
{"prompt":"Implementación de sistema Web para gestión y control de mantenimiento en equipos y sistemas del área de instrumentos meteorológicos de dirección general de Aviación Civil del Ecuador. ->","completion":" PDFEn el 2020, el Área de Instrumentos Meteorológicos de la Dirección General de la Aviación Civil del Ecuador, lleva el proceso de gestión y control de mantenimiento en equipos y sistema de forma manual usando hojas de papel. Por lo que el principal objetivo del presente proyecto es implementar un sistema web que permite el control del mantenimiento de los equipos y sistemas por medio de un módulo de reporte gráfico y notificaciones vía correo electrónico y mensaje de WhatsApp, permitiendo también informes y órdenes de trabajo. Las herramientas que se usaron en el presente proyecto fueron los Frameworks Laravel, Nodejs (Expressjs), .Net Core 3.1, Bootstrap, JavaScript, Jquery. El almacenamiento de la información se la alojó en el gestor de base de datos MySQL. El propósito del proyecto es reducir carga operacional, gastos de insumo de papel, tinta y espacio de trabajo. Para gestionar este proyecto en cuanto a la investigación, se utilizó la técnica de la encuesta y entrevista, para saber los conflictos, carencias y viabilidad de este, a la cual se le aplicó a una población de 5 personas, mientras que para el desarrollo e implementación se empleó la metodología SCRUM ya que este permitió el desarrollo por etapas o Sprint. Se propone utilizar el sistema a fin de llevar el control del mantenimiento de los equipos y sistemas para optimizar los tiempos de respuesta en las gestiones que realizan los usuarios, finalmente el sistema generará información por medio de reportes.In 2020, the Area of Meteorological Instruments of the General Directorate of Civil Aviation of Ecuador, carries out the process of management and control of maintenance in equipment and system manually using sheets of paper. Therefore, the main objective of this project is to implement a web system that allows control of the maintenance of equipment and systems through a graphical report module and notifications via email and WhatsApp message, also allowing reports and work orders . The tools used in this project were Laravel Frameworks, Nodejs (Expressjs), .Net Core 3.1, Bootstrap, JavaScript, Jquery. The information storage was housed in the MySQL database manager. The purpose of the project is to reduce operational load, paper, ink and workspace input costs. To manage this project in terms of research, the survey and interview technique was used, to find out the conflicts, deficiencies and viability of this, to which it was applied to a population of 5 people, while for the development and implementation, the SCRUM methodology was used since it allowed development in stages or Sprint. It is proposed to use the system in order to keep control of the maintenance of equipment and systems to optimize response times in the procedures carried out by users, finally the system will generate information through reports.\n"}
{"prompt":"Desarrollo de una aplicación móvil para la gestión de reservas y promoción de servicios del Hotel Grand Victoria boutique de la ciudad de Loja. ->","completion":" The present degree has as purpose the development of a mobile application for the reservation of rooms. This application benefits in great measure to the hotel GREAT VICTORY BOUTIQUE (HGVB) in the process of reservations, which allows them to administer the reservations and rooms through the application web, improving the time of answer and the service toward the clients. The mobile application contains detailed information of the hotel, as the services that offers like the detail of the rooms, its location that is captured in a map, and contact information. The user will be able to create an account and manage it, where through it, he will be able to make his reservations and be able to visualize them. In the development of the project research methods were used, this allowed to identify the problems and give the respective solution. For the collection of information, techniques were applied such as interviews with users of the establishment, and the survey of hotel clients, this information was used to support the development of the project, which together with the MOBILE-D methodology was carried out the development of an ordered way in a short time. The mobile application was developed in Android with the Java programming language, it interacts with the API-REST web service that was developed with the PHP language with the help of the Laravel \/ Lumen framework, and the web application that is the administration part of reserves the same that was developed with the Angular framework. In the process of developing the project of degree, with the methodology MOBILE-D was initiated with the obtaining of the requirements, by means of the use of the techniques as the interview and the survey, then the specification of requirements was made following the standard IEEE 830. Then, in the production phase, the software architecture was carried out with the Kruchten model, and based on this the different application modules were coded. Finally, the acceptance tests were carried out in the HGVB, which were satisfactory. As a result of the above, it was possible to comply with the proposed objectives, giving solution to the HGVB room reservation process, through the construction of the mobile and web application.El presente trabajo de titulación tiene como propósito el desarrollo de una aplicación móvil para la reservación de habitaciones. Esta aplicación beneficia en gran medida al Hotel Grand Victoria Boutique (HGVB) en el proceso de reservas, lo cual a través de la aplicación web les permite administrar las reservaciones y habitaciones, mejorando el tiempo de respuesta y el servicio hacia los clientes. La aplicación móvil contiene información detallada del hotel, como los servicios que ofrece, el detalle de las habitaciones, su ubicación que está plasmado en un mapa, e información de contacto. El usuario va a poder crear una cuenta y gestionarla, donde a través de la misma visualizará y realizará sus reservaciones. En el desarrollo del proyecto se utilizaron métodos de investigación, esto permitió ayudar a identificar los problemas y dar la respectiva solución. Para la recolección de información se aplicaron técnicas como la entrevista a usuarios del establecimiento, y la encuesta a los clientes Hotel, cuya información se utilizó para respaldar el desarrollo del proyecto, que conjuntamente con la metodología MOBILE-D se llevó a cabo el desarrollo de una manera ordena en un tiempo corto. La aplicación móvil fue desarrollada en Android con el lenguaje de programación Java, la cual interactúa con el servicio web API-REST que se desarrolló con el lenguaje PHP con la ayuda del framework Laravel\/Lumen, y la aplicación web que es la parte de administración de reservas fue desarrollada con el framework Angular. En el proceso de desarrollo del proyecto de titulación, con la metodología MOBILE-D se inició con la obtención de los requisitos, mediante el uso de las técnicas como la entrevista y la encuesta, luego se realizó la especificación de requisitos siguiendo el estándar IEEE 830. Luego en la fase de producción se llevó a cabo la arquitectura de software con el modelo de Kruchten, y en base a eso se codificó los distintos módulos de la aplicación. Finalmente se ejecutaron las pruebas de aceptación, que se efectuaron en el HGVB las cuales fueron satisfactorias. Como resultado de lo expuesto anteriormente, se pudo cumplir con los objetivos planteados, dando solución al proceso de reservación de habitaciones del HGVB, a través de la construcción de la aplicación móvil y web.\n"}
{"prompt":"IMPLEMENTACIÓN DE UNA APLICACIÓN MÓVIL PARA EL ASEGURAMIENTO DE LA ALTA DISPONIBILIDAD DE LOS SERVIDORES CRÍTICOS DE LA EMPRESA DAYSCRIPT ECUADOR S.A. UTILIZANDO WEB SERVICES RESTFUL. ->","completion":" AdobeEste proyecto proveerá a la empresa Dayscript Ecuador S.A. de una herramienta para la administración de los servicios instalados en los servidores que están bajo su potestad, el cual necesita crear el aplicativo móvil para la plataforma Android, los usuarios administradores que posean teléfonos con este sistema operativo podrán hacer uso de la misma. Para hacer uso de esta aplicación el usuario administrador deberá previamente estar configurado por el administrador de la aplicación, el mismo que es el responsable de la creación de los recursos a administrarse por medio de un módulo web. En este módulo web el administrador podrá crear, modificar y\/o eliminar usuarios, servidores, filesystem y comandos en la base de datos MySql configurada. Estos recursos serán accedidos desde la aplicación móvil por medio de un API que tendrá disponible los métodos para la autenticación de los usuarios, listado de servidores configurados, listado de comandos para ejecutar en el servidor seleccionado y ejecución del comando escogido. Dispondrá adicionalmente del envío de push notification para informar del estado de los recursos y\/o servicios.This project will provide the company Dayscript SA a tool for managing the services installed on servers that are under its jurisdiction, which consists in creating a mobile application on the Android platform, where administrators users with phones with this operating system may use Of the same. To use this application, the administrator user must first be configured by the administrator of the application, the same that is responsible for creating resources administered through a web module. In this Web module the administrator can create, edit and \/ or delete users, servers, and file system commands in the MySql database configured. These resources will be accessed from the mobile application through an API in the methods that are available for authenticating users, list of servers configured list of commands to run on the selected server and executing the selected command. Additionally shipping available push notification to report the status of resources and \/ or services.\n"}
{"prompt":"Proceso de reingeniería para el desarrollo de un software administrativo contable web usando una base de datos multivalor y servicios RESTful ->","completion":" The business accounting software SIP by Admindysad Cía. Ltda. needs a technologic update and the development of a web application is proposed. The main requirement is to keep the same Rocket D3 multivalue database, already used in SIP, and include it on the proposed application, SIPweb, using RESTful API. To achieve an adequate implementation of the new technology, a reengineering process is needed over the SIP software that involves processes of reconstruction, transformation, refining and implementation. In order to update the legacy technology into a web context, it is needed a reconstruction of the architecture and its adaptation into a Model-View-Controller design pattern...El software administrativo contable SIP, de la empresa Admindysad Cía, Ltda., necesita una actualización tecnológica y se propone el desarrollo de una aplicación web. El requerimiento principal es mantener la misma base de datos multivalor Rocket D3, utilizada en SIP, e incluirla en la aplicación propuesta, SIPweb, utilizando API RESTful. Para realizar una implementación adecuada de la nueva tecnología, se realiza un proceso de reingeniería sobre SIP que involucra procesos de reconstrucción, transformación, refinación e implementación. Para actualizar la tecnología heredada a un contexto web es necesaria una reconstrucción de la arquitectura y su adaptación a un patrón de diseño Modelo-Vista-Controlador...\n"}
{"prompt":"Diseño e implementación de una arquitectura basada en web services RESTFul para garantizar la interoperabilidad semántica e integridad de datos académicos ->","completion":" La creciente cantidad de información en las organizaciones ha ocasionado problemas de interoperabilidad obligando así al desarrollo y adopción de nuevas tecnologías que permitan dar solución a estos problemas. Una solución para este problema es emplear el enfoque que brinda la Web Semántica para conseguir una interoperabilidad de datos entre los diferentes sistemas. Otra de las ventajas que ofrece la Web semántica es la construcción de modelos descriptivos de datos basados en ontologías como estructuras más completas para la descripción de los datos. Esto permite una representación formal de un concepto además de la representación semántica y sintáctica del mismo. La presente investigación describe el diseño de una arquitectura basada en web services RESTful que garantice la interoperabilidad semántica e integridad de datos académicos de la Universidad Técnica Particular de Loja. La implementación de la solución propuesta en esta investigación se encuentra en el desarrollo de un prototipo de un RESTful API el cual provee información general acerca de Estudiantes, Docentes, Autoridades y Componentes Académicos. Estos datos se encuentran almacenados en Apache Marmotta una plataforma para datos en RDF.The increasing information quantity in the organizations has caused problems of interoperability forcing this way to the development and adoption of new technologies that allow to give solution to these problems. A solution for this problem is to use the approach that offers to us the Semantic Web to obtain an interoperability of the information between the different systems. Another advantage that offers us the Semantic Web is the construction of models describing data based on ontologies as structures more complete for the description of the data. This allows a formal representation of a concept as well as the representation of semantics and syntax of the same. The present research describes the design of an architecture based on web services RESTful that interoperability semantics and data integrity academics of the Private Technical University of Loja. The implementation of the solution proposed in this research is the development of a prototype of a RESTful API, which provides general information about students, teachers, authorities and academic components. These data are stored in Apache Marmotta a platform for data in RDF\n"}
{"prompt":"Diseño e Implementacion de una Aplicación Móvil para Uso de Pacientes con Problemas de Diabetes, el Mismo que Tendrá Como Soporte un Portal Web Para uso de los Médicos a Fin de Asistir en el Monitoreo, Evaluación y Control de Diabetes Mellitus Tipo 1, Tipo 2 y Gestacional, enfocado en Arquitectura de Web Services, Creacion y Disponibilizacion de Servicios Web RestFul Hacia la Base de Datos MARIADB ->","completion":" ADOBEpara sistemas operativos Android, se tiene como objetivo la creación web utilizando un estilo de Arquitectura REST mediante el lenguaje Jdaev sae drveibciidoos a sus múltiples ventajas como son: independencia de tecnologías, escalabilidad, fiabilidad, flexibilidad; cabe mencionar que Twiter y Facebook aplican este modelo de Arquitectura. Los servicios web serán alojados en el servidor de aplicaciones WildFly 10.0de código abierto, por tener una plataforma de alto rendimiento y fuerte estabilidad con el fin de que realice las conexiones para registrar y ejecutar procedimientos que se encuentran en la base de datos (MariaDB).En la base se guardarán todos los síntomas y variables necesarias para el control de la diabetes. Lo cual debe permitir un mejor examen sobre esta deenf ecrrmeaerd asedr vpiocrio psa rwtee bd eul tidliozcatnodr op aerl al eenmgiutiar jeu nd dei apgrnoógsratimcoa ccoiórnre Jcatov.a L ae l faccuialild aeds Orientado a Objetos, no se ha visto mejor implementado que con el API JAX-RS dpiavriad ieRnEdSo Teflu pl,r oebl lecumaal yfa lcoiglitraa nddiosp aolncaibnilzizaar ru lnó gailctoa sg rdaed on deeg odceiose pmaprae ñeoAndroid operating systems, the objective is to create web services using a REST architecture style through the Java language due to its many as: technology independence, scalability, reliability , flexib ailidtyv;a nItta gise s wsourcthh mentioning that Twiter and Facebook apply this model of Architecture. Web shearvvinicge sa whiilgl hb ep ehrfoosrtmeda nocen pthlaet foWrmild Falnyd 1s0t.r0o nogp esnta bsiloituyr cine oarpdpelirc atoti omn askeer vtehre, connections to register and execute procedures that are in the database (MariaDB). All the symptoms and variables needed to control diabetes will be stored at the base. This should allow a better examination of this disease by the doctor to make a correct diagnosis. The ease of creating web services using the iJmavpale mperongteradm mthianng wlainthg utahgee , AwPhI icJhA Xis- ROSb jefocrt ROErieSnTtfeudl,, whahsic hn ofta cbieliteante sb etttheer provision of business logic for the user, dividing the problem and reaching a high degree of performance\n"}
{"prompt":"Estudio de las propiedades antimicrobianas y antifúngicas de la miel de abeja (apis mellifera) como tratamiento de infecciones causadas clostridium perfringens, pseudomona aeruginosa, candida tropicalis y aspergillus brasiliensis ->","completion":" The honey of bees (Apis mellifera) has been used as a treatment for bacterial and even fungal infections, as well as a cheap alternative compared to traditional medicines. We search for this option due to the increased of microbial resistance in the recent years. The present study was conducted to establish the antimicrobial and antifungal capacity of single-flower honeys from ñachag, turnip and tropical flowers against Clostridium perfringens, Pseudomonas aeruginosa y Aspergillus brasiliensis. For this the ATCC strains of microorganisms of interest were inoculated in a solid medium, the next day the monofloral honeys were placed at different concentrations and proceeded to read data. According to the data, the three monofloral honeys, at all concentrations of 100%, 75%, 50%, 25% between 8 -72 hours of incubation, have an inhibitory effect on P. aeruginosa and C. perfringens, while showed no effect on growth inhibition of the fungus strain A. brasiliensis and C. tropicalis, at any concentration. The honey, on which showed greater inhibition zone, at concentrations of 100%, 50% and 25% (at 72 h) before the P. aeruginosa strain was ñachag honey; meanwhile the honey of tropical flowers at a concentration of 25%, showed the best inhibitory effects, differing significantly (p ≤ 0.05) compared with the rest of the honeys.La miel de abeja (Apis Melífera) ha sido utilizada como un tratamiento para infecciones bacterianas e inclusive fúngicas, además de ser una alternativa barata en relación a los medicamentos tradicionales. Se busca esta opción debido al incremento de resistencia microbiana en los últimos años. En el presente estudio se realizó con el objetivo establecer la capacidad antimicrobiana y antifúngica de mieles monoflorales de ñachag, nabo y flores tropicales ante Clostridium perfringens, Pseudomona aeruginosa, Aspergillus brasiliensis y Candida tropicalis. Para esto se inoculó las cepas ATCC de los microorganismos de interés, en un medio sólido, al día siguiente se colocaron las mieles monoflorales a diferentes concentraciones y se procedió a la lectura de datos. Según los datos obtenidos, las tres mieles monoflorales, en todas las concentraciones del 100%, 75%, 50%, 25%, entre las 8 -72 horas de incubación, presentan un efecto de inhibición sobre P. aeruginosa y C. perfringens, mientras que no mostraron ningún efecto de inhibición de crecimiento sobre la cepa del hongo A. brasiliensis y C. tropicalis, a ninguna concentración. La miel, que presentó mayor halo de inhibición, a las concentraciones del 100%, 50% y 25% (a las 72 h), ante la cepa de P. aeruginosa fue la miel de ñachag; mientras que la miel de flores tropicales a una concentración del 25 %, presentó los mejores efectos inhibitorios, difiriendo significativamente (p ≤ 0,05), en comparación con el resto de las mieles.\n"}
{"prompt":"Aplicación móvil para la georeferenciación de buses urbanos en la ciudad de Loja. ->","completion":" This thesis project is the analysis, design and implementation of a mobile application for georeferencing of urban buses in the city of Loja Android operating system, which is aimed at any type of user you want to interact with an application easily use with friendly and intuitive interfaces. One of the highlights of this work is the synchronization mechanism of two databases (one located on a remote server and the other on the mobile device), which allows the possibility of displaying information without internet connection. The methodology used to develop the application is mobile-d, which is an agile software methodology. Mobile-D is based on extreme programming (XP) for implementation, methodologies glass scalability and Unified Development Process RUP coverage lifecycle. Mobile-D consists of 5 phases such as: Exploration, Initialization, Production, Testing and System Stabilization. Using the methodology, procedures and techniques used for the development of the thesis project has allowed meet the objectives for the development of mobile application that allows visualization of urban buses from the city of Loja in real time.El presente proyecto de tesis consiste en el análisis, diseño e implementación de una aplicación móvil para la georreferenciación de buses urbanos en la ciudad de Loja para sistema operativo Android, la cual está encaminado a cualquier tipo de usuario que desee interactuar con un aplicativo de fácil uso, con interfaces amigables e intuitivas. Uno de los puntos a destacar del presente trabajo es el mecanismo de sincronización de dos bases de datos (una ubicada en un servidor remoto y la otra en el dispositivo móvil), el cual permite la posibilidad de visualizar información sin conexión a internet. La metodología utilizada para el desarrollo de la aplicación es Mobile-d, la cual es una metodología ágil de software. Mobile-D se basa en la programación extrema (XP) para la implementación, cristal methodologies para la escalabilidad y el Proceso Unificado de Desarrollo RUP para la cobertura del ciclo de vida. Mobile-D se compone de 5 fases como es: Exploración, Inicialización, Producción, Estabilización y Pruebas de Sistema. Con ayuda de la metodología, procedimientos y técnicas utilizadas para el desarrollo del proyecto de tesis ha permitido cumplir con los objetivos planteados para el desarrollo de la aplicación móvil que permite la visualización de buses urbanos de la ciudad de Loja en tiempo real\n"}
{"prompt":"Métodos de seguridad de la información para proteger la comunicación y los datos de servicios web REST en peticiones HTTP utilizando JSON web token y keycloak red hat single sign on ->","completion":" Actualmente los protocolos y estándares abiertos que se utilizan para intercambiar datos entre aplicaciones o sistemas son los servicios web. REST es la API de servicios de internet más utilizada debido a la lógica y facilidad para intercambiar datos sin embargo esta tecnología al utilizar el protocolo no seguro HTTP como medio de comunicación compromete la información que gestiona. Este artículo identifica alternativas de mitigación a las vulnerabilidades que surgen al utilizar web services REST sobre el protocolo HTTP, a través de una combinación de las tecnologías JSON Web Token y Keycloak Red Hat Single Sign On se formula métodos de seguridad de la información que permiten proteger la comunicación y los datos de servicios web REST en peticiones HTTP. Se exponen los resultados obtenidos al realizar pruebas con la solución planteada y se compara los hallazgos generados con artículos similares.\n"}
{"prompt":"Arquitectura de software para exponer datos abiertos de E-commerce aplicando metodología SCRUM y la Norma ISO \/ IEC 25023 en la Cámara Ecuatoriana de Comercio Electrónico. ->","completion":" El proceso de este trabajo investigativo consta de etapas secuenciales, que con llevarán al cumplimiento de los objetivos planteados. Para empezar el estudio se realiza como primera etapa el marco teórico, por medio de una investigación del estado del arte la cual permita establecer principios puntuales acerca de los envoltorios tecnológicos a partir de datos cuyo origen son API REST; igualmente establecer las ventajas del uso y manipulación con lenguaje de consultas GraphQL y el beneficio de esta herramienta como una alternativa al consumo de API REST. En esta investigación también se mencionan los servicios que brinda la Cámara Ecuatoriana de Comercio Electrónico para la consulta de datos abiertos en el Ecuador para los desarrolladores y cómo estos pueden ser consumidos por clientes. En la etapa de creación del producto, se construye un API GraphQL qué envuelve las funcionalidades del servicio del API REST aplicando la metodología ágil SCRUM. Se utiliza los datos abiertos de la Cámara Ecuatoriana de Comercio Electrónico, que es parte del Proyecto de investigación de e-commerce manejado por la Universidad Espíritu Santo. Para la comprobación de la funcionalidad del API desarrollada se realizan pruebas de aceptación con los interesados del proyecto, así para comprobar la eficiencia mediante el consumo óptimo de las respuestas de la API GraphQL (envoltorio) y la API REST, se consumen las dos tecnologías y verifica cuál es la mejor, utilizando métricas basadas en la ISO\/IEC 25023 en diferentes casos de usos específicos de consumos de datos de e-commerce, se utiliza un modelo o método estadístico para la comprobación de resultados que se adapte del envoltorio del API REST generado con GraphQL, obteniendo como resultado un API GraphQL (backend) y de un cliente (frontend) llegando a la conclusión que se puede optimizar el tiempo y el desempeño al consumir los datos por parte de los usuarios al usar este tipo de tecnología.ESPEL\n"}
{"prompt":"Desarrollo de un MASHUP comercial para la publicación y búsqueda de bienes inmuebles en quito integrando distintas APIS públicas y proveyendo de las interfaces necesarias para que sea consumido desde cualquier tipo de aplicación informática ->","completion":" Actualmente en Quito la búsqueda de bienes inmuebles en medios impresos o en páginas web ha sido un tanto limitada, dado que además de los datos propios del bien se necesita observar información adicional que confiera una idea del contexto en el que está situado el mismo, así, se ha visto la oportunidad de crear un MASHUP, que es un aplicación web hibrida donde se puedan integrar distintas APIs públicas como son Facebook, Flickr, Google Maps y YouTube; además la creación de una API pública propia donde se exponen los servicios e información para que se pueda ocupar desde otras aplicaciones. Al estudiar la creación de MASHUPs se observó que en la construcción de este tipo de aplicaciones es conveniente utilizar una metodología de desarrollo ágil la cual permite realizar prototipos rápidamente que son entregados al usuario final para su revisión y retroalimentación, con esto se mejora al sistema de una manera iterativa. Para lograr este objetivo se estudió la metodología de Programación Extrema que cubre las necesidades de la aplicación. En cuanto a la tecnología se investigó arquitecturas como REST y SOA que son orientadas a servicios, de las cuales se seleccionó REST debido a que está orientado a recursos y a sistemas distribuidos de hipermedia como lo es WWW así como por ser la más usada para la generación de APIs públicas.\n"}
{"prompt":"Desarrollo de una aplicación móvil colaborativa para brindar y solicitar ayuda en áreas académicas destinada a los Estudiantes de la Carrera de Ingeniería en Sistemas Computacionales de la Universidad de Guayaquil. ->","completion":" PDFEl presente trabajo de titulación tiene como propósito desarrollar una aplicación móvil usando el sistema operativo Android en la que se pueden ofrecer y solicitar ayudantías académicas entre estudiantes. Así mismo se tiene un foro académico que permite a los estudiantes intercambiar conocimiento de manera colaborativa; para efectuar el intercambio de información entre la aplicación y un servidor en el que se almacenarán los datos, se hará uso de una API de tipo REST. En el sistema, los estudiantes de la Carrera de Ingeniería en Sistemas Computacionales de la Universidad de Guayaquil contribuyen mutuamente aportando con sus saberes relativos a su etapa de estudio en un medio que permite la retroalimentación con afinidad estudiantil. El desarrollo del sistema se realizó empleando las etapas de la metodología Extreme Programing (XP), que ofrece ventajas para proyectos con un pequeño grupo de desarrolladores, duración en el corto plazo y flexibilidad en el desarrollo. Con el desarrollo del prototipo “UG Ants”, se obtuvo una plataforma tecnológica que ofrece la oportunidad de brindar y solicitar ayuda en aspectos académicos entre los miembros de la comunidad de estudiantes de la carrera, haciendo uso de un módulo de ayudantías y de un foro para fomentar el aprendizaje fuera de las horas de clase.The purpose of this degree work is to develop a mobile application for the Android operating system in which you can offer and request academic assistantships among students. Likewise, there is an academic forum that allows students to exchange knowledge in a collaborative manner; to carry out the exchange of information between the application and a server where the data will be stored, an API of type REST will be used. In the system, the students of the Computer Systems Engineering Career of the University of Guayaquil contribute with their knowledge related to their stage of study in an environment that allows feedback with student affinity. The development of the system was made using the stages of the Extreme Programming (XP) methodology, which offers advantages for projects with a small group of developers, duration in the short term and flexibility in the development. With the development of the \"UG Ants\" prototype, was obtained a technological platform that provides the opportunity to offer and request help in academic aspects among the members of the community of students of the career, making use of an assistantship module and a forum to promote learning outside of class hours.\n"}
{"prompt":"Desarrollo e implementación de aplicativo móvil para el proceso de despacho de los productos de la empresa “Fábrica de envases Fadesa S.A” sector metálico. ->","completion":" El presente proyecto tiene como finalidad el automatizar el registro de despachos de los productos terminados que se realiza en las bodegas Producto Terminado y El Universo en la empresa “Fábrica de envases Fadesa S.A”, donde el objetivo principal es desarrollar e implementar un aplicativo móvil para el control efectivo y oportuno. Para la creación de la aplicación móvil se utilizó el entorno de desarrollo Android Studio basado en la codificación Java, permitiendo el uso de extracción, Api Zebra, biblioteca que integra una serie de elementos para la manipulación del lector QR del dispositivo Hand Hell MC3300 – Zebra; con respecto al tipo de comunicación usada para la inserción y consulta de la data emitida por el dispositivo tecnológico, se optó por la creación de un servicio web tipo RestFul, recurso que es almacenado del lado del servidor para que un cliente realice el consumo. Por consiguiente, este tipo de comunicación fue desarrollado debido a que se utilizó las herramientas Xampp y Php. Para el control de la información se instanció un fichero Excel donde se realiza la conexión con la base de datos de la empresa y por lo consiguiente se creó una tabla dinámica con la data obtenida. Referente al tipo de investigación que se necesitó para el proyecto, se requirió el exploratorio, investigación aplicada y de campo, utilizando como entrevista como técnica para el levantamiento, recolección de información, la misma que fue dada a seis personas de diferentes departamentos de la empresa Fadesa. Haciendo énfasis al levantamiento de datos en las bodegas Producto Terminado y El Universo, se conoció el proceso de registro de despachos de los productos terminados reconociendo la necesidad de automatización. Después de la implementación de la aplicación móvil en el dispositivo tecnológico, se pudo constatar la optimización en el proceso de registro de despachos de los productos terminados, generando un mayor control, efectividad en la información y tiempo de operación.The purpose of this project is to automate the registration of shipments of finished products that is carried out in the Product Finished and El Universo wineries in the company \"Fábrica de Excelencia Fadesa SA\", where the main objective is to develop and implement a mobile application for effective and timely control. The Android Studio development environment based on Java coding was used to create the mobile application, allowing the use of extraction, Api Zebra, a library that integrates a series of elements for manipulating the QR reader of the Hand Hell MC3300 device - Zebra ; Regarding the type of communication used for the insertion and consultation of the data issued by the technological device, it was decided to create a RestFul-type web service, a resource that is stored on the server side for a client to consume. Therefore, this type of communication was developed due to the use of the Xampp and Php tools. To control the information, an Excel file was created where the connection with the company's database is made, and therefore a dynamic table was created with the data obtained. Regarding the type of research that was needed for the project, the exploratory, applied and field research was required, using as an interview as a technique for raising, collecting information, the same that was given to six people from different departments of the company Fadesa. Emphasizing the data collection in the Product Finished and El Universo warehouses, the process of registering shipments of finished products was known, recognizing the need for automation. After the implementation of the mobile application in the technological device, it was possible to verify the optimization in the process of registration of shipments of finished products, generating greater control, effectiveness in information and operating time.\n"}
